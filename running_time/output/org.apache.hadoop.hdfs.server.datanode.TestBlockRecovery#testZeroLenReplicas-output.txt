2020-12-03 07:22:47,956 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:47,968 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:47,990 [main] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is cf1f280bf45f
2020-12-03 07:22:47,991 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:47,996 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:48,137 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /0.0.0.0:37602
2020-12-03 07:22:48,142 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:48,143 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:48,236 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,257 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2482ms
2020-12-03 07:22:48,434 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,439 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:48,440 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,457 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,461 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:48,462 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,464 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,510 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38996
2020-12-03 07:22:48,513 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:48,598 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b695b06{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:48,600 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f53b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:48,649 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@776a6d9b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:48,662 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1169afe1{HTTP/1.1,[http/1.1]}{localhost:38996}
2020-12-03 07:22:48,663 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2887ms
2020-12-03 07:22:49,305 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /0.0.0.0:43256
2020-12-03 07:22:49,315 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1046d517] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:49,331 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:49,332 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:49,378 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:49,399 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:49,434 [Listener at 0.0.0.0/41005] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /0.0.0.0:41005
2020-12-03 07:22:49,455 [Listener at 0.0.0.0/41005] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:49,469 [Listener at 0.0.0.0/41005] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:49,482 [Thread-13] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:5020 starting to offer service
2020-12-03 07:22:49,498 [Thread-13] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:22:49,537 [Thread-13] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/in_use.lock acquired by nodename 7044@cf1f280bf45f
2020-12-03 07:22:49,538 [Thread-13] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data is not formatted for namespace 1. Formatting...
2020-12-03 07:22:49,540 [Thread-13] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0fc1a87f-a93c-4264-a301-7f1c13143f1f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data 
2020-12-03 07:22:49,719 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-TEST
2020-12-03 07:22:49,720 [Thread-13] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST
2020-12-03 07:22:49,720 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data and block pool id BP-TEST is not formatted. Formatting ...
2020-12-03 07:22:49,721 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-TEST directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current
2020-12-03 07:22:49,788 [Thread-13] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1;bpid=BP-TEST;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1;c=1;bpid=BP-TEST;dnuuid=null
2020-12-03 07:22:49,830 [Thread-13] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a6ce9720-e689-4bde-a753-a3f37919ede5
2020-12-03 07:22:50,196 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0fc1a87f-a93c-4264-a301-7f1c13143f1f
2020-12-03 07:22:50,197 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, StorageType: DISK
2020-12-03 07:22:50,201 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:50,207 [Thread-13] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:50,241 [Thread-13] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:50,244 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-TEST
2020-12-03 07:22:50,245 [Thread-18] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data...
2020-12-03 07:22:50,293 [Thread-18] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-TEST on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data: 47ms
2020-12-03 07:22:50,294 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-TEST: 50ms
2020-12-03 07:22:50,298 [Thread-20] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data...
2020-12-03 07:22:50,298 [Thread-20] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/replicas doesn't exist 
2020-12-03 07:22:50,300 [Thread-20] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data: 2ms
2020-12-03 07:22:50,301 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-TEST: 4ms
2020-12-03 07:22:50,307 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:50,309 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-0fc1a87f-a93c-4264-a301-7f1c13143f1f): finished scanning block pool BP-TEST
2020-12-03 07:22:50,349 [Thread-13] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:03 PM with interval of 21600000ms
2020-12-03 07:22:50,358 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5) service to localhost/127.0.0.1:5020 beginning handshake with NN
2020-12-03 07:22:50,360 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5) service to localhost/127.0.0.1:5020 successfully registered with NN
2020-12-03 07:22:50,361 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:5020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:50,365 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5) service to localhost/127.0.0.1:5020 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:50,365 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5) service to localhost/127.0.0.1:5020
2020-12-03 07:22:50,368 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-0fc1a87f-a93c-4264-a301-7f1c13143f1f): no suitable block pools found to scan.  Waiting 1814399938 ms.
2020-12-03 07:22:50,378 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9570fd46e9d6ad45,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 1 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:50,649 [Thread-24] DEBUG datanode.TestBlockRecovery (TestBlockRecovery.java:testZeroLenReplicas(598)) - Running testZeroLenReplicas
2020-12-03 07:22:50,897 [Thread-24] WARN  protocol.InterDatanodeProtocol (BlockRecoveryWorker.java:recover(169)) - Failed to recover block (block=BP-TEST:blk_1000_2000, datanode=DatanodeInfoWithStorage[127.0.0.1:9866,null,null])
java.net.ConnectException: Call From cf1f280bf45f/172.17.0.11 to localhost:9867 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy24.initReplicaRecovery(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.InterDatanodeProtocolTranslatorPB.initReplicaRecovery(InterDatanodeProtocolTranslatorPB.java:83)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker.callInitReplicaRecovery(BlockRecoveryWorker.java:565)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker.access$400(BlockRecoveryWorker.java:57)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.recover(BlockRecoveryWorker.java:134)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous$$EnhancerByMockitoWithCGLIB$$76caa271.CGLIB$recover$1(<generated>)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous$$EnhancerByMockitoWithCGLIB$$76caa271$$FastClassByMockitoWithCGLIB$$88288413.invoke(<generated>)
	at org.mockito.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:216)
	at org.mockito.internal.creation.AbstractMockitoMethodProxy.invokeSuper(AbstractMockitoMethodProxy.java:10)
	at org.mockito.internal.invocation.realmethod.CGLIBProxyRealMethod.invoke(CGLIBProxyRealMethod.java:22)
	at org.mockito.internal.invocation.realmethod.FilteredCGLIBProxyRealMethod.invoke(FilteredCGLIBProxyRealMethod.java:27)
	at org.mockito.internal.invocation.Invocation.callRealMethod(Invocation.java:211)
	at org.mockito.internal.stubbing.answers.CallsRealMethods.answer(CallsRealMethods.java:36)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:99)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous$$EnhancerByMockitoWithCGLIB$$76caa271.recover(<generated>)
	at org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testZeroLenReplicas(TestBlockRecovery.java:609)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 29 more
2020-12-03 07:22:50,903 [Thread-24] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-TEST:blk_1000_2000 (length=3000), isTruncateRecovery=false, syncList=[]
2020-12-03 07:22:50,913 [Listener at 0.0.0.0/41005] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:50,915 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-0fc1a87f-a93c-4264-a301-7f1c13143f1f) exiting.
2020-12-03 07:22:50,960 [Listener at 0.0.0.0/41005] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@776a6d9b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:50,967 [Listener at 0.0.0.0/41005] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1169afe1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:50,967 [Listener at 0.0.0.0/41005] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f53b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:50,968 [Listener at 0.0.0.0/41005] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b695b06{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:50,973 [Listener at 0.0.0.0/41005] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41005
2020-12-03 07:22:50,974 [BP-TEST heartbeating to localhost/127.0.0.1:5020] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:50,974 [BP-TEST heartbeating to localhost/127.0.0.1:5020] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5) service to localhost/127.0.0.1:5020
2020-12-03 07:22:50,975 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-TEST (Datanode Uuid a6ce9720-e689-4bde-a753-a3f37919ede5)
2020-12-03 07:22:50,975 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-TEST
2020-12-03 07:22:50,976 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:50,978 [Listener at 0.0.0.0/41005] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:50,978 [Listener at 0.0.0.0/41005] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:50,979 [Listener at 0.0.0.0/41005] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:50,979 [Listener at 0.0.0.0/41005] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:50,987 [Listener at 0.0.0.0/41005] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
msx-rc 0
