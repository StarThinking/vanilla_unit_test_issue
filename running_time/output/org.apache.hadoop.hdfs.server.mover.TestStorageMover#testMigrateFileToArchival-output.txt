2020-12-03 07:21:45,074 [main] INFO  mover.TestStorageMover (TestStorageMover.java:testMigrateFileToArchival(476)) - testMigrateFileToArchival
2020-12-03 07:21:45,145 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=6
Formatting using clusterid: testClusterID
2020-12-03 07:21:45,972 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:45,987 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:45,988 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:45,989 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:45,999 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:46,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:46,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:46,001 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:46,042 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:46,047 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:21:46,048 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:46,048 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:46,049 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:46,049 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:46,059 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:46,060 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:46
2020-12-03 07:21:46,062 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:46,063 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:46,065 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:21:46,066 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:46,083 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:46,084 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:46,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:46,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:46,088 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:46,088 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:46,093 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:46,094 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:46,094 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:46,094 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:46,095 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:46,095 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:46,096 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:46,096 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:46,096 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:46,096 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:46,097 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:46,134 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:21:46,135 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:46,135 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:46,135 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:46,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:46,151 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:46,151 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:21:46,152 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:46,158 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:46,158 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:46,159 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:46,159 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:46,165 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:46,171 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:46,179 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:46,179 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:46,180 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:21:46,180 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:46,193 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:46,193 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:46,193 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:46,199 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:46,199 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:46,202 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:46,203 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:46,203 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:21:46,203 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:46,239 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:46,340 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:21:46,417 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:21:46,454 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:46,454 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:46,609 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:46,609 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:46,998 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:47,001 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:47,112 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:47,415 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:47,416 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:47,453 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:47,506 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de76cc7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:47,524 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:47,530 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:47,544 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3581ms
2020-12-03 07:21:47,671 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:47,675 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:47,676 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:47,685 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:47,688 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:47,688 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:47,689 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:47,719 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:47,720 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:47,730 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36794
2020-12-03 07:21:47,732 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:47,778 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:47,779 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:47,821 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a3793c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:47,832 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:36794}
2020-12-03 07:21:47,833 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3870ms
2020-12-03 07:21:47,849 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:47,851 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:47,852 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:47,852 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:47,853 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:47,854 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:47,854 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:47,855 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:47,858 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:47,859 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,859 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:47,860 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:47,860 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,861 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:47,862 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:47
2020-12-03 07:21:47,862 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:47,863 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,863 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:47,864 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:47,869 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,870 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,871 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:47,871 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:47,872 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:47,872 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,873 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:47,873 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:47,874 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:47,874 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:47,874 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:47,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:47,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:47,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:47,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:47,876 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:47,876 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:47,877 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:47,877 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,878 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:47,878 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:47,893 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:47,894 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:47,894 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:47,895 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:47,895 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:47,896 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:47,896 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:47,896 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,897 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:47,897 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:47,899 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:47,901 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:47,901 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:47,901 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:47,902 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:47,902 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:47,902 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,903 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:47,903 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:47,974 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:48,093 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:48,097 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:48,097 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:48,098 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:48,099 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:48,128 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:48,136 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:48,136 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:48,141 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:48,142 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:48,338 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:48,339 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 432 msecs
2020-12-03 07:21:48,544 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:48,592 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:48,610 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:48,904 [Listener at localhost/38854] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38854 to access this namenode/service.
2020-12-03 07:21:48,907 [Listener at localhost/38854] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:48,930 [Listener at localhost/38854] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:48,942 [Listener at localhost/38854] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:48,943 [Listener at localhost/38854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:48,943 [Listener at localhost/38854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:48,943 [Listener at localhost/38854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:48,947 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:48,947 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:48,947 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:48,947 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:48,947 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:48,948 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:21:48,973 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:48,974 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:48,977 [Listener at localhost/38854] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38854
2020-12-03 07:21:48,980 [Listener at localhost/38854] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:48,980 [Listener at localhost/38854] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:48,988 [Listener at localhost/38854] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:48,993 [CacheReplicationMonitor(392208129)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:48,997 [Listener at localhost/38854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:49,066 [Listener at localhost/38854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:49,082 [Listener at localhost/38854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:49,101 [Listener at localhost/38854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,106 [Listener at localhost/38854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,108 [Listener at localhost/38854] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,113 [Listener at localhost/38854] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,114 [Listener at localhost/38854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,114 [Listener at localhost/38854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,114 [Listener at localhost/38854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,119 [Listener at localhost/38854] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,125 [Listener at localhost/38854] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42231
2020-12-03 07:21:49,127 [Listener at localhost/38854] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,128 [Listener at localhost/38854] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,147 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,149 [Listener at localhost/38854] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,150 [Listener at localhost/38854] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,150 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,152 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,153 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,156 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,156 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,161 [Listener at localhost/38854] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34747
2020-12-03 07:21:49,161 [Listener at localhost/38854] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,163 [Listener at localhost/38854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,164 [Listener at localhost/38854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,173 [Listener at localhost/38854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61526469{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,177 [Listener at localhost/38854] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:34747}
2020-12-03 07:21:49,177 [Listener at localhost/38854] INFO  server.Server (Server.java:doStart(419)) - Started @5215ms
2020-12-03 07:21:49,632 [Listener at localhost/38854] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42498
2020-12-03 07:21:49,633 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@200a26bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,635 [Listener at localhost/38854] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,635 [Listener at localhost/38854] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,893 [Listener at localhost/38854] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,896 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,931 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39738
2020-12-03 07:21:49,960 [Listener at localhost/39738] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,965 [Listener at localhost/39738] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,002 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,015 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,015 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,020 [Listener at localhost/39738] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:50,024 [Listener at localhost/39738] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:50,024 [Listener at localhost/39738] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:50,028 [Listener at localhost/39738] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:50,028 [Listener at localhost/39738] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,029 [Listener at localhost/39738] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:50,029 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:50,030 [Listener at localhost/39738] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,030 [Listener at localhost/39738] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,030 [Listener at localhost/39738] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,031 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:50,032 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45731
2020-12-03 07:21:50,032 [Listener at localhost/39738] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:50,033 [Listener at localhost/39738] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:50,035 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,039 [Listener at localhost/39738] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:50,041 [Listener at localhost/39738] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:50,041 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,045 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:50,046 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:50,047 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:50,047 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:50,050 [Listener at localhost/39738] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45773
2020-12-03 07:21:50,050 [Listener at localhost/39738] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:50,054 [Listener at localhost/39738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:50,055 [Listener at localhost/39738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,091 [Listener at localhost/39738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29ad44e3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:50,093 [Listener at localhost/39738] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:45773}
2020-12-03 07:21:50,102 [Listener at localhost/39738] INFO  server.Server (Server.java:doStart(419)) - Started @6139ms
2020-12-03 07:21:50,173 [Listener at localhost/39738] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41892
2020-12-03 07:21:50,174 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43c67247] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:50,174 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:50,174 [Listener at localhost/39738] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:50,175 [Listener at localhost/39738] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:50,176 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:50,187 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36542
2020-12-03 07:21:50,193 [Listener at localhost/36542] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:50,193 [Listener at localhost/36542] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,194 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,196 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,196 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,203 [Listener at localhost/36542] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:50,206 [Listener at localhost/36542] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:50,208 [Listener at localhost/36542] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:50,211 [Listener at localhost/36542] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:50,212 [Listener at localhost/36542] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,212 [Listener at localhost/36542] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:50,213 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:50,213 [Listener at localhost/36542] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,213 [Listener at localhost/36542] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,213 [Listener at localhost/36542] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,213 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:50,214 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33979
2020-12-03 07:21:50,215 [Listener at localhost/36542] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:50,215 [Listener at localhost/36542] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:50,216 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,218 [Listener at localhost/36542] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:50,219 [Listener at localhost/36542] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:50,219 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,222 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:50,223 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:50,223 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:50,223 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:50,224 [Listener at localhost/36542] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45668
2020-12-03 07:21:50,224 [Listener at localhost/36542] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:50,228 [Listener at localhost/36542] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:50,229 [Listener at localhost/36542] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,238 [Listener at localhost/36542] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d4d3fe7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:50,239 [Listener at localhost/36542] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:45668}
2020-12-03 07:21:50,239 [Listener at localhost/36542] INFO  server.Server (Server.java:doStart(419)) - Started @6277ms
2020-12-03 07:21:50,265 [Listener at localhost/36542] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45955
2020-12-03 07:21:50,266 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:50,266 [Listener at localhost/36542] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:50,267 [Listener at localhost/36542] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:50,268 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ce1f601] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:50,268 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:50,273 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44431
2020-12-03 07:21:50,281 [Listener at localhost/44431] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:50,282 [Listener at localhost/44431] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,282 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,285 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,286 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,289 [Listener at localhost/44431] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:50,291 [Listener at localhost/44431] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:50,292 [Listener at localhost/44431] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:50,294 [Listener at localhost/44431] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:50,295 [Listener at localhost/44431] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,295 [Listener at localhost/44431] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:50,295 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:50,296 [Listener at localhost/44431] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,296 [Listener at localhost/44431] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,296 [Listener at localhost/44431] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,297 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:50,300 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33329
2020-12-03 07:21:50,301 [Listener at localhost/44431] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:50,301 [Listener at localhost/44431] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:50,342 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,344 [Listener at localhost/44431] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:50,345 [Listener at localhost/44431] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:50,345 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,348 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:50,349 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:50,349 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:50,349 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:50,350 [Listener at localhost/44431] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39914
2020-12-03 07:21:50,351 [Listener at localhost/44431] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:50,354 [Listener at localhost/44431] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:50,355 [Listener at localhost/44431] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,363 [Listener at localhost/44431] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37d3d232{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:50,365 [Listener at localhost/44431] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:39914}
2020-12-03 07:21:50,365 [Listener at localhost/44431] INFO  server.Server (Server.java:doStart(419)) - Started @6403ms
2020-12-03 07:21:50,470 [Listener at localhost/44431] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34610
2020-12-03 07:21:50,471 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22db8f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:50,471 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:50,471 [Listener at localhost/44431] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:50,472 [Listener at localhost/44431] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:50,473 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:50,483 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40956
2020-12-03 07:21:50,488 [Listener at localhost/40956] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:50,489 [Listener at localhost/40956] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,489 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,491 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,492 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,495 [Listener at localhost/40956] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:50,497 [Listener at localhost/40956] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:50,497 [Listener at localhost/40956] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:50,507 [Listener at localhost/40956] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:50,507 [Listener at localhost/40956] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,508 [Listener at localhost/40956] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:50,508 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:50,509 [Listener at localhost/40956] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,509 [Listener at localhost/40956] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,509 [Listener at localhost/40956] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,510 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:50,511 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39540
2020-12-03 07:21:50,511 [Listener at localhost/40956] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:50,511 [Listener at localhost/40956] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:50,512 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,535 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,557 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,559 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,562 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,561 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,561 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,560 [Listener at localhost/40956] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:50,564 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,564 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,564 [Listener at localhost/40956] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:50,565 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,568 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:50,571 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:50,571 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:50,571 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:50,572 [Listener at localhost/40956] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45304
2020-12-03 07:21:50,572 [Listener at localhost/40956] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:50,576 [Listener at localhost/40956] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:50,576 [Listener at localhost/40956] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,585 [Listener at localhost/40956] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bc53649{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:50,586 [Listener at localhost/40956] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:45304}
2020-12-03 07:21:50,587 [Listener at localhost/40956] INFO  server.Server (Server.java:doStart(419)) - Started @6625ms
2020-12-03 07:21:50,603 [Listener at localhost/40956] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34014
2020-12-03 07:21:50,603 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:50,603 [Listener at localhost/40956] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:50,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@475b7792] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:50,604 [Listener at localhost/40956] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:50,605 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:50,608 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34983
2020-12-03 07:21:50,612 [Listener at localhost/34983] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:50,613 [Listener at localhost/34983] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,613 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,615 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,615 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,620 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,621 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,622 [Listener at localhost/34983] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:50,623 [Listener at localhost/34983] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:50,624 [Listener at localhost/34983] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:50,625 [Listener at localhost/34983] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:50,626 [Listener at localhost/34983] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,626 [Listener at localhost/34983] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:50,626 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:50,626 [Listener at localhost/34983] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,627 [Listener at localhost/34983] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,627 [Listener at localhost/34983] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,627 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:50,628 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35266
2020-12-03 07:21:50,628 [Listener at localhost/34983] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:50,628 [Listener at localhost/34983] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:50,629 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,631 [Listener at localhost/34983] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:50,632 [Listener at localhost/34983] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:50,632 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:50,634 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:50,635 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:50,635 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:50,635 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:50,636 [Listener at localhost/34983] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40865
2020-12-03 07:21:50,636 [Listener at localhost/34983] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:50,638 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,638 [Listener at localhost/34983] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:50,638 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,638 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,638 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,639 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,639 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,639 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,639 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,638 [Listener at localhost/34983] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,641 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:50,641 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:21:50,642 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6aba9027-eb8e-409e-aae1-00bca57939fa for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:50,643 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:50,645 [Listener at localhost/34983] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a23a01d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:50,647 [Listener at localhost/34983] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:40865}
2020-12-03 07:21:50,647 [Listener at localhost/34983] INFO  server.Server (Server.java:doStart(419)) - Started @6684ms
2020-12-03 07:21:50,661 [Listener at localhost/34983] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35180
2020-12-03 07:21:50,662 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:50,662 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3301500b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:50,662 [Listener at localhost/34983] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:50,662 [Listener at localhost/34983] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:50,663 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:50,666 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46869
2020-12-03 07:21:50,671 [Listener at localhost/46869] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:50,672 [Listener at localhost/46869] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:50,673 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854 starting to offer service
2020-12-03 07:21:50,674 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:50,674 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:50,679 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38854
2020-12-03 07:21:50,679 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:50,758 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,759 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,761 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0b79796c-92a6-4041-b124-487655e159e8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:21:50,843 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:50,843 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:50,844 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-67d43213-2051-4db1-bb58-b3bee09c60c9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:21:51,118 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,118 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,118 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,119 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,119 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:51,118 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,119 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,118 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,121 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d605f99a-cc80-400e-b796-fb43014c99cd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:51,121 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:21:51,121 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,124 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:51,172 [IPC Server handler 3 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,182 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,182 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,214 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,214 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,217 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-42a1aae5-3a99-4c4c-b138-e2811361d2de for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:21:51,285 [IPC Server handler 0 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,287 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,287 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,316 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5889@b120fe239ee9
2020-12-03 07:21:51,316 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1272315793. Formatting...
2020-12-03 07:21:51,317 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:21:51,389 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,390 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,390 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,468 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,468 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,468 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,468 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,469 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,468 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,469 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,469 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,469 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,470 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,469 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,470 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,470 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,471 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,471 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,471 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,493 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,494 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,494 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,551 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,551 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,552 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,552 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,596 [IPC Server handler 8 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,597 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,597 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,613 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,614 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:51,614 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:51,614 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:51,700 [IPC Server handler 1 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,700 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,701 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,803 [IPC Server handler 9 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,804 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,804 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,906 [IPC Server handler 6 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,907 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,907 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,009 [IPC Server handler 3 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,010 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,011 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,113 [IPC Server handler 0 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,114 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,115 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,217 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,218 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,218 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,227 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,227 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,227 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,227 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,229 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,229 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,229 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,229 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,229 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,229 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,230 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,230 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,230 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,230 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,230 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,230 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,320 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,321 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,321 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,347 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,348 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,348 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,348 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,423 [IPC Server handler 8 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,424 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,424 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,447 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,448 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:52,448 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1629078178-172.17.0.8-1606980106227 is not formatted. Formatting ...
2020-12-03 07:21:52,448 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1629078178-172.17.0.8-1606980106227 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1629078178-172.17.0.8-1606980106227/current
2020-12-03 07:21:52,530 [IPC Server handler 7 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,531 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,532 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,610 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,610 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,610 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,610 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,635 [IPC Server handler 1 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,636 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,636 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,665 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,740 [IPC Server handler 9 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,740 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,741 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,786 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1272315793;bpid=BP-1629078178-172.17.0.8-1606980106227;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1272315793;c=1606980106227;bpid=BP-1629078178-172.17.0.8-1606980106227;dnuuid=null
2020-12-03 07:21:52,843 [IPC Server handler 6 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,844 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,844 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,948 [IPC Server handler 2 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:52,948 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:52,949 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:52,960 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ec0094e0-560a-4031-81df-ada112d08205
2020-12-03 07:21:52,960 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5acb39eb-5728-4202-8118-3ee3263f83b8
2020-12-03 07:21:52,961 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e8a203d1-0819-4572-aa20-1d3c1baf7085
2020-12-03 07:21:52,961 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6
2020-12-03 07:21:53,050 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b0096ae2-cc7b-4df7-9b03-27070a28f7f3
2020-12-03 07:21:53,051 [IPC Server handler 0 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,052 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:53,053 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:53,092 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2
2020-12-03 07:21:53,092 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:53,093 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0b79796c-92a6-4041-b124-487655e159e8
2020-12-03 07:21:53,094 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-797d4d2d-e4ee-4c91-895f-c249c9f58349
2020-12-03 07:21:53,095 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b
2020-12-03 07:21:53,095 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:21:53,094 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6aba9027-eb8e-409e-aae1-00bca57939fa
2020-12-03 07:21:53,093 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97
2020-12-03 07:21:53,096 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:53,096 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:53,095 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:53,096 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:53,098 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-42a1aae5-3a99-4c4c-b138-e2811361d2de
2020-12-03 07:21:53,098 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: ARCHIVE
2020-12-03 07:21:53,099 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727
2020-12-03 07:21:53,100 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:53,101 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d605f99a-cc80-400e-b796-fb43014c99cd
2020-12-03 07:21:53,102 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: ARCHIVE
2020-12-03 07:21:53,103 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44
2020-12-03 07:21:53,104 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,104 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,104 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,104 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,105 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: ARCHIVE
2020-12-03 07:21:53,108 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,112 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:53,113 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:53,114 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:53,115 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:53,116 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:53,122 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:53,123 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:53,126 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:53,126 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:53,126 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:53,127 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:53,126 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:53,128 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,129 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:53,126 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:53,126 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:53,130 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:53,130 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:53,130 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:53,129 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:53,129 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:53,127 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:53,131 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,132 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,131 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:53,133 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,133 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:53,133 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:53,135 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:53,137 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:53,137 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:53,137 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,138 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:53,138 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:53,139 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:53,147 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID cbfee30d-4220-4633-9768-a706de590b0e
2020-12-03 07:21:53,151 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-67d43213-2051-4db1-bb58-b3bee09c60c9
2020-12-03 07:21:53,152 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:21:53,154 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3
2020-12-03 07:21:53,155 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: ARCHIVE
2020-12-03 07:21:53,156 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:53,158 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:53,166 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:53,166 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,166 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:53,167 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:53,167 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:53,167 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:53,167 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,168 [Thread-208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:53,169 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:53,219 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 88ms
2020-12-03 07:21:53,224 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 85ms
2020-12-03 07:21:53,226 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 87ms
2020-12-03 07:21:53,228 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 90ms
2020-12-03 07:21:53,228 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 90ms
2020-12-03 07:21:53,229 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 96ms
2020-12-03 07:21:53,229 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 91ms
2020-12-03 07:21:53,229 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 97ms
2020-12-03 07:21:53,230 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 97ms
2020-12-03 07:21:53,231 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 61ms
2020-12-03 07:21:53,231 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 95ms
2020-12-03 07:21:53,232 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 99ms
2020-12-03 07:21:53,232 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:53,232 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:53,232 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:53,232 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:53,237 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:53,237 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:53,233 [Thread-223] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,232 [Thread-224] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,232 [Thread-222] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,237 [Thread-226] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,237 [Thread-225] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,237 [Thread-221] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,239 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-12-03 07:21:53,239 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 110ms
2020-12-03 07:21:53,240 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 112ms
2020-12-03 07:21:53,240 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 8ms
2020-12-03 07:21:53,240 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:21:53,240 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:21:53,240 [Thread-208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 72ms
2020-12-03 07:21:53,240 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1629078178-172.17.0.8-1606980106227 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 102ms
2020-12-03 07:21:53,242 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 74ms
2020-12-03 07:21:53,241 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 11ms
2020-12-03 07:21:53,242 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 10ms
2020-12-03 07:21:53,242 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:53,242 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 5ms
2020-12-03 07:21:53,242 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1629078178-172.17.0.8-1606980106227: 110ms
2020-12-03 07:21:53,242 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 10ms
2020-12-03 07:21:53,242 [Thread-227] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,243 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:53,242 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 12ms
2020-12-03 07:21:53,243 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:21:53,242 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:53,243 [Thread-231] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,243 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:53,242 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:53,242 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:53,244 [Thread-229] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,244 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:21:53,244 [Thread-228] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,244 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:21:53,244 [Thread-232] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,244 [Thread-230] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1629078178-172.17.0.8-1606980106227/current/replicas doesn't exist 
2020-12-03 07:21:53,245 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:53,245 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:53,245 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:53,246 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 2ms
2020-12-03 07:21:53,246 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 4ms
2020-12-03 07:21:53,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:53,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:53,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:53,247 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 3ms
2020-12-03 07:21:53,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:53,247 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 7ms
2020-12-03 07:21:53,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:53,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6aba9027-eb8e-409e-aae1-00bca57939fa): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-797d4d2d-e4ee-4c91-895f-c249c9f58349): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-67d43213-2051-4db1-bb58-b3bee09c60c9): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,251 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-42a1aae5-3a99-4c4c-b138-e2811361d2de): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,251 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 8ms
2020-12-03 07:21:53,253 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1629078178-172.17.0.8-1606980106227: 11ms
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-0b79796c-92a6-4041-b124-487655e159e8): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:53,253 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d605f99a-cc80-400e-b796-fb43014c99cd): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1629078178-172.17.0.8-1606980106227 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:53,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b): finished scanning block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,274 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,275 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:53,276 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:53,275 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:04 AM with interval of 21600000ms
2020-12-03 07:21:53,276 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:38 AM with interval of 21600000ms
2020-12-03 07:21:53,279 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:19 AM with interval of 21600000ms
2020-12-03 07:21:53,280 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:41 PM with interval of 21600000ms
2020-12-03 07:21:53,279 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:17 AM with interval of 21600000ms
2020-12-03 07:21:53,280 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:09 PM with interval of 21600000ms
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-67d43213-2051-4db1-bb58-b3bee09c60c9): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-0b79796c-92a6-4041-b124-487655e159e8): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-797d4d2d-e4ee-4c91-895f-c249c9f58349): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-42a1aae5-3a99-4c4c-b138-e2811361d2de): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d605f99a-cc80-400e-b796-fb43014c99cd): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:21:53,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6aba9027-eb8e-409e-aae1-00bca57939fa): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid e8a203d1-0819-4572-aa20-1d3c1baf7085) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid ec0094e0-560a-4031-81df-ada112d08205) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 5acb39eb-5728-4202-8118-3ee3263f83b8) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid b0096ae2-cc7b-4df7-9b03-27070a28f7f3) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid cbfee30d-4220-4633-9768-a706de590b0e) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,290 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6) service to localhost/127.0.0.1:38854 beginning handshake with NN
2020-12-03 07:21:53,304 [IPC Server handler 9 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage 5acb39eb-5728-4202-8118-3ee3263f83b8
2020-12-03 07:21:53,306 [IPC Server handler 9 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42231
2020-12-03 07:21:53,307 [IPC Server handler 9 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5acb39eb-5728-4202-8118-3ee3263f83b8 (127.0.0.1:42231).
2020-12-03 07:21:53,309 [IPC Server handler 1 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage b0096ae2-cc7b-4df7-9b03-27070a28f7f3
2020-12-03 07:21:53,309 [IPC Server handler 1 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39540
2020-12-03 07:21:53,309 [IPC Server handler 1 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b0096ae2-cc7b-4df7-9b03-27070a28f7f3 (127.0.0.1:39540).
2020-12-03 07:21:53,309 [IPC Server handler 8 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6
2020-12-03 07:21:53,310 [IPC Server handler 8 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45731
2020-12-03 07:21:53,310 [IPC Server handler 8 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6 (127.0.0.1:45731).
2020-12-03 07:21:53,310 [IPC Server handler 2 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage e8a203d1-0819-4572-aa20-1d3c1baf7085
2020-12-03 07:21:53,310 [IPC Server handler 2 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33329
2020-12-03 07:21:53,311 [IPC Server handler 2 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e8a203d1-0819-4572-aa20-1d3c1baf7085 (127.0.0.1:33329).
2020-12-03 07:21:53,311 [IPC Server handler 7 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage cbfee30d-4220-4633-9768-a706de590b0e
2020-12-03 07:21:53,311 [IPC Server handler 7 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35266
2020-12-03 07:21:53,311 [IPC Server handler 7 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cbfee30d-4220-4633-9768-a706de590b0e (127.0.0.1:35266).
2020-12-03 07:21:53,311 [IPC Server handler 6 on default port 38854] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227) storage ec0094e0-560a-4031-81df-ada112d08205
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid e8a203d1-0819-4572-aa20-1d3c1baf7085) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 5acb39eb-5728-4202-8118-3ee3263f83b8) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid b0096ae2-cc7b-4df7-9b03-27070a28f7f3) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid cbfee30d-4220-4633-9768-a706de590b0e) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,312 [IPC Server handler 6 on default port 38854] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33979
2020-12-03 07:21:53,312 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,313 [IPC Server handler 6 on default port 38854] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ec0094e0-560a-4031-81df-ada112d08205 (127.0.0.1:33979).
2020-12-03 07:21:53,314 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid ec0094e0-560a-4031-81df-ada112d08205) service to localhost/127.0.0.1:38854 successfully registered with NN
2020-12-03 07:21:53,315 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38854 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:53,332 [IPC Server handler 4 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b79796c-92a6-4041-b124-487655e159e8 for DN 127.0.0.1:39540
2020-12-03 07:21:53,333 [IPC Server handler 4 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-42a1aae5-3a99-4c4c-b138-e2811361d2de for DN 127.0.0.1:39540
2020-12-03 07:21:53,334 [IPC Server handler 8 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-67d43213-2051-4db1-bb58-b3bee09c60c9 for DN 127.0.0.1:35266
2020-12-03 07:21:53,335 [IPC Server handler 8 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 for DN 127.0.0.1:35266
2020-12-03 07:21:53,335 [IPC Server handler 9 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 for DN 127.0.0.1:42231
2020-12-03 07:21:53,335 [IPC Server handler 9 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 for DN 127.0.0.1:42231
2020-12-03 07:21:53,336 [IPC Server handler 5 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6aba9027-eb8e-409e-aae1-00bca57939fa for DN 127.0.0.1:45731
2020-12-03 07:21:53,336 [IPC Server handler 5 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 for DN 127.0.0.1:45731
2020-12-03 07:21:53,337 [IPC Server handler 3 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 for DN 127.0.0.1:33979
2020-12-03 07:21:53,337 [IPC Server handler 3 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d605f99a-cc80-400e-b796-fb43014c99cd for DN 127.0.0.1:33979
2020-12-03 07:21:53,338 [IPC Server handler 0 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 for DN 127.0.0.1:33329
2020-12-03 07:21:53,338 [IPC Server handler 0 on default port 38854] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b for DN 127.0.0.1:33329
2020-12-03 07:21:53,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x50eb7fc8aef8eb16: Processing first storage report for DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 from datanode e8a203d1-0819-4572-aa20-1d3c1baf7085
2020-12-03 07:21:53,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb16: from storage DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbd26e41e5e2c4365: Processing first storage report for DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 from datanode ec0094e0-560a-4031-81df-ada112d08205
2020-12-03 07:21:53,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4365: from storage DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x632e6550bda314c0: Processing first storage report for DS-6aba9027-eb8e-409e-aae1-00bca57939fa from datanode 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6
2020-12-03 07:21:53,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c0: from storage DS-6aba9027-eb8e-409e-aae1-00bca57939fa node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5cb9606951215d02: Processing first storage report for DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 from datanode 5acb39eb-5728-4202-8118-3ee3263f83b8
2020-12-03 07:21:53,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d02: from storage DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,374 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4cf44e0684633d5e: Processing first storage report for DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 from datanode cbfee30d-4220-4633-9768-a706de590b0e
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d5e: from storage DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a1aacf3725b5cbd: Processing first storage report for DS-0b79796c-92a6-4041-b124-487655e159e8 from datanode b0096ae2-cc7b-4df7-9b03-27070a28f7f3
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbd: from storage DS-0b79796c-92a6-4041-b124-487655e159e8 node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x50eb7fc8aef8eb16: Processing first storage report for DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b from datanode e8a203d1-0819-4572-aa20-1d3c1baf7085
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb16: from storage DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbd26e41e5e2c4365: Processing first storage report for DS-d605f99a-cc80-400e-b796-fb43014c99cd from datanode ec0094e0-560a-4031-81df-ada112d08205
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4365: from storage DS-d605f99a-cc80-400e-b796-fb43014c99cd node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,375 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x632e6550bda314c0: Processing first storage report for DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 from datanode 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6
2020-12-03 07:21:53,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c0: from storage DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5cb9606951215d02: Processing first storage report for DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 from datanode 5acb39eb-5728-4202-8118-3ee3263f83b8
2020-12-03 07:21:53,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d02: from storage DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4cf44e0684633d5e: Processing first storage report for DS-67d43213-2051-4db1-bb58-b3bee09c60c9 from datanode cbfee30d-4220-4633-9768-a706de590b0e
2020-12-03 07:21:53,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d5e: from storage DS-67d43213-2051-4db1-bb58-b3bee09c60c9 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a1aacf3725b5cbd: Processing first storage report for DS-42a1aae5-3a99-4c4c-b138-e2811361d2de from datanode b0096ae2-cc7b-4df7-9b03-27070a28f7f3
2020-12-03 07:21:53,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbd: from storage DS-42a1aae5-3a99-4c4c-b138-e2811361d2de node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,379 [IPC Server handler 0 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,389 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:53,399 [IPC Server handler 8 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x632e6550bda314c0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a1aacf3725b5cbd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5cb9606951215d02,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4cf44e0684633d5e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x50eb7fc8aef8eb16,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,400 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbd26e41e5e2c4365,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,401 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,402 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,407 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:53,424 [IPC Server handler 9 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,471 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:53,515 [IPC Server handler 0 on default port 38854] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:53,517 [IPC Server handler 0 on default port 38854] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,519 [IPC Server handler 0 on default port 38854] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,524 [IPC Server handler 0 on default port 38854] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:42231, 127.0.0.1:39540, 127.0.0.1:35266 for /foo
2020-12-03 07:21:53,542 [Thread-251] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,620 [Thread-251] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "b0096ae2-cc7b-4df7-9b03-27070a28f7f3"
    xferPort: 39540
    infoPort: 34014
    ipcPort: 34983
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113333
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102256
  lastBlockReportTime: 1606980113379
  lastBlockReportMonotonic: 141102302
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113335
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102258
  lastBlockReportTime: 1606980113377
  lastBlockReportMonotonic: 141102300
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-797d4d2d-e4ee-4c91-895f-c249c9f58349"
targetStorageIds: "DS-0b79796c-92a6-4041-b124-487655e159e8"
targetStorageIds: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,623 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:50566 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 src: /127.0.0.1:50566 dest: /127.0.0.1:42231
2020-12-03 07:21:53,645 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:50566 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,647 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:50566 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113335
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102258
  lastBlockReportTime: 1606980113377
  lastBlockReportMonotonic: 141102300
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-0b79796c-92a6-4041-b124-487655e159e8"
targetStorageIds: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,648 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56426 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 src: /127.0.0.1:56426 dest: /127.0.0.1:39540
2020-12-03 07:21:53,650 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56426 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,651 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56426 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,652 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:39026 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 src: /127.0.0.1:39026 dest: /127.0.0.1:35266
2020-12-03 07:21:53,688 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39026, dest: /127.0.0.1:35266, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: cbfee30d-4220-4633-9768-a706de590b0e, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, duration(ns): 19070037
2020-12-03 07:21:53,688 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:53,692 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56426, dest: /127.0.0.1:39540, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: b0096ae2-cc7b-4df7-9b03-27070a28f7f3, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, duration(ns): 25817275
2020-12-03 07:21:53,693 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266] terminating
2020-12-03 07:21:53,696 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39540, 127.0.0.1:35266]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50566, dest: /127.0.0.1:42231, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: 5acb39eb-5728-4202-8118-3ee3263f83b8, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, duration(ns): 26990604
2020-12-03 07:21:53,696 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39540, 127.0.0.1:35266]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39540, 127.0.0.1:35266] terminating
2020-12-03 07:21:53,700 [IPC Server handler 5 on default port 38854] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:53,701 [IPC Server handler 5 on default port 38854] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,701 [IPC Server handler 5 on default port 38854] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,705 [IPC Server handler 5 on default port 38854] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:39540, 127.0.0.1:33979, 127.0.0.1:35266 for /foo
2020-12-03 07:21:53,708 [DataStreamer for file /foo] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,711 [DataStreamer for file /foo] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "ec0094e0-560a-4031-81df-ada112d08205"
    xferPort: 33979
    infoPort: 45955
    ipcPort: 44431
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113337
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102260
  lastBlockReportTime: 1606980113376
  lastBlockReportMonotonic: 141102299
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113335
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102258
  lastBlockReportTime: 1606980113377
  lastBlockReportMonotonic: 141102300
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-0b79796c-92a6-4041-b124-487655e159e8"
targetStorageIds: "DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97"
targetStorageIds: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,712 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56432 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 src: /127.0.0.1:56432 dest: /127.0.0.1:39540
2020-12-03 07:21:53,713 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56432 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,715 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:56432 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198461878272
  blockPoolUsed: 49152
  lastUpdate: 1606980113335
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090762240
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102258
  lastBlockReportTime: 1606980113377
  lastBlockReportMonotonic: 141102300
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97"
targetStorageIds: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,716 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:53840 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 src: /127.0.0.1:53840 dest: /127.0.0.1:33979
2020-12-03 07:21:53,717 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:53840 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,719 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:53840 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1629078178-172.17.0.8-1606980106227"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_789290982_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-67d43213-2051-4db1-bb58-b3bee09c60c9"

2020-12-03 07:21:53,719 [DataXceiver for client DFSClient_NONMAPREDUCE_789290982_1 at /127.0.0.1:39036 [Receiving block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 src: /127.0.0.1:39036 dest: /127.0.0.1:35266
2020-12-03 07:21:53,732 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39036, dest: /127.0.0.1:35266, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: cbfee30d-4220-4633-9768-a706de590b0e, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, duration(ns): 9104962
2020-12-03 07:21:53,733 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:53,736 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53840, dest: /127.0.0.1:33979, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: ec0094e0-560a-4031-81df-ada112d08205, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, duration(ns): 13405181
2020-12-03 07:21:53,736 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35266] terminating
2020-12-03 07:21:53,739 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33979, 127.0.0.1:35266]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56432, dest: /127.0.0.1:39540, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_789290982_1, offset: 0, srvID: b0096ae2-cc7b-4df7-9b03-27070a28f7f3, blockid: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, duration(ns): 16672716
2020-12-03 07:21:53,739 [PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33979, 127.0.0.1:35266]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33979, 127.0.0.1:35266] terminating
2020-12-03 07:21:53,745 [IPC Server handler 4 on default port 38854] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_789290982_1
2020-12-03 07:21:53,754 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:53,757 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d03: from storage DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,757 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d03: from storage DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,758 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5cb9606951215d03,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,758 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,852 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:53,854 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c1: from storage DS-6aba9027-eb8e-409e-aae1-00bca57939fa node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,854 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c1: from storage DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,855 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x632e6550bda314c1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,855 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:53,955 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:53,956 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4366: from storage DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,957 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4366: from storage DS-d605f99a-cc80-400e-b796-fb43014c99cd node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,957 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbd26e41e5e2c4366,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,957 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:54,054 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:54,056 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb17: from storage DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,056 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb17: from storage DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,057 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x50eb7fc8aef8eb17,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:54,057 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:54,155 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:54,156 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbe: from storage DS-0b79796c-92a6-4041-b124-487655e159e8 node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,157 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbe: from storage DS-42a1aae5-3a99-4c4c-b138-e2811361d2de node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,157 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a1aacf3725b5cbe,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:54,157 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:54,255 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:21:54,257 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d5f: from storage DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,257 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d5f: from storage DS-67d43213-2051-4db1-bb58-b3bee09c60c9 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:54,258 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4cf44e0684633d5f,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:54,258 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:21:54,354 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,360 [IPC Server handler 3 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,380 [IPC Server handler 6 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:54,383 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:54,383 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:54,384 [Listener at localhost/46869] INFO  mover.Mover (Mover.java:run(642)) - namenodes = {hdfs://localhost:38854=null}
2020-12-03 07:21:54,442 [IPC Server handler 8 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,447 [IPC Server handler 9 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/system/mover.id	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:54,449 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,453 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:54,453 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:54,470 [IPC Server handler 2 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,479 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33329
2020-12-03 07:21:54,479 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42231
2020-12-03 07:21:54,479 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33979
2020-12-03 07:21:54,480 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45731
2020-12-03 07:21:54,480 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35266
2020-12-03 07:21:54,480 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39540
2020-12-03 07:21:54,487 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,490 [IPC Server handler 3 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,496 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:42231:DISK to 127.0.0.1:42231:ARCHIVE through 127.0.0.1:42231
2020-12-03 07:21:54,497 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:54,497 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:42231:DISK to 127.0.0.1:42231:ARCHIVE through 127.0.0.1:42231
2020-12-03 07:21:54,498 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:54,499 [IPC Server handler 6 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,506 [pool-83-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:54,506 [pool-84-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:54,512 [pool-84-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "b0096ae2-cc7b-4df7-9b03-27070a28f7f3"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "b0096ae2-cc7b-4df7-9b03-27070a28f7f3"
    xferPort: 39540
    infoPort: 34014
    ipcPort: 34983
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51230
  remaining: 1198460223488
  blockPoolUsed: 51230
  lastUpdate: 1606980114152
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626092414946
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141103075
  lastBlockReportTime: 1606980114157
  lastBlockReportMonotonic: 141103080
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:54,512 [pool-83-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "5acb39eb-5728-4202-8118-3ee3263f83b8"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "5acb39eb-5728-4202-8118-3ee3263f83b8"
    xferPort: 42231
    infoPort: 42498
    ipcPort: 39738
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50191
  remaining: 1198461034496
  blockPoolUsed: 50191
  lastUpdate: 1606980113751
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626091604977
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102674
  lastBlockReportTime: 1606980113757
  lastBlockReportMonotonic: 141102680
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:54,517 [DataXceiver for client /127.0.0.1:50612 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from 5acb39eb-5728-4202-8118-3ee3263f83b8]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:21:54,517 [DataXceiver for client /127.0.0.1:56472 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from b0096ae2-cc7b-4df7-9b03-27070a28f7f3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:54,518 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:42231:DISK to 127.0.0.1:42231:ARCHIVE through 127.0.0.1:42231
2020-12-03 07:21:54,518 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:54,520 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:39540
2020-12-03 07:21:54,521 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:42231
2020-12-03 07:21:59,501 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:59,501 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:59,504 [IPC Server handler 7 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:59,506 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33979
2020-12-03 07:21:59,507 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45731
2020-12-03 07:21:59,507 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42231
2020-12-03 07:21:59,507 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33329
2020-12-03 07:21:59,507 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35266
2020-12-03 07:21:59,507 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39540
2020-12-03 07:21:59,508 [IPC Server handler 8 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:59,510 [IPC Server handler 9 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:59,512 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:59,513 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=1024 from 127.0.0.1:33979:DISK to 127.0.0.1:33979:ARCHIVE through 127.0.0.1:33979
2020-12-03 07:21:59,513 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:59,513 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=1024 from 127.0.0.1:33979:DISK to 127.0.0.1:33979:ARCHIVE through 127.0.0.1:33979
2020-12-03 07:21:59,514 [pool-85-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:59,514 [pool-86-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:59,515 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:59,516 [pool-85-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "b0096ae2-cc7b-4df7-9b03-27070a28f7f3"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "b0096ae2-cc7b-4df7-9b03-27070a28f7f3"
    xferPort: 39540
    infoPort: 34014
    ipcPort: 34983
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51245
  remaining: 1198437203968
  blockPoolUsed: 51245
  lastUpdate: 1606980119155
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626115434451
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141108078
  lastBlockReportTime: 1606980114157
  lastBlockReportMonotonic: 141103080
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:59,516 [pool-86-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "ec0094e0-560a-4031-81df-ada112d08205"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "ec0094e0-560a-4031-81df-ada112d08205"
    xferPort: 33979
    infoPort: 45955
    ipcPort: 44431
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50191
  remaining: 1198436532224
  blockPoolUsed: 50191
  lastUpdate: 1606980118953
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626116107249
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107876
  lastBlockReportTime: 1606980113957
  lastBlockReportMonotonic: 141102880
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:59,519 [DataXceiver for client /127.0.0.1:56744 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from b0096ae2-cc7b-4df7-9b03-27070a28f7f3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,520 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:39540:DISK to 127.0.0.1:39540:ARCHIVE through 127.0.0.1:39540
2020-12-03 07:21:59,522 [DataXceiver for client /127.0.0.1:54150 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from ec0094e0-560a-4031-81df-ada112d08205]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,522 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=1024 from 127.0.0.1:33979:DISK to 127.0.0.1:33979:ARCHIVE through 127.0.0.1:33979
2020-12-03 07:21:59,522 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:39540
2020-12-03 07:21:59,523 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:33979
2020-12-03 07:22:04,517 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,517 [Listener at localhost/46869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,520 [IPC Server handler 2 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,522 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39540
2020-12-03 07:22:04,522 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42231
2020-12-03 07:22:04,522 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33979
2020-12-03 07:22:04,522 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33329
2020-12-03 07:22:04,523 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35266
2020-12-03 07:22:04,523 [Listener at localhost/46869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45731
2020-12-03 07:22:04,524 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,525 [IPC Server handler 3 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,528 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,529 [Listener at localhost/46869] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,529 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,529 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:04,530 [IPC Server handler 6 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,531 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "cbfee30d-4220-4633-9768-a706de590b0e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51230
  remaining: 1198447345664
  blockPoolUsed: 51230
  lastUpdate: 1606980124253
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626105292770
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141113176
  lastBlockReportTime: 1606980114258
  lastBlockReportMonotonic: 141103180
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:04,535 [DataXceiver for client /127.0.0.1:39394 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from cbfee30d-4220-4633-9768-a706de590b0e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:22:04,535 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,536 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,536 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:04,537 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:35266
2020-12-03 07:22:04,560 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1629078178-172.17.0.8-1606980106227"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "cbfee30d-4220-4633-9768-a706de590b0e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "cbfee30d-4220-4633-9768-a706de590b0e"
    xferPort: 35266
    infoPort: 35180
    ipcPort: 46869
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51230
  remaining: 1198447345664
  blockPoolUsed: 51230
  lastUpdate: 1606980124253
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626105292770
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141113176
  lastBlockReportTime: 1606980114258
  lastBlockReportMonotonic: 141103180
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:04,565 [DataXceiver for client /127.0.0.1:39396 [Replacing block BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from cbfee30d-4220-4633-9768-a706de590b0e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1629078178-172.17.0.8-1606980106227:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:22:04,565 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=1024 from 127.0.0.1:35266:DISK to 127.0.0.1:35266:ARCHIVE through 127.0.0.1:35266
2020-12-03 07:22:04,571 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:35266
2020-12-03 07:22:05,533 [IPC Server handler 1 on default port 38854] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /system/mover.id is closed by DFSClient_NONMAPREDUCE_789290982_1
2020-12-03 07:22:05,548 [IPC Server handler 7 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/system/mover.id	dst=null	perm=null	proto=rpc
Mover Successful: all blocks satisfy the specified storage policy. Exiting...
2020-12-03 07:22:14,554 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:14,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d04: from storage DS-797d4d2d-e4ee-4c91-895f-c249c9f58349 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,557 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cb9606951215d04: from storage DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727 node DatanodeRegistration(127.0.0.1:42231, datanodeUuid=5acb39eb-5728-4202-8118-3ee3263f83b8, infoPort=42498, infoSecurePort=0, ipcPort=39738, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,557 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5cb9606951215d04,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,558 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:14,654 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:14,656 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c2: from storage DS-6aba9027-eb8e-409e-aae1-00bca57939fa node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,656 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x632e6550bda314c2: from storage DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44 node DatanodeRegistration(127.0.0.1:45731, datanodeUuid=1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6, infoPort=41892, infoSecurePort=0, ipcPort=36542, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,657 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x632e6550bda314c2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,657 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:14,755 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:14,756 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4367: from storage DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97 node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,757 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbd26e41e5e2c4367: from storage DS-d605f99a-cc80-400e-b796-fb43014c99cd node DatanodeRegistration(127.0.0.1:33979, datanodeUuid=ec0094e0-560a-4031-81df-ada112d08205, infoPort=45955, infoSecurePort=0, ipcPort=44431, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,757 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbd26e41e5e2c4367,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,758 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:14,854 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:14,856 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb18: from storage DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2 node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,856 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50eb7fc8aef8eb18: from storage DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b node DatanodeRegistration(127.0.0.1:33329, datanodeUuid=e8a203d1-0819-4572-aa20-1d3c1baf7085, infoPort=34610, infoSecurePort=0, ipcPort=40956, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,857 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x50eb7fc8aef8eb18,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,857 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:14,955 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:14,957 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbf: from storage DS-0b79796c-92a6-4041-b124-487655e159e8 node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,957 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a1aacf3725b5cbf: from storage DS-42a1aae5-3a99-4c4c-b138-e2811361d2de node DatanodeRegistration(127.0.0.1:39540, datanodeUuid=b0096ae2-cc7b-4df7-9b03-27070a28f7f3, infoPort=34014, infoSecurePort=0, ipcPort=34983, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,958 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a1aacf3725b5cbf,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,958 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,055 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38854
2020-12-03 07:22:15,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d60: from storage DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,057 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4cf44e0684633d60: from storage DS-67d43213-2051-4db1-bb58-b3bee09c60c9 node DatanodeRegistration(127.0.0.1:35266, datanodeUuid=cbfee30d-4220-4633-9768-a706de590b0e, infoPort=35180, infoSecurePort=0, ipcPort=46869, storageInfo=lv=-57;cid=testClusterID;nsid=1272315793;c=1606980106227), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,057 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4cf44e0684633d60,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:15,058 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,157 [IPC Server handler 4 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:15,160 [IPC Server handler 0 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:15,163 [IPC Server handler 2 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system	dst=null	perm=null	proto=rpc
2020-12-03 07:22:15,165 [IPC Server handler 5 on default port 38854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:22:15,165 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:15,166 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:15,168 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,168 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12f3afb5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,172 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fb5f41ac-8518-45eb-a16d-1b2c217ff0d3) exiting.
2020-12-03 07:22:15,172 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-67d43213-2051-4db1-bb58-b3bee09c60c9) exiting.
2020-12-03 07:22:15,388 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a23a01d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,417 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,418 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,419 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,435 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46869
2020-12-03 07:22:15,442 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,444 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,445 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:15,446 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid cbfee30d-4220-4633-9768-a706de590b0e) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,447 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid cbfee30d-4220-4633-9768-a706de590b0e)
2020-12-03 07:22:15,447 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,449 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,449 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,458 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,458 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,459 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,459 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:15,467 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:15,467 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:15,467 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,468 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5949eba8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-42a1aae5-3a99-4c4c-b138-e2811361d2de) exiting.
2020-12-03 07:22:15,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-0b79796c-92a6-4041-b124-487655e159e8) exiting.
2020-12-03 07:22:15,561 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bc53649{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,562 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,563 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,563 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,565 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34983
2020-12-03 07:22:15,582 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,583 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:15,586 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid b0096ae2-cc7b-4df7-9b03-27070a28f7f3) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,586 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid b0096ae2-cc7b-4df7-9b03-27070a28f7f3)
2020-12-03 07:22:15,586 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,594 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,597 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,601 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,605 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,605 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,609 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,610 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:15,630 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:15,631 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:15,631 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,631 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29539e36] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,634 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-2b38062b-e69c-4cb6-adf2-8087f105b3c2) exiting.
2020-12-03 07:22:15,634 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b7045bb9-8f47-465f-bf76-dbfda34ba16b) exiting.
2020-12-03 07:22:15,687 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37d3d232{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,689 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,690 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,690 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,706 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40956
2020-12-03 07:22:15,708 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,711 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,712 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:15,712 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid e8a203d1-0819-4572-aa20-1d3c1baf7085) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,712 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid e8a203d1-0819-4572-aa20-1d3c1baf7085)
2020-12-03 07:22:15,712 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,715 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,716 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,722 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,723 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,725 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,725 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:15,729 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:15,729 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:15,730 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,730 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c25b8a7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e65a520e-1abc-4acd-90b9-3cb26b68fb97) exiting.
2020-12-03 07:22:15,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d605f99a-cc80-400e-b796-fb43014c99cd) exiting.
2020-12-03 07:22:15,770 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid ec0094e0-560a-4031-81df-ada112d08205) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,771 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid ec0094e0-560a-4031-81df-ada112d08205)
2020-12-03 07:22:15,771 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,772 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,772 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,776 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d4d3fe7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,781 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,782 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,782 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,785 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44431
2020-12-03 07:22:15,792 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,792 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,809 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,809 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,812 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,813 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:15,821 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:15,821 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:15,822 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,825 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41200e0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,825 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0cfa4dae-a64d-4b26-9319-846bd63f0d44) exiting.
2020-12-03 07:22:15,825 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6aba9027-eb8e-409e-aae1-00bca57939fa) exiting.
2020-12-03 07:22:15,850 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29ad44e3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,856 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,857 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,857 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,863 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36542
2020-12-03 07:22:15,871 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,876 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,877 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:15,877 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,877 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 1b2baf48-4cd6-4218-9009-fd4b0bf7a3a6)
2020-12-03 07:22:15,877 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,878 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,879 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,890 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,890 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,891 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,891 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:15,901 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:15,902 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:15,902 [Listener at localhost/46869] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:15,902 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4c6daf0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:15,907 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-797d4d2d-e4ee-4c91-895f-c249c9f58349) exiting.
2020-12-03 07:22:15,907 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9fe6d2eb-4559-402d-9a2f-c0d50735a727) exiting.
2020-12-03 07:22:15,939 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61526469{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:15,940 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:15,940 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:15,941 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:15,943 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39738
2020-12-03 07:22:15,949 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:15,955 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:15,955 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:15,955 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 5acb39eb-5728-4202-8118-3ee3263f83b8) service to localhost/127.0.0.1:38854
2020-12-03 07:22:15,956 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1629078178-172.17.0.8-1606980106227 (Datanode Uuid 5acb39eb-5728-4202-8118-3ee3263f83b8)
2020-12-03 07:22:15,956 [BP-1629078178-172.17.0.8-1606980106227 heartbeating to localhost/127.0.0.1:38854] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1629078178-172.17.0.8-1606980106227
2020-12-03 07:22:15,957 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,957 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1629078178-172.17.0.8-1606980106227] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:15,984 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:15,985 [Listener at localhost/46869] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:15,989 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:15,989 [Listener at localhost/46869] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:16,001 [Listener at localhost/46869] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:16,002 [Listener at localhost/46869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:16,002 [Listener at localhost/46869] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:16,003 [Listener at localhost/46869] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 14
2020-12-03 07:22:16,004 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1b065145] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:16,005 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@45cff11c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:16,006 [Listener at localhost/46869] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 15 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 1 Number of syncs: 15 SyncTimes(ms): 2 2 
2020-12-03 07:22:16,008 [Listener at localhost/46869] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-12-03 07:22:16,009 [Listener at localhost/46869] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-12-03 07:22:16,014 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:16,015 [CacheReplicationMonitor(392208129)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:16,017 [Listener at localhost/46869] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38854
2020-12-03 07:22:16,053 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:16,054 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:16,061 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:16,061 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:16,118 [Listener at localhost/46869] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:16,119 [Listener at localhost/46869] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:16,121 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a3793c7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:16,123 [Listener at localhost/46869] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:16,123 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:16,124 [Listener at localhost/46869] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:16,125 [Listener at localhost/46869] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:16,161 [Listener at localhost/46869] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:16,162 [Listener at localhost/46869] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
