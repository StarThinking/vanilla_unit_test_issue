2020-12-03 07:19:28,264 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=11
Formatting using clusterid: testClusterID
2020-12-03 07:19:29,245 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:29,263 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:29,264 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:29,265 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:29,290 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:29,290 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:29,291 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:29,291 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:29,349 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:29,357 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:19:29,358 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:29,358 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:29,367 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:29,368 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:29
2020-12-03 07:19:29,372 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:29,374 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,378 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:19:29,378 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:29,405 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:29,406 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:19:29,406 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:19:29,432 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:29,433 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:29,433 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:29,433 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:29,434 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:29,435 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:29,435 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:29,435 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:19:29,436 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:29,436 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:29,436 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:29,471 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:19:29,472 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,472 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,473 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,489 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:29,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:19:29,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:29,497 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:29,497 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:29,498 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:29,498 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:29,506 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:29,510 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:29,517 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:29,517 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,518 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:19:29,518 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:29,527 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:29,528 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:29,528 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:29,534 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:29,534 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:29,538 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:29,538 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,539 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:19:29,539 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:29,582 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:29,772 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:19:29,894 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:19:29,929 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:29,929 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:30,130 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:30,130 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:30,194 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:19:30,198 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:30,753 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:19:30,890 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:19:30,891 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:19:30,940 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:19:30,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36916eb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:31,026 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:19:31,035 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,060 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3830ms
2020-12-03 07:19:31,247 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:31,251 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:31,251 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,261 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:31,263 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:31,264 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:31,264 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:31,300 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:31,300 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:31,313 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34435
2020-12-03 07:19:31,317 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:31,409 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41330d4f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:31,412 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e0e1046{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:31,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c39680d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:31,495 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28b46423{HTTP/1.1,[http/1.1]}{localhost:34435}
2020-12-03 07:19:31,495 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4266ms
2020-12-03 07:19:31,513 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:31,514 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:31,514 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:31,515 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:31,515 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:31,516 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:31,516 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:31,517 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:31,518 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:31,518 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:31,519 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:31,520 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:31,520 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:31
2020-12-03 07:19:31,521 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:31,521 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,522 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:31,522 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:31,529 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:31,529 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:19:31,530 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:19:31,531 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:31,532 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:31,532 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:31,533 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:31,533 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:31,534 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:31,534 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:31,534 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:19:31,535 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:31,535 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:31,535 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:31,536 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:31,536 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,536 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:31,537 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:31,539 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:31,540 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:31,540 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:31,540 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:31,540 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:31,540 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:31,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:31,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:31,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:31,543 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:31,543 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:31,543 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:31,543 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:31,543 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:31,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:31,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:31,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:31,586 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:31,637 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:31,642 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:31,642 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:31,643 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:31,644 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:31,685 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:31,694 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:31,695 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:31,700 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:19:31,702 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:19:31,799 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:31,800 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 253 msecs
2020-12-03 07:19:32,019 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:19:32,076 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:32,091 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:32,475 [Listener at localhost/33068] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33068 to access this namenode/service.
2020-12-03 07:19:32,480 [Listener at localhost/33068] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:32,507 [Listener at localhost/33068] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:32,547 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@52e7a6b2] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(263)) - Updating block keys
2020-12-03 07:19:32,573 [Listener at localhost/33068] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:32,574 [Listener at localhost/33068] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:32,575 [Listener at localhost/33068] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:32,575 [Listener at localhost/33068] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:32,580 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:19:32,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:32,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:32,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:32,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:32,581 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:19:32,630 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:32,676 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:32,683 [Listener at localhost/33068] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33068
2020-12-03 07:19:32,690 [Listener at localhost/33068] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:32,691 [Listener at localhost/33068] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:32,710 [Listener at localhost/33068] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 18 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:32,715 [CacheReplicationMonitor(532657337)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:32,723 [Listener at localhost/33068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:32,877 [Listener at localhost/33068] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:32,899 [Listener at localhost/33068] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:32,956 [Listener at localhost/33068] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:32,963 [Listener at localhost/33068] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:32,968 [Listener at localhost/33068] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:32,974 [Listener at localhost/33068] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:32,976 [Listener at localhost/33068] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:32,981 [Listener at localhost/33068] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:33,007 [Listener at localhost/33068] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35494
2020-12-03 07:19:33,011 [Listener at localhost/33068] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:33,011 [Listener at localhost/33068] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:33,037 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:33,042 [Listener at localhost/33068] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:33,046 [Listener at localhost/33068] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:33,047 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:33,076 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:33,077 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:33,079 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:33,079 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:33,089 [Listener at localhost/33068] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37273
2020-12-03 07:19:33,097 [Listener at localhost/33068] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:33,114 [Listener at localhost/33068] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29ef6856{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:33,115 [Listener at localhost/33068] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3faf2e7d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:33,128 [Listener at localhost/33068] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4ebea12c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:33,130 [Listener at localhost/33068] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a1edad4{HTTP/1.1,[http/1.1]}{localhost:37273}
2020-12-03 07:19:33,131 [Listener at localhost/33068] INFO  server.Server (Server.java:doStart(419)) - Started @5901ms
2020-12-03 07:19:34,283 [Listener at localhost/33068] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43709
2020-12-03 07:19:34,285 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63f34b70] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,285 [Listener at localhost/33068] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,285 [Listener at localhost/33068] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,312 [Listener at localhost/33068] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,313 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,324 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35672
2020-12-03 07:19:34,346 [Listener at localhost/35672] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,348 [Listener at localhost/35672] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,360 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:34,377 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,380 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,410 [Listener at localhost/35672] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:34,414 [Listener at localhost/35672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:34,419 [Listener at localhost/35672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:34,421 [Listener at localhost/35672] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,423 [Listener at localhost/35672] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,423 [Listener at localhost/35672] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,424 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,425 [Listener at localhost/35672] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,425 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,426 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37038
2020-12-03 07:19:34,426 [Listener at localhost/35672] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,427 [Listener at localhost/35672] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,428 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,431 [Listener at localhost/35672] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,432 [Listener at localhost/35672] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,432 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,435 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,436 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,437 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,437 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,438 [Listener at localhost/35672] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35407
2020-12-03 07:19:34,439 [Listener at localhost/35672] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,442 [Listener at localhost/35672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d8445d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,448 [Listener at localhost/35672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@384fc774{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,458 [Listener at localhost/35672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@241a53ef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,468 [Listener at localhost/35672] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@344344fa{HTTP/1.1,[http/1.1]}{localhost:35407}
2020-12-03 07:19:34,469 [Listener at localhost/35672] INFO  server.Server (Server.java:doStart(419)) - Started @7240ms
2020-12-03 07:19:34,571 [Listener at localhost/35672] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46044
2020-12-03 07:19:34,575 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,576 [Listener at localhost/35672] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,575 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70e659aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,576 [Listener at localhost/35672] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,577 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,592 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43854
2020-12-03 07:19:34,600 [Listener at localhost/43854] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,600 [Listener at localhost/43854] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,601 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:34,604 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,604 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,635 [Listener at localhost/43854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:34,638 [Listener at localhost/43854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:34,642 [Listener at localhost/43854] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:34,644 [Listener at localhost/43854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,645 [Listener at localhost/43854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,645 [Listener at localhost/43854] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,646 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,646 [Listener at localhost/43854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,647 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,647 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35590
2020-12-03 07:19:34,648 [Listener at localhost/43854] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,648 [Listener at localhost/43854] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,650 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,653 [Listener at localhost/43854] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,654 [Listener at localhost/43854] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,654 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,658 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,660 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,661 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,661 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,662 [Listener at localhost/43854] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43027
2020-12-03 07:19:34,662 [Listener at localhost/43854] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,674 [Listener at localhost/43854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ed190be{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,677 [Listener at localhost/43854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bbc9f97{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,695 [Listener at localhost/43854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@20312893{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,704 [Listener at localhost/43854] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70eecdc2{HTTP/1.1,[http/1.1]}{localhost:43027}
2020-12-03 07:19:34,707 [Listener at localhost/43854] INFO  server.Server (Server.java:doStart(419)) - Started @7478ms
2020-12-03 07:19:34,738 [Listener at localhost/43854] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45801
2020-12-03 07:19:34,739 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,739 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7db0565c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,740 [Listener at localhost/43854] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,741 [Listener at localhost/43854] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,744 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,758 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33916
2020-12-03 07:19:34,765 [Listener at localhost/33916] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,766 [Listener at localhost/33916] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,767 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:34,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,770 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,784 [Listener at localhost/33916] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:34,788 [Listener at localhost/33916] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:34,789 [Listener at localhost/33916] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:34,791 [Listener at localhost/33916] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,792 [Listener at localhost/33916] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,792 [Listener at localhost/33916] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,793 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,793 [Listener at localhost/33916] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,794 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,795 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39022
2020-12-03 07:19:34,795 [Listener at localhost/33916] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,796 [Listener at localhost/33916] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,797 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,799 [Listener at localhost/33916] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,801 [Listener at localhost/33916] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,801 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,805 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,806 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,807 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,807 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,808 [Listener at localhost/33916] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44434
2020-12-03 07:19:34,809 [Listener at localhost/33916] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,811 [Listener at localhost/33916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433ffad1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,816 [Listener at localhost/33916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2575f671{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,826 [Listener at localhost/33916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@238b521e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,830 [Listener at localhost/33916] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1b39fd82{HTTP/1.1,[http/1.1]}{localhost:44434}
2020-12-03 07:19:34,831 [Listener at localhost/33916] INFO  server.Server (Server.java:doStart(419)) - Started @7601ms
2020-12-03 07:19:34,905 [Listener at localhost/33916] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34882
2020-12-03 07:19:34,905 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,905 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21680803] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,906 [Listener at localhost/33916] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,907 [Listener at localhost/33916] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,909 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,923 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36003
2020-12-03 07:19:34,929 [Listener at localhost/36003] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,930 [Listener at localhost/36003] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,931 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:34,932 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,932 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,935 [Listener at localhost/36003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:34,937 [Listener at localhost/36003] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:34,937 [Listener at localhost/36003] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:34,943 [Listener at localhost/36003] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,946 [Listener at localhost/36003] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,946 [Listener at localhost/36003] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,948 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,948 [Listener at localhost/36003] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,950 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,952 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45518
2020-12-03 07:19:34,952 [Listener at localhost/36003] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,952 [Listener at localhost/36003] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,954 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,955 [Listener at localhost/36003] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,968 [Listener at localhost/36003] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,969 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,972 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,973 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,974 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,974 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,975 [Listener at localhost/36003] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46732
2020-12-03 07:19:34,975 [Listener at localhost/36003] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,982 [Listener at localhost/36003] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c8bdd5b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,985 [Listener at localhost/36003] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40e4ea87{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,993 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:34,993 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:34,993 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:34,995 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:34,996 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:34,996 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:34,996 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:34,996 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,003 [Listener at localhost/36003] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33a2499c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,004 [Listener at localhost/36003] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e72dba7{HTTP/1.1,[http/1.1]}{localhost:46732}
2020-12-03 07:19:35,004 [Listener at localhost/36003] INFO  server.Server (Server.java:doStart(419)) - Started @7775ms
2020-12-03 07:19:35,026 [Listener at localhost/36003] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44676
2020-12-03 07:19:35,027 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,027 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dfd5f51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,027 [Listener at localhost/36003] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,028 [Listener at localhost/36003] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,029 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,034 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38178
2020-12-03 07:19:35,038 [Listener at localhost/38178] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,041 [Listener at localhost/38178] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,042 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,044 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,046 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,049 [Listener at localhost/38178] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:35,051 [Listener at localhost/38178] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:35,052 [Listener at localhost/38178] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:35,053 [Listener at localhost/38178] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,054 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,054 [Listener at localhost/38178] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,054 [Listener at localhost/38178] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,055 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,055 [Listener at localhost/38178] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,056 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,057 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,058 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39132
2020-12-03 07:19:35,058 [Listener at localhost/38178] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,058 [Listener at localhost/38178] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,059 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,061 [Listener at localhost/38178] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,062 [Listener at localhost/38178] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,062 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,065 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,066 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,067 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,067 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,072 [Listener at localhost/38178] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39290
2020-12-03 07:19:35,073 [Listener at localhost/38178] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,075 [Listener at localhost/38178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ca320ab{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,076 [Listener at localhost/38178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e53135d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,083 [Listener at localhost/38178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@106faf11{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,084 [Listener at localhost/38178] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70f43b45{HTTP/1.1,[http/1.1]}{localhost:39290}
2020-12-03 07:19:35,084 [Listener at localhost/38178] INFO  server.Server (Server.java:doStart(419)) - Started @7855ms
2020-12-03 07:19:35,099 [Listener at localhost/38178] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37963
2020-12-03 07:19:35,100 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,100 [Listener at localhost/38178] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,101 [Listener at localhost/38178] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,102 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,104 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10ad20cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,106 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41207
2020-12-03 07:19:35,111 [Listener at localhost/41207] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,111 [Listener at localhost/41207] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,112 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,113 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,113 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,117 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,117 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,138 [Listener at localhost/41207] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:35,140 [Listener at localhost/41207] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:35,140 [Listener at localhost/41207] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:35,142 [Listener at localhost/41207] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,142 [Listener at localhost/41207] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,143 [Listener at localhost/41207] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,143 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,144 [Listener at localhost/41207] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,144 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,145 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35607
2020-12-03 07:19:35,145 [Listener at localhost/41207] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,146 [Listener at localhost/41207] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,148 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,150 [Listener at localhost/41207] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,151 [Listener at localhost/41207] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,151 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,154 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,154 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,154 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,155 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,155 [Listener at localhost/41207] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45277
2020-12-03 07:19:35,156 [Listener at localhost/41207] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,161 [Listener at localhost/41207] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a71c100{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,162 [Listener at localhost/41207] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f325091{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,172 [Listener at localhost/41207] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@308a6984{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,174 [Listener at localhost/41207] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@66b72664{HTTP/1.1,[http/1.1]}{localhost:45277}
2020-12-03 07:19:35,174 [Listener at localhost/41207] INFO  server.Server (Server.java:doStart(419)) - Started @7945ms
2020-12-03 07:19:35,198 [Listener at localhost/41207] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44724
2020-12-03 07:19:35,199 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58cd06cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,199 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,199 [Listener at localhost/41207] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,200 [Listener at localhost/41207] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,201 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,206 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33550
2020-12-03 07:19:35,212 [Listener at localhost/33550] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,213 [Listener at localhost/33550] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,214 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,216 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,216 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,238 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,238 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,239 [Listener at localhost/33550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:35,240 [Listener at localhost/33550] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:35,241 [Listener at localhost/33550] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:35,243 [Listener at localhost/33550] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,244 [Listener at localhost/33550] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,244 [Listener at localhost/33550] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,244 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,244 [Listener at localhost/33550] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,245 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,246 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45951
2020-12-03 07:19:35,246 [Listener at localhost/33550] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,246 [Listener at localhost/33550] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,248 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,249 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,250 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,251 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,251 [Listener at localhost/33550] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,251 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,251 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,251 [Listener at localhost/33550] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,252 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,252 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,254 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-82870e1d-b232-4d81-a859-1b455f784120 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:19:35,254 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,255 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,255 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-45973715-37be-4d46-9516-7d0ea92ed50a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:19:35,255 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,255 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,255 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:19:35,255 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:19:35,255 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c94ed69f-d0d6-497a-a0e3-319dd1660919 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:19:35,266 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,266 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,267 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,267 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,268 [Listener at localhost/33550] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43861
2020-12-03 07:19:35,268 [Listener at localhost/33550] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,278 [Listener at localhost/33550] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@492fc69e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,279 [Listener at localhost/33550] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fb68ec6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,287 [Listener at localhost/33550] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f2d2181{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,288 [Listener at localhost/33550] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49bf29c6{HTTP/1.1,[http/1.1]}{localhost:43861}
2020-12-03 07:19:35,288 [Listener at localhost/33550] INFO  server.Server (Server.java:doStart(419)) - Started @8059ms
2020-12-03 07:19:35,353 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,354 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,365 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,366 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,369 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:19:35,369 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-496c99a4-9c42-4795-ab05-26b41a1c7696 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:19:35,406 [Listener at localhost/33550] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44776
2020-12-03 07:19:35,412 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,412 [Listener at localhost/33550] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,412 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fcdcf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,413 [Listener at localhost/33550] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,414 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,428 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37074
2020-12-03 07:19:35,435 [Listener at localhost/37074] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,436 [Listener at localhost/37074] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,447 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,452 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,497 [Listener at localhost/37074] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:35,499 [Listener at localhost/37074] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:35,500 [Listener at localhost/37074] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:35,518 [Listener at localhost/37074] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,519 [Listener at localhost/37074] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,519 [Listener at localhost/37074] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,520 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,520 [Listener at localhost/37074] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,521 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,522 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38186
2020-12-03 07:19:35,522 [Listener at localhost/37074] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,522 [Listener at localhost/37074] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,520 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,524 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,525 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,527 [Listener at localhost/37074] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,530 [Listener at localhost/37074] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,530 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,533 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,534 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,537 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,538 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,539 [Listener at localhost/37074] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36908
2020-12-03 07:19:35,539 [Listener at localhost/37074] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,545 [Listener at localhost/37074] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a6d5a8f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,546 [Listener at localhost/37074] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@315ba14a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,553 [Listener at localhost/37074] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2237bada{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,555 [Listener at localhost/37074] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77e2a6e2{HTTP/1.1,[http/1.1]}{localhost:36908}
2020-12-03 07:19:35,555 [Listener at localhost/37074] INFO  server.Server (Server.java:doStart(419)) - Started @8325ms
2020-12-03 07:19:35,595 [Listener at localhost/37074] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41378
2020-12-03 07:19:35,596 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@199e4c2b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,596 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,596 [Listener at localhost/37074] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,597 [Listener at localhost/37074] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,603 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,620 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34087
2020-12-03 07:19:35,627 [Listener at localhost/34087] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,627 [Listener at localhost/34087] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,628 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,633 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,633 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,640 [Listener at localhost/34087] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:35,641 [Listener at localhost/34087] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:35,642 [Listener at localhost/34087] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:35,645 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,648 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,651 [Listener at localhost/34087] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,651 [Listener at localhost/34087] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,651 [Listener at localhost/34087] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,652 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,652 [Listener at localhost/34087] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,652 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,653 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37179
2020-12-03 07:19:35,653 [Listener at localhost/34087] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,654 [Listener at localhost/34087] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,655 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,657 [Listener at localhost/34087] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,657 [Listener at localhost/34087] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,657 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,659 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,660 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,660 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,660 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,661 [Listener at localhost/34087] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43074
2020-12-03 07:19:35,662 [Listener at localhost/34087] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,663 [Listener at localhost/34087] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,664 [Listener at localhost/34087] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22175d4f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,673 [Listener at localhost/34087] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6594402a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,675 [Listener at localhost/34087] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30f4b1a6{HTTP/1.1,[http/1.1]}{localhost:43074}
2020-12-03 07:19:35,676 [Listener at localhost/34087] INFO  server.Server (Server.java:doStart(419)) - Started @8446ms
2020-12-03 07:19:35,695 [Listener at localhost/34087] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41274
2020-12-03 07:19:35,695 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,695 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e1162e7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,695 [Listener at localhost/34087] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,696 [Listener at localhost/34087] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,697 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,700 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41795
2020-12-03 07:19:35,706 [Listener at localhost/41795] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,707 [Listener at localhost/41795] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,707 [Thread-260] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,714 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,715 [Thread-260] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,716 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,716 [Thread-260] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,719 [Listener at localhost/41795] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:35,720 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,720 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,721 [Listener at localhost/41795] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:35,721 [Listener at localhost/41795] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:35,724 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-11a59c2b-5f15-4182-99d7-cd928d304916 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:19:35,739 [Listener at localhost/41795] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,740 [Listener at localhost/41795] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,740 [Listener at localhost/41795] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,740 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,740 [Listener at localhost/41795] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,741 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,742 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35504
2020-12-03 07:19:35,742 [Listener at localhost/41795] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,742 [Listener at localhost/41795] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,743 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,745 [Listener at localhost/41795] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,746 [Listener at localhost/41795] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,746 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,748 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,749 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,749 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,749 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,750 [Listener at localhost/41795] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36210
2020-12-03 07:19:35,750 [Listener at localhost/41795] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,752 [Listener at localhost/41795] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@88a8218{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,752 [Listener at localhost/41795] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4163f1cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,759 [Listener at localhost/41795] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c1e23ff{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,761 [Listener at localhost/41795] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ceb4bd2{HTTP/1.1,[http/1.1]}{localhost:36210}
2020-12-03 07:19:35,761 [Listener at localhost/41795] INFO  server.Server (Server.java:doStart(419)) - Started @8532ms
2020-12-03 07:19:35,780 [Listener at localhost/41795] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44398
2020-12-03 07:19:35,780 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,780 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1bf0f6f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,781 [Listener at localhost/41795] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,781 [Listener at localhost/41795] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,782 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,786 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42882
2020-12-03 07:19:35,799 [Listener at localhost/42882] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,800 [Listener at localhost/42882] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,801 [Thread-282] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068 starting to offer service
2020-12-03 07:19:35,804 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,804 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,808 [Thread-282] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33068
2020-12-03 07:19:35,811 [Thread-282] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,858 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,858 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,859 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,859 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,863 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:19:35,864 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0d497f2e-afaf-4667-a680-93ed3b5544ff for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:19:35,990 [Thread-282] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,990 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,990 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,991 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,990 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,991 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,991 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,991 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:35,992 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,991 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,990 [Thread-282] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,991 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:35,995 [Thread-282] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-49e3219b-40ed-4f88-bc50-839433223d0b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-12-03 07:19:35,995 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-511acede-de90-4fdf-adb8-34c074eb66c4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:19:35,996 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:19:35,995 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-df1c0970-3a20-4d55-bcb1-b18c363404df for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:19:35,995 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-949c0406-6db1-4ef3-bb39-80b03217bb5c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:19:35,995 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1cc92295-b44a-444b-884d-567c2848ebbe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:19:36,116 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,116 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,117 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,117 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,121 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c0a5f938-ab86-441e-a74e-7e98d06730d3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:19:36,121 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ea22c840-87f2-48ce-8f13-7cb74470fabe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:19:36,355 [IPC Server handler 5 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,366 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,366 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,469 [IPC Server handler 8 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,470 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,470 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,499 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,500 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,504 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:19:36,513 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,513 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,514 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,514 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,515 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,516 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,516 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,516 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,516 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,516 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,516 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,516 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,518 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,518 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,518 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,518 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,524 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,524 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,524 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,525 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,573 [IPC Server handler 9 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,574 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,574 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,622 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,623 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,629 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0639ba98-7aec-4136-8d58-21ae277f1908 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:19:36,622 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,633 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,634 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-25ef4552-87b3-49fc-9514-397b5b72979d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:19:36,634 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,635 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,635 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,635 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,642 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,643 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:36,643 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:36,643 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:36,677 [IPC Server handler 0 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,678 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,678 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,765 [Thread-282] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 275@2bb02abc3fe0
2020-12-03 07:19:36,765 [Thread-282] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 1605269718. Formatting...
2020-12-03 07:19:36,771 [Thread-282] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9d78baa6-1945-43eb-8689-8827bac14d05 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-12-03 07:19:36,781 [IPC Server handler 4 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,782 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,782 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,885 [IPC Server handler 2 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,886 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,886 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,989 [IPC Server handler 3 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,990 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,990 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,040 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,040 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,040 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,041 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,041 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,042 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,042 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,042 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,041 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,041 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,042 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,042 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,043 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,043 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,043 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,046 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,047 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,047 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,047 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,093 [IPC Server handler 7 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,093 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,094 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,176 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,176 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,176 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,176 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,177 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,178 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,178 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,178 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,178 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,179 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,179 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,179 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,185 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,185 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,185 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,186 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,202 [IPC Server handler 6 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,203 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,204 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,306 [IPC Server handler 5 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,307 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,308 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,356 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,356 [Thread-282] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,357 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,357 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,410 [IPC Server handler 8 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,411 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,411 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,513 [IPC Server handler 9 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,514 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,514 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,613 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,613 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,614 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,613 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,615 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,617 [IPC Server handler 0 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,618 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,618 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,630 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,630 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,630 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,631 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,720 [IPC Server handler 4 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,721 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,721 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,764 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,770 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:37,775 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,775 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,775 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,775 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,776 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,776 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,776 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,777 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,824 [IPC Server handler 2 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,831 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,832 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,920 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,921 [Thread-282] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:37,921 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-2144674998-172.17.0.5-1606979969566 is not formatted. Formatting ...
2020-12-03 07:19:37,921 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2144674998-172.17.0.5-1606979969566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2144674998-172.17.0.5-1606979969566/current
2020-12-03 07:19:37,940 [IPC Server handler 1 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,941 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,942 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,044 [IPC Server handler 7 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,045 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,046 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,148 [IPC Server handler 6 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,149 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,149 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,226 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6fde81a4-289b-4295-8406-6637e46e6aa2
2020-12-03 07:19:38,226 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d0cea7f3-b94e-46be-8cab-ab9b066065fe
2020-12-03 07:19:38,226 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1ddb58c3-7b1b-4718-8522-82dab72ae09b
2020-12-03 07:19:38,226 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:38,226 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d85b61b3-ef21-4772-acfd-077b1a8d8394
2020-12-03 07:19:38,226 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f
2020-12-03 07:19:38,252 [IPC Server handler 5 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,252 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,253 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,330 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d5f73667-91cd-4934-8423-541b27f4a3de
2020-12-03 07:19:38,330 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:38,331 [Thread-260] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:38,335 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 29316998-18c6-4068-af30-b4ef5dd9b939
2020-12-03 07:19:38,358 [IPC Server handler 8 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,359 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,360 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,379 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb
2020-12-03 07:19:38,395 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-82870e1d-b232-4d81-a859-1b455f784120
2020-12-03 07:19:38,388 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c94ed69f-d0d6-497a-a0e3-319dd1660919
2020-12-03 07:19:38,407 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:19:38,404 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:19:38,403 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-496c99a4-9c42-4795-ab05-26b41a1c7696
2020-12-03 07:19:38,398 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-45973715-37be-4d46-9516-7d0ea92ed50a
2020-12-03 07:19:38,395 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0
2020-12-03 07:19:38,395 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:19:38,395 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf
2020-12-03 07:19:38,410 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:19:38,410 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:19:38,410 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:19:38,410 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:19:38,417 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-949c0406-6db1-4ef3-bb39-80b03217bb5c
2020-12-03 07:19:38,419 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:19:38,419 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5
2020-12-03 07:19:38,419 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:19:38,422 [Thread-282] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1605269718;bpid=BP-2144674998-172.17.0.5-1606979969566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1605269718;c=1606979969566;bpid=BP-2144674998-172.17.0.5-1606979969566;dnuuid=null
2020-12-03 07:19:38,426 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ea22c840-87f2-48ce-8f13-7cb74470fabe
2020-12-03 07:19:38,429 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,428 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,430 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:19:38,430 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,432 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c0a5f938-ab86-441e-a74e-7e98d06730d3
2020-12-03 07:19:38,445 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-511acede-de90-4fdf-adb8-34c074eb66c4
2020-12-03 07:19:38,447 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:19:38,448 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:19:38,449 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,452 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,453 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1cc92295-b44a-444b-884d-567c2848ebbe
2020-12-03 07:19:38,453 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:19:38,455 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,458 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-df1c0970-3a20-4d55-bcb1-b18c363404df
2020-12-03 07:19:38,460 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:19:38,460 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,462 [IPC Server handler 9 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,466 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,467 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,466 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:38,469 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:38,471 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:38,473 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:38,498 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:38,501 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:38,505 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:38,507 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:38,508 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:38,509 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:38,512 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:38,513 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:38,513 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:38,514 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:38,514 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,519 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:38,520 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:38,520 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:38,520 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:38,520 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,521 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:38,521 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:38,541 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,529 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:38,541 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:38,528 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:38,542 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:38,542 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:38,523 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:38,523 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:38,523 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:38,545 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,545 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:38,548 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:38,550 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:38,556 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:38,556 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:38,556 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:38,556 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:38,556 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:38,559 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,560 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,561 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:38,573 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:38,574 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:38,575 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:38,577 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,581 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 53fc9ac1-3951-4eae-baef-413586f8057e
2020-12-03 07:19:38,581 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:38,581 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:38,596 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-11a59c2b-5f15-4182-99d7-cd928d304916
2020-12-03 07:19:38,596 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:19:38,598 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51
2020-12-03 07:19:38,592 [IPC Server handler 0 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,601 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:19:38,619 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,624 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,626 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,659 [Thread-260] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 90ad47e9-9fe2-4fc3-bfcf-6019048261b1
2020-12-03 07:19:38,674 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:38,689 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b1c23357-dcda-435c-8e01-8e989d3f9601
2020-12-03 07:19:38,692 [Thread-282] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f8147b50-fa2c-49a6-af1f-3f8e63395129
2020-12-03 07:19:38,698 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-49e3219b-40ed-4f88-bc50-839433223d0b
2020-12-03 07:19:38,698 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:19:38,748 [IPC Server handler 2 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,752 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0d497f2e-afaf-4667-a680-93ed3b5544ff
2020-12-03 07:19:38,752 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:19:38,753 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0639ba98-7aec-4136-8d58-21ae277f1908
2020-12-03 07:19:38,754 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:19:38,754 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,754 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9d78baa6-1945-43eb-8689-8827bac14d05
2020-12-03 07:19:38,755 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:19:38,755 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,755 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:38,756 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:38,756 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:38,756 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,757 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,757 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:38,757 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:38,772 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:38,756 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:38,773 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,756 [Thread-282] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:38,774 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e
2020-12-03 07:19:38,774 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:19:38,780 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-25ef4552-87b3-49fc-9514-397b5b72979d
2020-12-03 07:19:38,780 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:19:38,781 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,782 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:38,786 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:38,786 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:38,786 [Thread-282] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:38,787 [Thread-282] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:38,875 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:19:38,876 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:19:38,877 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:38,877 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 333ms
2020-12-03 07:19:38,882 [Thread-282] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:38,882 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,882 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:19:38,883 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 338ms
2020-12-03 07:19:38,883 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,883 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:19:38,884 [IPC Server handler 1 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,884 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:38,887 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,888 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,892 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 299ms
2020-12-03 07:19:38,892 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 311ms
2020-12-03 07:19:38,893 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 343ms
2020-12-03 07:19:38,893 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 333ms
2020-12-03 07:19:38,894 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 353ms
2020-12-03 07:19:38,894 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 372ms
2020-12-03 07:19:38,894 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 320ms
2020-12-03 07:19:38,894 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 319ms
2020-12-03 07:19:38,900 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,901 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 324ms
2020-12-03 07:19:38,901 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:38,902 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 326ms
2020-12-03 07:19:38,901 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:19:38,904 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 383ms
2020-12-03 07:19:38,903 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 342ms
2020-12-03 07:19:38,907 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:19:38,907 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 344ms
2020-12-03 07:19:38,910 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:38,910 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:38,911 [Thread-354] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,919 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:38,919 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:38,919 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:38,919 [Thread-357] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,919 [Thread-355] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,920 [Thread-361] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,911 [Thread-358] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,919 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:38,941 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:38,932 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 385ms
2020-12-03 07:19:38,942 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,932 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 389ms
2020-12-03 07:19:38,925 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 14ms
2020-12-03 07:19:38,925 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:38,942 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 402ms
2020-12-03 07:19:38,942 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 397ms
2020-12-03 07:19:38,942 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 22ms
2020-12-03 07:19:38,942 [Thread-363] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,943 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:19:38,943 [Thread-362] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,943 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:38,944 [Thread-366] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,944 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:38,944 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:19:38,947 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 28ms
2020-12-03 07:19:38,944 [Thread-368] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,950 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 31ms
2020-12-03 07:19:38,953 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 408ms
2020-12-03 07:19:38,953 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 439ms
2020-12-03 07:19:38,954 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:38,954 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:38,954 [Thread-373] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,962 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 18ms
2020-12-03 07:19:38,954 [Thread-374] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,963 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 20ms
2020-12-03 07:19:38,963 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 21ms
2020-12-03 07:19:38,963 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 20ms
2020-12-03 07:19:38,963 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 56ms
2020-12-03 07:19:38,963 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 8ms
2020-12-03 07:19:38,963 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 56ms
2020-12-03 07:19:38,963 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:38,964 [Thread-367] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,965 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 54ms
2020-12-03 07:19:38,965 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:19:38,965 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:38,966 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 62ms
2020-12-03 07:19:38,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:38,966 [Thread-375] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:38,973 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 19ms
2020-12-03 07:19:38,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,973 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 9ms
2020-12-03 07:19:38,973 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 31ms
2020-12-03 07:19:38,974 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 66ms
2020-12-03 07:19:38,984 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 108ms
2020-12-03 07:19:38,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:39,002 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c94ed69f-d0d6-497a-a0e3-319dd1660919): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:39,003 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-949c0406-6db1-4ef3-bb39-80b03217bb5c): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:38,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:39,004 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-df1c0970-3a20-4d55-bcb1-b18c363404df): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,004 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,974 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:38,974 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:39,005 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-496c99a4-9c42-4795-ab05-26b41a1c7696): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,005 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-511acede-de90-4fdf-adb8-34c074eb66c4): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,974 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:39,006 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-45973715-37be-4d46-9516-7d0ea92ed50a): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:38,970 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:38,970 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:39,007 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-82870e1d-b232-4d81-a859-1b455f784120): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,007 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0a5f938-ab86-441e-a74e-7e98d06730d3): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,007 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-1cc92295-b44a-444b-884d-567c2848ebbe): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:38,979 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:39,009 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 56ms
2020-12-03 07:19:39,009 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-ea22c840-87f2-48ce-8f13-7cb74470fabe): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,024 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:39,025 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:48 AM with interval of 21600000ms
2020-12-03 07:19:39,025 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,027 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:39,028 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,036 [IPC Server handler 7 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,038 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,038 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,038 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 154ms
2020-12-03 07:19:39,025 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:24 AM with interval of 21600000ms
2020-12-03 07:19:39,025 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:25 AM with interval of 21600000ms
2020-12-03 07:19:39,060 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 186ms
2020-12-03 07:19:39,028 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:41 AM with interval of 21600000ms
2020-12-03 07:19:39,027 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:35 AM with interval of 21600000ms
2020-12-03 07:19:39,061 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 287ms
2020-12-03 07:19:39,062 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 157ms
2020-12-03 07:19:39,028 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:07 AM with interval of 21600000ms
2020-12-03 07:19:39,063 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:19:39,063 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:19:39,063 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,063 [Thread-395] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,064 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:19:39,064 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:19:39,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0): no suitable block pools found to scan.  Waiting 1814399902 ms.
2020-12-03 07:19:39,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0a5f938-ab86-441e-a74e-7e98d06730d3): no suitable block pools found to scan.  Waiting 1814399902 ms.
2020-12-03 07:19:39,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-1cc92295-b44a-444b-884d-567c2848ebbe): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-12-03 07:19:39,064 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 3ms
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-82870e1d-b232-4d81-a859-1b455f784120): no suitable block pools found to scan.  Waiting 1814399905 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-496c99a4-9c42-4795-ab05-26b41a1c7696): no suitable block pools found to scan.  Waiting 1814399909 ms.
2020-12-03 07:19:39,028 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:15 AM with interval of 21600000ms
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-949c0406-6db1-4ef3-bb39-80b03217bb5c): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c94ed69f-d0d6-497a-a0e3-319dd1660919): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-45973715-37be-4d46-9516-7d0ea92ed50a): no suitable block pools found to scan.  Waiting 1814399909 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-ea22c840-87f2-48ce-8f13-7cb74470fabe): no suitable block pools found to scan.  Waiting 1814399909 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-df1c0970-3a20-4d55-bcb1-b18c363404df): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:39,065 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 6fde81a4-289b-4295-8406-6637e46e6aa2) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:39,066 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-511acede-de90-4fdf-adb8-34c074eb66c4): no suitable block pools found to scan.  Waiting 1814399908 ms.
2020-12-03 07:19:39,066 [Thread-260] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:37 PM with interval of 21600000ms
2020-12-03 07:19:39,069 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0639ba98-7aec-4136-8d58-21ae277f1908): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,066 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:19:39,070 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0639ba98-7aec-4136-8d58-21ae277f1908): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:19:39,071 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0d497f2e-afaf-4667-a680-93ed3b5544ff): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,066 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:19:39,072 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0d497f2e-afaf-4667-a680-93ed3b5544ff): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:19:39,074 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 166ms
2020-12-03 07:19:39,074 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 173ms
2020-12-03 07:19:39,075 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:19:39,075 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:19:39,075 [Thread-402] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,075 [Thread-403] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,076 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 1ms
2020-12-03 07:19:39,076 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 1ms
2020-12-03 07:19:39,080 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 197ms
2020-12-03 07:19:39,081 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 199ms
2020-12-03 07:19:39,084 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 1ddb58c3-7b1b-4718-8522-82dab72ae09b) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,084 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d5f73667-91cd-4934-8423-541b27f4a3de) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,084 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:19:39,084 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 29316998-18c6-4068-af30-b4ef5dd9b939) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,084 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,084 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d0cea7f3-b94e-46be-8cab-ab9b066065fe) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,084 [Thread-404] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,086 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:19:39,087 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d85b61b3-ef21-4772-acfd-077b1a8d8394) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,090 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 188ms
2020-12-03 07:19:39,084 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:19:39,092 [Thread-405] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,095 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 3ms
2020-12-03 07:19:39,103 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 90ad47e9-9fe2-4fc3-bfcf-6019048261b1) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,103 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 22ms
2020-12-03 07:19:39,110 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:30 AM with interval of 21600000ms
2020-12-03 07:19:39,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:39,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:19:39,103 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 29ms
2020-12-03 07:19:39,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:39,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-9d78baa6-1945-43eb-8689-8827bac14d05): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-9d78baa6-1945-43eb-8689-8827bac14d05): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:19:39,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:39,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-49e3219b-40ed-4f88-bc50-839433223d0b): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-49e3219b-40ed-4f88-bc50-839433223d0b): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:19:39,117 [Thread-282] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:52 AM with interval of 21600000ms
2020-12-03 07:19:39,118 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:39,118 [IPC Server handler 6 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35494, datanodeUuid=6fde81a4-289b-4295-8406-6637e46e6aa2, infoPort=43709, infoSecurePort=0, ipcPort=35672, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 6fde81a4-289b-4295-8406-6637e46e6aa2
2020-12-03 07:19:39,118 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-25ef4552-87b3-49fc-9514-397b5b72979d): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,123 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid f8147b50-fa2c-49a6-af1f-3f8e63395129) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,133 [IPC Server handler 6 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35494
2020-12-03 07:19:39,136 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-25ef4552-87b3-49fc-9514-397b5b72979d): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:19:39,136 [IPC Server handler 6 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6fde81a4-289b-4295-8406-6637e46e6aa2 (127.0.0.1:35494).
2020-12-03 07:19:39,138 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2144674998-172.17.0.5-1606979969566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 253ms
2020-12-03 07:19:39,138 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2144674998-172.17.0.5-1606979969566: 254ms
2020-12-03 07:19:39,139 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:39,139 [Thread-412] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,140 [IPC Server handler 5 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 29316998-18c6-4068-af30-b4ef5dd9b939
2020-12-03 07:19:39,141 [IPC Server handler 5 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39132
2020-12-03 07:19:39,144 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:39,153 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 14ms
2020-12-03 07:19:39,153 [IPC Server handler 5 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 29316998-18c6-4068-af30-b4ef5dd9b939 (127.0.0.1:39132).
2020-12-03 07:19:39,155 [IPC Server handler 8 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage d85b61b3-ef21-4772-acfd-077b1a8d8394
2020-12-03 07:19:39,155 [IPC Server handler 8 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39022
2020-12-03 07:19:39,155 [IPC Server handler 8 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d85b61b3-ef21-4772-acfd-077b1a8d8394 (127.0.0.1:39022).
2020-12-03 07:19:39,156 [IPC Server handler 9 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45518, datanodeUuid=d0cea7f3-b94e-46be-8cab-ab9b066065fe, infoPort=44676, infoSecurePort=0, ipcPort=38178, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage d0cea7f3-b94e-46be-8cab-ab9b066065fe
2020-12-03 07:19:39,157 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d85b61b3-ef21-4772-acfd-077b1a8d8394) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,157 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,163 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 6fde81a4-289b-4295-8406-6637e46e6aa2) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,163 [IPC Server handler 9 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45518
2020-12-03 07:19:39,160 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 29316998-18c6-4068-af30-b4ef5dd9b939) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,164 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,164 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,165 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,159 [Thread-413] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2144674998-172.17.0.5-1606979969566/current/replicas doesn't exist 
2020-12-03 07:19:39,166 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 22ms
2020-12-03 07:19:39,166 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2144674998-172.17.0.5-1606979969566: 28ms
2020-12-03 07:19:39,166 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:39,158 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid b1c23357-dcda-435c-8e01-8e989d3f9601) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,180 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,180 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2144674998-172.17.0.5-1606979969566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:39,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-11a59c2b-5f15-4182-99d7-cd928d304916): finished scanning block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51): no suitable block pools found to scan.  Waiting 1814399985 ms.
2020-12-03 07:19:39,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-11a59c2b-5f15-4182-99d7-cd928d304916): no suitable block pools found to scan.  Waiting 1814399985 ms.
2020-12-03 07:19:39,164 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,181 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,164 [IPC Server handler 9 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d0cea7f3-b94e-46be-8cab-ab9b066065fe (127.0.0.1:45518).
2020-12-03 07:19:39,164 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,184 [IPC Server handler 0 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f
2020-12-03 07:19:39,184 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:43 PM with interval of 21600000ms
2020-12-03 07:19:39,184 [IPC Server handler 0 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35590
2020-12-03 07:19:39,184 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,184 [IPC Server handler 0 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f (127.0.0.1:35590).
2020-12-03 07:19:39,185 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d0cea7f3-b94e-46be-8cab-ab9b066065fe) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,185 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,185 [IPC Server handler 4 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35607, datanodeUuid=d5f73667-91cd-4934-8423-541b27f4a3de, infoPort=44724, infoSecurePort=0, ipcPort=33550, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage d5f73667-91cd-4934-8423-541b27f4a3de
2020-12-03 07:19:39,185 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,186 [IPC Server handler 4 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35607
2020-12-03 07:19:39,186 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,186 [IPC Server handler 4 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d5f73667-91cd-4934-8423-541b27f4a3de (127.0.0.1:35607).
2020-12-03 07:19:39,186 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,186 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,186 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,186 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,186 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=1ddb58c3-7b1b-4718-8522-82dab72ae09b, infoPort=46044, infoSecurePort=0, ipcPort=43854, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 1ddb58c3-7b1b-4718-8522-82dab72ae09b
2020-12-03 07:19:39,187 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,187 [IPC Server handler 2 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37038
2020-12-03 07:19:39,187 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d5f73667-91cd-4934-8423-541b27f4a3de) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,187 [IPC Server handler 2 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1ddb58c3-7b1b-4718-8522-82dab72ae09b (127.0.0.1:37038).
2020-12-03 07:19:39,187 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,187 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,190 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 53fc9ac1-3951-4eae-baef-413586f8057e) service to localhost/127.0.0.1:33068 beginning handshake with NN
2020-12-03 07:19:39,198 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,212 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 1ddb58c3-7b1b-4718-8522-82dab72ae09b) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,215 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,215 [IPC Server handler 3 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,215 [IPC Server handler 1 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage f8147b50-fa2c-49a6-af1f-3f8e63395129
2020-12-03 07:19:39,216 [IPC Server handler 1 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35504
2020-12-03 07:19:39,216 [IPC Server handler 1 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f8147b50-fa2c-49a6-af1f-3f8e63395129 (127.0.0.1:35504).
2020-12-03 07:19:39,215 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,216 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,219 [IPC Server handler 7 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 90ad47e9-9fe2-4fc3-bfcf-6019048261b1
2020-12-03 07:19:39,219 [IPC Server handler 7 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37179
2020-12-03 07:19:39,220 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid f8147b50-fa2c-49a6-af1f-3f8e63395129) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,220 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,220 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,220 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,220 [IPC Server handler 7 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 90ad47e9-9fe2-4fc3-bfcf-6019048261b1 (127.0.0.1:37179).
2020-12-03 07:19:39,227 [IPC Server handler 5 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage b1c23357-dcda-435c-8e01-8e989d3f9601
2020-12-03 07:19:39,228 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 90ad47e9-9fe2-4fc3-bfcf-6019048261b1) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,228 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,228 [IPC Server handler 5 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38186
2020-12-03 07:19:39,228 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,228 [IPC Server handler 5 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b1c23357-dcda-435c-8e01-8e989d3f9601 (127.0.0.1:38186).
2020-12-03 07:19:39,228 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,228 [IPC Server handler 8 on default port 33068] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45951, datanodeUuid=53fc9ac1-3951-4eae-baef-413586f8057e, infoPort=44776, infoSecurePort=0, ipcPort=37074, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566) storage 53fc9ac1-3951-4eae-baef-413586f8057e
2020-12-03 07:19:39,229 [IPC Server handler 8 on default port 33068] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45951
2020-12-03 07:19:39,229 [IPC Server handler 8 on default port 33068] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 53fc9ac1-3951-4eae-baef-413586f8057e (127.0.0.1:45951).
2020-12-03 07:19:39,236 [IPC Server handler 9 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-496c99a4-9c42-4795-ab05-26b41a1c7696 for DN 127.0.0.1:39132
2020-12-03 07:19:39,237 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,237 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,237 [IPC Server handler 9 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ea22c840-87f2-48ce-8f13-7cb74470fabe for DN 127.0.0.1:39132
2020-12-03 07:19:39,238 [IPC Server handler 6 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45973715-37be-4d46-9516-7d0ea92ed50a for DN 127.0.0.1:35494
2020-12-03 07:19:39,241 [IPC Server handler 6 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-511acede-de90-4fdf-adb8-34c074eb66c4 for DN 127.0.0.1:35494
2020-12-03 07:19:39,242 [IPC Server handler 5 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c94ed69f-d0d6-497a-a0e3-319dd1660919 for DN 127.0.0.1:35590
2020-12-03 07:19:39,244 [IPC Server handler 5 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-949c0406-6db1-4ef3-bb39-80b03217bb5c for DN 127.0.0.1:35590
2020-12-03 07:19:39,244 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid b1c23357-dcda-435c-8e01-8e989d3f9601) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,244 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,245 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,245 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,248 [IPC Server handler 4 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-49e3219b-40ed-4f88-bc50-839433223d0b for DN 127.0.0.1:35504
2020-12-03 07:19:39,249 [IPC Server handler 4 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9d78baa6-1945-43eb-8689-8827bac14d05 for DN 127.0.0.1:35504
2020-12-03 07:19:39,249 [IPC Server handler 0 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf for DN 127.0.0.1:37038
2020-12-03 07:19:39,249 [IPC Server handler 0 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5 for DN 127.0.0.1:37038
2020-12-03 07:19:39,252 [IPC Server handler 1 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0 for DN 127.0.0.1:35607
2020-12-03 07:19:39,252 [IPC Server handler 1 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0a5f938-ab86-441e-a74e-7e98d06730d3 for DN 127.0.0.1:35607
2020-12-03 07:19:39,253 [IPC Server handler 8 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb for DN 127.0.0.1:39022
2020-12-03 07:19:39,253 [IPC Server handler 8 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-df1c0970-3a20-4d55-bcb1-b18c363404df for DN 127.0.0.1:39022
2020-12-03 07:19:39,253 [IPC Server handler 3 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-82870e1d-b232-4d81-a859-1b455f784120 for DN 127.0.0.1:45518
2020-12-03 07:19:39,253 [IPC Server handler 3 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1cc92295-b44a-444b-884d-567c2848ebbe for DN 127.0.0.1:45518
2020-12-03 07:19:39,254 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 53fc9ac1-3951-4eae-baef-413586f8057e) service to localhost/127.0.0.1:33068 successfully registered with NN
2020-12-03 07:19:39,254 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-2144674998-172.17.0.5-1606979969566 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,254 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,255 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33068 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,261 [IPC Server handler 7 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e for DN 127.0.0.1:38186
2020-12-03 07:19:39,261 [IPC Server handler 7 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-25ef4552-87b3-49fc-9514-397b5b72979d for DN 127.0.0.1:38186
2020-12-03 07:19:39,263 [IPC Server handler 2 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0d497f2e-afaf-4667-a680-93ed3b5544ff for DN 127.0.0.1:37179
2020-12-03 07:19:39,263 [IPC Server handler 2 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0639ba98-7aec-4136-8d58-21ae277f1908 for DN 127.0.0.1:37179
2020-12-03 07:19:39,271 [IPC Server handler 2 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-11a59c2b-5f15-4182-99d7-cd928d304916 for DN 127.0.0.1:45951
2020-12-03 07:19:39,272 [IPC Server handler 2 on default port 33068] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51 for DN 127.0.0.1:45951
2020-12-03 07:19:39,310 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98f3011d600efdb8: Processing first storage report for DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0 from datanode d5f73667-91cd-4934-8423-541b27f4a3de
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98f3011d600efdb8: from storage DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0 node DatanodeRegistration(127.0.0.1:35607, datanodeUuid=d5f73667-91cd-4934-8423-541b27f4a3de, infoPort=44724, infoSecurePort=0, ipcPort=33550, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xee49765db0b56ecf: Processing first storage report for DS-45973715-37be-4d46-9516-7d0ea92ed50a from datanode 6fde81a4-289b-4295-8406-6637e46e6aa2
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xee49765db0b56ecf: from storage DS-45973715-37be-4d46-9516-7d0ea92ed50a node DatanodeRegistration(127.0.0.1:35494, datanodeUuid=6fde81a4-289b-4295-8406-6637e46e6aa2, infoPort=43709, infoSecurePort=0, ipcPort=35672, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a17fd4bf8fe5105: Processing first storage report for DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf from datanode 1ddb58c3-7b1b-4718-8522-82dab72ae09b
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a17fd4bf8fe5105: from storage DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf node DatanodeRegistration(127.0.0.1:37038, datanodeUuid=1ddb58c3-7b1b-4718-8522-82dab72ae09b, infoPort=46044, infoSecurePort=0, ipcPort=43854, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x64ca4df38f3ac2af: Processing first storage report for DS-ea22c840-87f2-48ce-8f13-7cb74470fabe from datanode 29316998-18c6-4068-af30-b4ef5dd9b939
2020-12-03 07:19:39,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x64ca4df38f3ac2af: from storage DS-ea22c840-87f2-48ce-8f13-7cb74470fabe node DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70aa7be32b827d8e: Processing first storage report for DS-c94ed69f-d0d6-497a-a0e3-319dd1660919 from datanode 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70aa7be32b827d8e: from storage DS-c94ed69f-d0d6-497a-a0e3-319dd1660919 node DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9292a418809d0103: Processing first storage report for DS-9d78baa6-1945-43eb-8689-8827bac14d05 from datanode f8147b50-fa2c-49a6-af1f-3f8e63395129
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9292a418809d0103: from storage DS-9d78baa6-1945-43eb-8689-8827bac14d05 node DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98f3011d600efdb8: Processing first storage report for DS-c0a5f938-ab86-441e-a74e-7e98d06730d3 from datanode d5f73667-91cd-4934-8423-541b27f4a3de
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98f3011d600efdb8: from storage DS-c0a5f938-ab86-441e-a74e-7e98d06730d3 node DatanodeRegistration(127.0.0.1:35607, datanodeUuid=d5f73667-91cd-4934-8423-541b27f4a3de, infoPort=44724, infoSecurePort=0, ipcPort=33550, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xee49765db0b56ecf: Processing first storage report for DS-511acede-de90-4fdf-adb8-34c074eb66c4 from datanode 6fde81a4-289b-4295-8406-6637e46e6aa2
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xee49765db0b56ecf: from storage DS-511acede-de90-4fdf-adb8-34c074eb66c4 node DatanodeRegistration(127.0.0.1:35494, datanodeUuid=6fde81a4-289b-4295-8406-6637e46e6aa2, infoPort=43709, infoSecurePort=0, ipcPort=35672, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a17fd4bf8fe5105: Processing first storage report for DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5 from datanode 1ddb58c3-7b1b-4718-8522-82dab72ae09b
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a17fd4bf8fe5105: from storage DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5 node DatanodeRegistration(127.0.0.1:37038, datanodeUuid=1ddb58c3-7b1b-4718-8522-82dab72ae09b, infoPort=46044, infoSecurePort=0, ipcPort=43854, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x64ca4df38f3ac2af: Processing first storage report for DS-496c99a4-9c42-4795-ab05-26b41a1c7696 from datanode 29316998-18c6-4068-af30-b4ef5dd9b939
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x64ca4df38f3ac2af: from storage DS-496c99a4-9c42-4795-ab05-26b41a1c7696 node DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70aa7be32b827d8e: Processing first storage report for DS-949c0406-6db1-4ef3-bb39-80b03217bb5c from datanode 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70aa7be32b827d8e: from storage DS-949c0406-6db1-4ef3-bb39-80b03217bb5c node DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,316 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9292a418809d0103: Processing first storage report for DS-49e3219b-40ed-4f88-bc50-839433223d0b from datanode f8147b50-fa2c-49a6-af1f-3f8e63395129
2020-12-03 07:19:39,317 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9292a418809d0103: from storage DS-49e3219b-40ed-4f88-bc50-839433223d0b node DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,339 [IPC Server handler 8 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,342 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:39,347 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x70aa7be32b827d8e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 20 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,347 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x98f3011d600efdb8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 20 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,347 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x64ca4df38f3ac2af,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 17 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,348 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,348 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xee49765db0b56ecf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 19 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,348 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,347 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,347 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,357 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a17fd4bf8fe5105,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 18 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,358 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,358 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9292a418809d0103,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 18 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,358 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:39,372 [IPC Server handler 6 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:19:39,408 [IPC Server handler 9 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:19:39,414 [IPC Server handler 2 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,419 [Thread-417] INFO  hdfs.TestFileChecksum (TestFileChecksum.java:testStripedFileChecksumWithMissedDataBlocksRangeQuery(290)) - Checksum file:/striped/stripedFileChecksum1, requested length:377487359
2020-12-03 07:19:40,462 [IPC Server handler 8 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,508 [IPC Server handler 1 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/striped/stripedFileChecksum1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:40,984 [IPC Server handler 4 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:39132, 127.0.0.1:37038, 127.0.0.1:35494, 127.0.0.1:38186, 127.0.0.1:35590, 127.0.0.1:35504, 127.0.0.1:45518, 127.0.0.1:37179, 127.0.0.1:45951 for /striped/stripedFileChecksum1
2020-12-03 07:19:41,017 [Thread-418] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,058 [Thread-419] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,082 [Thread-420] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,130 [Thread-421] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,149 [Thread-422] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,045 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10ad20cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2414ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,046 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@199e4c2b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2437ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,046 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70e659aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2462ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,046 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dfd5f51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2487ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,048 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21680803] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2597ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,048 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fcdcf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2597ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,049 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63f34b70] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2672ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,049 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1bf0f6f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2761ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,049 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36916eb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2797ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7db0565c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2805ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58cd06cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2843ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e1162e7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2851ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1314ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1546ms
2020-12-03 07:19:44,220 [Thread-423] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,247 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53554 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001 src: /127.0.0.1:53554 dest: /127.0.0.1:37038
2020-12-03 07:19:44,247 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60814 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001 src: /127.0.0.1:60814 dest: /127.0.0.1:38186
2020-12-03 07:19:44,247 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:59808 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001 src: /127.0.0.1:59808 dest: /127.0.0.1:35590
2020-12-03 07:19:44,256 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54070 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001 src: /127.0.0.1:54070 dest: /127.0.0.1:39132
2020-12-03 07:19:44,247 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40292 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001 src: /127.0.0.1:40292 dest: /127.0.0.1:35494
2020-12-03 07:19:44,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb13061c61644eada: Processing first storage report for DS-df1c0970-3a20-4d55-bcb1-b18c363404df from datanode d85b61b3-ef21-4772-acfd-077b1a8d8394
2020-12-03 07:19:44,270 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb13061c61644eada: from storage DS-df1c0970-3a20-4d55-bcb1-b18c363404df node DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 11 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,270 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf8f356a8e98621dc: Processing first storage report for DS-0d497f2e-afaf-4667-a680-93ed3b5544ff from datanode 90ad47e9-9fe2-4fc3-bfcf-6019048261b1
2020-12-03 07:19:44,271 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8f356a8e98621dc: from storage DS-0d497f2e-afaf-4667-a680-93ed3b5544ff node DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,271 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x85e15864561e3821: Processing first storage report for DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e from datanode b1c23357-dcda-435c-8e01-8e989d3f9601
2020-12-03 07:19:44,271 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x85e15864561e3821: from storage DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e node DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,271 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf8f356a8e98621dc: Processing first storage report for DS-0639ba98-7aec-4136-8d58-21ae277f1908 from datanode 90ad47e9-9fe2-4fc3-bfcf-6019048261b1
2020-12-03 07:19:44,271 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8f356a8e98621dc: from storage DS-0639ba98-7aec-4136-8d58-21ae277f1908 node DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,301 [Thread-424] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,308 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55350 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001 src: /127.0.0.1:55350 dest: /127.0.0.1:35504
2020-12-03 07:19:44,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x85e15864561e3821: Processing first storage report for DS-25ef4552-87b3-49fc-9514-397b5b72979d from datanode b1c23357-dcda-435c-8e01-8e989d3f9601
2020-12-03 07:19:44,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x85e15864561e3821: from storage DS-25ef4552-87b3-49fc-9514-397b5b72979d node DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,309 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb13061c61644eada: Processing first storage report for DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb from datanode d85b61b3-ef21-4772-acfd-077b1a8d8394
2020-12-03 07:19:44,309 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb13061c61644eada: from storage DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb node DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,327 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb8efa1698aa9419c: Processing first storage report for DS-82870e1d-b232-4d81-a859-1b455f784120 from datanode d0cea7f3-b94e-46be-8cab-ab9b066065fe
2020-12-03 07:19:44,328 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf8f356a8e98621dc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,328 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb8efa1698aa9419c: from storage DS-82870e1d-b232-4d81-a859-1b455f784120 node DatanodeRegistration(127.0.0.1:45518, datanodeUuid=d0cea7f3-b94e-46be-8cab-ab9b066065fe, infoPort=44676, infoSecurePort=0, ipcPort=38178, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,328 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:44,328 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x85e15864561e3821,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 71 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,328 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:44,328 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb13061c61644eada,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 182 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,332 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:44,328 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb8efa1698aa9419c: Processing first storage report for DS-1cc92295-b44a-444b-884d-567c2848ebbe from datanode d0cea7f3-b94e-46be-8cab-ab9b066065fe
2020-12-03 07:19:44,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb8efa1698aa9419c: from storage DS-1cc92295-b44a-444b-884d-567c2848ebbe node DatanodeRegistration(127.0.0.1:45518, datanodeUuid=d0cea7f3-b94e-46be-8cab-ab9b066065fe, infoPort=44676, infoSecurePort=0, ipcPort=38178, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74693ae6ab07fa5a: Processing first storage report for DS-11a59c2b-5f15-4182-99d7-cd928d304916 from datanode 53fc9ac1-3951-4eae-baef-413586f8057e
2020-12-03 07:19:44,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74693ae6ab07fa5a: from storage DS-11a59c2b-5f15-4182-99d7-cd928d304916 node DatanodeRegistration(127.0.0.1:45951, datanodeUuid=53fc9ac1-3951-4eae-baef-413586f8057e, infoPort=44776, infoSecurePort=0, ipcPort=37074, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74693ae6ab07fa5a: Processing first storage report for DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51 from datanode 53fc9ac1-3951-4eae-baef-413586f8057e
2020-12-03 07:19:44,337 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74693ae6ab07fa5a: from storage DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51 node DatanodeRegistration(127.0.0.1:45951, datanodeUuid=53fc9ac1-3951-4eae-baef-413586f8057e, infoPort=44776, infoSecurePort=0, ipcPort=37074, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,337 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb8efa1698aa9419c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 68 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,337 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:44,337 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74693ae6ab07fa5a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,353 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:44,364 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:44922 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001 src: /127.0.0.1:44922 dest: /127.0.0.1:45518
2020-12-03 07:19:44,422 [Thread-425] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,451 [Thread-426] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,505 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:50936 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001 src: /127.0.0.1:50936 dest: /127.0.0.1:37179
2020-12-03 07:19:44,552 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40212 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001 src: /127.0.0.1:40212 dest: /127.0.0.1:45951
2020-12-03 07:19:44,894 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50936, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001, duration(ns): 366440513
2020-12-03 07:19:44,895 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,903 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54070, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001, duration(ns): 483873507
2020-12-03 07:19:44,903 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40212, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001, duration(ns): 273517480
2020-12-03 07:19:44,908 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,904 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40292, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001, duration(ns): 493424650
2020-12-03 07:19:44,904 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55350, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001, duration(ns): 473174282
2020-12-03 07:19:44,912 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,912 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,908 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59808, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001, duration(ns): 491143395
2020-12-03 07:19:44,912 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,908 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,917 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60814, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001, duration(ns): 474071823
2020-12-03 07:19:44,917 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,918 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53554, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001, duration(ns): 487172064
2020-12-03 07:19:44,917 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44922, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001, duration(ns): 473123440
2020-12-03 07:19:44,920 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,921 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,937 [IPC Server handler 4 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:39022, 127.0.0.1:45951, 127.0.0.1:35504, 127.0.0.1:39132, 127.0.0.1:37179, 127.0.0.1:35590, 127.0.0.1:38186, 127.0.0.1:37038, 127.0.0.1:35607 for /striped/stripedFileChecksum1
2020-12-03 07:19:44,956 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,960 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,964 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,975 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:37188 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 src: /127.0.0.1:37188 dest: /127.0.0.1:39022
2020-12-03 07:19:44,976 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40300 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002 src: /127.0.0.1:40300 dest: /127.0.0.1:45951
2020-12-03 07:19:44,977 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,977 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55456 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 src: /127.0.0.1:55456 dest: /127.0.0.1:35504
2020-12-03 07:19:44,982 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,983 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,000 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54252 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 src: /127.0.0.1:54252 dest: /127.0.0.1:39132
2020-12-03 07:19:45,001 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:59990 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 src: /127.0.0.1:59990 dest: /127.0.0.1:35590
2020-12-03 07:19:45,007 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,009 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51042 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 src: /127.0.0.1:51042 dest: /127.0.0.1:37179
2020-12-03 07:19:45,012 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,033 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,053 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53762 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002 src: /127.0.0.1:53762 dest: /127.0.0.1:37038
2020-12-03 07:19:45,055 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:32784 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 src: /127.0.0.1:32784 dest: /127.0.0.1:38186
2020-12-03 07:19:45,109 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53360 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002 src: /127.0.0.1:53360 dest: /127.0.0.1:35607
2020-12-03 07:19:45,385 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54252, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002, duration(ns): 373082963
2020-12-03 07:19:45,385 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,392 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59990, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002, duration(ns): 369267260
2020-12-03 07:19:45,392 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,410 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40300, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002, duration(ns): 404531580
2020-12-03 07:19:45,410 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,417 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53762, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002, duration(ns): 326662644
2020-12-03 07:19:45,417 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53360, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002, duration(ns): 287709763
2020-12-03 07:19:45,417 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,418 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,418 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51042, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002, duration(ns): 373533343
2020-12-03 07:19:45,418 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,420 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55456, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002, duration(ns): 420184379
2020-12-03 07:19:45,420 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37188, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002, duration(ns): 408914726
2020-12-03 07:19:45,421 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32784, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002, duration(ns): 307120529
2020-12-03 07:19:45,434 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,420 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,434 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,471 [IPC Server handler 0 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:35494, 127.0.0.1:38186, 127.0.0.1:39132, 127.0.0.1:45518, 127.0.0.1:37038, 127.0.0.1:37179, 127.0.0.1:35504, 127.0.0.1:35607, 127.0.0.1:45951 for /striped/stripedFileChecksum1
2020-12-03 07:19:45,477 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,479 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,479 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40594 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003 src: /127.0.0.1:40594 dest: /127.0.0.1:35494
2020-12-03 07:19:45,481 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:32884 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003 src: /127.0.0.1:32884 dest: /127.0.0.1:38186
2020-12-03 07:19:45,482 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,484 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,484 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,484 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45148 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003 src: /127.0.0.1:45148 dest: /127.0.0.1:45518
2020-12-03 07:19:45,485 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,526 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53866 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003 src: /127.0.0.1:53866 dest: /127.0.0.1:37038
2020-12-03 07:19:45,526 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51164 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003 src: /127.0.0.1:51164 dest: /127.0.0.1:37179
2020-12-03 07:19:45,526 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54382 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003 src: /127.0.0.1:54382 dest: /127.0.0.1:39132
2020-12-03 07:19:45,542 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,555 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,562 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,564 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55606 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003 src: /127.0.0.1:55606 dest: /127.0.0.1:35504
2020-12-03 07:19:45,565 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40462 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003 src: /127.0.0.1:40462 dest: /127.0.0.1:45951
2020-12-03 07:19:45,565 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53482 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003 src: /127.0.0.1:53482 dest: /127.0.0.1:35607
2020-12-03 07:19:45,892 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55606, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003, duration(ns): 313234719
2020-12-03 07:19:45,892 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,944 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53866, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003, duration(ns): 374059768
2020-12-03 07:19:45,944 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32884, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003, duration(ns): 457931806
2020-12-03 07:19:45,945 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54382, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003, duration(ns): 402511878
2020-12-03 07:19:45,944 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51164, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003, duration(ns): 350712893
2020-12-03 07:19:45,945 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,945 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,945 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,947 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,985 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45148, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003, duration(ns): 412242826
2020-12-03 07:19:45,986 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40462, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003, duration(ns): 349966510
2020-12-03 07:19:45,986 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,986 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,993 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40594, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003, duration(ns): 418582894
2020-12-03 07:19:46,016 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,019 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53482, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003, duration(ns): 307478205
2020-12-03 07:19:46,019 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,029 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775744_1004, replicas=127.0.0.1:45951, 127.0.0.1:39022, 127.0.0.1:45518, 127.0.0.1:35590, 127.0.0.1:39132, 127.0.0.1:37179, 127.0.0.1:38186, 127.0.0.1:37038, 127.0.0.1:35504 for /striped/stripedFileChecksum1
2020-12-03 07:19:46,048 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,050 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,060 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,064 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,064 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45308 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004 src: /127.0.0.1:45308 dest: /127.0.0.1:45518
2020-12-03 07:19:46,064 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:37480 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004 src: /127.0.0.1:37480 dest: /127.0.0.1:39022
2020-12-03 07:19:46,064 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40588 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004 src: /127.0.0.1:40588 dest: /127.0.0.1:45951
2020-12-03 07:19:46,066 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,100 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54544 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004 src: /127.0.0.1:54544 dest: /127.0.0.1:39132
2020-12-03 07:19:46,141 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60272 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004 src: /127.0.0.1:60272 dest: /127.0.0.1:35590
2020-12-03 07:19:46,151 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,153 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51324 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004 src: /127.0.0.1:51324 dest: /127.0.0.1:37179
2020-12-03 07:19:46,156 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,171 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,182 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54032 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004 src: /127.0.0.1:54032 dest: /127.0.0.1:37038
2020-12-03 07:19:46,187 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:33054 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004 src: /127.0.0.1:33054 dest: /127.0.0.1:38186
2020-12-03 07:19:46,192 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,235 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55766 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004 src: /127.0.0.1:55766 dest: /127.0.0.1:35504
2020-12-03 07:19:46,556 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40588, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004, duration(ns): 477808257
2020-12-03 07:19:46,557 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,570 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54032, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004, duration(ns): 377104087
2020-12-03 07:19:46,579 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,570 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51324, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004, duration(ns): 376721710
2020-12-03 07:19:46,595 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,581 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55766, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004, duration(ns): 316537513
2020-12-03 07:19:46,599 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,604 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54544, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004, duration(ns): 419323886
2020-12-03 07:19:46,620 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,604 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45308, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004, duration(ns): 464799795
2020-12-03 07:19:46,624 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,630 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37480, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004, duration(ns): 440571595
2020-12-03 07:19:46,631 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,632 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60272, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004, duration(ns): 446006289
2020-12-03 07:19:46,632 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,648 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33054, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004, duration(ns): 320879333
2020-12-03 07:19:46,649 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,655 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775728_1005, replicas=127.0.0.1:45951, 127.0.0.1:35504, 127.0.0.1:35494, 127.0.0.1:39022, 127.0.0.1:39132, 127.0.0.1:45518, 127.0.0.1:35590, 127.0.0.1:37179, 127.0.0.1:37038 for /striped/stripedFileChecksum1
2020-12-03 07:19:46,662 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,664 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40714 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005 src: /127.0.0.1:40714 dest: /127.0.0.1:45951
2020-12-03 07:19:46,702 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,705 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,710 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,717 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40886 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005 src: /127.0.0.1:40886 dest: /127.0.0.1:35494
2020-12-03 07:19:46,732 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55872 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005 src: /127.0.0.1:55872 dest: /127.0.0.1:35504
2020-12-03 07:19:46,763 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,763 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,769 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:37612 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005 src: /127.0.0.1:37612 dest: /127.0.0.1:39022
2020-12-03 07:19:46,769 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54684 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005 src: /127.0.0.1:54684 dest: /127.0.0.1:39132
2020-12-03 07:19:46,769 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45452 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005 src: /127.0.0.1:45452 dest: /127.0.0.1:45518
2020-12-03 07:19:46,780 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,790 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60418 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005 src: /127.0.0.1:60418 dest: /127.0.0.1:35590
2020-12-03 07:19:46,801 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,808 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,808 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51470 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005 src: /127.0.0.1:51470 dest: /127.0.0.1:37179
2020-12-03 07:19:46,812 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54180 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005 src: /127.0.0.1:54180 dest: /127.0.0.1:37038
2020-12-03 07:19:47,134 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40886, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005, duration(ns): 362266274
2020-12-03 07:19:47,135 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,148 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54684, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005, duration(ns): 322443902
2020-12-03 07:19:47,148 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,149 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37612, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005, duration(ns): 321889366
2020-12-03 07:19:47,149 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45452, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005, duration(ns): 321112831
2020-12-03 07:19:47,149 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,149 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,161 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51470, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005, duration(ns): 278717970
2020-12-03 07:19:47,162 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,162 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60418, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005, duration(ns): 280476578
2020-12-03 07:19:47,163 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,164 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55872, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005, duration(ns): 325703430
2020-12-03 07:19:47,165 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,165 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54180, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005, duration(ns): 277845927
2020-12-03 07:19:47,166 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,168 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40714, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005, duration(ns): 436815716
2020-12-03 07:19:47,168 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,175 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775712_1006, replicas=127.0.0.1:35590, 127.0.0.1:35494, 127.0.0.1:45951, 127.0.0.1:39022, 127.0.0.1:35607, 127.0.0.1:38186, 127.0.0.1:35504, 127.0.0.1:45518, 127.0.0.1:37179 for /striped/stripedFileChecksum1
2020-12-03 07:19:47,183 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,184 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,184 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60524 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006 src: /127.0.0.1:60524 dest: /127.0.0.1:35590
2020-12-03 07:19:47,186 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41014 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006 src: /127.0.0.1:41014 dest: /127.0.0.1:35494
2020-12-03 07:19:47,186 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,189 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,194 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:37744 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006 src: /127.0.0.1:37744 dest: /127.0.0.1:39022
2020-12-03 07:19:47,195 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,197 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40850 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006 src: /127.0.0.1:40850 dest: /127.0.0.1:45951
2020-12-03 07:19:47,197 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,197 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53882 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006 src: /127.0.0.1:53882 dest: /127.0.0.1:35607
2020-12-03 07:19:47,199 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:33314 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006 src: /127.0.0.1:33314 dest: /127.0.0.1:38186
2020-12-03 07:19:47,205 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,220 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:56018 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006 src: /127.0.0.1:56018 dest: /127.0.0.1:35504
2020-12-03 07:19:47,228 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,229 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,231 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45584 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006 src: /127.0.0.1:45584 dest: /127.0.0.1:45518
2020-12-03 07:19:47,231 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51596 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006 src: /127.0.0.1:51596 dest: /127.0.0.1:37179
2020-12-03 07:19:47,495 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45584, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006, duration(ns): 256053981
2020-12-03 07:19:47,495 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40850, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006, duration(ns): 296642685
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,495 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51596, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006, duration(ns): 261953045
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33314, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006, duration(ns): 282591314
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,495 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37744, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006, duration(ns): 286573482
2020-12-03 07:19:47,496 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60524, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006, duration(ns): 302131277
2020-12-03 07:19:47,501 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,501 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56018, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006, duration(ns): 265629452
2020-12-03 07:19:47,503 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53882, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006, duration(ns): 297246210
2020-12-03 07:19:47,504 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,505 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,501 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,516 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41014, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006, duration(ns): 304086073
2020-12-03 07:19:47,528 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,531 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775696_1007, replicas=127.0.0.1:37038, 127.0.0.1:45951, 127.0.0.1:35607, 127.0.0.1:37179, 127.0.0.1:35494, 127.0.0.1:35590, 127.0.0.1:39022, 127.0.0.1:35504, 127.0.0.1:45518 for /striped/stripedFileChecksum1
2020-12-03 07:19:47,537 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,541 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,542 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54390 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007 src: /127.0.0.1:54390 dest: /127.0.0.1:37038
2020-12-03 07:19:47,544 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:40962 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007 src: /127.0.0.1:40962 dest: /127.0.0.1:45951
2020-12-03 07:19:47,550 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,552 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:53988 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007 src: /127.0.0.1:53988 dest: /127.0.0.1:35607
2020-12-03 07:19:47,555 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,559 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,565 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41134 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007 src: /127.0.0.1:41134 dest: /127.0.0.1:35494
2020-12-03 07:19:47,565 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51692 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007 src: /127.0.0.1:51692 dest: /127.0.0.1:37179
2020-12-03 07:19:47,572 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,588 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60648 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007 src: /127.0.0.1:60648 dest: /127.0.0.1:35590
2020-12-03 07:19:47,598 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,600 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:37862 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007 src: /127.0.0.1:37862 dest: /127.0.0.1:39022
2020-12-03 07:19:47,604 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,610 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,614 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:56134 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007 src: /127.0.0.1:56134 dest: /127.0.0.1:35504
2020-12-03 07:19:47,614 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45700 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007 src: /127.0.0.1:45700 dest: /127.0.0.1:45518
2020-12-03 07:19:48,111 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54390, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007, duration(ns): 560948837
2020-12-03 07:19:48,111 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51692, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007, duration(ns): 536224570
2020-12-03 07:19:48,111 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45700, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007, duration(ns): 492377207
2020-12-03 07:19:48,112 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40962, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007, duration(ns): 561429703
2020-12-03 07:19:48,112 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,112 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,112 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,113 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37862, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007, duration(ns): 506968037
2020-12-03 07:19:48,113 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56134, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007, duration(ns): 496453845
2020-12-03 07:19:48,113 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60648, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007, duration(ns): 519990125
2020-12-03 07:19:48,113 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,112 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,114 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,113 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,114 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41134, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007, duration(ns): 541764903
2020-12-03 07:19:48,115 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,115 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53988, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007, duration(ns): 559596089
2020-12-03 07:19:48,116 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,136 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775680_1008, replicas=127.0.0.1:39132, 127.0.0.1:35590, 127.0.0.1:35607, 127.0.0.1:37038, 127.0.0.1:35504, 127.0.0.1:45951, 127.0.0.1:39022, 127.0.0.1:45518, 127.0.0.1:37179 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,142 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,145 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,145 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55150 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008 src: /127.0.0.1:55150 dest: /127.0.0.1:39132
2020-12-03 07:19:48,147 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:60886 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008 src: /127.0.0.1:60886 dest: /127.0.0.1:35590
2020-12-03 07:19:48,150 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,153 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,156 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54650 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008 src: /127.0.0.1:54650 dest: /127.0.0.1:37038
2020-12-03 07:19:48,156 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54240 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008 src: /127.0.0.1:54240 dest: /127.0.0.1:35607
2020-12-03 07:19:48,157 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,158 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:56378 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008 src: /127.0.0.1:56378 dest: /127.0.0.1:35504
2020-12-03 07:19:48,162 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,164 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41230 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008 src: /127.0.0.1:41230 dest: /127.0.0.1:45951
2020-12-03 07:19:48,175 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,177 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:38136 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008 src: /127.0.0.1:38136 dest: /127.0.0.1:39022
2020-12-03 07:19:48,178 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,186 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:45966 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008 src: /127.0.0.1:45966 dest: /127.0.0.1:45518
2020-12-03 07:19:48,191 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,194 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:51982 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008 src: /127.0.0.1:51982 dest: /127.0.0.1:37179
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55150, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008, duration(ns): 281049652
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60886, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008, duration(ns): 279355605
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41230, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008, duration(ns): 260465141
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54650, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008, duration(ns): 269971725
2020-12-03 07:19:48,430 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38136, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008, duration(ns): 242581686
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45966, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008, duration(ns): 240067114
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54240, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008, duration(ns): 260377814
2020-12-03 07:19:48,432 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56378, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008, duration(ns): 268022324
2020-12-03 07:19:48,432 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,432 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,429 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51982, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008, duration(ns): 231250355
2020-12-03 07:19:48,435 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,433 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,442 [IPC Server handler 2 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775664_1009, replicas=127.0.0.1:35494, 127.0.0.1:38186, 127.0.0.1:45951, 127.0.0.1:35590, 127.0.0.1:37179, 127.0.0.1:37038, 127.0.0.1:35504, 127.0.0.1:45518, 127.0.0.1:39022 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,448 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,450 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41552 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009 src: /127.0.0.1:41552 dest: /127.0.0.1:35494
2020-12-03 07:19:48,452 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,454 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,455 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:33842 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009 src: /127.0.0.1:33842 dest: /127.0.0.1:38186
2020-12-03 07:19:48,456 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41390 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009 src: /127.0.0.1:41390 dest: /127.0.0.1:45951
2020-12-03 07:19:48,456 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,460 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:32838 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009 src: /127.0.0.1:32838 dest: /127.0.0.1:35590
2020-12-03 07:19:48,460 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,462 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:52122 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009 src: /127.0.0.1:52122 dest: /127.0.0.1:37179
2020-12-03 07:19:48,463 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,465 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54828 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009 src: /127.0.0.1:54828 dest: /127.0.0.1:37038
2020-12-03 07:19:48,496 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,498 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:56572 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009 src: /127.0.0.1:56572 dest: /127.0.0.1:35504
2020-12-03 07:19:48,498 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,499 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:46136 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009 src: /127.0.0.1:46136 dest: /127.0.0.1:45518
2020-12-03 07:19:48,508 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,509 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:38312 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009 src: /127.0.0.1:38312 dest: /127.0.0.1:39022
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33842, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009, duration(ns): 193926399
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56572, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009, duration(ns): 162103464
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38312, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009, duration(ns): 150243344
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41552, dest: /127.0.0.1:35494, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 6fde81a4-289b-4295-8406-6637e46e6aa2, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009, duration(ns): 196040931
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32838, dest: /127.0.0.1:35590, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009, duration(ns): 196415263
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41390, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009, duration(ns): 181108265
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54828, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009, duration(ns): 182656737
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46136, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009, duration(ns): 161200710
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52122, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009, duration(ns): 182337034
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,662 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,663 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,671 [IPC Server handler 7 on default port 33068] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775648_1010, replicas=127.0.0.1:38186, 127.0.0.1:39022, 127.0.0.1:35607, 127.0.0.1:45518, 127.0.0.1:45951, 127.0.0.1:35504, 127.0.0.1:37038, 127.0.0.1:37179, 127.0.0.1:39132 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,678 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,679 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:33970 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010 src: /127.0.0.1:33970 dest: /127.0.0.1:38186
2020-12-03 07:19:48,680 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,681 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:38412 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010 src: /127.0.0.1:38412 dest: /127.0.0.1:39022
2020-12-03 07:19:48,682 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,684 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,685 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:46248 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010 src: /127.0.0.1:46248 dest: /127.0.0.1:45518
2020-12-03 07:19:48,685 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54552 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010 src: /127.0.0.1:54552 dest: /127.0.0.1:35607
2020-12-03 07:19:48,691 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,692 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,693 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:41546 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010 src: /127.0.0.1:41546 dest: /127.0.0.1:45951
2020-12-03 07:19:48,694 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:56704 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010 src: /127.0.0.1:56704 dest: /127.0.0.1:35504
2020-12-03 07:19:48,704 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,706 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:54994 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010 src: /127.0.0.1:54994 dest: /127.0.0.1:37038
2020-12-03 07:19:48,707 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,709 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:52300 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010 src: /127.0.0.1:52300 dest: /127.0.0.1:37179
2020-12-03 07:19:48,710 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,711 [DataXceiver for client DFSClient_NONMAPREDUCE_401154611_1 at /127.0.0.1:55532 [Receiving block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010 src: /127.0.0.1:55532 dest: /127.0.0.1:39132
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56704, dest: /127.0.0.1:35504, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: f8147b50-fa2c-49a6-af1f-3f8e63395129, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010, duration(ns): 166785274
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38412, dest: /127.0.0.1:39022, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d85b61b3-ef21-4772-acfd-077b1a8d8394, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010, duration(ns): 180994600
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55532, dest: /127.0.0.1:39132, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 29316998-18c6-4068-af30-b4ef5dd9b939, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010, duration(ns): 150968671
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41546, dest: /127.0.0.1:45951, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 53fc9ac1-3951-4eae-baef-413586f8057e, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010, duration(ns): 169283082
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54552, dest: /127.0.0.1:35607, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d5f73667-91cd-4934-8423-541b27f4a3de, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010, duration(ns): 177513930
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52300, dest: /127.0.0.1:37179, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 90ad47e9-9fe2-4fc3-bfcf-6019048261b1, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010, duration(ns): 152994195
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46248, dest: /127.0.0.1:45518, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: d0cea7f3-b94e-46be-8cab-ab9b066065fe, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010, duration(ns): 177016736
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54994, dest: /127.0.0.1:37038, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: 1ddb58c3-7b1b-4718-8522-82dab72ae09b, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010, duration(ns): 156345481
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33970, dest: /127.0.0.1:38186, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401154611_1, offset: 0, srvID: b1c23357-dcda-435c-8e01-8e989d3f9601, blockid: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010, duration(ns): 182840906
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,866 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,865 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,864 [PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,872 [IPC Server handler 7 on default port 33068] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /striped/stripedFileChecksum1 is closed by DFSClient_NONMAPREDUCE_401154611_1
2020-12-03 07:19:48,894 [IPC Server handler 3 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,929 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-45973715-37be-4d46-9516-7d0ea92ed50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:48,982 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:extractChecksumProperties(430)) - set bytesPerCRC=512, crcPerBlock=12288
2020-12-03 07:19:48,983 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK]: blockChecksum=e199faa66ca34a63cc13e2c4448e3716, blockChecksumType=MD5CRC
2020-12-03 07:19:48,983 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,007 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK]: blockChecksum=4b648ddfb75e52fc4ab8acf75e7116cf, blockChecksumType=MD5CRC
2020-12-03 07:19:49,008 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-1cc92295-b44a-444b-884d-567c2848ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-c0a5f938-ab86-441e-a74e-7e98d06730d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,026 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK]: blockChecksum=67708555cca0bd9ee68540924fa61776, blockChecksumType=MD5CRC
2020-12-03 07:19:49,026 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775744_1004; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-df1c0970-3a20-4d55-bcb1-b18c363404df,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,043 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK]: blockChecksum=4b0b124b13c998a25d246802f733b088, blockChecksumType=MD5CRC
2020-12-03 07:19:49,044 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775728_1005; getBlockSize()=37748736; corrupt=false; offset=150994944; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-45973715-37be-4d46-9516-7d0ea92ed50a,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-1cc92295-b44a-444b-884d-567c2848ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,069 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK]: blockChecksum=51cd424ab95d87cdb83537c2851632ce, blockChecksumType=MD5CRC
2020-12-03 07:19:49,070 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775712_1006; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-df1c0970-3a20-4d55-bcb1-b18c363404df,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,106 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK]: blockChecksum=89aa04e67e713dc683b754d2f2ef667b, blockChecksumType=MD5CRC
2020-12-03 07:19:49,107 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775696_1007; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-c0a5f938-ab86-441e-a74e-7e98d06730d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-45973715-37be-4d46-9516-7d0ea92ed50a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-1cc92295-b44a-444b-884d-567c2848ebbe,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,123 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK]: blockChecksum=dfe7bac951dcb0667d7f7df4eb6cf90a, blockChecksumType=MD5CRC
2020-12-03 07:19:49,124 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775680_1008; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-df1c0970-3a20-4d55-bcb1-b18c363404df,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,144 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK]: blockChecksum=9c3cec3f3a04864d00f8b7af0c6afe6d, blockChecksumType=MD5CRC
2020-12-03 07:19:49,144 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775664_1009; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-11a59c2b-5f15-4182-99d7-cd928d304916,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-1cc92295-b44a-444b-884d-567c2848ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,160 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:35494,DS-511acede-de90-4fdf-adb8-34c074eb66c4,DISK]: blockChecksum=eacc1d4fa7716608ec43c4a99fd6b039, blockChecksumType=MD5CRC
2020-12-03 07:19:49,161 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775648_1010; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-df1c0970-3a20-4d55-bcb1-b18c363404df,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-c0a5f938-ab86-441e-a74e-7e98d06730d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,187 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK]: blockChecksum=a4830341f63278de9908fee2c7e00eef, blockChecksumType=MD5CRC
2020-12-03 07:19:49,195 [IPC Server handler 0 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:49,201 [Thread-417] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,204 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5a12c728] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,207 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-11a59c2b-5f15-4182-99d7-cd928d304916) exiting.
2020-12-03 07:19:49,207 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1019b683-5ef4-49eb-bf6a-bfffd846ff51) exiting.
2020-12-03 07:19:49,271 [Thread-417] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f2d2181{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,277 [Thread-417] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49bf29c6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,281 [Thread-417] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fb68ec6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,283 [Thread-417] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@492fc69e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,294 [Thread-417] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37074
2020-12-03 07:19:49,314 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,315 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,325 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,325 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 53fc9ac1-3951-4eae-baef-413586f8057e) service to localhost/127.0.0.1:33068
2020-12-03 07:19:49,326 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 53fc9ac1-3951-4eae-baef-413586f8057e)
2020-12-03 07:19:49,326 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:49,328 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,328 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,336 [Thread-417] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,336 [Thread-417] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,337 [Thread-417] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,337 [Thread-417] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,346 [Thread-417] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,348 [Thread-417] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:45951, removeBlocksFromBlockMap true
2020-12-03 07:19:49,352 [Thread-417] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:45951
2020-12-03 07:19:49,365 [IPC Server handler 6 on default port 33068] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:49,376 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-45973715-37be-4d46-9516-7d0ea92ed50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-c94ed69f-d0d6-497a-a0e3-319dd1660919,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-49e3219b-40ed-4f88-bc50-839433223d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-82870e1d-b232-4d81-a859-1b455f784120,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0d497f2e-afaf-4667-a680-93ed3b5544ff,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}
2020-12-03 07:19:49,399 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:extractChecksumProperties(430)) - set bytesPerCRC=512, crcPerBlock=12288
2020-12-03 07:19:49,399 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39132,DS-496c99a4-9c42-4795-ab05-26b41a1c7696,DISK]: blockChecksum=e199faa66ca34a63cc13e2c4448e3716, blockChecksumType=MD5CRC
2020-12-03 07:19:49,400 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,415 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,442 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,445 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,447 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,449 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,451 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,462 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[0]=DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,462 [DataXceiver for client /127.0.0.1:39018 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:39018 dst: /127.0.0.1:39022
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,469 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,474 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,477 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,480 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,482 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,483 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,491 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,500 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[1]=DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,504 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,505 [DataXceiver for client /127.0.0.1:57318 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:57318 dst: /127.0.0.1:35504
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,511 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,516 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,518 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,520 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,521 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,523 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,613 [DataXceiver for client /127.0.0.1:56132 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:56132 dst: /127.0.0.1:39132
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,614 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[2]=DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,615 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,622 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,629 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,631 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,641 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,645 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,647 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,668 [DataXceiver for client /127.0.0.1:52962 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:52962 dst: /127.0.0.1:37179
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,668 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[3]=DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,671 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,682 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,689 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,696 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,701 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,703 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,708 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,714 [DataXceiver for client /127.0.0.1:33716 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:33716 dst: /127.0.0.1:35590
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,714 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[4]=DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,718 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,723 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,730 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,732 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,738 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,745 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,750 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,772 [DataXceiver for client /127.0.0.1:34758 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:34758 dst: /127.0.0.1:38186
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,780 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[5]=DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,783 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,788 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,802 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,805 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,806 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,808 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,809 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,816 [DataXceiver for client /127.0.0.1:55780 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37038:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:55780 dst: /127.0.0.1:37038
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,816 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[6]=DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,821 [Thread-417] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-9d78baa6-1945-43eb-8689-8827bac14d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ea22c840-87f2-48ce-8f13-7cb74470fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-0639ba98-7aec-4136-8d58-21ae277f1908,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-949c0406-6db1-4ef3-bb39-80b03217bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-25ef4552-87b3-49fc-9514-397b5b72979d,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,824 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,826 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,828 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,829 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,831 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,832 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,837 [DataXceiver for client /127.0.0.1:55390 [Getting checksum for block groupBP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35607:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:55390 dst: /127.0.0.1:35607
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,837 [Thread-417] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[7]=DatanodeInfoWithStorage[127.0.0.1:35607,DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,840 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:19:49,843 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:19:49,843 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,843 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7d2a6eac] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-49e3219b-40ed-4f88-bc50-839433223d0b) exiting.
2020-12-03 07:19:49,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-9d78baa6-1945-43eb-8689-8827bac14d05) exiting.
2020-12-03 07:19:49,904 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c1e23ff{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,905 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ceb4bd2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,906 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4163f1cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,906 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@88a8218{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,910 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42882
2020-12-03 07:19:49,911 [DataXceiver for client  at /127.0.0.1:57446 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,911 [DataXceiver for client  at /127.0.0.1:57348 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,911 [DataXceiver for client  at /127.0.0.1:57398 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,911 [DataXceiver for client  at /127.0.0.1:57526 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,918 [DataXceiver for client  at /127.0.0.1:57472 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,927 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,927 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,926 [DataXceiver for client  at /127.0.0.1:57328 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,926 [DataXceiver for client  at /127.0.0.1:57302 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,918 [DataXceiver for client  at /127.0.0.1:57526 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,918 [DataXceiver for client  at /127.0.0.1:57510 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,934 [DataXceiver for client  at /127.0.0.1:57526 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57526
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,932 [DataXceiver for client  at /127.0.0.1:57302 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,930 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid f8147b50-fa2c-49a6-af1f-3f8e63395129) service to localhost/127.0.0.1:33068
2020-12-03 07:19:49,935 [DataXceiver for client  at /127.0.0.1:57328 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,935 [DataXceiver for client  at /127.0.0.1:57302 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57302
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,936 [DataXceiver for client  at /127.0.0.1:57328 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57328
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,936 [DataXceiver for client  at /127.0.0.1:57472 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,936 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid f8147b50-fa2c-49a6-af1f-3f8e63395129)
2020-12-03 07:19:49,940 [DataXceiver for client  at /127.0.0.1:57472 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57472
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,939 [DataXceiver for client  at /127.0.0.1:57446 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,941 [DataXceiver for client  at /127.0.0.1:57348 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,942 [DataXceiver for client  at /127.0.0.1:57446 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57446
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,942 [DataXceiver for client  at /127.0.0.1:57348 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57348
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,942 [DataXceiver for client  at /127.0.0.1:57398 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,945 [DataXceiver for client  at /127.0.0.1:57510 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 on DS-9d78baa6-1945-43eb-8689-8827bac14d05, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,946 [DataXceiver for client  at /127.0.0.1:57398 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57398
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,945 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:49,946 [DataXceiver for client  at /127.0.0.1:57510 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35504, datanodeUuid=f8147b50-fa2c-49a6-af1f-3f8e63395129, infoPort=44398, infoSecurePort=0, ipcPort=42882, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002 to /127.0.0.1:57510
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57302 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57302 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57328 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57328 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57472 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57472 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57446 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57446 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57348 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57348 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57526 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57526 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,951 [DataXceiver for client  at /127.0.0.1:57398 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57398 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,950 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,960 [DataXceiver for client  at /127.0.0.1:57510 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775774_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35504:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:57510 dst: /127.0.0.1:35504
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,959 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,980 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,984 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,993 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,996 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,996 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:19:49,997 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,997 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6c2d4cc6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,000 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0639ba98-7aec-4136-8d58-21ae277f1908) exiting.
2020-12-03 07:19:50,000 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0d497f2e-afaf-4667-a680-93ed3b5544ff) exiting.
2020-12-03 07:19:50,025 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 90ad47e9-9fe2-4fc3-bfcf-6019048261b1) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,025 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 90ad47e9-9fe2-4fc3-bfcf-6019048261b1)
2020-12-03 07:19:50,025 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,026 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,027 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,028 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6594402a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,029 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30f4b1a6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,030 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22175d4f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,030 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,031 [DataXceiver for client  at /127.0.0.1:52924 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,035 [DataXceiver for client  at /127.0.0.1:52878 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,035 [DataXceiver for client  at /127.0.0.1:52904 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,032 [DataXceiver for client  at /127.0.0.1:53056 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,032 [DataXceiver for client  at /127.0.0.1:53102 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,032 [DataXceiver for client  at /127.0.0.1:53024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,032 [DataXceiver for client  at /127.0.0.1:53086 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,031 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41795
2020-12-03 07:19:50,038 [DataXceiver for client  at /127.0.0.1:52924 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,049 [DataXceiver for client  at /127.0.0.1:52924 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:52924
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,051 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,053 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,054 [DataXceiver for client  at /127.0.0.1:52924 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:52924 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,051 [DataXceiver for client  at /127.0.0.1:53086 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,062 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,064 [DataXceiver for client  at /127.0.0.1:53086 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:53086
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,064 [DataXceiver for client  at /127.0.0.1:53024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,065 [DataXceiver for client  at /127.0.0.1:53102 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,065 [DataXceiver for client  at /127.0.0.1:53086 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53086 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,084 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,084 [DataXceiver for client  at /127.0.0.1:53102 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:53102
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,084 [DataXceiver for client  at /127.0.0.1:53056 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,084 [DataXceiver for client  at /127.0.0.1:53024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:53024
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,087 [DataXceiver for client  at /127.0.0.1:52904 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,087 [DataXceiver for client  at /127.0.0.1:53102 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53102 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,093 [DataXceiver for client  at /127.0.0.1:52904 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:52904
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,087 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,097 [DataXceiver for client  at /127.0.0.1:52904 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:52904 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,093 [DataXceiver for client  at /127.0.0.1:52878 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 on DS-0639ba98-7aec-4136-8d58-21ae277f1908, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,104 [DataXceiver for client  at /127.0.0.1:52878 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:52878
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,091 [DataXceiver for client  at /127.0.0.1:53056 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37179, datanodeUuid=90ad47e9-9fe2-4fc3-bfcf-6019048261b1, infoPort=41274, infoSecurePort=0, ipcPort=41795, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002 to /127.0.0.1:53056
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,104 [DataXceiver for client  at /127.0.0.1:53056 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53056 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,089 [DataXceiver for client  at /127.0.0.1:53024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53024 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,104 [DataXceiver for client  at /127.0.0.1:52878 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37179:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:52878 dst: /127.0.0.1:37179
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,097 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,130 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,130 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:19:50,131 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,131 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bbbdd4b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-25ef4552-87b3-49fc-9514-397b5b72979d) exiting.
2020-12-03 07:19:50,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-ee1c4d00-92d9-487d-8ec8-7b77e0b23f0e) exiting.
2020-12-03 07:19:50,160 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2237bada{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,161 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77e2a6e2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,161 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@315ba14a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,162 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a6d5a8f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,164 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34087
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34708 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34834 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34756 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34658 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34610 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34636 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34818 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34794 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,180 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,180 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,179 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,164 [DataXceiver for client  at /127.0.0.1:34708 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,181 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid b1c23357-dcda-435c-8e01-8e989d3f9601) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,184 [DataXceiver for client  at /127.0.0.1:34708 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34708
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,184 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid b1c23357-dcda-435c-8e01-8e989d3f9601)
2020-12-03 07:19:50,184 [DataXceiver for client  at /127.0.0.1:34794 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,185 [DataXceiver for client  at /127.0.0.1:34708 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34708 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,189 [DataXceiver for client  at /127.0.0.1:34794 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34794
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,188 [DataXceiver for client  at /127.0.0.1:34818 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,195 [DataXceiver for client  at /127.0.0.1:34636 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,195 [DataXceiver for client  at /127.0.0.1:34818 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34818
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,199 [DataXceiver for client  at /127.0.0.1:34636 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34636
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,199 [DataXceiver for client  at /127.0.0.1:34610 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,199 [DataXceiver for client  at /127.0.0.1:34794 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34794 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,205 [DataXceiver for client  at /127.0.0.1:34610 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34610
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,205 [DataXceiver for client  at /127.0.0.1:34658 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,211 [DataXceiver for client  at /127.0.0.1:34756 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,202 [DataXceiver for client  at /127.0.0.1:34636 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34636 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,199 [DataXceiver for client  at /127.0.0.1:34818 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34818 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,219 [DataXceiver for client  at /127.0.0.1:34658 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34658
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,214 [DataXceiver for client  at /127.0.0.1:34756 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34756
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,214 [DataXceiver for client  at /127.0.0.1:34834 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 on DS-25ef4552-87b3-49fc-9514-397b5b72979d, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,214 [DataXceiver for client  at /127.0.0.1:34610 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34610 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,248 [DataXceiver for client  at /127.0.0.1:34756 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34756 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,248 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,249 [DataXceiver for client  at /127.0.0.1:34834 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38186, datanodeUuid=b1c23357-dcda-435c-8e01-8e989d3f9601, infoPort=41378, infoSecurePort=0, ipcPort=34087, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002 to /127.0.0.1:34834
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,241 [DataXceiver for client  at /127.0.0.1:34658 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34658 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,249 [DataXceiver for client  at /127.0.0.1:34834 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38186:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:34834 dst: /127.0.0.1:38186
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,253 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,254 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,280 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,280 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,283 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,283 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,287 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,287 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:19:50,287 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:50,288 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37074
2020-12-03 07:19:50,288 [Listener at localhost/42882] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-53fc9ac1-3951-4eae-baef-413586f8057e
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-53fc9ac1-3951-4eae-baef-413586f8057e
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.TestFileChecksum.tearDown(TestFileChecksum.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:50,289 [Listener at localhost/42882] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:50,289 [Listener at localhost/42882] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:50,291 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,291 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:19:50,291 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,291 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@e041f0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,294 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-c0a5f938-ab86-441e-a74e-7e98d06730d3) exiting.
2020-12-03 07:19:50,294 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-1bce2bb9-c2d2-4900-b7cd-071cdd011fd0) exiting.
2020-12-03 07:19:50,385 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@308a6984{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,387 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@66b72664{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,387 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f325091{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,388 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a71c100{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,389 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33550
2020-12-03 07:19:50,390 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,391 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,391 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d5f73667-91cd-4934-8423-541b27f4a3de) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,391 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d5f73667-91cd-4934-8423-541b27f4a3de)
2020-12-03 07:19:50,391 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,391 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,399 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,401 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,401 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,401 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,404 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,404 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,409 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,410 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:19:50,410 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,410 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1deb2c43] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,414 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-ea22c840-87f2-48ce-8f13-7cb74470fabe) exiting.
2020-12-03 07:19:50,414 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-496c99a4-9c42-4795-ab05-26b41a1c7696) exiting.
2020-12-03 07:19:50,448 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@106faf11{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,449 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70f43b45{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,450 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e53135d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,450 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ca320ab{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,451 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41207
2020-12-03 07:19:50,451 [DataXceiver for client  at /127.0.0.1:56242 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,452 [DataXceiver for client  at /127.0.0.1:56144 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,452 [DataXceiver for client  at /127.0.0.1:56270 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,461 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,452 [DataXceiver for client  at /127.0.0.1:56194 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,451 [DataXceiver for client  at /127.0.0.1:56306 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,462 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 29316998-18c6-4068-af30-b4ef5dd9b939) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,461 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,461 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,461 [DataXceiver for client  at /127.0.0.1:56242 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,456 [DataXceiver for client  at /127.0.0.1:56098 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,460 [DataXceiver for client  at /127.0.0.1:56124 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,467 [DataXceiver for client  at /127.0.0.1:56242 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56242
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,463 [DataXceiver for client  at /127.0.0.1:56306 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,462 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 29316998-18c6-4068-af30-b4ef5dd9b939)
2020-12-03 07:19:50,472 [DataXceiver for client  at /127.0.0.1:56242 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56242 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,468 [DataXceiver for client  at /127.0.0.1:56306 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56306
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,468 [DataXceiver for client  at /127.0.0.1:56194 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,480 [DataXceiver for client  at /127.0.0.1:56306 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56306 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,480 [DataXceiver for client  at /127.0.0.1:56270 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,484 [DataXceiver for client  at /127.0.0.1:56194 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56194
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,491 [DataXceiver for client  at /127.0.0.1:56270 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56270
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,491 [DataXceiver for client  at /127.0.0.1:56194 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56194 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,491 [DataXceiver for client  at /127.0.0.1:56144 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,495 [DataXceiver for client  at /127.0.0.1:56270 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56270 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,502 [DataXceiver for client  at /127.0.0.1:56144 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56144
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,502 [DataXceiver for client  at /127.0.0.1:56124 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,502 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,511 [DataXceiver for client  at /127.0.0.1:56124 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56124
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,511 [DataXceiver for client  at /127.0.0.1:56098 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 on DS-ea22c840-87f2-48ce-8f13-7cb74470fabe, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,511 [DataXceiver for client  at /127.0.0.1:56144 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56144 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,514 [DataXceiver for client  at /127.0.0.1:56098 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39132, datanodeUuid=29316998-18c6-4068-af30-b4ef5dd9b939, infoPort=37963, infoSecurePort=0, ipcPort=41207, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002 to /127.0.0.1:56098
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,514 [DataXceiver for client  at /127.0.0.1:56124 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56124 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,520 [DataXceiver for client  at /127.0.0.1:56098 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39132:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56098 dst: /127.0.0.1:39132
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,538 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,544 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,552 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,553 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,555 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,556 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,564 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,564 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:19:50,565 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,565 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68ed96ca] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,570 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-1cc92295-b44a-444b-884d-567c2848ebbe) exiting.
2020-12-03 07:19:50,570 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-82870e1d-b232-4d81-a859-1b455f784120) exiting.
2020-12-03 07:19:50,592 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33a2499c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,593 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@e72dba7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,594 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40e4ea87{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,595 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c8bdd5b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,596 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38178
2020-12-03 07:19:50,597 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,597 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,602 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,602 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d0cea7f3-b94e-46be-8cab-ab9b066065fe) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,603 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d0cea7f3-b94e-46be-8cab-ab9b066065fe)
2020-12-03 07:19:50,603 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,604 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,604 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,618 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,618 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,621 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,621 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,626 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,626 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:19:50,626 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,626 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@781e7326] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb) exiting.
2020-12-03 07:19:50,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-df1c0970-3a20-4d55-bcb1-b18c363404df) exiting.
2020-12-03 07:19:50,647 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@238b521e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,648 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1b39fd82{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,649 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2575f671{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,649 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433ffad1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,650 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36003
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39082 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39176 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39204 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39260 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,660 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39244 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39130 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:39024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,660 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d85b61b3-ef21-4772-acfd-077b1a8d8394) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,660 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,659 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,656 [DataXceiver for client  at /127.0.0.1:39082 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,661 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid d85b61b3-ef21-4772-acfd-077b1a8d8394)
2020-12-03 07:19:50,665 [DataXceiver for client  at /127.0.0.1:39024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,665 [DataXceiver for client  at /127.0.0.1:39082 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39082
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,665 [DataXceiver for client  at /127.0.0.1:39024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39024
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,665 [DataXceiver for client  at /127.0.0.1:39130 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,669 [DataXceiver for client  at /127.0.0.1:39024 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39024 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,669 [DataXceiver for client  at /127.0.0.1:39082 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39082 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,669 [DataXceiver for client  at /127.0.0.1:39130 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39130
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,669 [DataXceiver for client  at /127.0.0.1:39244 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,681 [DataXceiver for client  at /127.0.0.1:39130 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39130 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,681 [DataXceiver for client  at /127.0.0.1:39244 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39244
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,681 [DataXceiver for client  at /127.0.0.1:39260 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,690 [DataXceiver for client  at /127.0.0.1:39244 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39244 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,690 [DataXceiver for client  at /127.0.0.1:39260 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39260
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,690 [DataXceiver for client  at /127.0.0.1:39204 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,699 [DataXceiver for client  at /127.0.0.1:39260 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39260 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,699 [DataXceiver for client  at /127.0.0.1:39204 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39204
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,699 [DataXceiver for client  at /127.0.0.1:39176 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 on DS-db75caf7-7aa0-4f42-9399-d9b02687b3cb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,707 [DataXceiver for client  at /127.0.0.1:39204 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39204 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,707 [DataXceiver for client  at /127.0.0.1:39176 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39022, datanodeUuid=d85b61b3-ef21-4772-acfd-077b1a8d8394, infoPort=34882, infoSecurePort=0, ipcPort=36003, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002 to /127.0.0.1:39176
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,707 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,714 [DataXceiver for client  at /127.0.0.1:39176 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39022:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:39176 dst: /127.0.0.1:39022
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,720 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,720 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,729 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,730 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,732 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,732 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,738 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,738 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:19:50,739 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,739 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@600b0b7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,742 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c94ed69f-d0d6-497a-a0e3-319dd1660919) exiting.
2020-12-03 07:19:50,742 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-949c0406-6db1-4ef3-bb39-80b03217bb5c) exiting.
2020-12-03 07:19:50,759 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@20312893{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,760 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70eecdc2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,760 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bbc9f97{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,760 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ed190be{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,762 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33916
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33626 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33824 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33808 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33780 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33646 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33600 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33698 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33746 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,763 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,763 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,763 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,762 [DataXceiver for client  at /127.0.0.1:33626 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,787 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,787 [DataXceiver for client  at /127.0.0.1:33746 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,787 [DataXceiver for client  at /127.0.0.1:33626 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33626
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,792 [DataXceiver for client  at /127.0.0.1:33746 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33746
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,792 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f)
2020-12-03 07:19:50,792 [DataXceiver for client  at /127.0.0.1:33698 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,796 [DataXceiver for client  at /127.0.0.1:33746 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33746 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,796 [DataXceiver for client  at /127.0.0.1:33626 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33626 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,796 [DataXceiver for client  at /127.0.0.1:33698 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33698
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,796 [DataXceiver for client  at /127.0.0.1:33600 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,806 [DataXceiver for client  at /127.0.0.1:33698 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33698 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,806 [DataXceiver for client  at /127.0.0.1:33600 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33600
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,806 [DataXceiver for client  at /127.0.0.1:33646 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,811 [DataXceiver for client  at /127.0.0.1:33600 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33600 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,812 [DataXceiver for client  at /127.0.0.1:33646 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33646
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,812 [DataXceiver for client  at /127.0.0.1:33780 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,846 [DataXceiver for client  at /127.0.0.1:33646 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33646 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,846 [DataXceiver for client  at /127.0.0.1:33780 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33780
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,846 [DataXceiver for client  at /127.0.0.1:33808 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,847 [DataXceiver for client  at /127.0.0.1:33780 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33780 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,847 [DataXceiver for client  at /127.0.0.1:33808 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33808
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,847 [DataXceiver for client  at /127.0.0.1:33824 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 on DS-949c0406-6db1-4ef3-bb39-80b03217bb5c, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,847 [DataXceiver for client  at /127.0.0.1:33808 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33808 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,847 [DataXceiver for client  at /127.0.0.1:33824 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35590, datanodeUuid=7ebecfe4-7e05-4cd8-bba1-5c190cdf4c1f, infoPort=45801, infoSecurePort=0, ipcPort=33916, storageInfo=lv=-57;cid=testClusterID;nsid=1605269718;c=1606979969566):Got exception while serving BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002 to /127.0.0.1:33824
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,847 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,848 [DataXceiver for client  at /127.0.0.1:33824 [Sending block BP-2144674998-172.17.0.5-1606979969566:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35590:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:33824 dst: /127.0.0.1:35590
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,849 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,849 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,877 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,878 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,881 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,882 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,902 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,903 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:19:50,903 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,903 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@70e29e14] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,908 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-55e8dc88-dba9-4fe2-b2c5-1ad20a76eddf) exiting.
2020-12-03 07:19:50,908 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0d272bb6-e499-48c7-bfa5-0059dca3bbf5) exiting.
2020-12-03 07:19:50,927 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@241a53ef{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,928 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@344344fa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,928 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@384fc774{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,929 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d8445d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,930 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43854
2020-12-03 07:19:50,930 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,937 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,937 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 1ddb58c3-7b1b-4718-8522-82dab72ae09b) service to localhost/127.0.0.1:33068
2020-12-03 07:19:50,938 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 1ddb58c3-7b1b-4718-8522-82dab72ae09b)
2020-12-03 07:19:50,938 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:50,939 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,939 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,944 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,945 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,949 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,949 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,950 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,950 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:19:50,950 [Listener at localhost/42882] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,950 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@48c35007] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-511acede-de90-4fdf-adb8-34c074eb66c4) exiting.
2020-12-03 07:19:50,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-45973715-37be-4d46-9516-7d0ea92ed50a) exiting.
2020-12-03 07:19:50,974 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4ebea12c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,975 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a1edad4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,975 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3faf2e7d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,976 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29ef6856{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,977 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35672
2020-12-03 07:19:50,979 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,979 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,986 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,986 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 6fde81a4-289b-4295-8406-6637e46e6aa2) service to localhost/127.0.0.1:33068
2020-12-03 07:19:51,087 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2144674998-172.17.0.5-1606979969566 (Datanode Uuid 6fde81a4-289b-4295-8406-6637e46e6aa2)
2020-12-03 07:19:51,087 [BP-2144674998-172.17.0.5-1606979969566 heartbeating to localhost/127.0.0.1:33068] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2144674998-172.17.0.5-1606979969566
2020-12-03 07:19:51,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:51,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2144674998-172.17.0.5-1606979969566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:51,095 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:51,095 [Listener at localhost/42882] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:51,099 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:51,099 [Listener at localhost/42882] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:51,100 [Listener at localhost/42882] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:19:51,101 [Listener at localhost/42882] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:19:51,102 [Listener at localhost/42882] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:19:51,102 [Listener at localhost/42882] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,103 [Listener at localhost/42882] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:51,103 [Listener at localhost/42882] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:51,103 [Listener at localhost/42882] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 36
2020-12-03 07:19:51,104 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@150ab4ed] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:19:51,104 [Listener at localhost/42882] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 37 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 12 Number of syncs: 26 SyncTimes(ms): 6 4 
2020-12-03 07:19:51,104 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@a8c1f44] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:19:51,653 [Listener at localhost/42882] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:19:51,668 [Listener at localhost/42882] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:19:51,669 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:19:51,670 [CacheReplicationMonitor(532657337)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:19:51,670 [Listener at localhost/42882] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33068
2020-12-03 07:19:51,671 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:51,671 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:51,680 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:51,680 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:51,746 [Listener at localhost/42882] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:51,747 [Listener at localhost/42882] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:51,748 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c39680d{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:51,750 [Listener at localhost/42882] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28b46423{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:51,751 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e0e1046{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:51,751 [Listener at localhost/42882] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41330d4f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
msx-rc 1
