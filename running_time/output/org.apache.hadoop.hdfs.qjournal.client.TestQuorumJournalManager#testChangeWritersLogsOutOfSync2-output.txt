2020-12-03 07:23:05,526 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:23:05,784 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:05,936 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:05,937 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:23:06,091 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:06,108 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,124 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1476ms
2020-12-03 07:23:06,264 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:06,308 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:06,308 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,325 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:06,329 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:06,329 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:06,330 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:06,370 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37819
2020-12-03 07:23:06,373 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:06,435 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:06,440 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:06,488 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@740cae06{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:06,498 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:37819}
2020-12-03 07:23:06,498 [main] INFO  server.Server (Server.java:doStart(419)) - Started @1851ms
2020-12-03 07:23:06,500 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:06,537 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:06,553 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:06,867 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:06,867 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:06,871 [Listener at localhost/46667] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:06,875 [Listener at localhost/46667] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:06,875 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,877 [Listener at localhost/46667] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:06,878 [Listener at localhost/46667] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:06,878 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,882 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:06,883 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:06,884 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:06,884 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:06,886 [Listener at localhost/46667] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44465
2020-12-03 07:23:06,886 [Listener at localhost/46667] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:06,890 [Listener at localhost/46667] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:06,891 [Listener at localhost/46667] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:06,901 [Listener at localhost/46667] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4397ad89{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:06,903 [Listener at localhost/46667] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59cba5a{HTTP/1.1,[http/1.1]}{localhost:44465}
2020-12-03 07:23:06,903 [Listener at localhost/46667] INFO  server.Server (Server.java:doStart(419)) - Started @2256ms
2020-12-03 07:23:06,905 [Listener at localhost/46667] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:06,906 [Listener at localhost/46667] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:06,908 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:06,914 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:06,914 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,001 [Listener at localhost/42013] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:07,008 [Listener at localhost/42013] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:07,009 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,011 [Listener at localhost/42013] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:07,014 [Listener at localhost/42013] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:07,015 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,019 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:07,020 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:07,021 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:07,021 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:07,023 [Listener at localhost/42013] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37803
2020-12-03 07:23:07,023 [Listener at localhost/42013] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:07,028 [Listener at localhost/42013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79dc5318{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:07,030 [Listener at localhost/42013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37e4d7bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:07,043 [Listener at localhost/42013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69f1a286{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:07,045 [Listener at localhost/42013] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7922d892{HTTP/1.1,[http/1.1]}{localhost:37803}
2020-12-03 07:23:07,045 [Listener at localhost/42013] INFO  server.Server (Server.java:doStart(419)) - Started @2397ms
2020-12-03 07:23:07,047 [Listener at localhost/42013] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:07,048 [Listener at localhost/42013] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,049 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,055 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,056 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:08,032 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 96: Call -> /127.0.0.1:46667: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,032 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 98: Call -> /127.0.0.1:38084: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,032 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 97: Call -> /127.0.0.1:42013: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,110 [IPC Server handler 1 on default port 42013] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/waitactive
2020-12-03 07:23:08,115 [IPC Server handler 0 on default port 46667] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/waitactive
2020-12-03 07:23:08,117 [IPC Server handler 0 on default port 38084] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/waitactive
2020-12-03 07:23:08,148 [IPC Server handler 0 on default port 38084] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/waitactive does not exist
2020-12-03 07:23:08,148 [IPC Server handler 0 on default port 46667] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/waitactive does not exist
2020-12-03 07:23:08,148 [IPC Server handler 1 on default port 42013] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/waitactive does not exist
2020-12-03 07:23:08,154 [IPC Server handler 0 on default port 46667] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,154 [IPC Server handler 1 on default port 42013] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,156 [IPC Server handler 0 on default port 38084] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,206 [IPC Server handler 0 on default port 46667] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:08,206 [IPC Server handler 0 on default port 46667] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:08,210 [IPC Server handler 0 on default port 38084] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:08,210 [IPC Server handler 0 on default port 38084] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:08,213 [IPC Server handler 1 on default port 42013] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:08,213 [IPC Server handler 1 on default port 42013] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:08,220 [Logger channel (from single-thread executor) to /127.0.0.1:46667] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 369ms
2020-12-03 07:23:08,222 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 96: Response <- /127.0.0.1:46667: isFormatted {isFormatted: false}
2020-12-03 07:23:08,224 [Logger channel (from single-thread executor) to /127.0.0.1:42013] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 373ms
2020-12-03 07:23:08,224 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 97: Response <- /127.0.0.1:42013: isFormatted {isFormatted: false}
2020-12-03 07:23:08,226 [Logger channel (from single-thread executor) to /127.0.0.1:38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 375ms
2020-12-03 07:23:08,226 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 98: Response <- /127.0.0.1:38084: isFormatted {isFormatted: false}
2020-12-03 07:23:08,241 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 108: Call -> /127.0.0.1:38084: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,242 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 106: Call -> /127.0.0.1:46667: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,242 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 107: Call -> /127.0.0.1:42013: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,254 [Logger channel (from single-thread executor) to /127.0.0.1:38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 13ms
2020-12-03 07:23:08,254 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 108: Response <- /127.0.0.1:38084: isFormatted {isFormatted: false}
2020-12-03 07:23:08,255 [Logger channel (from single-thread executor) to /127.0.0.1:42013] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 13ms
2020-12-03 07:23:08,256 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 107: Response <- /127.0.0.1:42013: isFormatted {isFormatted: false}
2020-12-03 07:23:08,259 [Logger channel (from single-thread executor) to /127.0.0.1:46667] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 17ms
2020-12-03 07:23:08,260 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 106: Response <- /127.0.0.1:46667: isFormatted {isFormatted: false}
2020-12-03 07:23:08,281 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 116: Call -> /127.0.0.1:42013: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,281 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 115: Call -> /127.0.0.1:46667: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,285 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 117: Call -> /127.0.0.1:38084: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:08,286 [Logger channel (from single-thread executor) to /127.0.0.1:42013] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 5ms
2020-12-03 07:23:08,286 [Logger channel (from single-thread executor) to /127.0.0.1:42013] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 116: Response <- /127.0.0.1:42013: isFormatted {isFormatted: false}
2020-12-03 07:23:08,289 [Logger channel (from single-thread executor) to /127.0.0.1:46667] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 8ms
2020-12-03 07:23:08,290 [Logger channel (from single-thread executor) to /127.0.0.1:46667] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 115: Response <- /127.0.0.1:46667: isFormatted {isFormatted: false}
2020-12-03 07:23:08,291 [Logger channel (from single-thread executor) to /127.0.0.1:38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 7ms
2020-12-03 07:23:08,292 [Logger channel (from single-thread executor) to /127.0.0.1:38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 117: Response <- /127.0.0.1:38084: isFormatted {isFormatted: false}
2020-12-03 07:23:08,590 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46667: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:08,605 [IPC Server handler 4 on default port 46667] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal
2020-12-03 07:23:08,606 [IPC Server handler 4 on default port 46667] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal does not exist
2020-12-03 07:23:08,606 [IPC Server handler 4 on default port 46667] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,611 [IPC Server handler 4 on default port 46667] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:08,611 [IPC Server handler 4 on default port 46667] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:08,611 [IPC Server handler 4 on default port 46667] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:08,612 [IPC Server handler 4 on default port 46667] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal does not exist. Creating ...
2020-12-03 07:23:08,667 [IPC Server handler 4 on default port 46667] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:08,669 [IPC Server handler 4 on default port 46667] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal; location= null with nsid: 12345
2020-12-03 07:23:08,727 [IPC Server handler 4 on default port 46667] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/paxos
2020-12-03 07:23:08,769 [IPC Server handler 4 on default port 46667] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:08,770 [IPC Server handler 4 on default port 46667] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,774 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 188ms
2020-12-03 07:23:08,776 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46667: format {}
2020-12-03 07:23:08,779 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42013: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:08,793 [IPC Server handler 3 on default port 42013] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal
2020-12-03 07:23:08,794 [IPC Server handler 3 on default port 42013] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal does not exist
2020-12-03 07:23:08,794 [IPC Server handler 3 on default port 42013] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,799 [IPC Server handler 3 on default port 42013] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:08,799 [IPC Server handler 3 on default port 42013] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:08,799 [IPC Server handler 3 on default port 42013] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:08,799 [IPC Server handler 3 on default port 42013] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal does not exist. Creating ...
2020-12-03 07:23:08,874 [IPC Server handler 3 on default port 42013] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:08,875 [IPC Server handler 3 on default port 42013] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal; location= null with nsid: 12345
2020-12-03 07:23:08,938 [IPC Server handler 3 on default port 42013] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal/current/paxos
2020-12-03 07:23:08,988 [IPC Server handler 3 on default port 42013] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:08,989 [IPC Server handler 3 on default port 42013] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:08,991 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 211ms
2020-12-03 07:23:08,991 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:42013: format {}
2020-12-03 07:23:08,994 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38084: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:09,004 [IPC Server handler 4 on default port 38084] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal
2020-12-03 07:23:09,004 [IPC Server handler 4 on default port 38084] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal does not exist
2020-12-03 07:23:09,005 [IPC Server handler 4 on default port 38084] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:09,009 [IPC Server handler 4 on default port 38084] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:09,009 [IPC Server handler 4 on default port 38084] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:09,009 [IPC Server handler 4 on default port 38084] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:09,009 [IPC Server handler 4 on default port 38084] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal does not exist. Creating ...
2020-12-03 07:23:09,039 [IPC Server handler 4 on default port 38084] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:09,040 [IPC Server handler 4 on default port 38084] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal; location= null with nsid: 12345
2020-12-03 07:23:09,090 [IPC Server handler 4 on default port 38084] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/paxos
2020-12-03 07:23:09,132 [IPC Server handler 4 on default port 38084] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/in_use.lock acquired by nodename 5953@2ac649718063
2020-12-03 07:23:09,133 [IPC Server handler 4 on default port 38084] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:09,134 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 141ms
2020-12-03 07:23:09,134 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38084: format {}
2020-12-03 07:23:09,136 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:09,140 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46667: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:09,156 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 17ms
2020-12-03 07:23:09,158 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46667: getJournalState {lastPromisedEpoch: 0 httpPort: 37819 fromURL: "http://localhost:37819"}
2020-12-03 07:23:09,159 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42013: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:09,171 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 12ms
2020-12-03 07:23:09,172 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:42013: getJournalState {lastPromisedEpoch: 0 httpPort: 44465 fromURL: "http://localhost:44465"}
2020-12-03 07:23:09,174 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38084: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:09,190 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 17ms
2020-12-03 07:23:09,191 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38084: getJournalState {lastPromisedEpoch: 0 httpPort: 37803 fromURL: "http://localhost:37803"}
2020-12-03 07:23:09,198 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:09,228 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,268 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal)
2020-12-03 07:23:09,270 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal)
2020-12-03 07:23:09,271 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 76ms
2020-12-03 07:23:09,272 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: newEpoch {}
2020-12-03 07:23:09,274 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:09,278 [IPC Server handler 2 on default port 42013] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,317 [IPC Server handler 2 on default port 42013] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal)
2020-12-03 07:23:09,318 [IPC Server handler 2 on default port 42013] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal)
2020-12-03 07:23:09,319 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 45ms
2020-12-03 07:23:09,319 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42013: newEpoch {}
2020-12-03 07:23:09,321 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:09,330 [IPC Server handler 3 on default port 38084] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,367 [IPC Server handler 3 on default port 38084] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal)
2020-12-03 07:23:09,368 [IPC Server handler 3 on default port 38084] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal)
2020-12-03 07:23:09,371 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 51ms
2020-12-03 07:23:09,372 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: newEpoch {}
2020-12-03 07:23:09,374 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:23:09,382 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:09,386 [IPC Server handler 4 on default port 46667] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,695 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 315ms
2020-12-03 07:23:09,696 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: startLogSegment {}
2020-12-03 07:23:09,697 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:09,702 [IPC Server handler 3 on default port 42013] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,790 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 93ms
2020-12-03 07:23:09,791 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42013: startLogSegment {}
2020-12-03 07:23:09,792 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:09,796 [IPC Server handler 4 on default port 38084] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:09,872 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 80ms
2020-12-03 07:23:09,873 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: startLogSegment {}
2020-12-03 07:23:09,986 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:09,992 [IPC Server handler 0 on default port 46667] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:10,015 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 31ms
2020-12-03 07:23:10,020 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: journal {}
2020-12-03 07:23:10,023 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:10,028 [IPC Server handler 1 on default port 42013] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:10,041 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 18ms
2020-12-03 07:23:10,043 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42013: journal {}
2020-12-03 07:23:10,045 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:10,056 [IPC Server handler 0 on default port 38084] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:10,069 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 25ms
2020-12-03 07:23:10,070 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: journal {}
2020-12-03 07:23:10,076 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:10,100 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 24ms
2020-12-03 07:23:10,101 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42013: journal {}
2020-12-03 07:23:10,112 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:10,179 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 76ms
2020-12-03 07:23:10,180 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: journal {}
2020-12-03 07:23:10,188 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:10,197 [IPC Server handler 2 on default port 46667] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 46667, call Call#26 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.journal from 127.0.0.1:43414
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:10,215 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:46667: journal {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
}
2020-12-03 07:23:10,221 [Listener at localhost/38084] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(400)) - Remote journal 127.0.0.1:46667 failed to write txns 5-5. Will try to write to this JN again after the next log roll.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:191)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:397)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:390)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:57)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at org.apache.hadoop.hdfs.qjournal.client.DirectExecutorService.execute(DirectExecutorService.java:152)
	at com.google.common.util.concurrent.MoreExecutors$ListeningDecorator.execute(MoreExecutors.java:525)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134)
	at com.google.common.util.concurrent.AbstractListeningExecutorService.submit(AbstractListeningExecutorService.java:66)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.sendEdits(IPCLoggerChannel.java:390)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01.CGLIB$sendEdits$10(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01$$FastClassByMockitoWithCGLIB$$70d642a7.invoke(<generated>)
	at org.mockito.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:216)
	at org.mockito.internal.creation.AbstractMockitoMethodProxy.invokeSuper(AbstractMockitoMethodProxy.java:10)
	at org.mockito.internal.invocation.realmethod.CGLIBProxyRealMethod.invoke(CGLIBProxyRealMethod.java:22)
	at org.mockito.internal.invocation.realmethod.FilteredCGLIBProxyRealMethod.invoke(FilteredCGLIBProxyRealMethod.java:27)
	at org.mockito.internal.invocation.Invocation.callRealMethod(Invocation.java:211)
	at org.mockito.internal.stubbing.answers.CallsRealMethods.answer(CallsRealMethods.java:36)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:99)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01.sendEdits(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:110)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:115)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:109)
	at org.apache.hadoop.hdfs.qjournal.QJMTestUtil.writeTxns(QJMTestUtil.java:112)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setupLoggers345(TestQuorumJournalManager.java:579)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.doOutOfSyncTest(TestQuorumJournalManager.java:437)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testChangeWritersLogsOutOfSync2(TestQuorumJournalManager.java:423)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:10,226 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 3 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:10,263 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 38ms
2020-12-03 07:23:10,264 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: journal {}
2020-12-03 07:23:10,268 [Listener at localhost/38084] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42013
2020-12-03 07:23:10,269 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:10,270 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:10,280 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4397ad89{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:10,288 [Listener at localhost/38084] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59cba5a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:10,290 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:10,290 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:10,295 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/waitactive; location= null
2020-12-03 07:23:10,296 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal; location= null
2020-12-03 07:23:10,302 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:10,304 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46667: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:10,307 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 3ms
2020-12-03 07:23:10,307 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46667: getJournalState {lastPromisedEpoch: 1 httpPort: 37819 fromURL: "http://localhost:37819"}
2020-12-03 07:23:10,310 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42013: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:10,313 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:42013: getJournalState {java.net.ConnectException: Call From 2ac649718063/172.17.0.8 to localhost:42013 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:10,314 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38084: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:10,318 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 4ms
2020-12-03 07:23:10,319 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38084: getJournalState {lastPromisedEpoch: 1 httpPort: 37803 fromURL: "http://localhost:37803"}
2020-12-03 07:23:10,320 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:10,323 [IPC Server handler 1 on default port 46667] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:10,366 [IPC Server handler 1 on default port 46667] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal)
2020-12-03 07:23:10,411 [IPC Server handler 1 on default port 46667] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:10,412 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 92ms
2020-12-03 07:23:10,413 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:10,414 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:10,416 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:42013: newEpoch {java.net.ConnectException: Call From 2ac649718063/172.17.0.8 to localhost:42013 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:10,417 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:10,435 [IPC Server handler 4 on default port 38084] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:10,477 [IPC Server handler 4 on default port 38084] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal)
2020-12-03 07:23:10,496 [IPC Server handler 4 on default port 38084] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:10,498 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 81ms
2020-12-03 07:23:10,498 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:10,500 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:23:10,501 [Listener at localhost/38084] DEBUG client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(482)) - newEpoch(2) responses:
127.0.0.1:38084: lastSegmentTxId: 1
127.0.0.1:46667: lastSegmentTxId: 1
2020-12-03 07:23:10,502 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 1
2020-12-03 07:23:10,506 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:10,531 [IPC Server handler 0 on default port 46667] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 3 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:10,532 [IPC Server handler 0 on default port 46667] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4 ; journal id: test-journal
2020-12-03 07:23:10,534 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 29ms
2020-12-03 07:23:10,534 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: prepareRecovery {segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4}
2020-12-03 07:23:10,535 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:10,537 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:42013: getJournalState {java.net.ConnectException: Call From 2ac649718063/172.17.0.8 to localhost:42013 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:10,537 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:10,554 [IPC Server handler 0 on default port 38084] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:10,555 [IPC Server handler 0 on default port 38084] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4 ; journal id: test-journal
2020-12-03 07:23:10,563 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 26ms
2020-12-03 07:23:10,564 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: prepareRecovery {segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4}
2020-12-03 07:23:10,566 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:38084: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4
127.0.0.1:46667: segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4
2020-12-03 07:23:10,572 [Listener at localhost/38084] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:38084=segmentState {
  startTxId: 1
  endTxId: 5
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 4

2020-12-03 07:23:10,578 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:37803/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:10,602 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 3 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:10,602 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Synchronizing log startTxId: 1 endTxId: 5 isInProgress: true: old segment startTxId: 1 endTxId: 3 isInProgress: true is not the right length ; journal id: test-journal
2020-12-03 07:23:10,605 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:syncLog(995)) - Synchronizing log startTxId: 1 endTxId: 5 isInProgress: true from http://localhost:37803/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true
2020-12-03 07:23:10,792 [qtp137275020-86] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:10,887 [IPC Server handler 2 on default port 46667] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.04s. The file download took 0.04s at 29257.14 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001.epoch=2 took 0.00s.
2020-12-03 07:23:10,974 [IPC Server handler 2 on default port 46667] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:10,976 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 399ms
2020-12-03 07:23:10,978 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: acceptRecovery {}
2020-12-03 07:23:10,980 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:37803/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:10,982 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:42013: acceptRecovery {java.net.ConnectException: Call From 2ac649718063/172.17.0.8 to localhost:42013 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:10,983 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:37803/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:10,991 [IPC Server handler 2 on default port 38084] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:10,992 [IPC Server handler 2 on default port 38084] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: true: already have up-to-date logs ; journal id: test-journal
2020-12-03 07:23:11,049 [IPC Server handler 2 on default port 38084] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:11,050 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 68ms
2020-12-03 07:23:11,050 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: acceptRecovery {}
2020-12-03 07:23:11,057 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46667: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 2 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:11,061 [IPC Server handler 3 on default port 46667] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:11,066 [IPC Server handler 3 on default port 46667] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:23:11,095 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 41ms
2020-12-03 07:23:11,096 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46667: finalizeLogSegment {}
2020-12-03 07:23:11,097 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42013: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:11,099 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:42013: finalizeLogSegment {java.net.ConnectException: Call From 2ac649718063/172.17.0.8 to localhost:42013 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:11,100 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38084: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 2 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:11,104 [IPC Server handler 1 on default port 38084] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:11,107 [IPC Server handler 1 on default port 38084] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:23:11,109 [Listener at localhost/38084] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 10ms
2020-12-03 07:23:11,110 [Listener at localhost/38084] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38084: finalizeLogSegment {}
2020-12-03 07:23:11,119 [Listener at localhost/38084] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46667
2020-12-03 07:23:11,120 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:11,120 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:11,123 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@740cae06{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:11,125 [Listener at localhost/38084] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:11,126 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:11,126 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:11,128 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/waitactive; location= null
2020-12-03 07:23:11,128 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-0/test-journal; location= null
2020-12-03 07:23:11,129 [Listener at localhost/38084] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42013
2020-12-03 07:23:11,129 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/waitactive; location= null
2020-12-03 07:23:11,130 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-1/test-journal; location= null
2020-12-03 07:23:11,130 [Listener at localhost/38084] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JournalNode metrics system...
2020-12-03 07:23:11,132 [Listener at localhost/38084] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JournalNode metrics system stopped.
2020-12-03 07:23:11,132 [Listener at localhost/38084] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - JournalNode metrics system shutdown complete.
2020-12-03 07:23:11,132 [Listener at localhost/38084] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38084
2020-12-03 07:23:11,133 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:11,134 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69f1a286{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:11,139 [Listener at localhost/38084] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7922d892{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:11,139 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37e4d7bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:11,140 [Listener at localhost/38084] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79dc5318{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:11,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:11,143 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/waitactive; location= null
2020-12-03 07:23:11,143 [Listener at localhost/38084] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/YMOwtpZY32/journalnode-2/test-journal; location= null
msx-rc 0
