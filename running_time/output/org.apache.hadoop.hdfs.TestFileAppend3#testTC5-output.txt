2020-12-03 07:23:24,330 [main] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=-5571152823944959894
2020-12-03 07:23:24,339 [main] INFO  hdfs.AppendTestUtil (TestFileAppend3.java:setUp(76)) - setUp()
2020-12-03 07:23:24,605 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=5
Formatting using clusterid: testClusterID
2020-12-03 07:23:25,506 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:25,520 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:25,522 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:25,522 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:25,533 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:25,533 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:25,534 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:25,535 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:25,604 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:25,610 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:25,610 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:25,611 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:25,617 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:25,619 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:25
2020-12-03 07:23:25,622 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:25,622 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:25,625 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:25,625 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:25,648 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:25,649 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:25,657 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:25,657 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:25,658 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:25,658 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:25,659 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:25,659 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:25,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:25,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:25,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:25,660 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:25,661 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:25,703 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:25,704 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:25,704 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:25,704 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:25,725 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:25,725 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:25,726 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:25,726 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:25,733 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:25,733 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:25,734 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:25,734 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:25,741 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:25,745 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:25,753 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:25,754 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:25,754 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:25,755 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:25,768 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:25,769 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:25,769 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:25,775 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:25,775 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:25,779 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:25,780 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:25,780 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:25,781 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:25,823 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:25,905 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:25,976 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:26,013 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:26,013 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:26,168 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:26,168 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:26,242 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:26,247 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:26,363 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:26,697 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:26,697 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:26,736 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:26,782 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4f2b503c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:26,804 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:26,811 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:26,832 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3323ms
2020-12-03 07:23:26,987 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:26,993 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:26,993 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,009 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:27,012 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:27,012 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:27,013 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:27,054 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:27,055 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:27,069 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41518
2020-12-03 07:23:27,072 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:27,136 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2657d4dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:27,137 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47caedad{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:27,188 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@f627d13{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:27,198 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@651aed93{HTTP/1.1,[http/1.1]}{localhost:41518}
2020-12-03 07:23:27,198 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3690ms
2020-12-03 07:23:27,216 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:27,217 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:27,217 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:27,218 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:27,218 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:27,218 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:27,218 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:27,219 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:27,220 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:27,220 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:27,221 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:27,221 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:27,222 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:27
2020-12-03 07:23:27,222 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:27,222 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:27,223 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:27,223 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:27,228 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:27,229 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:27,229 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:27,230 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:27,230 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:27,231 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:27,231 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:27,231 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:27,231 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:27,232 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:27,232 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:27,232 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:27,232 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:27,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:27,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:27,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:27,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:27,237 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:27,238 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:27,238 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:27,238 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:27,239 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:27,239 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:27,239 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:27,239 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:27,240 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:27,240 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:27,244 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:27,245 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:27,245 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:27,246 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:27,246 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:27,246 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:27,247 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:27,247 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:27,248 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:27,301 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:27,329 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:27,334 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:27,335 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:27,336 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:27,336 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:27,377 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:27,385 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:27,386 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:27,394 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:27,395 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:27,468 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:27,468 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 216 msecs
2020-12-03 07:23:27,707 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:27,756 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,771 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:28,130 [Listener at localhost/38268] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38268 to access this namenode/service.
2020-12-03 07:23:28,134 [Listener at localhost/38268] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:28,157 [Listener at localhost/38268] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:28,175 [Listener at localhost/38268] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:28,176 [Listener at localhost/38268] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:28,177 [Listener at localhost/38268] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:28,177 [Listener at localhost/38268] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:28,181 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:28,182 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:28,182 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:28,182 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:28,182 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:28,182 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:23:28,228 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:28,228 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:28,236 [Listener at localhost/38268] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38268
2020-12-03 07:23:28,244 [Listener at localhost/38268] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:28,244 [Listener at localhost/38268] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:28,256 [Listener at localhost/38268] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 12 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:28,264 [CacheReplicationMonitor(2025313041)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:28,278 [Listener at localhost/38268] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:28,360 [Listener at localhost/38268] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:28,380 [Listener at localhost/38268] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:28,409 [Listener at localhost/38268] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:28,414 [Listener at localhost/38268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:28,418 [Listener at localhost/38268] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:28,423 [Listener at localhost/38268] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:28,424 [Listener at localhost/38268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:28,433 [Listener at localhost/38268] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:28,445 [Listener at localhost/38268] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35861
2020-12-03 07:23:28,449 [Listener at localhost/38268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:28,449 [Listener at localhost/38268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:28,479 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:28,482 [Listener at localhost/38268] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:28,483 [Listener at localhost/38268] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:28,483 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:28,487 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:28,489 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:28,489 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:28,489 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:28,506 [Listener at localhost/38268] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35479
2020-12-03 07:23:28,506 [Listener at localhost/38268] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:28,509 [Listener at localhost/38268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34a75079{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:28,510 [Listener at localhost/38268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@107ed6fc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:28,528 [Listener at localhost/38268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24faea88{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:28,529 [Listener at localhost/38268] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a320ade{HTTP/1.1,[http/1.1]}{localhost:35479}
2020-12-03 07:23:28,530 [Listener at localhost/38268] INFO  server.Server (Server.java:doStart(419)) - Started @5021ms
2020-12-03 07:23:28,932 [Listener at localhost/38268] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32903
2020-12-03 07:23:28,934 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3deb2326] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:28,936 [Listener at localhost/38268] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:28,937 [Listener at localhost/38268] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:29,298 [Listener at localhost/38268] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:29,302 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:29,394 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40681
2020-12-03 07:23:29,422 [Listener at localhost/40681] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:29,425 [Listener at localhost/40681] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:29,445 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268 starting to offer service
2020-12-03 07:23:29,454 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:29,455 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:29,473 [Listener at localhost/40681] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:29,476 [Listener at localhost/40681] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:29,481 [Listener at localhost/40681] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:29,482 [Listener at localhost/40681] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:29,483 [Listener at localhost/40681] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,493 [Listener at localhost/40681] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:29,499 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:29,499 [Listener at localhost/40681] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,499 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:29,500 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45352
2020-12-03 07:23:29,501 [Listener at localhost/40681] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:29,501 [Listener at localhost/40681] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:29,502 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,504 [Listener at localhost/40681] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:29,505 [Listener at localhost/40681] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:29,505 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,508 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:29,509 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:29,509 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:29,509 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:29,511 [Listener at localhost/40681] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42653
2020-12-03 07:23:29,511 [Listener at localhost/40681] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:29,514 [Listener at localhost/40681] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35038141{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:29,515 [Listener at localhost/40681] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@672f11c2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:29,525 [Listener at localhost/40681] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e29e14{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:29,529 [Listener at localhost/40681] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b7efaeb{HTTP/1.1,[http/1.1]}{localhost:42653}
2020-12-03 07:23:29,530 [Listener at localhost/40681] INFO  server.Server (Server.java:doStart(419)) - Started @6021ms
2020-12-03 07:23:29,648 [Listener at localhost/40681] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34716
2020-12-03 07:23:29,648 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:29,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a4bef8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:29,649 [Listener at localhost/40681] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:29,649 [Listener at localhost/40681] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:29,650 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:29,655 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36749
2020-12-03 07:23:29,665 [Listener at localhost/36749] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:29,666 [Listener at localhost/36749] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:29,667 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268 starting to offer service
2020-12-03 07:23:29,668 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:29,668 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:29,694 [Listener at localhost/36749] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:29,697 [Listener at localhost/36749] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:29,699 [Listener at localhost/36749] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:29,704 [Listener at localhost/36749] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:29,705 [Listener at localhost/36749] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,706 [Listener at localhost/36749] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:29,707 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:29,707 [Listener at localhost/36749] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,707 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:29,710 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44491
2020-12-03 07:23:29,710 [Listener at localhost/36749] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:29,711 [Listener at localhost/36749] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:29,713 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,715 [Listener at localhost/36749] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:29,717 [Listener at localhost/36749] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:29,717 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,721 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:29,723 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:29,724 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:29,724 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:29,727 [Listener at localhost/36749] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38076
2020-12-03 07:23:29,728 [Listener at localhost/36749] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:29,734 [Listener at localhost/36749] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@615f972{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:29,736 [Listener at localhost/36749] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73393584{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:29,744 [Listener at localhost/36749] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5be82d43{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:29,746 [Listener at localhost/36749] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@600b0b7{HTTP/1.1,[http/1.1]}{localhost:38076}
2020-12-03 07:23:29,746 [Listener at localhost/36749] INFO  server.Server (Server.java:doStart(419)) - Started @6238ms
2020-12-03 07:23:29,789 [Listener at localhost/36749] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35493
2020-12-03 07:23:29,790 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:29,790 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ea502e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:29,790 [Listener at localhost/36749] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:29,790 [Listener at localhost/36749] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:29,792 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:29,797 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44864
2020-12-03 07:23:29,806 [Listener at localhost/44864] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:29,807 [Listener at localhost/44864] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:29,808 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268 starting to offer service
2020-12-03 07:23:29,810 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:29,810 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:29,817 [Listener at localhost/44864] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:29,820 [Listener at localhost/44864] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:29,829 [Listener at localhost/44864] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:29,831 [Listener at localhost/44864] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:29,832 [Listener at localhost/44864] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,832 [Listener at localhost/44864] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:29,833 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:29,833 [Listener at localhost/44864] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:29,834 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:29,835 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42092
2020-12-03 07:23:29,835 [Listener at localhost/44864] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:29,835 [Listener at localhost/44864] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:29,836 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,839 [Listener at localhost/44864] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:29,840 [Listener at localhost/44864] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:29,841 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:29,844 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:29,845 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:29,845 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:29,845 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:29,846 [Listener at localhost/44864] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36483
2020-12-03 07:23:29,846 [Listener at localhost/44864] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:29,849 [Listener at localhost/44864] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52eacb4b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:29,849 [Listener at localhost/44864] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a551a63{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:29,863 [Listener at localhost/44864] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@781e7326{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:29,864 [Listener at localhost/44864] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22680f52{HTTP/1.1,[http/1.1]}{localhost:36483}
2020-12-03 07:23:29,866 [Listener at localhost/44864] INFO  server.Server (Server.java:doStart(419)) - Started @6358ms
2020-12-03 07:23:29,975 [Listener at localhost/44864] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35860
2020-12-03 07:23:29,984 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@39c11e6c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:29,984 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:29,985 [Listener at localhost/44864] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:29,986 [Listener at localhost/44864] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:29,988 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:30,007 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34231
2020-12-03 07:23:30,014 [Listener at localhost/34231] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:30,015 [Listener at localhost/34231] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:30,016 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268 starting to offer service
2020-12-03 07:23:30,018 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:30,018 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:30,027 [Listener at localhost/34231] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:30,030 [Listener at localhost/34231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:30,032 [Listener at localhost/34231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:30,034 [Listener at localhost/34231] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:30,036 [Listener at localhost/34231] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:30,036 [Listener at localhost/34231] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:30,037 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:30,038 [Listener at localhost/34231] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:30,038 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:30,039 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268
2020-12-03 07:23:30,039 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268
2020-12-03 07:23:30,041 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:30,043 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:30,043 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46481
2020-12-03 07:23:30,043 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268
2020-12-03 07:23:30,043 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268
2020-12-03 07:23:30,043 [Listener at localhost/34231] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:30,043 [Listener at localhost/34231] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:30,044 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:30,046 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:30,048 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:30,048 [Listener at localhost/34231] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:30,049 [Listener at localhost/34231] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:30,050 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:30,053 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:30,054 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:30,054 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:30,054 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:30,055 [Listener at localhost/34231] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46195
2020-12-03 07:23:30,056 [Listener at localhost/34231] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:30,059 [Listener at localhost/34231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21680803{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:30,061 [Listener at localhost/34231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c8b96ec{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:30,070 [Listener at localhost/34231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4d157787{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:30,071 [Listener at localhost/34231] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@68ed96ca{HTTP/1.1,[http/1.1]}{localhost:46195}
2020-12-03 07:23:30,072 [Listener at localhost/34231] INFO  server.Server (Server.java:doStart(419)) - Started @6563ms
2020-12-03 07:23:30,089 [Listener at localhost/34231] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40382
2020-12-03 07:23:30,090 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:30,090 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3228d990] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:30,091 [Listener at localhost/34231] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:30,091 [Listener at localhost/34231] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:30,092 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:30,097 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38253
2020-12-03 07:23:30,104 [Listener at localhost/38253] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:30,105 [Listener at localhost/38253] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:30,106 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268 starting to offer service
2020-12-03 07:23:30,107 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:30,107 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:30,109 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,109 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,109 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,109 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,110 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,110 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,110 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,110 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,115 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:23:30,115 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:23:30,115 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:23:30,115 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0f484599-eccb-489e-9df4-5174a9c1ce99 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:23:30,122 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38268
2020-12-03 07:23:30,123 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:30,185 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,186 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,186 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:23:30,304 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,304 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,305 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,305 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,305 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,305 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,305 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:23:30,306 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:23:30,306 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-955d791f-a07c-4bbc-a809-49dc699e8596 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:23:30,340 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,340 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,342 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9493e2c8-78f1-4634-845a-3e6288543417 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:23:30,398 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 9753@157c7e6daf75
2020-12-03 07:23:30,399 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 2143374157. Formatting...
2020-12-03 07:23:30,399 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e67e1514-a5ee-431f-89b5-5c468fb18954 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:23:30,472 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,472 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,472 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,473 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,473 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,473 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,474 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,474 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,474 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,474 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,474 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,475 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,500 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,500 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,501 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,501 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,549 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,549 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,549 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,549 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,617 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,618 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,618 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,618 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,618 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,619 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,619 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,620 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,624 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,626 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,626 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,627 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,642 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,642 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,643 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,643 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,678 [IPC Server handler 3 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,690 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:30,690 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:30,694 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,694 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:30,695 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-464985465-172.17.0.4-1606980205807 is not formatted. Formatting ...
2020-12-03 07:23:30,695 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464985465-172.17.0.4-1606980205807 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464985465-172.17.0.4-1606980205807/current
2020-12-03 07:23:30,775 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2143374157;bpid=BP-464985465-172.17.0.4-1606980205807;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2143374157;c=1606980205807;bpid=BP-464985465-172.17.0.4-1606980205807;dnuuid=null
2020-12-03 07:23:30,776 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2143374157;bpid=BP-464985465-172.17.0.4-1606980205807;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2143374157;c=1606980205807;bpid=BP-464985465-172.17.0.4-1606980205807;dnuuid=null
2020-12-03 07:23:30,793 [IPC Server handler 1 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,795 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:30,795 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:30,800 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2143374157;bpid=BP-464985465-172.17.0.4-1606980205807;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2143374157;c=1606980205807;bpid=BP-464985465-172.17.0.4-1606980205807;dnuuid=null
2020-12-03 07:23:30,800 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2143374157;bpid=BP-464985465-172.17.0.4-1606980205807;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2143374157;c=1606980205807;bpid=BP-464985465-172.17.0.4-1606980205807;dnuuid=null
2020-12-03 07:23:30,845 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2143374157;bpid=BP-464985465-172.17.0.4-1606980205807;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2143374157;c=1606980205807;bpid=BP-464985465-172.17.0.4-1606980205807;dnuuid=null
2020-12-03 07:23:30,902 [IPC Server handler 6 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,903 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:30,903 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:30,916 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2bdf22ee-48cf-453a-b54f-d0a9277d73c6
2020-12-03 07:23:30,921 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 591dcf68-88cc-4620-912b-223dc6c67fcd
2020-12-03 07:23:30,947 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6a131d7f-2964-4cfd-a61a-36b71b52c4e4
2020-12-03 07:23:30,947 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3
2020-12-03 07:23:30,975 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 96caf383-2e10-4c55-8aaf-dd6ab49628af
2020-12-03 07:23:31,007 [IPC Server handler 9 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,009 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:31,009 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:31,092 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c
2020-12-03 07:23:31,092 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:31,092 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0f484599-eccb-489e-9df4-5174a9c1ce99
2020-12-03 07:23:31,094 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:31,092 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5
2020-12-03 07:23:31,092 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77
2020-12-03 07:23:31,094 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:31,092 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb
2020-12-03 07:23:31,095 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:31,095 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:23:31,096 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9493e2c8-78f1-4634-845a-3e6288543417
2020-12-03 07:23:31,096 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:31,099 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-955d791f-a07c-4bbc-a809-49dc699e8596
2020-12-03 07:23:31,100 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:31,100 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37
2020-12-03 07:23:31,100 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:31,101 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105
2020-12-03 07:23:31,101 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:31,102 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e67e1514-a5ee-431f-89b5-5c468fb18954
2020-12-03 07:23:31,102 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:23:31,107 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:31,107 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:31,107 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:31,107 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:31,107 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:31,118 [IPC Server handler 4 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,118 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:31,127 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:31,127 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:31,129 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:31,131 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:31,135 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:31,136 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:31,137 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:31,139 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:31,140 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:31,139 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:31,141 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:31,142 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:31,140 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:31,143 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:31,143 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:31,140 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:31,144 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,140 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:31,144 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:31,144 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:31,145 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:31,145 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:31,145 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:31,145 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:31,149 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,150 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:31,150 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:31,161 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,162 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,163 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:31,179 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,179 [Thread-178] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:31,181 [Thread-181] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:31,181 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:31,185 [Thread-179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:31,195 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:31,234 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 71ms
2020-12-03 07:23:31,251 [IPC Server handler 5 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,252 [Thread-181] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 71ms
2020-12-03 07:23:31,252 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:31,256 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:31,255 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 105ms
2020-12-03 07:23:31,281 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 136ms
2020-12-03 07:23:31,290 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 95ms
2020-12-03 07:23:31,291 [Thread-179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 106ms
2020-12-03 07:23:31,291 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 110ms
2020-12-03 07:23:31,292 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464985465-172.17.0.4-1606980205807: 113ms
2020-12-03 07:23:31,292 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 143ms
2020-12-03 07:23:31,293 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464985465-172.17.0.4-1606980205807: 131ms
2020-12-03 07:23:31,294 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 144ms
2020-12-03 07:23:31,294 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464985465-172.17.0.4-1606980205807: 145ms
2020-12-03 07:23:31,295 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:31,296 [Thread-193] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,296 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464985465-172.17.0.4-1606980205807: 152ms
2020-12-03 07:23:31,296 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:31,296 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:31,296 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:31,297 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:31,298 [Thread-178] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464985465-172.17.0.4-1606980205807 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 119ms
2020-12-03 07:23:31,298 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464985465-172.17.0.4-1606980205807: 137ms
2020-12-03 07:23:31,300 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:31,305 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:31,305 [Thread-197] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,305 [Thread-200] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,297 [Thread-198] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,306 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:31,297 [Thread-196] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,296 [Thread-194] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,296 [Thread-195] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,309 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 13ms
2020-12-03 07:23:31,310 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 14ms
2020-12-03 07:23:31,300 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:31,311 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 15ms
2020-12-03 07:23:31,309 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 12ms
2020-12-03 07:23:31,308 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 13ms
2020-12-03 07:23:31,308 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:23:31,308 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:31,307 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:31,313 [Thread-202] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,312 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464985465-172.17.0.4-1606980205807: 18ms
2020-12-03 07:23:31,313 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464985465-172.17.0.4-1606980205807: 18ms
2020-12-03 07:23:31,312 [Thread-199] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,313 [Thread-201] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/replicas doesn't exist 
2020-12-03 07:23:31,314 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:23:31,315 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464985465-172.17.0.4-1606980205807: 21ms
2020-12-03 07:23:31,315 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-12-03 07:23:31,315 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464985465-172.17.0.4-1606980205807: 19ms
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:31,316 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 3ms
2020-12-03 07:23:31,320 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:31,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:31,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9493e2c8-78f1-4634-845a-3e6288543417): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:31,324 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464985465-172.17.0.4-1606980205807: 26ms
2020-12-03 07:23:31,325 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:31,325 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:31,327 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,327 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:31,328 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-0f484599-eccb-489e-9df4-5174a9c1ce99): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,326 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-e67e1514-a5ee-431f-89b5-5c468fb18954): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,325 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:31,329 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464985465-172.17.0.4-1606980205807 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:31,330 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-955d791f-a07c-4bbc-a809-49dc699e8596): finished scanning block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9493e2c8-78f1-4634-845a-3e6288543417): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-0f484599-eccb-489e-9df4-5174a9c1ce99): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-955d791f-a07c-4bbc-a809-49dc699e8596): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,347 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:23:31,348 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:23:31,348 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:23:31,350 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-e67e1514-a5ee-431f-89b5-5c468fb18954): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:23:31,354 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:03 AM with interval of 21600000ms
2020-12-03 07:23:31,354 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:22 PM with interval of 21600000ms
2020-12-03 07:23:31,354 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:24 AM with interval of 21600000ms
2020-12-03 07:23:31,354 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:07 AM with interval of 21600000ms
2020-12-03 07:23:31,354 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:19 PM with interval of 21600000ms
2020-12-03 07:23:31,359 [IPC Server handler 3 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,360 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:31,360 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:31,366 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 6a131d7f-2964-4cfd-a61a-36b71b52c4e4) service to localhost/127.0.0.1:38268 beginning handshake with NN
2020-12-03 07:23:31,366 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 591dcf68-88cc-4620-912b-223dc6c67fcd) service to localhost/127.0.0.1:38268 beginning handshake with NN
2020-12-03 07:23:31,371 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3) service to localhost/127.0.0.1:38268 beginning handshake with NN
2020-12-03 07:23:31,379 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 2bdf22ee-48cf-453a-b54f-d0a9277d73c6) service to localhost/127.0.0.1:38268 beginning handshake with NN
2020-12-03 07:23:31,379 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 96caf383-2e10-4c55-8aaf-dd6ab49628af) service to localhost/127.0.0.1:38268 beginning handshake with NN
2020-12-03 07:23:31,384 [IPC Server handler 9 on default port 38268] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44491, datanodeUuid=c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3, infoPort=35493, infoSecurePort=0, ipcPort=44864, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) storage c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3
2020-12-03 07:23:31,387 [IPC Server handler 9 on default port 38268] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44491
2020-12-03 07:23:31,388 [IPC Server handler 9 on default port 38268] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3 (127.0.0.1:44491).
2020-12-03 07:23:31,390 [IPC Server handler 6 on default port 38268] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42092, datanodeUuid=2bdf22ee-48cf-453a-b54f-d0a9277d73c6, infoPort=35860, infoSecurePort=0, ipcPort=34231, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) storage 2bdf22ee-48cf-453a-b54f-d0a9277d73c6
2020-12-03 07:23:31,391 [IPC Server handler 6 on default port 38268] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42092
2020-12-03 07:23:31,391 [IPC Server handler 6 on default port 38268] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2bdf22ee-48cf-453a-b54f-d0a9277d73c6 (127.0.0.1:42092).
2020-12-03 07:23:31,392 [IPC Server handler 1 on default port 38268] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45352, datanodeUuid=591dcf68-88cc-4620-912b-223dc6c67fcd, infoPort=34716, infoSecurePort=0, ipcPort=36749, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) storage 591dcf68-88cc-4620-912b-223dc6c67fcd
2020-12-03 07:23:31,398 [IPC Server handler 1 on default port 38268] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45352
2020-12-03 07:23:31,398 [IPC Server handler 1 on default port 38268] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 591dcf68-88cc-4620-912b-223dc6c67fcd (127.0.0.1:45352).
2020-12-03 07:23:31,395 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3) service to localhost/127.0.0.1:38268 successfully registered with NN
2020-12-03 07:23:31,399 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38268 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:31,399 [IPC Server handler 6 on default port 38268] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46481, datanodeUuid=96caf383-2e10-4c55-8aaf-dd6ab49628af, infoPort=40382, infoSecurePort=0, ipcPort=38253, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) storage 96caf383-2e10-4c55-8aaf-dd6ab49628af
2020-12-03 07:23:31,400 [IPC Server handler 6 on default port 38268] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46481
2020-12-03 07:23:31,400 [IPC Server handler 6 on default port 38268] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 96caf383-2e10-4c55-8aaf-dd6ab49628af (127.0.0.1:46481).
2020-12-03 07:23:31,405 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 96caf383-2e10-4c55-8aaf-dd6ab49628af) service to localhost/127.0.0.1:38268 successfully registered with NN
2020-12-03 07:23:31,405 [IPC Server handler 5 on default port 38268] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35861, datanodeUuid=6a131d7f-2964-4cfd-a61a-36b71b52c4e4, infoPort=32903, infoSecurePort=0, ipcPort=40681, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) storage 6a131d7f-2964-4cfd-a61a-36b71b52c4e4
2020-12-03 07:23:31,405 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38268 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:31,411 [IPC Server handler 5 on default port 38268] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35861
2020-12-03 07:23:31,411 [IPC Server handler 5 on default port 38268] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6a131d7f-2964-4cfd-a61a-36b71b52c4e4 (127.0.0.1:35861).
2020-12-03 07:23:31,410 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 591dcf68-88cc-4620-912b-223dc6c67fcd) service to localhost/127.0.0.1:38268 successfully registered with NN
2020-12-03 07:23:31,412 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38268 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:31,411 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 2bdf22ee-48cf-453a-b54f-d0a9277d73c6) service to localhost/127.0.0.1:38268 successfully registered with NN
2020-12-03 07:23:31,413 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38268 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:31,413 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 6a131d7f-2964-4cfd-a61a-36b71b52c4e4) service to localhost/127.0.0.1:38268 successfully registered with NN
2020-12-03 07:23:31,413 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38268 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:31,435 [IPC Server handler 8 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5 for DN 127.0.0.1:44491
2020-12-03 07:23:31,436 [IPC Server handler 8 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37 for DN 127.0.0.1:44491
2020-12-03 07:23:31,439 [IPC Server handler 7 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb for DN 127.0.0.1:46481
2020-12-03 07:23:31,440 [IPC Server handler 7 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e67e1514-a5ee-431f-89b5-5c468fb18954 for DN 127.0.0.1:46481
2020-12-03 07:23:31,442 [IPC Server handler 2 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c for DN 127.0.0.1:35861
2020-12-03 07:23:31,442 [IPC Server handler 2 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9493e2c8-78f1-4634-845a-3e6288543417 for DN 127.0.0.1:35861
2020-12-03 07:23:31,443 [IPC Server handler 0 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77 for DN 127.0.0.1:45352
2020-12-03 07:23:31,443 [IPC Server handler 0 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105 for DN 127.0.0.1:45352
2020-12-03 07:23:31,451 [IPC Server handler 3 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f484599-eccb-489e-9df4-5174a9c1ce99 for DN 127.0.0.1:42092
2020-12-03 07:23:31,453 [IPC Server handler 3 on default port 38268] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-955d791f-a07c-4bbc-a809-49dc699e8596 for DN 127.0.0.1:42092
2020-12-03 07:23:31,472 [IPC Server handler 9 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,494 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:31,498 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x565c3c598647ba75: Processing first storage report for DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105 from datanode 591dcf68-88cc-4620-912b-223dc6c67fcd
2020-12-03 07:23:31,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x565c3c598647ba75: from storage DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105 node DatanodeRegistration(127.0.0.1:45352, datanodeUuid=591dcf68-88cc-4620-912b-223dc6c67fcd, infoPort=34716, infoSecurePort=0, ipcPort=36749, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1447de5f284f1e0f: Processing first storage report for DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb from datanode 96caf383-2e10-4c55-8aaf-dd6ab49628af
2020-12-03 07:23:31,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1447de5f284f1e0f: from storage DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb node DatanodeRegistration(127.0.0.1:46481, datanodeUuid=96caf383-2e10-4c55-8aaf-dd6ab49628af, infoPort=40382, infoSecurePort=0, ipcPort=38253, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f43f34e1b9d0f98: Processing first storage report for DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37 from datanode c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3
2020-12-03 07:23:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f43f34e1b9d0f98: from storage DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37 node DatanodeRegistration(127.0.0.1:44491, datanodeUuid=c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3, infoPort=35493, infoSecurePort=0, ipcPort=44864, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x91ef63f13106fb4f: Processing first storage report for DS-9493e2c8-78f1-4634-845a-3e6288543417 from datanode 6a131d7f-2964-4cfd-a61a-36b71b52c4e4
2020-12-03 07:23:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x91ef63f13106fb4f: from storage DS-9493e2c8-78f1-4634-845a-3e6288543417 node DatanodeRegistration(127.0.0.1:35861, datanodeUuid=6a131d7f-2964-4cfd-a61a-36b71b52c4e4, infoPort=32903, infoSecurePort=0, ipcPort=40681, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x565c3c598647ba75: Processing first storage report for DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77 from datanode 591dcf68-88cc-4620-912b-223dc6c67fcd
2020-12-03 07:23:31,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x565c3c598647ba75: from storage DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77 node DatanodeRegistration(127.0.0.1:45352, datanodeUuid=591dcf68-88cc-4620-912b-223dc6c67fcd, infoPort=34716, infoSecurePort=0, ipcPort=36749, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x91ef63f13106fb4f: Processing first storage report for DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c from datanode 6a131d7f-2964-4cfd-a61a-36b71b52c4e4
2020-12-03 07:23:31,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x91ef63f13106fb4f: from storage DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c node DatanodeRegistration(127.0.0.1:35861, datanodeUuid=6a131d7f-2964-4cfd-a61a-36b71b52c4e4, infoPort=32903, infoSecurePort=0, ipcPort=40681, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1447de5f284f1e0f: Processing first storage report for DS-e67e1514-a5ee-431f-89b5-5c468fb18954 from datanode 96caf383-2e10-4c55-8aaf-dd6ab49628af
2020-12-03 07:23:31,505 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1447de5f284f1e0f: from storage DS-e67e1514-a5ee-431f-89b5-5c468fb18954 node DatanodeRegistration(127.0.0.1:46481, datanodeUuid=96caf383-2e10-4c55-8aaf-dd6ab49628af, infoPort=40382, infoSecurePort=0, ipcPort=38253, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,505 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f43f34e1b9d0f98: Processing first storage report for DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5 from datanode c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3
2020-12-03 07:23:31,505 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f43f34e1b9d0f98: from storage DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5 node DatanodeRegistration(127.0.0.1:44491, datanodeUuid=c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3, infoPort=35493, infoSecurePort=0, ipcPort=44864, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,506 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x76ea9c13cd37db18: Processing first storage report for DS-955d791f-a07c-4bbc-a809-49dc699e8596 from datanode 2bdf22ee-48cf-453a-b54f-d0a9277d73c6
2020-12-03 07:23:31,507 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x76ea9c13cd37db18: from storage DS-955d791f-a07c-4bbc-a809-49dc699e8596 node DatanodeRegistration(127.0.0.1:42092, datanodeUuid=2bdf22ee-48cf-453a-b54f-d0a9277d73c6, infoPort=35860, infoSecurePort=0, ipcPort=34231, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,507 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x76ea9c13cd37db18: Processing first storage report for DS-0f484599-eccb-489e-9df4-5174a9c1ce99 from datanode 2bdf22ee-48cf-453a-b54f-d0a9277d73c6
2020-12-03 07:23:31,507 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x76ea9c13cd37db18: from storage DS-0f484599-eccb-489e-9df4-5174a9c1ce99 node DatanodeRegistration(127.0.0.1:42092, datanodeUuid=2bdf22ee-48cf-453a-b54f-d0a9277d73c6, infoPort=35860, infoSecurePort=0, ipcPort=34231, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:31,509 [IPC Server handler 4 on default port 38268] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x76ea9c13cd37db18
p=/TC5/foo
2020-12-03 07:23:31,518 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TC5/foo: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:23:31,537 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(774)) - *DIR* NameNode.create: file /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1 at 127.0.0.1
2020-12-03 07:23:31,538 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2460)) - DIR* NameSystem.startFile: src=/TC5/foo, holder=DFSClient_NONMAPREDUCE_-456895244_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE], blockSize=65536, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-12-03 07:23:31,540 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x76ea9c13cd37db18,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:31,540 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,541 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1447de5f284f1e0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 13 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:31,541 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,544 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x91ef63f13106fb4f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 69 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:31,544 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4f43f34e1b9d0f98,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 13 msec to generate and 68 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:31,547 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,550 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x565c3c598647ba75,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 66 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:31,550 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,544 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:31,562 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (FSDirMkdirOp.java:createSingleDirectory(182)) - mkdirs: created directory /TC5
2020-12-03 07:23:31,568 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(579)) - DIR* addFile: foo is added
2020-12-03 07:23:31,570 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(415)) - DIR* NameSystem.startFile: added /TC5/foo inode 16387 DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:31,587 [IPC Server handler 8 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TC5/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:31,609 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TC5/foo, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:23:31,625 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TC5/foo, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:23:31,638 [IPC Server handler 2 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /TC5/foo  inodeId 16387 for DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:31,648 [IPC Server handler 2 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /TC5/foo with blk_1073741825_1001 block is added to the in-memory file system
2020-12-03 07:23:31,649 [IPC Server handler 2 on default port 38268] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:46481, 127.0.0.1:42092, 127.0.0.1:35861 for /TC5/foo
2020-12-03 07:23:31,649 [IPC Server handler 2 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /TC5/foo with new block blk_1073741825_1001, current total block count is 1
2020-12-03 07:23:31,670 [Thread-218] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,684 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1804f60d] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_CREATE, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=0, bytesRcvd=[0, 0]
  targets=[127.0.0.1:42092, 127.0.0.1:35861]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:60930 dest: /127.0.0.1:46481
2020-12-03 07:23:31,768 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:60930, myAddr=/127.0.0.1:46481
 stage=PIPELINE_SETUP_CREATE, newGs=0, minBytesRcvd=0, maxBytesRcvd=0
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:46481
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb
2020-12-03 07:23:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 0
2020-12-03 07:23:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1001.meta of size 0
2020-12-03 07:23:31,784 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(784)) - Connecting to datanode 127.0.0.1:42092
2020-12-03 07:23:31,786 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4e9658b5] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:31,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_CREATE, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=0, bytesRcvd=[0, 0]
  targets=[127.0.0.1:35861]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:31,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:31,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:31,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:40418 dest: /127.0.0.1:42092
2020-12-03 07:23:31,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:40418, myAddr=/127.0.0.1:42092
 stage=PIPELINE_SETUP_CREATE, newGs=0, minBytesRcvd=0, maxBytesRcvd=0
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:42092
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-955d791f-a07c-4bbc-a809-49dc699e8596
2020-12-03 07:23:31,793 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 0
2020-12-03 07:23:31,793 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1001.meta of size 0
2020-12-03 07:23:31,793 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(784)) - Connecting to datanode 127.0.0.1:35861
2020-12-03 07:23:31,794 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@346939bf] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:31,794 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_CREATE, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=0, bytesRcvd=[0, 0]
  targets=[]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:31,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:31,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:31,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:55090 dest: /127.0.0.1:35861
2020-12-03 07:23:31,797 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:55090, myAddr=/127.0.0.1:35861
 stage=PIPELINE_SETUP_CREATE, newGs=0, minBytesRcvd=0, maxBytesRcvd=0
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:35861
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-9493e2c8-78f1-4634-845a-3e6288543417
2020-12-03 07:23:31,797 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 0
2020-12-03 07:23:31,797 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1001.meta of size 0
2020-12-03 07:23:31,810 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:waitForAckHead(1327)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE: seqno=-2 waiting for local datanode to finish write.
2020-12-03 07:23:31,823 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=33028 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 32768

2020-12-03 07:23:31,823 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]: enqueue Packet(seqno=0, lastPacketInBlock=false, offsetInBlock=32768, ackEnqueueNanoTime=141203598621764, ackStatus=SUCCESS)
2020-12-03 07:23:31,824 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=33028 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 32768

2020-12-03 07:23:31,824 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]: enqueue Packet(seqno=0, lastPacketInBlock=false, offsetInBlock=32768, ackEnqueueNanoTime=141203599735513, ackStatus=SUCCESS)
2020-12-03 07:23:31,825 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=33028 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 32768

2020-12-03 07:23:31,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE: enqueue Packet(seqno=0, lastPacketInBlock=false, offsetInBlock=32768, ackEnqueueNanoTime=141203607193341, ackStatus=SUCCESS)
2020-12-03 07:23:31,843 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE, replyAck=seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:31,843 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:waitForAckHead(1327)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE: seqno=-2 waiting for local datanode to finish write.
2020-12-03 07:23:31,844 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861] got seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:31,846 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861], replyAck=seqno: 0 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 15986432 flag: 0 flag: 0
2020-12-03 07:23:31,847 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861] got seqno: 0 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 15986432 flag: 0 flag: 0
2020-12-03 07:23:31,848 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861], replyAck=seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 23179622 flag: 0 flag: 0 flag: 0
2020-12-03 07:23:31,853 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 1
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:31,854 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]: enqueue Packet(seqno=1, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141203628934832, ackStatus=SUCCESS)
2020-12-03 07:23:31,854 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
2020-12-03 07:23:31,854 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 1
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]: enqueue Packet(seqno=1, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141203629978776, ackStatus=SUCCESS)
2020-12-03 07:23:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
2020-12-03 07:23:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 1
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
2020-12-03 07:23:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE: enqueue Packet(seqno=1, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141203630895837, ackStatus=SUCCESS)
2020-12-03 07:23:31,862 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55090, dest: /127.0.0.1:35861, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 6a131d7f-2964-4cfd-a61a-36b71b52c4e4, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, duration(ns): 48015866
2020-12-03 07:23:31,862 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE, replyAck=seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:31,862 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:31,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=LAST_IN_PIPELINE: closing
2020-12-03 07:23:31,862 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861] got seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:31,864 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55090 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:35861:Number of active connections is: 2
2020-12-03 07:23:31,870 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40418, dest: /127.0.0.1:42092, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 2bdf22ee-48cf-453a-b54f-d0a9277d73c6, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, duration(ns): 56672256
2020-12-03 07:23:31,871 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861], replyAck=seqno: 1 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7738794 flag: 0 flag: 0
2020-12-03 07:23:31,871 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861] terminating
2020-12-03 07:23:31,872 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35861]: closing
2020-12-03 07:23:31,872 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861] got seqno: 1 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 7738794 flag: 0 flag: 0
2020-12-03 07:23:31,872 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40418 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:42092:Number of active connections is: 2
2020-12-03 07:23:31,876 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60930, dest: /127.0.0.1:46481, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 96caf383-2e10-4c55-8aaf-dd6ab49628af, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, duration(ns): 64423940
2020-12-03 07:23:31,878 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861], replyAck=seqno: 1 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 17402259 flag: 0 flag: 0 flag: 0
2020-12-03 07:23:31,878 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861] terminating
2020-12-03 07:23:31,878 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42092, 127.0.0.1:35861]: closing
2020-12-03 07:23:31,879 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:60930 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:46481:Number of active connections is: 2
2020-12-03 07:23:31,884 [IPC Server handler 0 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:31,887 [IPC Server handler 4 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46481, datanodeUuid=96caf383-2e10-4c55-8aaf-dd6ab49628af, infoPort=40382, infoSecurePort=0, ipcPort=38253, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:31,887 [IPC Server handler 9 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42092, datanodeUuid=2bdf22ee-48cf-453a-b54f-d0a9277d73c6, infoPort=35860, infoSecurePort=0, ipcPort=34231, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:31,890 [IPC Server handler 0 on default port 38268] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /TC5/foo
2020-12-03 07:23:31,890 [IPC Server handler 4 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35861, datanodeUuid=6a131d7f-2964-4cfd-a61a-36b71b52c4e4, infoPort=32903, infoSecurePort=0, ipcPort=40681, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:31,892 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1001 on 127.0.0.1:46481 size 32768 replicaState = FINALIZED
2020-12-03 07:23:31,892 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMMITTED
2020-12-03 07:23:31,893 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:46481 is added to blk_1073741825_1001 (size=32768)
2020-12-03 07:23:31,895 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:46481
2020-12-03 07:23:31,895 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46481 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:31,895 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_1073741825_1001
2020-12-03 07:23:31,895 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1001 on 127.0.0.1:35861 size 32768 replicaState = FINALIZED
2020-12-03 07:23:31,895 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:23:31,896 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35861 is added to blk_1073741825_1001 (size=32768)
2020-12-03 07:23:31,896 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:35861
2020-12-03 07:23:31,896 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35861 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:31,896 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_1073741825_1001
2020-12-03 07:23:31,896 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1001 on 127.0.0.1:42092 size 32768 replicaState = FINALIZED
2020-12-03 07:23:31,896 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:23:31,897 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:42092 is added to blk_1073741825_1001 (size=32768)
2020-12-03 07:23:31,898 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:42092
2020-12-03 07:23:31,898 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42092 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:32,295 [IPC Server handler 7 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:32,296 [IPC Server handler 7 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /TC5/foo with 1 blocks is persisted to the file system
2020-12-03 07:23:32,296 [IPC Server handler 7 on default port 38268] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TC5/foo is closed by DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:32,302 [IPC Server handler 5 on default port 38268] DEBUG hdfs.StateChange (NameNodeRpcServer.java:append(809)) - *DIR* NameNode.append: file /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1 at 127.0.0.1
2020-12-03 07:23:32,303 [IPC Server handler 5 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:appendFile(2710)) - DIR* NameSystem.appendFile: src=/TC5/foo, holder=DFSClient_NONMAPREDUCE_-456895244_1, clientMachine=127.0.0.1
2020-12-03 07:23:32,313 [IPC Server handler 5 on default port 38268] DEBUG hdfs.StateChange (FSDirAppendOp.java:appendFile(154)) - DIR* NameSystem.appendFile: file /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1 at 127.0.0.1 block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 block size 32768
2020-12-03 07:23:32,314 [IPC Server handler 5 on default port 38268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/TC5/foo	dst=null	perm=null	proto=rpc
2020-12-03 07:23:32,322 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TC5/foo, chunkSize=516, chunksPerPacket=63, packetSize=32508
2020-12-03 07:23:32,346 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:23:32,360 [IPC Server handler 1 on default port 38268] DEBUG hdfs.StateChange (NameNodeRpcServer.java:append(809)) - *DIR* NameNode.append: file /TC5/foo for DFSClient_NONMAPREDUCE_234430493_1 at 127.0.0.1
2020-12-03 07:23:32,361 [IPC Server handler 1 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:appendFile(2710)) - DIR* NameSystem.appendFile: src=/TC5/foo, holder=DFSClient_NONMAPREDUCE_234430493_1, clientMachine=127.0.0.1
2020-12-03 07:23:32,361 [IPC Server handler 1 on default port 38268] WARN  hdfs.StateChange (FSDirAppendOp.java:appendFile(145)) - DIR* NameSystem.append: Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_234430493_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
2020-12-03 07:23:32,362 [IPC Server handler 1 on default port 38268] INFO  ipc.Server (Server.java:logException(2969)) - IPC Server handler 1 on default port 38268, call Call#37 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.append from 127.0.0.1:58246: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_234430493_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
2020-12-03 07:23:32,373 [Listener at localhost/38253] INFO  hdfs.AppendTestUtil (TestFileAppend3.java:testTC5(235)) - GOOD: got an exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_234430493_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2687)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:124)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2722)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:822)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:500)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:400)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy26.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1328)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1350)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1419)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1389)
	at org.apache.hadoop.hdfs.DistributedFileSystem$5.doCall(DistributedFileSystem.java:420)
	at org.apache.hadoop.hdfs.DistributedFileSystem$5.doCall(DistributedFileSystem.java:416)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:428)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:397)
	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1379)
	at org.apache.hadoop.hdfs.TestFileAppend3.testTC5(TestFileAppend3.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:32,376 [Listener at localhost/38253] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:23:32,383 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (NameNodeRpcServer.java:append(809)) - *DIR* NameNode.append: file /TC5/foo for DFSClient_NONMAPREDUCE_778343528_1 at 127.0.0.1
2020-12-03 07:23:32,384 [IPC Server handler 8 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:appendFile(2710)) - DIR* NameSystem.appendFile: src=/TC5/foo, holder=DFSClient_NONMAPREDUCE_778343528_1, clientMachine=127.0.0.1
2020-12-03 07:23:32,384 [IPC Server handler 8 on default port 38268] WARN  hdfs.StateChange (FSDirAppendOp.java:appendFile(145)) - DIR* NameSystem.append: Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_778343528_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
2020-12-03 07:23:32,384 [IPC Server handler 8 on default port 38268] INFO  ipc.Server (Server.java:logException(2969)) - IPC Server handler 8 on default port 38268, call Call#38 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.append from 127.0.0.1:58260: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_778343528_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
2020-12-03 07:23:32,388 [Listener at localhost/38253] INFO  hdfs.AppendTestUtil (TestFileAppend3.java:testTC5(244)) - GOOD: got an exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /TC5/foo for DFSClient_NONMAPREDUCE_778343528_1 on 127.0.0.1 because this file lease is currently owned by DFSClient_NONMAPREDUCE_-456895244_1 on 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2687)
	at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:124)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2722)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:822)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:500)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.append(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.append(ClientNamenodeProtocolTranslatorPB.java:400)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy26.append(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1328)
	at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1350)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1419)
	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1389)
	at org.apache.hadoop.hdfs.DistributedFileSystem$5.doCall(DistributedFileSystem.java:420)
	at org.apache.hadoop.hdfs.DistributedFileSystem$5.doCall(DistributedFileSystem.java:416)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:428)
	at org.apache.hadoop.hdfs.TestFileAppend3.testTC5(TestFileAppend3.java:240)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:32,405 [Thread-227] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:32,406 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1804f60d] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:32,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_APPEND, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=1002, bytesRcvd=[32768, 32768]
  targets=[127.0.0.1:35861, 127.0.0.1:42092]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:32,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:32,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:32,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:33014 dest: /127.0.0.1:46481
2020-12-03 07:23:32,409 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:33014, myAddr=/127.0.0.1:46481
 stage=PIPELINE_SETUP_APPEND, newGs=1002, minBytesRcvd=32768, maxBytesRcvd=32768
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:46481
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb
2020-12-03 07:23:32,409 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 32768
  getBytesOnDisk()  = 32768
  getVisibleLength()= 32768
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-03 07:23:32,455 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 32768
2020-12-03 07:23:32,455 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1002.meta of size 263
2020-12-03 07:23:32,456 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(784)) - Connecting to datanode 127.0.0.1:35861
2020-12-03 07:23:32,457 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@346939bf] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:32,457 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:32,470 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_APPEND, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=1002, bytesRcvd=[32768, 32768]
  targets=[127.0.0.1:42092]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:32,471 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:32,471 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:32,471 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:55386 dest: /127.0.0.1:35861
2020-12-03 07:23:32,471 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:55386, myAddr=/127.0.0.1:35861
 stage=PIPELINE_SETUP_APPEND, newGs=1002, minBytesRcvd=32768, maxBytesRcvd=32768
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:35861
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c
2020-12-03 07:23:32,472 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 32768
  getBytesOnDisk()  = 32768
  getVisibleLength()= 32768
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-03 07:23:32,514 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 32768
2020-12-03 07:23:32,514 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1002.meta of size 263
2020-12-03 07:23:32,515 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(784)) - Connecting to datanode 127.0.0.1:42092
2020-12-03 07:23:32,516 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4e9658b5] DEBUG datanode.DataNode (DataXceiver.java:<init>(154)) - Number of active connections is: 1
2020-12-03 07:23:32,516 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:32,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(728)) - opWriteBlock: stage=PIPELINE_SETUP_APPEND, clientname=DFSClient_NONMAPREDUCE_-456895244_1
  block  =BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001, newGs=1002, bytesRcvd=[32768, 32768]
  targets=[]; pipelineSize=3, srcDataNode=:0, pinning=false
2020-12-03 07:23:32,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(734)) - isDatanode=false, isClient=true, isTransfer=false
2020-12-03 07:23:32,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:writeBlock(736)) - writeBlock receive buf size 531128 tcp no delay true
2020-12-03 07:23:32,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001 src: /127.0.0.1:40738 dest: /127.0.0.1:42092
2020-12-03 07:23:32,518 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:<init>(191)) - BlockReceiver: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001
 storageType=DISK, inAddr=/127.0.0.1:40738, myAddr=/127.0.0.1:42092
 stage=PIPELINE_SETUP_APPEND, newGs=1002, minBytesRcvd=32768, maxBytesRcvd=32768
 clientname=DFSClient_NONMAPREDUCE_-456895244_1, srcDataNode=:0, datanode=127.0.0.1:42092
 requestedChecksum=DataChecksum(type=CRC32C, chunkSize=512)
 cachingStrategy=CachingStrategy(dropBehind=null, readahead=null)
 allowLazyPersist=false, pinning=false, isClient=true, isDatanode=false, responseInterval=30000, storageID=DS-0f484599-eccb-489e-9df4-5174a9c1ce99
2020-12-03 07:23:32,519 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 32768
  getBytesOnDisk()  = 32768
  getVisibleLength()= 32768
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-03 07:23:32,554 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(252)) - writeTo blockfile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825 of size 32768
2020-12-03 07:23:32,554 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (LocalReplicaInPipeline.java:createStreams(254)) - writeTo metafile is /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807/current/rbw/blk_1073741825_1002.meta of size 263
2020-12-03 07:23:32,555 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:waitForAckHead(1327)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE: seqno=-2 waiting for local datanode to finish write.
2020-12-03 07:23:32,572 [IPC Server handler 3 on default port 38268] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5430)) - updatePipeline(blk_1073741825_1001, newGS=1002, newLength=32768, newNodes=[127.0.0.1:46481, 127.0.0.1:35861, 127.0.0.1:42092], client=DFSClient_NONMAPREDUCE_-456895244_1)
2020-12-03 07:23:32,572 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3891)) - BLOCK* removeStoredBlock: blk_1073741825_1002 from 127.0.0.1:46481
2020-12-03 07:23:32,575 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStaleReplicas(3935)) - BLOCK* Removing stale replica ReplicaUC[[DISK]DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb:NORMAL:127.0.0.1:46481|RBW] of blk_1073741825_1001
2020-12-03 07:23:32,575 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3891)) - BLOCK* removeStoredBlock: blk_1073741825_1002 from 127.0.0.1:35861
2020-12-03 07:23:32,575 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStaleReplicas(3935)) - BLOCK* Removing stale replica ReplicaUC[[DISK]DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c:NORMAL:127.0.0.1:35861|RBW] of blk_1073741825_1001
2020-12-03 07:23:32,575 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3891)) - BLOCK* removeStoredBlock: blk_1073741825_1002 from 127.0.0.1:42092
2020-12-03 07:23:32,576 [IPC Server handler 3 on default port 38268] DEBUG BlockStateChange (BlockManager.java:removeStaleReplicas(3935)) - BLOCK* Removing stale replica ReplicaUC[[DISK]DS-0f484599-eccb-489e-9df4-5174a9c1ce99:NORMAL:127.0.0.1:42092|RBW] of blk_1073741825_1001
2020-12-03 07:23:32,577 [IPC Server handler 3 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(111)) - persistBlocks: /TC5/foo with 1 blocks is persisted to the file system
2020-12-03 07:23:32,577 [IPC Server handler 3 on default port 38268] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5448)) - updatePipeline(blk_1073741825_1001 => blk_1073741825_1002) success
2020-12-03 07:23:32,583 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 0
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:32,584 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]: enqueue Packet(seqno=0, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141204359221960, ackStatus=SUCCESS)
2020-12-03 07:23:32,584 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002
2020-12-03 07:23:32,585 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 0
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:32,585 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]: enqueue Packet(seqno=0, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141204360850197, ackStatus=SUCCESS)
2020-12-03 07:23:32,586 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002
2020-12-03 07:23:32,586 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(532)) - Receiving one packet for block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002: PacketHeader with packetLen=4 header data: offsetInBlock: 32768
seqno: 0
lastPacketInBlock: true
dataLen: 0

2020-12-03 07:23:32,586 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(613)) - Receiving an empty packet or the end of the block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002
2020-12-03 07:23:32,586 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:enqueue(1268)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE: enqueue Packet(seqno=0, lastPacketInBlock=true, offsetInBlock=32768, ackEnqueueNanoTime=141204361795183, ackStatus=SUCCESS)
2020-12-03 07:23:32,739 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40738, dest: /127.0.0.1:42092, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 2bdf22ee-48cf-453a-b54f-d0a9277d73c6, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, duration(ns): 36024009
2020-12-03 07:23:32,741 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE, replyAck=seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:32,741 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:32,741 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=LAST_IN_PIPELINE: closing
2020-12-03 07:23:32,741 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092] got seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:23:32,758 [IPC Server handler 9 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42092, datanodeUuid=2bdf22ee-48cf-453a-b54f-d0a9277d73c6, infoPort=35860, infoSecurePort=0, ipcPort=34231, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:32,759 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1002 on 127.0.0.1:42092 size 32768 replicaState = FINALIZED
2020-12-03 07:23:32,760 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:32,760 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55386, dest: /127.0.0.1:35861, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 6a131d7f-2964-4cfd-a61a-36b71b52c4e4, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, duration(ns): 195595146
2020-12-03 07:23:32,760 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:42092 is added to blk_1073741825_1002 (size=32768)
2020-12-03 07:23:32,761 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1002 is received from 127.0.0.1:42092
2020-12-03 07:23:32,762 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092], replyAck=seqno: 0 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 155284528 flag: 0 flag: 0
2020-12-03 07:23:32,763 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]] DEBUG datanode.DataNode (BlockReceiver.java:run(1387)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092] got seqno: 0 reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 155284528 flag: 0 flag: 0
2020-12-03 07:23:32,762 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:40738 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:42092:Number of active connections is: 2
2020-12-03 07:23:32,766 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33014, dest: /127.0.0.1:46481, bytes: 32768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-456895244_1, offset: 0, srvID: 96caf383-2e10-4c55-8aaf-dd6ab49628af, blockid: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, duration(ns): 199736589
2020-12-03 07:23:32,763 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]: closing
2020-12-03 07:23:32,766 [IPC Server handler 0 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35861, datanodeUuid=6a131d7f-2964-4cfd-a61a-36b71b52c4e4, infoPort=32903, infoSecurePort=0, ipcPort=40681, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:32,763 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42092] terminating
2020-12-03 07:23:32,762 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42092 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:32,768 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]] DEBUG datanode.DataNode (BlockReceiver.java:sendAckUpstreamUnprotected(1645)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092], replyAck=seqno: 0 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 178599191 flag: 0 flag: 0 flag: 0
2020-12-03 07:23:32,768 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1002 on 127.0.0.1:35861 size 32768 replicaState = FINALIZED
2020-12-03 07:23:32,768 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (BlockReceiver.java:close(1351)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]: closing
2020-12-03 07:23:32,768 [PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35861, 127.0.0.1:42092] terminating
2020-12-03 07:23:32,768 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:32,772 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35861 is added to blk_1073741825_1002 (size=32768)
2020-12-03 07:23:32,772 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1002 is received from 127.0.0.1:35861
2020-12-03 07:23:32,772 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35861 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:32,772 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:55386 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:35861:Number of active connections is: 2
2020-12-03 07:23:32,772 [IPC Server handler 4 on default port 38268] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46481, datanodeUuid=96caf383-2e10-4c55-8aaf-dd6ab49628af, infoPort=40382, infoSecurePort=0, ipcPort=38253, storageInfo=lv=-57;cid=testClusterID;nsid=2143374157;c=1606980205807) 1 blocks.
2020-12-03 07:23:32,773 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_1073741825_1002 on 127.0.0.1:46481 size 32768 replicaState = FINALIZED
2020-12-03 07:23:32,773 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:32,773 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:46481 is added to blk_1073741825_1002 (size=32768)
2020-12-03 07:23:32,774 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1002 is received from 127.0.0.1:46481
2020-12-03 07:23:32,774 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46481 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:32,774 [IPC Server handler 7 on default port 38268] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /TC5/foo for DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:32,775 [IPC Server handler 7 on default port 38268] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /TC5/foo with 1 blocks is persisted to the file system
2020-12-03 07:23:32,775 [IPC Server handler 7 on default port 38268] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TC5/foo is closed by DFSClient_NONMAPREDUCE_-456895244_1
2020-12-03 07:23:32,785 [DataXceiver for client DFSClient_NONMAPREDUCE_-456895244_1 at /127.0.0.1:33014 [Receiving block BP-464985465-172.17.0.4-1606980205807:blk_1073741825_1001]] DEBUG datanode.DataNode (DataXceiver.java:run(328)) - 127.0.0.1:46481:Number of active connections is: 2
2020-12-03 07:23:32,785 [Listener at localhost/38253] INFO  hdfs.AppendTestUtil (TestFileAppend3.java:tearDown(86)) - tearDown()
2020-12-03 07:23:32,789 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:32,789 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:23:32,791 [Listener at localhost/38253] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:32,791 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1804f60d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:32,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-e67e1514-a5ee-431f-89b5-5c468fb18954) exiting.
2020-12-03 07:23:32,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c354115d-1c30-4f9c-805a-1bdb51e03ecb) exiting.
2020-12-03 07:23:32,841 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4d157787{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:32,848 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@68ed96ca{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,849 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c8b96ec{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:32,851 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21680803{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:32,861 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38253
2020-12-03 07:23:32,865 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,865 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,867 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,867 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 96caf383-2e10-4c55-8aaf-dd6ab49628af) service to localhost/127.0.0.1:38268
2020-12-03 07:23:32,868 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 96caf383-2e10-4c55-8aaf-dd6ab49628af)
2020-12-03 07:23:32,868 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:32,871 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,872 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,876 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:32,876 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:32,877 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:32,877 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:32,886 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:32,886 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:32,887 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4e9658b5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:32,888 [Listener at localhost/38253] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:32,891 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-0f484599-eccb-489e-9df4-5174a9c1ce99) exiting.
2020-12-03 07:23:32,891 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-955d791f-a07c-4bbc-a809-49dc699e8596) exiting.
2020-12-03 07:23:33,151 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@781e7326{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:33,153 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22680f52{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:33,153 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a551a63{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,154 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52eacb4b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:33,167 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34231
2020-12-03 07:23:33,173 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,174 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,174 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:33,182 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 2bdf22ee-48cf-453a-b54f-d0a9277d73c6) service to localhost/127.0.0.1:38268
2020-12-03 07:23:33,183 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 2bdf22ee-48cf-453a-b54f-d0a9277d73c6)
2020-12-03 07:23:33,183 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:33,184 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,186 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,191 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:33,192 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:33,193 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:33,193 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:33,196 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:33,196 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:33,197 [Listener at localhost/38253] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:33,197 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@30c31dd7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:33,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a88d39dc-dc59-48b8-b9d0-d56291ce98e5) exiting.
2020-12-03 07:23:33,206 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-cbc0c80e-ec97-476d-9a56-9ec56ce40e37) exiting.
2020-12-03 07:23:33,260 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5be82d43{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:33,261 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@600b0b7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:33,262 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73393584{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,262 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@615f972{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:33,269 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44864
2020-12-03 07:23:33,272 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,272 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,273 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:33,275 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3) service to localhost/127.0.0.1:38268
2020-12-03 07:23:33,275 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid c6a18eb2-a1a3-44a9-9a6d-2422fa3379d3)
2020-12-03 07:23:33,276 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:33,280 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,284 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,293 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:33,293 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:33,296 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:33,296 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:33,300 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:33,300 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:33,300 [Listener at localhost/38253] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:33,300 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5149f008] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:33,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0e9959b6-9bf1-4351-b9f1-fccd4970cc77) exiting.
2020-12-03 07:23:33,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-ebdc5084-8fc0-4cd7-bfba-d2b9f48e2105) exiting.
2020-12-03 07:23:33,339 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70e29e14{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:33,341 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b7efaeb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:33,341 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@672f11c2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,342 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35038141{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:33,343 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36749
2020-12-03 07:23:33,347 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,347 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,347 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:33,350 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 591dcf68-88cc-4620-912b-223dc6c67fcd) service to localhost/127.0.0.1:38268
2020-12-03 07:23:33,351 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 591dcf68-88cc-4620-912b-223dc6c67fcd)
2020-12-03 07:23:33,351 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:33,351 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,361 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,368 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:33,368 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:33,371 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:33,371 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:33,376 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:33,376 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:33,376 [Listener at localhost/38253] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:33,376 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@346939bf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:33,379 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9493e2c8-78f1-4634-845a-3e6288543417) exiting.
2020-12-03 07:23:33,379 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-da96a200-bd7f-435c-a4e8-fb3aba56b27c) exiting.
2020-12-03 07:23:33,423 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@24faea88{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:33,424 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a320ade{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:33,425 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@107ed6fc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,425 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34a75079{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:33,427 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40681
2020-12-03 07:23:33,433 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,434 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,442 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:33,442 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 6a131d7f-2964-4cfd-a61a-36b71b52c4e4) service to localhost/127.0.0.1:38268
2020-12-03 07:23:33,442 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464985465-172.17.0.4-1606980205807 (Datanode Uuid 6a131d7f-2964-4cfd-a61a-36b71b52c4e4)
2020-12-03 07:23:33,442 [BP-464985465-172.17.0.4-1606980205807 heartbeating to localhost/127.0.0.1:38268] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464985465-172.17.0.4-1606980205807
2020-12-03 07:23:33,443 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,443 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464985465-172.17.0.4-1606980205807] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:33,458 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:33,458 [Listener at localhost/38253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:33,462 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:33,462 [Listener at localhost/38253] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:33,471 [Listener at localhost/38253] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:33,472 [Listener at localhost/38253] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:33,472 [Listener at localhost/38253] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:33,473 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@64dafeed] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:33,474 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@47605f2f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:33,474 [Listener at localhost/38253] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 11
2020-12-03 07:23:33,474 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2ece4966] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:33,476 [Listener at localhost/38253] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 12 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 1 1 
2020-12-03 07:23:33,477 [Listener at localhost/38253] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-12-03 07:23:33,478 [Listener at localhost/38253] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-12-03 07:23:33,479 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:33,480 [CacheReplicationMonitor(2025313041)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:33,545 [Listener at localhost/38253] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38268
2020-12-03 07:23:33,557 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,557 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:33,561 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:33,561 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,568 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@4fbda97b] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:33,631 [Listener at localhost/38253] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:33,631 [Listener at localhost/38253] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:33,636 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@f627d13{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:33,646 [Listener at localhost/38253] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@651aed93{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:33,646 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47caedad{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,647 [Listener at localhost/38253] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2657d4dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:33,656 [Listener at localhost/38253] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:33,677 [Listener at localhost/38253] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:33,678 [Listener at localhost/38253] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
