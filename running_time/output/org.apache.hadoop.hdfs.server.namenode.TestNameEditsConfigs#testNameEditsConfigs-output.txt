2020-12-03 07:23:37,539 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:23:38,195 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:38,196 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:38,216 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:38,217 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
Formatting using clusterid: testClusterID
2020-12-03 07:23:38,238 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:38,251 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:38,253 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:38,253 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:38,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:38,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:38,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:38,262 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:38,314 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:38,320 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:38,320 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:38,322 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:38,329 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:38,330 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:38
2020-12-03 07:23:38,332 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:38,332 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:38,334 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:38,334 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:38,355 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:38,356 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:38,363 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:38,364 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:38,364 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:38,364 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:38,365 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:38,365 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:38,366 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:38,366 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:38,366 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:38,366 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:38,367 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:38,405 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:38,405 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:38,405 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:38,406 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:38,421 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:38,421 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:38,422 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:38,422 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:38,429 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:38,429 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:38,429 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:38,430 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:38,436 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:38,438 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:38,443 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:38,443 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:38,444 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:38,444 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:38,455 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:38,455 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:38,455 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:38,461 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:38,462 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:38,464 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:38,465 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:38,465 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:38,465 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:38,500 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:38,567 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits has been successfully formatted.
2020-12-03 07:23:38,598 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:38,720 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:23:38,762 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:38,764 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:38,867 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:39,179 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:39,179 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:39,214 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:39,262 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d5b810e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:39,282 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:39,288 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,304 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2650ms
2020-12-03 07:23:39,443 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:39,447 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:39,447 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,456 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:39,458 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:39,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:39,459 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:39,493 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:39,493 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:39,504 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40350
2020-12-03 07:23:39,506 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:39,564 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1500b2f3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:39,565 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@126253fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:39,610 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@295cf707{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:39,619 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39d76cb5{HTTP/1.1,[http/1.1]}{localhost:40350}
2020-12-03 07:23:39,620 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2966ms
2020-12-03 07:23:39,620 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:39,621 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:39,621 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:39,622 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:39,622 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:39,623 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:39,634 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:39,635 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:39,636 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:39,636 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:39,637 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:39,637 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:39,637 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:39,638 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:39,639 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:39,640 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:39,640 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:39,641 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:39,642 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:39
2020-12-03 07:23:39,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:39,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:39,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:39,649 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:39,649 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:39,650 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:39,651 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:39,651 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:39,651 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:39,651 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:39,652 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:39,652 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:39,652 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:39,652 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:39,652 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:39,653 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:39,653 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:39,654 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,654 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:39,654 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:39,657 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:39,657 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:39,657 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:39,658 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:39,658 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:39,658 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:39,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:39,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,659 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:39,659 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:39,660 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:39,660 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:39,660 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:39,660 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:39,661 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:39,661 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:39,661 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,661 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:39,662 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:39,719 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:39,724 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current
2020-12-03 07:23:39,724 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:39,725 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:39,757 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:39,763 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:39,764 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000000
2020-12-03 07:23:39,768 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:39,769 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:39,811 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:39,812 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 146 msecs
2020-12-03 07:23:40,015 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:40,065 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:40,082 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,346 [Listener at localhost/46332] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46332 to access this namenode/service.
2020-12-03 07:23:40,350 [Listener at localhost/46332] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:40,351 [Listener at localhost/46332] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:40,363 [Listener at localhost/46332] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:40,374 [Listener at localhost/46332] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:40,375 [Listener at localhost/46332] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:40,375 [Listener at localhost/46332] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:40,375 [Listener at localhost/46332] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:40,378 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:40,379 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:40,379 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:40,379 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:40,379 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:40,379 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:23:40,410 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,410 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,413 [Listener at localhost/46332] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46332
2020-12-03 07:23:40,416 [Listener at localhost/46332] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:40,417 [Listener at localhost/46332] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:40,424 [Listener at localhost/46332] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:40,428 [CacheReplicationMonitor(978374323)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:40,436 [Listener at localhost/46332] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:40,511 [Listener at localhost/46332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:40,526 [Listener at localhost/46332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:40,545 [Listener at localhost/46332] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:40,550 [Listener at localhost/46332] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:40,553 [Listener at localhost/46332] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:40,557 [Listener at localhost/46332] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:40,558 [Listener at localhost/46332] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:40,563 [Listener at localhost/46332] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:40,572 [Listener at localhost/46332] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41118
2020-12-03 07:23:40,575 [Listener at localhost/46332] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:40,576 [Listener at localhost/46332] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:40,594 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,596 [Listener at localhost/46332] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,596 [Listener at localhost/46332] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:40,597 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,599 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,600 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:40,600 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,600 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,604 [Listener at localhost/46332] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42779
2020-12-03 07:23:40,604 [Listener at localhost/46332] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,605 [Listener at localhost/46332] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e029d61{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:40,606 [Listener at localhost/46332] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4052274f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,613 [Listener at localhost/46332] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@21005f6c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:40,614 [Listener at localhost/46332] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@32f0fba8{HTTP/1.1,[http/1.1]}{localhost:42779}
2020-12-03 07:23:40,614 [Listener at localhost/46332] INFO  server.Server (Server.java:doStart(419)) - Started @3960ms
2020-12-03 07:23:40,917 [Listener at localhost/46332] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36739
2020-12-03 07:23:40,918 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27cf3151] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,919 [Listener at localhost/46332] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:40,919 [Listener at localhost/46332] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:40,936 [Listener at localhost/46332] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:40,937 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,943 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35960
2020-12-03 07:23:41,121 [Listener at localhost/35960] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:41,125 [Listener at localhost/35960] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:41,139 [Thread-58] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332 starting to offer service
2020-12-03 07:23:41,146 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:41,146 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:41,151 [Listener at localhost/35960] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:41,154 [Listener at localhost/35960] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:41,154 [Listener at localhost/35960] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:41,156 [Listener at localhost/35960] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:41,156 [Listener at localhost/35960] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,157 [Listener at localhost/35960] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:41,157 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:41,158 [Listener at localhost/35960] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,158 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:41,159 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39535
2020-12-03 07:23:41,159 [Listener at localhost/35960] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:41,160 [Listener at localhost/35960] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:41,163 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,166 [Listener at localhost/35960] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:41,166 [Listener at localhost/35960] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:41,167 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,169 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:41,170 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:41,170 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:41,170 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:41,171 [Listener at localhost/35960] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35061
2020-12-03 07:23:41,171 [Listener at localhost/35960] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:41,173 [Listener at localhost/35960] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d511b5f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:41,174 [Listener at localhost/35960] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40f33492{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:41,181 [Listener at localhost/35960] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@62da83ed{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:41,183 [Listener at localhost/35960] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5d8445d7{HTTP/1.1,[http/1.1]}{localhost:35061}
2020-12-03 07:23:41,183 [Listener at localhost/35960] INFO  server.Server (Server.java:doStart(419)) - Started @4529ms
2020-12-03 07:23:41,328 [Listener at localhost/35960] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44340
2020-12-03 07:23:41,329 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@384fc774] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:41,329 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:41,329 [Listener at localhost/35960] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:41,330 [Listener at localhost/35960] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:41,332 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:41,337 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45892
2020-12-03 07:23:41,345 [Listener at localhost/45892] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:41,346 [Listener at localhost/45892] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:41,347 [Thread-82] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332 starting to offer service
2020-12-03 07:23:41,349 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:41,349 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:41,361 [Listener at localhost/45892] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:41,362 [Listener at localhost/45892] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:41,363 [Listener at localhost/45892] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:41,365 [Listener at localhost/45892] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:41,365 [Listener at localhost/45892] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,365 [Listener at localhost/45892] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:41,366 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:41,366 [Listener at localhost/45892] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,367 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:41,367 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44172
2020-12-03 07:23:41,368 [Listener at localhost/45892] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:41,368 [Listener at localhost/45892] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:41,369 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,371 [Listener at localhost/45892] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:41,372 [Listener at localhost/45892] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:41,372 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,377 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:41,378 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:41,378 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:41,378 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:41,379 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44068
2020-12-03 07:23:41,379 [Listener at localhost/45892] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:41,381 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4362d7df{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:41,382 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c25b8a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:41,388 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77b7ffa4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:41,389 [Listener at localhost/45892] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5ed190be{HTTP/1.1,[http/1.1]}{localhost:44068}
2020-12-03 07:23:41,390 [Listener at localhost/45892] INFO  server.Server (Server.java:doStart(419)) - Started @4736ms
2020-12-03 07:23:41,419 [Listener at localhost/45892] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46019
2020-12-03 07:23:41,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bbc9f97] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:41,420 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:41,420 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:41,421 [Listener at localhost/45892] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:41,423 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:41,429 [Listener at localhost/45878] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45878
2020-12-03 07:23:41,433 [Listener at localhost/45878] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:41,434 [Listener at localhost/45878] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:41,435 [Thread-104] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332 starting to offer service
2020-12-03 07:23:41,437 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:41,437 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:41,536 [Thread-104] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332
2020-12-03 07:23:41,536 [Thread-82] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332
2020-12-03 07:23:41,536 [Thread-58] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46332
2020-12-03 07:23:41,539 [Thread-58] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:41,539 [Thread-104] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:41,539 [Thread-82] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:41,628 [Thread-58] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,628 [Thread-82] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,629 [Thread-104] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,629 [Thread-82] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,629 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,629 [Thread-104] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,630 [Thread-104] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:23:41,630 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a942f057-deae-4f03-9702-7f6ecd90f93d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:23:41,630 [Thread-82] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:23:41,791 [Thread-104] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,791 [Thread-104] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,791 [Thread-58] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,792 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,793 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-479312ef-eeb1-4c34-b587-263125ea57db for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:23:41,791 [Thread-82] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:41,792 [Thread-104] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-20ea579c-cd28-4269-9aea-b545c0a7f417 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:23:41,794 [Thread-82] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 198152275. Formatting...
2020-12-03 07:23:41,803 [Thread-82] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-da04c649-932f-40d5-9a46-2ab5df792559 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:23:41,935 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,936 [Thread-58] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,936 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:41,937 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:41,941 [IPC Server handler 4 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,951 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:41,951 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:41,971 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,971 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,971 [Thread-82] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,972 [Thread-104] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:41,972 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:41,972 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:41,972 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:41,972 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:42,054 [IPC Server handler 3 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,055 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,055 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,127 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,128 [Thread-58] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,128 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:42,128 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:42,157 [IPC Server handler 2 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,158 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,158 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,170 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,170 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,171 [Thread-104] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,171 [Thread-82] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,171 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:42,171 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1775645091-172.17.0.11-1606980218489 is not formatted. Formatting ...
2020-12-03 07:23:42,171 [Thread-104] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:42,171 [Thread-82] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775645091-172.17.0.11-1606980218489 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current
2020-12-03 07:23:42,260 [IPC Server handler 6 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,261 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,261 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,296 [Thread-58] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=null
2020-12-03 07:23:42,335 [Thread-104] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=null
2020-12-03 07:23:42,335 [Thread-82] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=null
2020-12-03 07:23:42,363 [IPC Server handler 7 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,364 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,365 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,467 [IPC Server handler 0 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,468 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,468 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,480 [Thread-58] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:42,518 [Thread-82] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:42,518 [Thread-104] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:42,570 [IPC Server handler 4 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,570 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,571 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,620 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5
2020-12-03 07:23:42,620 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29
2020-12-03 07:23:42,621 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:42,621 [Thread-104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:42,620 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a942f057-deae-4f03-9702-7f6ecd90f93d
2020-12-03 07:23:42,621 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:42,623 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da04c649-932f-40d5-9a46-2ab5df792559
2020-12-03 07:23:42,623 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:42,624 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-479312ef-eeb1-4c34-b587-263125ea57db
2020-12-03 07:23:42,625 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:42,626 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20ea579c-cd28-4269-9aea-b545c0a7f417
2020-12-03 07:23:42,627 [Thread-104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:42,629 [Thread-104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:42,629 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:42,629 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:42,634 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:42,635 [Thread-82] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:42,636 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:42,643 [Thread-104] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:42,643 [Thread-82] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:42,643 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:42,645 [Thread-82] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:42,645 [Thread-104] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:42,645 [Thread-82] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:42,645 [Thread-104] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:42,645 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:42,646 [Thread-82] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,646 [Thread-104] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,646 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:42,646 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,647 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:42,647 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:42,647 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:42,647 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:42,647 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:42,647 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:42,675 [IPC Server handler 3 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,676 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:42,676 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,684 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 36ms
2020-12-03 07:23:42,684 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 37ms
2020-12-03 07:23:42,685 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 37ms
2020-12-03 07:23:42,685 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 38ms
2020-12-03 07:23:42,685 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 38ms
2020-12-03 07:23:42,686 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 38ms
2020-12-03 07:23:42,686 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 39ms
2020-12-03 07:23:42,687 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:42,687 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:42,687 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:42,687 [Thread-136] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,687 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:42,688 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,688 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,687 [Thread-137] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,689 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 41ms
2020-12-03 07:23:42,689 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 43ms
2020-12-03 07:23:42,689 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:23:42,691 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:23:42,692 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-12-03 07:23:42,692 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:42,692 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 6ms
2020-12-03 07:23:42,693 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,693 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 5ms
2020-12-03 07:23:42,693 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:42,693 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 7ms
2020-12-03 07:23:42,693 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas doesn't exist 
2020-12-03 07:23:42,693 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:23:42,694 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:23:42,695 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 6ms
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:42,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559): finished scanning block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,722 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:42,728 [Thread-82] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:17 AM with interval of 21600000ms
2020-12-03 07:23:42,728 [Thread-58] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:50 AM with interval of 21600000ms
2020-12-03 07:23:42,728 [Thread-104] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:49 AM with interval of 21600000ms
2020-12-03 07:23:42,736 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:46332 beginning handshake with NN
2020-12-03 07:23:42,736 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:46332 beginning handshake with NN
2020-12-03 07:23:42,736 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:46332 beginning handshake with NN
2020-12-03 07:23:42,748 [IPC Server handler 7 on default port 46332] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44172, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=46019, infoSecurePort=0, ipcPort=45878, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:42,751 [IPC Server handler 7 on default port 46332] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44172
2020-12-03 07:23:42,751 [IPC Server handler 7 on default port 46332] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0a9dab0c-df25-451f-9d45-48227165f30e (127.0.0.1:44172).
2020-12-03 07:23:42,753 [IPC Server handler 6 on default port 46332] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41118, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=36739, infoSecurePort=0, ipcPort=35960, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:42,753 [IPC Server handler 6 on default port 46332] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41118
2020-12-03 07:23:42,753 [IPC Server handler 6 on default port 46332] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bb9904b-e086-4883-b13d-90a0b829e439 (127.0.0.1:41118).
2020-12-03 07:23:42,753 [IPC Server handler 2 on default port 46332] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39535, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44340, infoSecurePort=0, ipcPort=45892, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:42,754 [IPC Server handler 2 on default port 46332] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39535
2020-12-03 07:23:42,754 [IPC Server handler 2 on default port 46332] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7b6bc5ce-f019-43bd-9069-f15868efab27 (127.0.0.1:39535).
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:46332 successfully registered with NN
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:46332 successfully registered with NN
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:46332 successfully registered with NN
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46332 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46332 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:42,756 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46332 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:42,777 [IPC Server handler 8 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 for DN 127.0.0.1:44172
2020-12-03 07:23:42,778 [IPC Server handler 8 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20ea579c-cd28-4269-9aea-b545c0a7f417 for DN 127.0.0.1:44172
2020-12-03 07:23:42,779 [IPC Server handler 9 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a942f057-deae-4f03-9702-7f6ecd90f93d for DN 127.0.0.1:41118
2020-12-03 07:23:42,779 [IPC Server handler 9 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-479312ef-eeb1-4c34-b587-263125ea57db for DN 127.0.0.1:41118
2020-12-03 07:23:42,780 [IPC Server handler 0 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 for DN 127.0.0.1:39535
2020-12-03 07:23:42,780 [IPC Server handler 5 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,780 [IPC Server handler 0 on default port 46332] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da04c649-932f-40d5-9a46-2ab5df792559 for DN 127.0.0.1:39535
2020-12-03 07:23:42,787 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:39535
2020-12-03 07:23:42,788 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:42,813 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe834cd3cdabbde35: Processing first storage report for DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:42,815 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe834cd3cdabbde35: from storage DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 node DatanodeRegistration(127.0.0.1:44172, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=46019, infoSecurePort=0, ipcPort=45878, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,815 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xef6630c2d340ab92: Processing first storage report for DS-da04c649-932f-40d5-9a46-2ab5df792559 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xef6630c2d340ab92: from storage DS-da04c649-932f-40d5-9a46-2ab5df792559 node DatanodeRegistration(127.0.0.1:39535, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44340, infoSecurePort=0, ipcPort=45892, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbb4d6d01e6d29e5f: Processing first storage report for DS-a942f057-deae-4f03-9702-7f6ecd90f93d from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbb4d6d01e6d29e5f: from storage DS-a942f057-deae-4f03-9702-7f6ecd90f93d node DatanodeRegistration(127.0.0.1:41118, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=36739, infoSecurePort=0, ipcPort=35960, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe834cd3cdabbde35: Processing first storage report for DS-20ea579c-cd28-4269-9aea-b545c0a7f417 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe834cd3cdabbde35: from storage DS-20ea579c-cd28-4269-9aea-b545c0a7f417 node DatanodeRegistration(127.0.0.1:44172, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=46019, infoSecurePort=0, ipcPort=45878, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xef6630c2d340ab92: Processing first storage report for DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:42,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xef6630c2d340ab92: from storage DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 node DatanodeRegistration(127.0.0.1:39535, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44340, infoSecurePort=0, ipcPort=45892, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,817 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbb4d6d01e6d29e5f: Processing first storage report for DS-479312ef-eeb1-4c34-b587-263125ea57db from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:42,817 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbb4d6d01e6d29e5f: from storage DS-479312ef-eeb1-4c34-b587-263125ea57db node DatanodeRegistration(127.0.0.1:41118, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=36739, infoSecurePort=0, ipcPort=35960, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbb4d6d01e6d29e5f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe834cd3cdabbde35,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xef6630c2d340ab92,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,836 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:42,890 [IPC Server handler 6 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,892 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:42,901 [IPC Server handler 2 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,903 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:42,907 [Listener at localhost/45878] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - SecondaryNameNode metrics system started (again)
2020-12-03 07:23:42,951 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:42,952 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:42,952 [Listener at localhost/45878] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:43,013 [Listener at localhost/45878] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:43,016 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:43,016 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:43,016 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:43,016 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:43,016 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:43,017 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:43,017 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:43,017 [Listener at localhost/45878] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:43,018 [Listener at localhost/45878] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:43,018 [Listener at localhost/45878] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:43,018 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:43,019 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:43
2020-12-03 07:23:43,019 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:43,019 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:43,019 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:43,019 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:43,033 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:43,034 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:43,034 [Listener at localhost/45878] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:43,034 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:43,035 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:43,036 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:43,036 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:43,036 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:43,037 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:43,037 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:43,042 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:43,042 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:43,043 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:43,044 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:43,044 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:43,045 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:43,045 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:43,045 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:43,049 [Listener at localhost/45878] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(261)) - Checkpoint Period   :3600 secs (60 min)
2020-12-03 07:23:43,049 [Listener at localhost/45878] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(263)) - Log Size Trigger    :1000000 txns
2020-12-03 07:23:43,066 [IPC Server handler 7 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,082 [IPC Server handler 5 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:43,149 [IPC Server handler 9 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/TestNameEditsConfigs1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:43,204 [IPC Server handler 0 on default port 46332] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41118, 127.0.0.1:39535, 127.0.0.1:44172 for /user/root/TestNameEditsConfigs1
2020-12-03 07:23:43,221 [Thread-155] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,305 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:59914 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001 src: /127.0.0.1:59914 dest: /127.0.0.1:41118
2020-12-03 07:23:43,337 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:59914 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,344 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:44280 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001 src: /127.0.0.1:44280 dest: /127.0.0.1:39535
2020-12-03 07:23:43,346 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:44280 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,349 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:33900 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001 src: /127.0.0.1:33900 dest: /127.0.0.1:44172
2020-12-03 07:23:43,404 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33900, dest: /127.0.0.1:44172, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, duration(ns): 37330083
2020-12-03 07:23:43,404 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:43,422 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44172]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44280, dest: /127.0.0.1:39535, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, duration(ns): 49095711
2020-12-03 07:23:43,422 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44172]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44172] terminating
2020-12-03 07:23:43,428 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39535, 127.0.0.1:44172]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59914, dest: /127.0.0.1:41118, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, duration(ns): 64084573
2020-12-03 07:23:43,430 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39535, 127.0.0.1:44172]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39535, 127.0.0.1:44172] terminating
2020-12-03 07:23:43,449 [IPC Server handler 6 on default port 46332] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:44172, 127.0.0.1:41118, 127.0.0.1:39535 for /user/root/TestNameEditsConfigs1
2020-12-03 07:23:43,453 [DataStreamer for file /user/root/TestNameEditsConfigs1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,458 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:33902 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002 src: /127.0.0.1:33902 dest: /127.0.0.1:44172
2020-12-03 07:23:43,460 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:33902 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,462 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:59922 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002 src: /127.0.0.1:59922 dest: /127.0.0.1:41118
2020-12-03 07:23:43,464 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:59922 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:43,465 [DataXceiver for client DFSClient_NONMAPREDUCE_521425130_1 at /127.0.0.1:44288 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002 src: /127.0.0.1:44288 dest: /127.0.0.1:39535
2020-12-03 07:23:43,479 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44288, dest: /127.0.0.1:39535, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, duration(ns): 10367374
2020-12-03 07:23:43,479 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:43,487 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39535]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59922, dest: /127.0.0.1:41118, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, duration(ns): 17457123
2020-12-03 07:23:43,487 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39535]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39535] terminating
2020-12-03 07:23:43,494 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41118, 127.0.0.1:39535]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33902, dest: /127.0.0.1:44172, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_521425130_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, duration(ns): 24402438
2020-12-03 07:23:43,494 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41118, 127.0.0.1:39535]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41118, 127.0.0.1:39535] terminating
2020-12-03 07:23:43,505 [IPC Server handler 7 on default port 46332] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/TestNameEditsConfigs1 is closed by DFSClient_NONMAPREDUCE_521425130_1
2020-12-03 07:23:43,515 [IPC Server handler 0 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,519 [IPC Server handler 8 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,531 [IPC Server handler 4 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,569 [IPC Server handler 1 on default port 46332] INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(4740)) - Roll Edit Log from 127.0.0.1
2020-12-03 07:23:43,569 [IPC Server handler 1 on default port 46332] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:43,570 [IPC Server handler 1 on default port 46332] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 11
2020-12-03 07:23:43,570 [IPC Server handler 1 on default port 46332] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 12 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 3 
2020-12-03 07:23:43,572 [IPC Server handler 1 on default port 46332] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000001-0000000000000000012
2020-12-03 07:23:43,573 [IPC Server handler 1 on default port 46332] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 13
2020-12-03 07:23:43,618 [IPC Server handler 1 on default port 46332] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rollEditLog	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,662 [Listener at localhost/45878] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(421)) - Image has changed. Downloading updated image from NN.
2020-12-03 07:23:43,666 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:40350/imagetransfer?getimage=1&txid=0&storageInfo=-65:198152275:1606980218489:testClusterID&bootstrapstandby=false
2020-12-03 07:23:43,795 [qtp252277567-48] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000000, fileSize: 396. Sent total: 396 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:43,851 [Listener at localhost/45878] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.01s. The file download took 0.01s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2020-12-03 07:23:43,851 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(122)) - Downloaded file fsimage.ckpt_0000000000000000000 size 396 bytes.
2020-12-03 07:23:43,886 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:40350/imagetransfer?getedit=1&startTxId=1&endTxId=12&storageInfo=-65:198152275:1606980218489:testClusterID
2020-12-03 07:23:43,889 [qtp252277567-742] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000001-0000000000000000012, fileSize: 782. Sent total: 782 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:43,918 [Listener at localhost/45878] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_tmp_0000000000000000001-0000000000000000012_0000000000141214214 took 0.00s.
2020-12-03 07:23:43,919 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(175)) - Downloaded file edits_tmp_0000000000000000001-0000000000000000012_0000000000141214214 size 0 bytes.
2020-12-03 07:23:43,979 [Listener at localhost/45878] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:43,981 [Listener at localhost/45878] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:43,982 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage_0000000000000000000
2020-12-03 07:23:43,982 [Listener at localhost/45878] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:43,990 [Listener at localhost/45878] INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(314)) - Checkpointer about to load edits from 1 stream(s).
2020-12-03 07:23:43,993 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000001-0000000000000000012 expecting start txid #1
2020-12-03 07:23:43,994 [Listener at localhost/45878] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000001-0000000000000000012 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:44,054 [Listener at localhost/45878] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000001-0000000000000000012) of total size 782.0, total edits 12.0, total load time 26.0 ms
2020-12-03 07:23:44,068 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000012 using no compression
2020-12-03 07:23:44,084 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000012 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:44,160 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits
2020-12-03 07:23:44,161 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits
2020-12-03 07:23:44,239 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:setTimeout(436)) - Image Transfer timeout configured to 60000 milliseconds
2020-12-03 07:23:44,241 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage_0000000000000000012, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:44,288 [qtp252277567-36] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000012 took 0.00s.
2020-12-03 07:23:44,289 [qtp252277567-36] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000012 size 653 bytes.
2020-12-03 07:23:44,332 [qtp252277567-36] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:23:44,337 [Listener at localhost/45878] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 12 to namenode at http://localhost:40350 in 0.116 seconds
2020-12-03 07:23:44,338 [Listener at localhost/45878] WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(585)) - Checkpoint done. New Image Size: 653
2020-12-03 07:23:44,339 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:44,339 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:44,340 [Listener at localhost/45878] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:44,340 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@70e659aa] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:44,342 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29) exiting.
2020-12-03 07:23:44,342 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417) exiting.
2020-12-03 07:23:44,393 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77b7ffa4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:44,401 [Listener at localhost/45878] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5ed190be{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:44,402 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c25b8a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:44,403 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4362d7df{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:44,407 [Listener at localhost/45878] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45878
2020-12-03 07:23:44,428 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:44,428 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:44,430 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:44,430 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:46332
2020-12-03 07:23:44,430 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e)
2020-12-03 07:23:44,430 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:44,432 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,433 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,436 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:44,436 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:44,437 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:44,437 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:44,443 [Listener at localhost/45878] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:44,443 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:44,444 [Listener at localhost/45878] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:44,444 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b5cb9b2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:44,446 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5) exiting.
2020-12-03 07:23:44,446 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559) exiting.
2020-12-03 07:23:44,641 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@62da83ed{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:44,654 [Listener at localhost/45878] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5d8445d7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:44,655 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40f33492{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:44,656 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d511b5f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:44,663 [Listener at localhost/45878] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45892
2020-12-03 07:23:44,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:44,674 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:44,673 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:44,692 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:46332
2020-12-03 07:23:44,692 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27)
2020-12-03 07:23:44,692 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:44,694 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,696 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,700 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:44,701 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:44,702 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:44,703 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:44,705 [Listener at localhost/45878] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:44,705 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:44,705 [Listener at localhost/45878] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:44,706 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@59d2103b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:44,706 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db) exiting.
2020-12-03 07:23:44,706 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d) exiting.
2020-12-03 07:23:44,941 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@21005f6c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:44,943 [Listener at localhost/45878] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@32f0fba8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:44,945 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4052274f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:44,945 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e029d61{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:44,958 [Listener at localhost/45878] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35960
2020-12-03 07:23:44,961 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:44,961 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:44,961 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:44,963 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:46332
2020-12-03 07:23:44,963 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439)
2020-12-03 07:23:44,964 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:46332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:44,965 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,966 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:44,985 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:44,985 [Listener at localhost/45878] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:44,986 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:44,987 [Listener at localhost/45878] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:44,990 [Listener at localhost/45878] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:44,990 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:44,991 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:44,991 [Listener at localhost/45878] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 13, 13
2020-12-03 07:23:44,991 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7be58f16] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:44,993 [Listener at localhost/45878] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:23:44,994 [Listener at localhost/45878] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000013 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000013-0000000000000000014
2020-12-03 07:23:44,995 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6111ba37] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:44,995 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:44,995 [CacheReplicationMonitor(978374323)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:45,006 [Listener at localhost/45878] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46332
2020-12-03 07:23:45,008 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:45,008 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:45,008 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,010 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,017 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:45,018 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:45,125 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@295cf707{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:45,133 [Listener at localhost/45878] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39d76cb5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,134 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@126253fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:45,135 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1500b2f3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:45,171 [Listener at localhost/45878] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:23:45,171 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:45,172 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:45,173 [Listener at localhost/45878] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:45,173 [Listener at localhost/45878] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:45,174 [Listener at localhost/45878] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:45,187 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73877e19] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:45,187 [Listener at localhost/45878] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:45,187 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,190 [Listener at localhost/45878] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:45,191 [Listener at localhost/45878] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:45,191 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,194 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:45,195 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:45,195 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:45,195 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:45,197 [Listener at localhost/45878] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:45,197 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:45,198 [Listener at localhost/45878] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44462
2020-12-03 07:23:45,198 [Listener at localhost/45878] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:45,201 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@783efb48{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:45,202 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e8e8621{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:45,210 [Listener at localhost/45878] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@66596a88{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:45,211 [Listener at localhost/45878] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5aae8eb5{HTTP/1.1,[http/1.1]}{localhost:44462}
2020-12-03 07:23:45,213 [Listener at localhost/45878] INFO  server.Server (Server.java:doStart(419)) - Started @8559ms
2020-12-03 07:23:45,214 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:45,214 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:45,215 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:45,215 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:45,215 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:45,215 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:45,216 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:45,216 [Listener at localhost/45878] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:45,219 [Listener at localhost/45878] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:45,219 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:45,219 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:45,220 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:45,220 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:45,220 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:45,221 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:45,221 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:45,222 [Listener at localhost/45878] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:45,225 [Listener at localhost/45878] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:45,225 [Listener at localhost/45878] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:45,226 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:45,235 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:45
2020-12-03 07:23:45,235 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:45,235 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,236 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:45,238 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:45,249 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:45,250 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:45,250 [Listener at localhost/45878] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:45,251 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:45,251 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:45,251 [Listener at localhost/45878] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:45,252 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:45,252 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:45,252 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:45,252 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:45,253 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:45,253 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:45,253 [Listener at localhost/45878] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:45,254 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:45,254 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,255 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:45,255 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:45,258 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:45,258 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:45,259 [Listener at localhost/45878] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:45,259 [Listener at localhost/45878] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:45,259 [Listener at localhost/45878] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:45,260 [Listener at localhost/45878] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:45,260 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:45,260 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,261 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:45,261 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:45,262 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:45,262 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:45,263 [Listener at localhost/45878] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:45,263 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:45,263 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:45,263 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:45,264 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,264 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:45,264 [Listener at localhost/45878] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:45,320 [Listener at localhost/45878] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:45,386 [Listener at localhost/45878] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:45,461 [Listener at localhost/45878] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:45,462 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(301)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name is not formatted.
2020-12-03 07:23:45,462 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(302)) - Formatting ...
2020-12-03 07:23:45,463 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(301)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits is not formatted.
2020-12-03 07:23:45,463 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(302)) - Formatting ...
2020-12-03 07:23:45,464 [Listener at localhost/45878] WARN  namenode.FSImage (NNStorage.java:readAndInspectDirs(1095)) - Storage directory Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name; location= null contains no VERSION file. Skipping...
2020-12-03 07:23:45,464 [Listener at localhost/45878] WARN  namenode.FSImage (NNStorage.java:readAndInspectDirs(1095)) - Storage directory Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits; location= null contains no VERSION file. Skipping...
2020-12-03 07:23:45,465 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name
2020-12-03 07:23:45,465 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits
2020-12-03 07:23:45,467 [Listener at localhost/45878] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current
2020-12-03 07:23:45,467 [Listener at localhost/45878] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current
2020-12-03 07:23:45,468 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2020-12-03 07:23:45,473 [Listener at localhost/45878] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:45,477 [Listener at localhost/45878] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:45,477 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 12 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000012
2020-12-03 07:23:45,477 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@44f3fe83 expecting start txid #13
2020-12-03 07:23:45,478 [Listener at localhost/45878] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000013-0000000000000000014 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:45,479 [Listener at localhost/45878] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000013-0000000000000000014' to transaction ID 13
2020-12-03 07:23:45,480 [Listener at localhost/45878] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000013-0000000000000000014) of total size 42.0, total edits 2.0, total load time 2.0 ms
2020-12-03 07:23:45,480 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:45,480 [Listener at localhost/45878] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:23:45,493 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000014 using no compression
2020-12-03 07:23:45,496 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000014 using no compression
2020-12-03 07:23:45,508 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000014 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:45,508 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000014 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:45,591 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name
2020-12-03 07:23:45,592 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits
2020-12-03 07:23:45,592 [Listener at localhost/45878] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 12
2020-12-03 07:23:45,592 [Listener at localhost/45878] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:45,599 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name
2020-12-03 07:23:45,599 [Listener at localhost/45878] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits
2020-12-03 07:23:45,829 [Listener at localhost/45878] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 15
2020-12-03 07:23:46,011 [Listener at localhost/45878] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:46,012 [Listener at localhost/45878] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 745 msecs
2020-12-03 07:23:46,012 [Listener at localhost/45878] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:46,013 [Listener at localhost/45878] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:46,018 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:46,030 [Listener at localhost/41518] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41518 to access this namenode/service.
2020-12-03 07:23:46,031 [Listener at localhost/41518] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:46,031 [Listener at localhost/41518] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:46,032 [Listener at localhost/41518] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:46,080 [Listener at localhost/41518] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:46,095 [Listener at localhost/41518] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 2.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:46,110 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:46,119 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,125 [Listener at localhost/41518] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41518
2020-12-03 07:23:46,125 [Listener at localhost/41518] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:46,125 [Listener at localhost/41518] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:46,143 [Listener at localhost/41518] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 17 milliseconds
name space=4
storage space=24576
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:46,148 [Listener at localhost/41518] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:46,150 [Listener at localhost/41518] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:46,155 [Listener at localhost/41518] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:46,163 [Listener at localhost/41518] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:46,164 [Listener at localhost/41518] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,164 [Listener at localhost/41518] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:46,165 [Listener at localhost/41518] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:46,165 [Listener at localhost/41518] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,165 [Listener at localhost/41518] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:46,166 [CacheReplicationMonitor(372640295)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:46,166 [Listener at localhost/41518] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40980
2020-12-03 07:23:46,167 [Listener at localhost/41518] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:46,167 [Listener at localhost/41518] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:46,168 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,179 [Listener at localhost/41518] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:46,187 [Listener at localhost/41518] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:46,188 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,198 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:46,199 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:46,199 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:46,199 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:46,200 [Listener at localhost/41518] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38653
2020-12-03 07:23:46,200 [Listener at localhost/41518] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:46,219 [Listener at localhost/41518] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f02251{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:46,220 [Listener at localhost/41518] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d8126f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:46,231 [Listener at localhost/41518] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@25d3cfc8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:46,232 [Listener at localhost/41518] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30331109{HTTP/1.1,[http/1.1]}{localhost:38653}
2020-12-03 07:23:46,232 [Listener at localhost/41518] INFO  server.Server (Server.java:doStart(419)) - Started @9578ms
2020-12-03 07:23:46,358 [Listener at localhost/41518] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40982
2020-12-03 07:23:46,362 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@74fe5966] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:46,362 [Listener at localhost/41518] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:46,367 [Listener at localhost/41518] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:46,367 [Listener at localhost/41518] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:46,371 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:46,379 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37610
2020-12-03 07:23:46,393 [Listener at localhost/37610] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:46,394 [Listener at localhost/37610] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:46,395 [Thread-224] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518 starting to offer service
2020-12-03 07:23:46,417 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:46,417 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,421 [Listener at localhost/37610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:46,422 [Listener at localhost/37610] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:46,423 [Listener at localhost/37610] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:46,428 [Listener at localhost/37610] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:46,428 [Listener at localhost/37610] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,429 [Listener at localhost/37610] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:46,429 [Thread-224] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518
2020-12-03 07:23:46,430 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:46,430 [Listener at localhost/37610] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,431 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:46,432 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40126
2020-12-03 07:23:46,432 [Listener at localhost/37610] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:46,432 [Listener at localhost/37610] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:46,434 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,436 [Listener at localhost/37610] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:46,437 [Listener at localhost/37610] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:46,437 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,440 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:46,441 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:46,441 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:46,442 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:46,454 [Thread-224] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:46,459 [Listener at localhost/37610] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44407
2020-12-03 07:23:46,459 [Listener at localhost/37610] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:46,468 [Listener at localhost/37610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:46,469 [Listener at localhost/37610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:46,488 [Listener at localhost/37610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@f2e4acf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:46,489 [Listener at localhost/37610] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24097e9b{HTTP/1.1,[http/1.1]}{localhost:44407}
2020-12-03 07:23:46,489 [Listener at localhost/37610] INFO  server.Server (Server.java:doStart(419)) - Started @9835ms
2020-12-03 07:23:46,490 [Thread-224] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:46,538 [Listener at localhost/37610] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36130
2020-12-03 07:23:46,539 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:46,539 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@68ba310d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:46,539 [Listener at localhost/37610] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:46,540 [Listener at localhost/37610] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:46,541 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:46,550 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36616
2020-12-03 07:23:46,557 [Thread-224] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:46,598 [Listener at localhost/36616] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:46,598 [Listener at localhost/36616] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:46,599 [Thread-247] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518 starting to offer service
2020-12-03 07:23:46,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:46,607 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,608 [Thread-224] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:46,609 [Thread-224] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:46,610 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:46,612 [Listener at localhost/36616] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:46,612 [Listener at localhost/36616] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:46,613 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:46,614 [Listener at localhost/36616] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,614 [Listener at localhost/36616] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:46,615 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:46,615 [Listener at localhost/36616] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,616 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:46,617 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37557
2020-12-03 07:23:46,617 [Listener at localhost/36616] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:46,617 [Listener at localhost/36616] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:46,619 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,621 [Listener at localhost/36616] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:46,622 [Listener at localhost/36616] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:46,645 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,650 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:46,652 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:46,672 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:46,672 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:46,674 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32898
2020-12-03 07:23:46,675 [Listener at localhost/36616] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:46,679 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d12b024{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:46,680 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43effd89{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:46,702 [Thread-247] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518
2020-12-03 07:23:46,715 [Thread-247] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:46,720 [Thread-224] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:46,722 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@281f23f2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:46,723 [Listener at localhost/36616] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@87abc48{HTTP/1.1,[http/1.1]}{localhost:32898}
2020-12-03 07:23:46,747 [Listener at localhost/36616] INFO  server.Server (Server.java:doStart(419)) - Started @10069ms
2020-12-03 07:23:46,757 [Thread-247] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:46,764 [Thread-224] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:46,814 [Listener at localhost/36616] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32869
2020-12-03 07:23:46,815 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:46,815 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@782168b7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:46,815 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:46,816 [Listener at localhost/36616] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:46,817 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:46,825 [Thread-224] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:46,826 [Listener at localhost/45361] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45361
2020-12-03 07:23:46,831 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a942f057-deae-4f03-9702-7f6ecd90f93d
2020-12-03 07:23:46,833 [Thread-224] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:46,834 [Listener at localhost/45361] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:46,835 [Listener at localhost/45361] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:46,843 [Thread-270] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518 starting to offer service
2020-12-03 07:23:46,849 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-479312ef-eeb1-4c34-b587-263125ea57db
2020-12-03 07:23:46,851 [Thread-224] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:46,851 [Thread-224] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:46,853 [Thread-224] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:46,854 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:46,854 [Thread-224] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:46,862 [Thread-224] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:46,862 [Thread-224] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:46,873 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,881 [Thread-224] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:46,893 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:46,893 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:46,894 [Thread-270] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41518
2020-12-03 07:23:46,897 [Thread-284] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:46,900 [Thread-270] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:46,906 [Thread-283] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:46,917 [IPC Server handler 3 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:46,925 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:46,925 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:46,931 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 38ms
2020-12-03 07:23:46,942 [Thread-247] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:46,945 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 52ms
2020-12-03 07:23:46,948 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 55ms
2020-12-03 07:23:46,948 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:46,949 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:46,952 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:46,952 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:46,952 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-12-03 07:23:46,952 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-12-03 07:23:46,953 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 4ms
2020-12-03 07:23:46,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db): no suitable block pools found to scan.  Waiting 1814395729 ms.
2020-12-03 07:23:46,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d): no suitable block pools found to scan.  Waiting 1814395729 ms.
2020-12-03 07:23:46,968 [Thread-224] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:36 AM with interval of 21600000ms
2020-12-03 07:23:46,970 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:41518 beginning handshake with NN
2020-12-03 07:23:46,975 [IPC Server handler 4 on default port 41518] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40980, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=40982, infoSecurePort=0, ipcPort=37610, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:46,976 [IPC Server handler 4 on default port 41518] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40980
2020-12-03 07:23:46,976 [IPC Server handler 4 on default port 41518] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bb9904b-e086-4883-b13d-90a0b829e439 (127.0.0.1:40980).
2020-12-03 07:23:46,991 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:41518 successfully registered with NN
2020-12-03 07:23:46,991 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41518 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:47,000 [IPC Server handler 5 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a942f057-deae-4f03-9702-7f6ecd90f93d for DN 127.0.0.1:40980
2020-12-03 07:23:47,001 [IPC Server handler 5 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-479312ef-eeb1-4c34-b587-263125ea57db for DN 127.0.0.1:40980
2020-12-03 07:23:47,014 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x73633293c2b815c5: Processing first storage report for DS-a942f057-deae-4f03-9702-7f6ecd90f93d from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:47,014 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:47,018 [Thread-270] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:47,022 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:47,023 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:47,023 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:47,023 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:47,025 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x73633293c2b815c5: from storage DS-a942f057-deae-4f03-9702-7f6ecd90f93d node DatanodeRegistration(127.0.0.1:40980, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=40982, infoSecurePort=0, ipcPort=37610, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: true, processing time: 10 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 2
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:47,030 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:23:47,031 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x73633293c2b815c5: Processing first storage report for DS-479312ef-eeb1-4c34-b587-263125ea57db from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:47,033 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x73633293c2b815c5: from storage DS-479312ef-eeb1-4c34-b587-263125ea57db node DatanodeRegistration(127.0.0.1:40980, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=40982, infoSecurePort=0, ipcPort=37610, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,034 [IPC Server handler 7 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,043 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x73633293c2b815c5,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:47,043 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,046 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,047 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,090 [Thread-247] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,091 [Thread-247] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,151 [IPC Server handler 0 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,152 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,152 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,173 [Thread-247] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,173 [Thread-247] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,180 [Thread-270] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:47,251 [Thread-247] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:47,254 [IPC Server handler 1 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,254 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5
2020-12-03 07:23:47,255 [Thread-247] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:47,256 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,256 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,257 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da04c649-932f-40d5-9a46-2ab5df792559
2020-12-03 07:23:47,258 [Thread-247] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:47,259 [Thread-247] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:47,261 [Thread-247] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:47,262 [Thread-247] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:47,262 [Thread-247] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:47,263 [Thread-247] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:47,263 [Thread-270] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,263 [Thread-270] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,266 [Thread-247] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,266 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:47,266 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:47,268 [Thread-293] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:47,269 [Thread-294] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:47,281 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 14ms
2020-12-03 07:23:47,296 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 30ms
2020-12-03 07:23:47,296 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 31ms
2020-12-03 07:23:47,297 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:47,303 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:47,303 [Thread-296] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:47,304 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:47,304 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:47,305 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 7ms
2020-12-03 07:23:47,305 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 9ms
2020-12-03 07:23:47,307 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559): no suitable block pools found to scan.  Waiting 1814395390 ms.
2020-12-03 07:23:47,307 [Thread-247] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:12 AM with interval of 21600000ms
2020-12-03 07:23:47,307 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5): no suitable block pools found to scan.  Waiting 1814395389 ms.
2020-12-03 07:23:47,309 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:41518 beginning handshake with NN
2020-12-03 07:23:47,322 [IPC Server handler 2 on default port 41518] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40126, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=36130, infoSecurePort=0, ipcPort=36616, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:47,322 [IPC Server handler 2 on default port 41518] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40126
2020-12-03 07:23:47,323 [IPC Server handler 2 on default port 41518] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7b6bc5ce-f019-43bd-9069-f15868efab27 (127.0.0.1:40126).
2020-12-03 07:23:47,324 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:41518 successfully registered with NN
2020-12-03 07:23:47,324 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41518 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:47,328 [Thread-270] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,329 [IPC Server handler 3 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 for DN 127.0.0.1:40126
2020-12-03 07:23:47,330 [IPC Server handler 3 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da04c649-932f-40d5-9a46-2ab5df792559 for DN 127.0.0.1:40126
2020-12-03 07:23:47,330 [Thread-270] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe1868a81608227d5: Processing first storage report for DS-da04c649-932f-40d5-9a46-2ab5df792559 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:47,337 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe1868a81608227d5: from storage DS-da04c649-932f-40d5-9a46-2ab5df792559 node DatanodeRegistration(127.0.0.1:40126, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=36130, infoSecurePort=0, ipcPort=36616, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,337 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe1868a81608227d5: Processing first storage report for DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:47,337 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe1868a81608227d5: from storage DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 node DatanodeRegistration(127.0.0.1:40126, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=36130, infoSecurePort=0, ipcPort=36616, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,339 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe1868a81608227d5,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:47,339 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,359 [IPC Server handler 5 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,360 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,360 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,417 [Thread-270] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:47,424 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29
2020-12-03 07:23:47,424 [Thread-270] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:47,427 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20ea579c-cd28-4269-9aea-b545c0a7f417
2020-12-03 07:23:47,427 [Thread-270] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:47,428 [Thread-270] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:47,432 [Thread-270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:47,433 [Thread-270] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:47,433 [Thread-270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:47,434 [Thread-270] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:47,434 [Thread-270] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,434 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:47,435 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:47,436 [Thread-302] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:47,436 [Thread-303] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current: 28711
2020-12-03 07:23:47,450 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 15ms
2020-12-03 07:23:47,456 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 22ms
2020-12-03 07:23:47,464 [IPC Server handler 6 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,465 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 30ms
2020-12-03 07:23:47,466 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:47,466 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,467 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,467 [Thread-304] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:47,467 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:23:47,470 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:47,471 [Thread-305] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:47,471 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:23:47,474 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 9ms
2020-12-03 07:23:47,475 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417): no suitable block pools found to scan.  Waiting 1814395221 ms.
2020-12-03 07:23:47,475 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29): no suitable block pools found to scan.  Waiting 1814395221 ms.
2020-12-03 07:23:47,476 [Thread-270] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:29 AM with interval of 21600000ms
2020-12-03 07:23:47,481 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:41518 beginning handshake with NN
2020-12-03 07:23:47,483 [IPC Server handler 7 on default port 41518] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37557, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=32869, infoSecurePort=0, ipcPort=45361, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:47,483 [IPC Server handler 7 on default port 41518] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37557
2020-12-03 07:23:47,483 [IPC Server handler 7 on default port 41518] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0a9dab0c-df25-451f-9d45-48227165f30e (127.0.0.1:37557).
2020-12-03 07:23:47,484 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:41518 successfully registered with NN
2020-12-03 07:23:47,485 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41518 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:47,488 [IPC Server handler 8 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 for DN 127.0.0.1:37557
2020-12-03 07:23:47,488 [IPC Server handler 8 on default port 41518] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20ea579c-cd28-4269-9aea-b545c0a7f417 for DN 127.0.0.1:37557
2020-12-03 07:23:47,495 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfb8d525d17ee5f5e: Processing first storage report for DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:47,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfb8d525d17ee5f5e: from storage DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 node DatanodeRegistration(127.0.0.1:37557, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=32869, infoSecurePort=0, ipcPort=45361, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfb8d525d17ee5f5e: Processing first storage report for DS-20ea579c-cd28-4269-9aea-b545c0a7f417 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:47,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfb8d525d17ee5f5e: from storage DS-20ea579c-cd28-4269-9aea-b545c0a7f417 node DatanodeRegistration(127.0.0.1:37557, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=32869, infoSecurePort=0, ipcPort=45361, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:47,498 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfb8d525d17ee5f5e,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:47,498 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:47,569 [IPC Server handler 0 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,571 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:47,575 [IPC Server handler 1 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,577 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:47,578 [Listener at localhost/45361] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - SecondaryNameNode metrics system started (again)
2020-12-03 07:23:47,581 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname in configuration.
2020-12-03 07:23:47,581 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:47,582 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits in configuration.
2020-12-03 07:23:47,582 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:47,583 [Listener at localhost/45361] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:47,635 [Listener at localhost/45361] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:47,695 [Listener at localhost/45361] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:47,737 [Listener at localhost/45361] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:47,738 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:47,739 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:47,739 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:47,739 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:47,739 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:47,739 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:47,740 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:47,740 [Listener at localhost/45361] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:47,741 [Listener at localhost/45361] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:47,741 [Listener at localhost/45361] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:47,742 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:47,742 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:47
2020-12-03 07:23:47,742 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:47,743 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:47,743 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:47,743 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:47,757 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:47,758 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:47,758 [Listener at localhost/45361] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:47,758 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:47,758 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:47,759 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:47,759 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:47,759 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:47,759 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:47,759 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:47,760 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:47,760 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:47,760 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:47,760 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:47,761 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:47,761 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:47,761 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:47,767 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:47,767 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:47,768 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:47,769 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:47,769 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:47,769 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:47,770 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:47,770 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:47,770 [Listener at localhost/45361] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(261)) - Checkpoint Period   :3600 secs (60 min)
2020-12-03 07:23:47,770 [Listener at localhost/45361] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(263)) - Log Size Trigger    :1000000 txns
2020-12-03 07:23:47,774 [IPC Server handler 2 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,777 [IPC Server handler 3 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,780 [IPC Server handler 4 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,783 [IPC Server handler 5 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,785 [IPC Server handler 6 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,801 [IPC Server handler 7 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,809 [IPC Server handler 8 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,811 [IPC Server handler 9 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:47,815 [IPC Server handler 0 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/TestNameEditsConfigs2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:47,830 [IPC Server handler 1 on default port 41518] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:40126, 127.0.0.1:37557, 127.0.0.1:40980 for /user/root/TestNameEditsConfigs2
2020-12-03 07:23:47,833 [Thread-313] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:48538 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003 src: /127.0.0.1:48538 dest: /127.0.0.1:40126
2020-12-03 07:23:47,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:48538 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,852 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:43640 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003 src: /127.0.0.1:43640 dest: /127.0.0.1:37557
2020-12-03 07:23:47,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:43640 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,858 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:41604 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003 src: /127.0.0.1:41604 dest: /127.0.0.1:40980
2020-12-03 07:23:47,916 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41604, dest: /127.0.0.1:40980, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, duration(ns): 52553807
2020-12-03 07:23:47,916 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:47,924 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40980]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43640, dest: /127.0.0.1:37557, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, duration(ns): 57256034
2020-12-03 07:23:47,926 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40980]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40980] terminating
2020-12-03 07:23:47,930 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37557, 127.0.0.1:40980]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48538, dest: /127.0.0.1:40126, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, duration(ns): 45213317
2020-12-03 07:23:47,932 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37557, 127.0.0.1:40980]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37557, 127.0.0.1:40980] terminating
2020-12-03 07:23:47,952 [IPC Server handler 6 on default port 41518] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:40980, 127.0.0.1:40126, 127.0.0.1:37557 for /user/root/TestNameEditsConfigs2
2020-12-03 07:23:47,959 [DataStreamer for file /user/root/TestNameEditsConfigs2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,962 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:41606 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004 src: /127.0.0.1:41606 dest: /127.0.0.1:40980
2020-12-03 07:23:47,964 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:41606 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,967 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:48546 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004 src: /127.0.0.1:48546 dest: /127.0.0.1:40126
2020-12-03 07:23:47,968 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:48546 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:47,970 [DataXceiver for client DFSClient_NONMAPREDUCE_-1226738196_1 at /127.0.0.1:43648 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004 src: /127.0.0.1:43648 dest: /127.0.0.1:37557
2020-12-03 07:23:47,999 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43648, dest: /127.0.0.1:37557, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, duration(ns): 23816580
2020-12-03 07:23:48,000 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:48,002 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37557]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48546, dest: /127.0.0.1:40126, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, duration(ns): 28673163
2020-12-03 07:23:48,003 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37557]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37557] terminating
2020-12-03 07:23:48,019 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40126, 127.0.0.1:37557]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41606, dest: /127.0.0.1:40980, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1226738196_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, duration(ns): 44561395
2020-12-03 07:23:48,019 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40126, 127.0.0.1:37557]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40126, 127.0.0.1:37557] terminating
2020-12-03 07:23:48,025 [IPC Server handler 0 on default port 41518] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/TestNameEditsConfigs2 is closed by DFSClient_NONMAPREDUCE_-1226738196_1
2020-12-03 07:23:48,030 [IPC Server handler 1 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,032 [IPC Server handler 2 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,039 [IPC Server handler 3 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,044 [IPC Server handler 4 on default port 41518] INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(4740)) - Roll Edit Log from 127.0.0.1
2020-12-03 07:23:48,044 [IPC Server handler 4 on default port 41518] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:48,044 [IPC Server handler 4 on default port 41518] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 15, 24
2020-12-03 07:23:48,044 [IPC Server handler 4 on default port 41518] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 11 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 17 Number of syncs: 9 SyncTimes(ms): 3 3 
2020-12-03 07:23:48,046 [IPC Server handler 4 on default port 41518] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000015-0000000000000000025
2020-12-03 07:23:48,047 [IPC Server handler 4 on default port 41518] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000015-0000000000000000025
2020-12-03 07:23:48,047 [IPC Server handler 4 on default port 41518] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 26
2020-12-03 07:23:48,178 [IPC Server handler 4 on default port 41518] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rollEditLog	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,183 [Listener at localhost/45361] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(421)) - Image has changed. Downloading updated image from NN.
2020-12-03 07:23:48,184 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:44462/imagetransfer?getimage=1&txid=14&storageInfo=-65:198152275:1606980218489:testClusterID&bootstrapstandby=false
2020-12-03 07:23:48,191 [qtp96453207-763] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000014, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:48,260 [Listener at localhost/45361] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000014 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000014 took 0.00s.
2020-12-03 07:23:48,260 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(122)) - Downloaded file fsimage.ckpt_0000000000000000014 size 653 bytes.
2020-12-03 07:23:48,338 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:44462/imagetransfer?getedit=1&startTxId=15&endTxId=25&storageInfo=-65:198152275:1606980218489:testClusterID
2020-12-03 07:23:48,341 [qtp96453207-1438] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000015-0000000000000000025, fileSize: 718. Sent total: 718 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:48,429 [Listener at localhost/45361] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_tmp_0000000000000000015-0000000000000000025_0000000000141218667 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_tmp_0000000000000000015-0000000000000000025_0000000000141218667 took 0.00s.
2020-12-03 07:23:48,429 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(175)) - Downloaded file edits_tmp_0000000000000000015-0000000000000000025_0000000000141218667 size 0 bytes.
2020-12-03 07:23:48,447 [Listener at localhost/45361] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:48,448 [Listener at localhost/45361] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:48,448 [Listener at localhost/45361] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 14 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000014
2020-12-03 07:23:48,449 [Listener at localhost/45361] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:48,449 [Listener at localhost/45361] INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(314)) - Checkpointer about to load edits from 1 stream(s).
2020-12-03 07:23:48,450 [Listener at localhost/45361] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000015-0000000000000000025 expecting start txid #15
2020-12-03 07:23:48,450 [Listener at localhost/45361] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000015-0000000000000000025 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:48,453 [Listener at localhost/45361] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000015-0000000000000000025) of total size 718.0, total edits 11.0, total load time 3.0 ms
2020-12-03 07:23:48,471 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000025 using no compression
2020-12-03 07:23:48,471 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000025 using no compression
2020-12-03 07:23:48,483 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000025 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:48,483 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000025 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:48,539 [Listener at localhost/45361] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname
2020-12-03 07:23:48,540 [Listener at localhost/45361] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits
2020-12-03 07:23:48,540 [Listener at localhost/45361] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 14
2020-12-03 07:23:48,541 [Listener at localhost/45361] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2020-12-03 07:23:48,541 [Listener at localhost/45361] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:48,543 [Listener at localhost/45361] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname
2020-12-03 07:23:48,543 [Listener at localhost/45361] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits
2020-12-03 07:23:48,727 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000025, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:48,793 [qtp96453207-751] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000025 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000025 took 0.00s.
2020-12-03 07:23:48,794 [qtp96453207-751] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000025 size 653 bytes.
2020-12-03 07:23:48,871 [qtp96453207-751] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 14
2020-12-03 07:23:48,872 [qtp96453207-751] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2020-12-03 07:23:48,875 [Listener at localhost/45361] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 25 to namenode at http://localhost:44462 in 0.149 seconds
2020-12-03 07:23:48,876 [Listener at localhost/45361] WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(585)) - Checkpoint done. New Image Size: 653
2020-12-03 07:23:48,876 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:48,877 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:48,877 [Listener at localhost/45361] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,877 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@398474a2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,879 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417) exiting.
2020-12-03 07:23:48,879 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29) exiting.
2020-12-03 07:23:48,937 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@281f23f2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,938 [Listener at localhost/45361] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@87abc48{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,939 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43effd89{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,940 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d12b024{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,943 [Listener at localhost/45361] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45361
2020-12-03 07:23:48,947 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,947 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,948 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,948 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:41518
2020-12-03 07:23:48,948 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e)
2020-12-03 07:23:48,948 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:48,950 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,950 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,964 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,964 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,965 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,965 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,968 [Listener at localhost/45361] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,968 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:48,969 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@773c0293] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,969 [Listener at localhost/45361] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5) exiting.
2020-12-03 07:23:48,975 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559) exiting.
2020-12-03 07:23:49,123 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@f2e4acf{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:49,139 [Listener at localhost/45361] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24097e9b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:49,140 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,140 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:49,153 [Listener at localhost/45361] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36616
2020-12-03 07:23:49,182 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:49,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:41518
2020-12-03 07:23:49,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27)
2020-12-03 07:23:49,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:49,207 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:49,211 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:49,212 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:49,213 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:49,214 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:49,215 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:49,218 [Listener at localhost/45361] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:49,219 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:49,219 [Listener at localhost/45361] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:49,219 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4784013e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:49,233 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db) exiting.
2020-12-03 07:23:49,234 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d) exiting.
2020-12-03 07:23:49,322 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@25d3cfc8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:49,323 [Listener at localhost/45361] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30331109{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:49,324 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d8126f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,332 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f02251{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:49,335 [Listener at localhost/45361] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37610
2020-12-03 07:23:49,345 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,345 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,347 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:49,348 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:41518
2020-12-03 07:23:49,348 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439)
2020-12-03 07:23:49,348 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:41518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:49,350 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:49,350 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:49,364 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:49,365 [Listener at localhost/45361] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:49,367 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:49,368 [Listener at localhost/45361] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:49,372 [Listener at localhost/45361] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:49,373 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:49,373 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:49,373 [Listener at localhost/45361] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 26, 26
2020-12-03 07:23:49,374 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5116ac09] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:49,374 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1bc425e7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:49,378 [Listener at localhost/45361] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 1 
2020-12-03 07:23:49,379 [Listener at localhost/45361] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000026 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000026-0000000000000000027
2020-12-03 07:23:49,380 [Listener at localhost/45361] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000026 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000026-0000000000000000027
2020-12-03 07:23:49,381 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:49,381 [CacheReplicationMonitor(372640295)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:49,393 [Listener at localhost/45361] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41518
2020-12-03 07:23:49,400 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,401 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:49,403 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:49,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,414 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:49,414 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:49,416 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@66596a88{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:49,420 [Listener at localhost/45361] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5aae8eb5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:49,421 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e8e8621{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,421 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@783efb48{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:49,728 [Listener at localhost/45361] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:23:49,729 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:49,730 [Listener at localhost/45361] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:49,731 [Listener at localhost/45361] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:49,732 [Listener at localhost/45361] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:49,744 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4441d567] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:49,744 [Listener at localhost/45361] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:49,745 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,747 [Listener at localhost/45361] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:49,747 [Listener at localhost/45361] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:49,747 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,749 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:49,750 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:49,750 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:49,750 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:49,752 [Listener at localhost/45361] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:49,752 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:49,753 [Listener at localhost/45361] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44017
2020-12-03 07:23:49,753 [Listener at localhost/45361] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:49,757 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@610df783{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:49,758 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b56f5f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:49,765 [Listener at localhost/45361] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1fde4f40{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:49,766 [Listener at localhost/45361] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49cf9028{HTTP/1.1,[http/1.1]}{localhost:44017}
2020-12-03 07:23:49,766 [Listener at localhost/45361] INFO  server.Server (Server.java:doStart(419)) - Started @13112ms
2020-12-03 07:23:49,766 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:49,767 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:49,767 [Listener at localhost/45361] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:49,767 [Listener at localhost/45361] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:49,767 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:49,768 [Listener at localhost/45361] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:49,769 [Listener at localhost/45361] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:49,770 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:49,770 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:49,773 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:49,774 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:49,774 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:49,774 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:49,774 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:49,775 [Listener at localhost/45361] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:49,775 [Listener at localhost/45361] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:49,775 [Listener at localhost/45361] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:49,776 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:49,776 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:49
2020-12-03 07:23:49,776 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:49,776 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,777 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:49,777 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:49,791 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:49,791 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:49,792 [Listener at localhost/45361] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:49,793 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:49,793 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:49,793 [Listener at localhost/45361] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:49,793 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:49,794 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:49,794 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:49,794 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:49,794 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:49,794 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:49,795 [Listener at localhost/45361] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:49,795 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:49,796 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,796 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:49,796 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:49,803 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:49,803 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:49,803 [Listener at localhost/45361] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:49,803 [Listener at localhost/45361] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:49,803 [Listener at localhost/45361] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:49,804 [Listener at localhost/45361] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:49,804 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:49,804 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,804 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:49,804 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:49,806 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:49,806 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:49,806 [Listener at localhost/45361] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:49,807 [Listener at localhost/45361] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:49,855 [Listener at localhost/45361] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:49,889 [Listener at localhost/45361] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:49,892 [Listener at localhost/45361] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current
2020-12-03 07:23:49,893 [Listener at localhost/45361] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2020-12-03 07:23:49,898 [Listener at localhost/45361] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:49,899 [Listener at localhost/45361] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:49,899 [Listener at localhost/45361] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 25 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000025
2020-12-03 07:23:49,899 [Listener at localhost/45361] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d774249 expecting start txid #26
2020-12-03 07:23:49,900 [Listener at localhost/45361] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000026-0000000000000000027 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:49,900 [Listener at localhost/45361] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000026-0000000000000000027' to transaction ID 26
2020-12-03 07:23:49,900 [Listener at localhost/45361] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000026-0000000000000000027) of total size 42.0, total edits 2.0, total load time 1.0 ms
2020-12-03 07:23:49,901 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:49,902 [Listener at localhost/45361] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 28
2020-12-03 07:23:49,982 [Listener at localhost/45361] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:49,982 [Listener at localhost/45361] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 174 msecs
2020-12-03 07:23:49,983 [Listener at localhost/45361] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:49,984 [Listener at localhost/45361] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:49,984 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:49,991 [Listener at localhost/38023] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38023 to access this namenode/service.
2020-12-03 07:23:49,992 [Listener at localhost/38023] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:49,993 [Listener at localhost/38023] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:50,012 [Listener at localhost/38023] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:50,015 [Listener at localhost/38023] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 2.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:50,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,024 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,039 [Listener at localhost/38023] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38023
2020-12-03 07:23:50,039 [Listener at localhost/38023] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:50,040 [Listener at localhost/38023] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:50,060 [Listener at localhost/38023] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 19 milliseconds
name space=4
storage space=24576
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:50,073 [CacheReplicationMonitor(154426308)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:50,076 [Listener at localhost/38023] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:50,078 [Listener at localhost/38023] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:50,078 [Listener at localhost/38023] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:50,080 [Listener at localhost/38023] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:50,083 [Listener at localhost/38023] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,083 [Listener at localhost/38023] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:50,084 [Listener at localhost/38023] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:50,084 [Listener at localhost/38023] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,085 [Listener at localhost/38023] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:50,086 [Listener at localhost/38023] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44515
2020-12-03 07:23:50,086 [Listener at localhost/38023] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:50,086 [Listener at localhost/38023] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:50,090 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,092 [Listener at localhost/38023] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,093 [Listener at localhost/38023] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:50,093 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,095 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,095 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:50,096 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,096 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,097 [Listener at localhost/38023] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40185
2020-12-03 07:23:50,097 [Listener at localhost/38023] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,098 [Listener at localhost/38023] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d0cc890{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,099 [Listener at localhost/38023] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ff60a8c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,105 [Listener at localhost/38023] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f672204{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:50,110 [Listener at localhost/38023] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@78b41097{HTTP/1.1,[http/1.1]}{localhost:40185}
2020-12-03 07:23:50,110 [Listener at localhost/38023] INFO  server.Server (Server.java:doStart(419)) - Started @13456ms
2020-12-03 07:23:50,137 [Listener at localhost/38023] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43291
2020-12-03 07:23:50,138 [Listener at localhost/38023] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:50,138 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@327c7bea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,138 [Listener at localhost/38023] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:50,139 [Listener at localhost/38023] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:50,140 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:50,149 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39690
2020-12-03 07:23:50,188 [Listener at localhost/39690] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:50,189 [Listener at localhost/39690] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:50,194 [Thread-379] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023 starting to offer service
2020-12-03 07:23:50,217 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,217 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,240 [Listener at localhost/39690] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:50,246 [Listener at localhost/39690] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:50,250 [Listener at localhost/39690] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:50,259 [Listener at localhost/39690] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:50,260 [Listener at localhost/39690] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,260 [Listener at localhost/39690] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:50,261 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:50,261 [Listener at localhost/39690] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,261 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:50,263 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42394
2020-12-03 07:23:50,263 [Thread-379] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023
2020-12-03 07:23:50,263 [Listener at localhost/39690] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:50,265 [Listener at localhost/39690] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:50,265 [Thread-379] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:50,267 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,269 [Listener at localhost/39690] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,269 [Listener at localhost/39690] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:50,270 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,272 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,273 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:50,273 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,274 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,275 [Listener at localhost/39690] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35840
2020-12-03 07:23:50,275 [Listener at localhost/39690] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,276 [Listener at localhost/39690] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bd0b0e5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,277 [Listener at localhost/39690] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f51431{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,283 [Listener at localhost/39690] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3157e4c0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:50,286 [Listener at localhost/39690] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6eaa21d8{HTTP/1.1,[http/1.1]}{localhost:35840}
2020-12-03 07:23:50,286 [Listener at localhost/39690] INFO  server.Server (Server.java:doStart(419)) - Started @13632ms
2020-12-03 07:23:50,325 [Thread-379] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,342 [Listener at localhost/39690] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45944
2020-12-03 07:23:50,342 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:50,342 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72e789cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,343 [Listener at localhost/39690] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:50,343 [Listener at localhost/39690] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:50,345 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:50,356 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46503
2020-12-03 07:23:50,376 [Listener at localhost/46503] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:50,377 [Listener at localhost/46503] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:50,378 [Thread-402] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023 starting to offer service
2020-12-03 07:23:50,385 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,387 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,390 [Listener at localhost/46503] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:50,414 [Listener at localhost/46503] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:50,415 [Listener at localhost/46503] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:50,412 [Thread-379] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,423 [Thread-402] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023
2020-12-03 07:23:50,444 [Listener at localhost/46503] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:50,445 [Listener at localhost/46503] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,445 [Listener at localhost/46503] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:50,446 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:50,446 [Listener at localhost/46503] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,446 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:50,446 [Thread-402] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:50,447 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33303
2020-12-03 07:23:50,447 [Listener at localhost/46503] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:50,447 [Listener at localhost/46503] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:50,449 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,450 [Listener at localhost/46503] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,451 [Listener at localhost/46503] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:50,451 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,454 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,455 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:50,455 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,455 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,456 [Listener at localhost/46503] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44075
2020-12-03 07:23:50,457 [Listener at localhost/46503] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,458 [Listener at localhost/46503] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@363f0ba0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,464 [Listener at localhost/46503] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c8909c3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,474 [Thread-379] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,475 [Listener at localhost/46503] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71dfcf21{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:50,476 [Listener at localhost/46503] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@b965857{HTTP/1.1,[http/1.1]}{localhost:44075}
2020-12-03 07:23:50,476 [Listener at localhost/46503] INFO  server.Server (Server.java:doStart(419)) - Started @13822ms
2020-12-03 07:23:50,475 [Thread-379] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,507 [Listener at localhost/46503] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41569
2020-12-03 07:23:50,508 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:50,508 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27a7ef08] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,508 [Listener at localhost/46503] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:50,509 [Listener at localhost/46503] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:50,510 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:50,512 [Thread-402] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,515 [Listener at localhost/39628] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39628
2020-12-03 07:23:50,529 [Listener at localhost/39628] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:50,529 [Listener at localhost/39628] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:50,530 [Thread-424] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023 starting to offer service
2020-12-03 07:23:50,538 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,541 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,541 [Thread-424] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38023
2020-12-03 07:23:50,549 [Thread-424] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:50,577 [IPC Server handler 3 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,578 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,578 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,588 [Thread-379] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,589 [Thread-379] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,637 [Thread-424] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,638 [Thread-379] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:50,643 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a942f057-deae-4f03-9702-7f6ecd90f93d
2020-12-03 07:23:50,643 [Thread-379] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:50,649 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-479312ef-eeb1-4c34-b587-263125ea57db
2020-12-03 07:23:50,652 [Thread-379] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:50,653 [Thread-379] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:50,655 [Thread-379] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:50,657 [Thread-379] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:50,657 [Thread-379] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:50,658 [Thread-379] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:50,662 [Thread-379] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,663 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:50,665 [Thread-402] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,665 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:50,666 [Thread-438] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:50,667 [Thread-439] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:50,679 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 13ms
2020-12-03 07:23:50,679 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 16ms
2020-12-03 07:23:50,682 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 20ms
2020-12-03 07:23:50,683 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:50,683 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:50,685 [IPC Server handler 4 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,689 [Thread-441] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:50,689 [Thread-440] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:50,691 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-12-03 07:23:50,691 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:23:50,693 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 10ms
2020-12-03 07:23:50,693 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,693 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db): no suitable block pools found to scan.  Waiting 1814392002 ms.
2020-12-03 07:23:50,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d): no suitable block pools found to scan.  Waiting 1814392002 ms.
2020-12-03 07:23:50,695 [Thread-379] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:03 AM with interval of 21600000ms
2020-12-03 07:23:50,697 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:38023 beginning handshake with NN
2020-12-03 07:23:50,698 [IPC Server handler 5 on default port 38023] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44515, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43291, infoSecurePort=0, ipcPort=39690, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:50,699 [IPC Server handler 5 on default port 38023] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44515
2020-12-03 07:23:50,699 [IPC Server handler 5 on default port 38023] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bb9904b-e086-4883-b13d-90a0b829e439 (127.0.0.1:44515).
2020-12-03 07:23:50,706 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:38023 successfully registered with NN
2020-12-03 07:23:50,706 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38023 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:50,721 [IPC Server handler 6 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a942f057-deae-4f03-9702-7f6ecd90f93d for DN 127.0.0.1:44515
2020-12-03 07:23:50,721 [IPC Server handler 6 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-479312ef-eeb1-4c34-b587-263125ea57db for DN 127.0.0.1:44515
2020-12-03 07:23:50,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xed24f1048638f06c: Processing first storage report for DS-a942f057-deae-4f03-9702-7f6ecd90f93d from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:50,731 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:50,734 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:50,735 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:50,735 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:50,735 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:50,738 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xed24f1048638f06c: from storage DS-a942f057-deae-4f03-9702-7f6ecd90f93d node DatanodeRegistration(127.0.0.1:44515, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43291, infoSecurePort=0, ipcPort=39690, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: true, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:23:50,744 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 2
2020-12-03 07:23:50,744 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:50,744 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:23:50,744 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:50,745 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:50,745 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-12-03 07:23:50,745 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xed24f1048638f06c: Processing first storage report for DS-479312ef-eeb1-4c34-b587-263125ea57db from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:50,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xed24f1048638f06c: from storage DS-479312ef-eeb1-4c34-b587-263125ea57db node DatanodeRegistration(127.0.0.1:44515, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43291, infoSecurePort=0, ipcPort=39690, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2020-12-03 07:23:50,751 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xed24f1048638f06c,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 0 msec to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:50,751 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,762 [Thread-402] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,762 [Thread-402] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,763 [Thread-424] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:50,799 [IPC Server handler 8 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,800 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,800 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,827 [Thread-402] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,828 [Thread-402] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,869 [Thread-424] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,869 [Thread-424] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,902 [IPC Server handler 9 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,903 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,903 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,932 [Thread-402] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:50,935 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5
2020-12-03 07:23:50,939 [Thread-402] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:50,945 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da04c649-932f-40d5-9a46-2ab5df792559
2020-12-03 07:23:50,948 [Thread-402] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:50,949 [Thread-402] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:50,951 [Thread-402] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:50,951 [Thread-402] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:50,951 [Thread-402] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:50,952 [Thread-402] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:50,958 [Thread-402] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:50,958 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:50,958 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:50,961 [Thread-449] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:51,056 [Thread-448] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:51,057 [IPC Server handler 1 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,058 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:51,058 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:51,077 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 119ms
2020-12-03 07:23:51,078 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 119ms
2020-12-03 07:23:51,078 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 120ms
2020-12-03 07:23:51,078 [Thread-424] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:51,079 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:51,079 [Thread-424] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:51,082 [Thread-451] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:51,087 [Thread-451] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:51,087 [Thread-450] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:51,088 [Thread-451] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 6ms
2020-12-03 07:23:51,088 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 9ms
2020-12-03 07:23:51,090 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 11ms
2020-12-03 07:23:51,092 [Thread-402] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:14 AM with interval of 21600000ms
2020-12-03 07:23:51,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559): no suitable block pools found to scan.  Waiting 1814391604 ms.
2020-12-03 07:23:51,097 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:38023 beginning handshake with NN
2020-12-03 07:23:51,097 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5): no suitable block pools found to scan.  Waiting 1814391599 ms.
2020-12-03 07:23:51,099 [IPC Server handler 0 on default port 38023] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42394, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=45944, infoSecurePort=0, ipcPort=46503, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:51,099 [IPC Server handler 0 on default port 38023] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42394
2020-12-03 07:23:51,099 [IPC Server handler 0 on default port 38023] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7b6bc5ce-f019-43bd-9069-f15868efab27 (127.0.0.1:42394).
2020-12-03 07:23:51,100 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:38023 successfully registered with NN
2020-12-03 07:23:51,101 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38023 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:51,106 [IPC Server handler 2 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 for DN 127.0.0.1:42394
2020-12-03 07:23:51,110 [IPC Server handler 2 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da04c649-932f-40d5-9a46-2ab5df792559 for DN 127.0.0.1:42394
2020-12-03 07:23:51,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6159d05ae1d8bd3c: Processing first storage report for DS-da04c649-932f-40d5-9a46-2ab5df792559 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:51,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6159d05ae1d8bd3c: from storage DS-da04c649-932f-40d5-9a46-2ab5df792559 node DatanodeRegistration(127.0.0.1:42394, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=45944, infoSecurePort=0, ipcPort=46503, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:51,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6159d05ae1d8bd3c: Processing first storage report for DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:51,115 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6159d05ae1d8bd3c: from storage DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 node DatanodeRegistration(127.0.0.1:42394, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=45944, infoSecurePort=0, ipcPort=46503, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:51,116 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6159d05ae1d8bd3c,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:51,116 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:51,132 [Thread-424] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:51,135 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29
2020-12-03 07:23:51,135 [Thread-424] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:51,148 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20ea579c-cd28-4269-9aea-b545c0a7f417
2020-12-03 07:23:51,149 [Thread-424] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:51,149 [Thread-424] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:51,154 [Thread-424] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:51,155 [Thread-424] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:51,156 [Thread-424] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:51,156 [Thread-424] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:51,158 [Thread-424] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:51,158 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:51,158 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:51,160 [IPC Server handler 4 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,160 [Thread-458] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:51,160 [Thread-457] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current: 32846
2020-12-03 07:23:51,161 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:51,161 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:51,177 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 19ms
2020-12-03 07:23:51,181 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 22ms
2020-12-03 07:23:51,181 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 24ms
2020-12-03 07:23:51,182 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:51,182 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:51,184 [Thread-459] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:51,184 [Thread-460] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:51,185 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:23:51,185 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:23:51,185 [Thread-424] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 3ms
2020-12-03 07:23:51,186 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417): no suitable block pools found to scan.  Waiting 1814391510 ms.
2020-12-03 07:23:51,186 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29): no suitable block pools found to scan.  Waiting 1814391510 ms.
2020-12-03 07:23:51,186 [Thread-424] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:22 AM with interval of 21600000ms
2020-12-03 07:23:51,188 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:38023 beginning handshake with NN
2020-12-03 07:23:51,192 [IPC Server handler 5 on default port 38023] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33303, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=41569, infoSecurePort=0, ipcPort=39628, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:51,193 [IPC Server handler 5 on default port 38023] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33303
2020-12-03 07:23:51,193 [IPC Server handler 5 on default port 38023] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0a9dab0c-df25-451f-9d45-48227165f30e (127.0.0.1:33303).
2020-12-03 07:23:51,194 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:38023 successfully registered with NN
2020-12-03 07:23:51,194 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38023 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:51,199 [IPC Server handler 6 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 for DN 127.0.0.1:33303
2020-12-03 07:23:51,199 [IPC Server handler 6 on default port 38023] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20ea579c-cd28-4269-9aea-b545c0a7f417 for DN 127.0.0.1:33303
2020-12-03 07:23:51,201 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4be1ce6a68d7010b: Processing first storage report for DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:51,201 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4be1ce6a68d7010b: from storage DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 node DatanodeRegistration(127.0.0.1:33303, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=41569, infoSecurePort=0, ipcPort=39628, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:51,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4be1ce6a68d7010b: Processing first storage report for DS-20ea579c-cd28-4269-9aea-b545c0a7f417 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:51,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4be1ce6a68d7010b: from storage DS-20ea579c-cd28-4269-9aea-b545c0a7f417 node DatanodeRegistration(127.0.0.1:33303, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=41569, infoSecurePort=0, ipcPort=39628, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:51,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4be1ce6a68d7010b,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:51,203 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:51,267 [IPC Server handler 8 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,269 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:51,281 [IPC Server handler 9 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,282 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:51,284 [Listener at localhost/39628] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - SecondaryNameNode metrics system started (again)
2020-12-03 07:23:51,291 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname in configuration.
2020-12-03 07:23:51,292 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits in configuration.
2020-12-03 07:23:51,294 [Listener at localhost/39628] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:51,325 [Listener at localhost/39628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:51,358 [Listener at localhost/39628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:51,360 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:51,360 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:51,360 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:51,361 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:51,361 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:51,361 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:51,361 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:51,362 [Listener at localhost/39628] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:51,363 [Listener at localhost/39628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:51,363 [Listener at localhost/39628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:51,363 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:51,364 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:51
2020-12-03 07:23:51,364 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:51,364 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,365 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:51,365 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:51,373 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:51,373 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:51,374 [Listener at localhost/39628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:51,374 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:51,374 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:51,374 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:51,374 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:51,375 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:51,377 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:51,377 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,377 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:51,377 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:51,384 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:51,385 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:51,385 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:51,385 [Listener at localhost/39628] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:51,385 [Listener at localhost/39628] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:51,385 [Listener at localhost/39628] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:51,386 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:51,386 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,386 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:51,386 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:51,387 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:51,387 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:51,388 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:51,389 [Listener at localhost/39628] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(261)) - Checkpoint Period   :3600 secs (60 min)
2020-12-03 07:23:51,389 [Listener at localhost/39628] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(263)) - Log Size Trigger    :1000000 txns
2020-12-03 07:23:51,392 [IPC Server handler 1 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,393 [IPC Server handler 0 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,396 [IPC Server handler 2 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,398 [IPC Server handler 3 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,400 [IPC Server handler 4 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,402 [IPC Server handler 5 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,411 [IPC Server handler 6 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,415 [IPC Server handler 7 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,427 [IPC Server handler 8 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:51,433 [IPC Server handler 9 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/TestNameEditsConfigs3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:51,447 [IPC Server handler 1 on default port 38023] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:42394, 127.0.0.1:44515, 127.0.0.1:33303 for /user/root/TestNameEditsConfigs3
2020-12-03 07:23:51,450 [Thread-468] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,457 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:43054 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005 src: /127.0.0.1:43054 dest: /127.0.0.1:42394
2020-12-03 07:23:51,458 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:43054 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,459 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:52308 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005 src: /127.0.0.1:52308 dest: /127.0.0.1:44515
2020-12-03 07:23:51,460 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:52308 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,461 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:32772 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005 src: /127.0.0.1:32772 dest: /127.0.0.1:33303
2020-12-03 07:23:51,533 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32772, dest: /127.0.0.1:33303, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, duration(ns): 31862458
2020-12-03 07:23:51,534 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:51,544 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52308, dest: /127.0.0.1:44515, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, duration(ns): 79740655
2020-12-03 07:23:51,545 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303] terminating
2020-12-03 07:23:51,549 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43054, dest: /127.0.0.1:42394, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, duration(ns): 75522102
2020-12-03 07:23:51,549 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303] terminating
2020-12-03 07:23:51,558 [IPC Server handler 2 on default port 38023] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:42394, 127.0.0.1:44515, 127.0.0.1:33303 for /user/root/TestNameEditsConfigs3
2020-12-03 07:23:51,563 [DataStreamer for file /user/root/TestNameEditsConfigs3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,565 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:43060 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006 src: /127.0.0.1:43060 dest: /127.0.0.1:42394
2020-12-03 07:23:51,566 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:43060 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,576 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:52314 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006 src: /127.0.0.1:52314 dest: /127.0.0.1:44515
2020-12-03 07:23:51,578 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:52314 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:51,579 [DataXceiver for client DFSClient_NONMAPREDUCE_1753492649_1 at /127.0.0.1:32778 [Receiving block BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006 src: /127.0.0.1:32778 dest: /127.0.0.1:33303
2020-12-03 07:23:51,597 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32778, dest: /127.0.0.1:33303, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 0a9dab0c-df25-451f-9d45-48227165f30e, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, duration(ns): 16333520
2020-12-03 07:23:51,598 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:51,599 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52314, dest: /127.0.0.1:44515, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 9bb9904b-e086-4883-b13d-90a0b829e439, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, duration(ns): 17764426
2020-12-03 07:23:51,599 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33303] terminating
2020-12-03 07:23:51,600 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43060, dest: /127.0.0.1:42394, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753492649_1, offset: 0, srvID: 7b6bc5ce-f019-43bd-9069-f15868efab27, blockid: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, duration(ns): 14862346
2020-12-03 07:23:51,600 [PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775645091-172.17.0.11-1606980218489:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44515, 127.0.0.1:33303] terminating
2020-12-03 07:23:51,602 [IPC Server handler 8 on default port 38023] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741830_1006 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/TestNameEditsConfigs3
2020-12-03 07:23:52,007 [IPC Server handler 1 on default port 38023] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/TestNameEditsConfigs3 is closed by DFSClient_NONMAPREDUCE_1753492649_1
2020-12-03 07:23:52,011 [IPC Server handler 0 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,013 [IPC Server handler 3 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,015 [IPC Server handler 4 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,018 [IPC Server handler 5 on default port 38023] INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(4740)) - Roll Edit Log from 127.0.0.1
2020-12-03 07:23:52,019 [IPC Server handler 5 on default port 38023] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:52,019 [IPC Server handler 5 on default port 38023] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 28, 37
2020-12-03 07:23:52,019 [IPC Server handler 5 on default port 38023] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 11 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 29 Number of syncs: 10 SyncTimes(ms): 5 
2020-12-03 07:23:52,020 [IPC Server handler 5 on default port 38023] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000028 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000028-0000000000000000038
2020-12-03 07:23:52,021 [IPC Server handler 5 on default port 38023] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 39
2020-12-03 07:23:52,157 [IPC Server handler 5 on default port 38023] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rollEditLog	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,160 [Listener at localhost/39628] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(421)) - Image has changed. Downloading updated image from NN.
2020-12-03 07:23:52,160 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:44017/imagetransfer?getimage=1&txid=25&storageInfo=-65:198152275:1606980218489:testClusterID&bootstrapstandby=false
2020-12-03 07:23:52,168 [qtp1656318404-1457] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000025, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:52,237 [Listener at localhost/39628] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000025 took 0.00s.
2020-12-03 07:23:52,238 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(122)) - Downloaded file fsimage.ckpt_0000000000000000025 size 653 bytes.
2020-12-03 07:23:52,383 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:44017/imagetransfer?getedit=1&startTxId=26&endTxId=27&storageInfo=-65:198152275:1606980218489:testClusterID
2020-12-03 07:23:52,386 [qtp1656318404-2128] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000026-0000000000000000027, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:52,466 [Listener at localhost/39628] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_tmp_0000000000000000026-0000000000000000027_0000000000141222712 took 0.00s.
2020-12-03 07:23:52,467 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(175)) - Downloaded file edits_tmp_0000000000000000026-0000000000000000027_0000000000141222712 size 0 bytes.
2020-12-03 07:23:52,467 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:44017/imagetransfer?getedit=1&startTxId=28&endTxId=38&storageInfo=-65:198152275:1606980218489:testClusterID
2020-12-03 07:23:52,470 [qtp1656318404-1445] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000028-0000000000000000038, fileSize: 717. Sent total: 717 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:52,508 [Listener at localhost/39628] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_tmp_0000000000000000028-0000000000000000038_0000000000141222797 took 0.00s.
2020-12-03 07:23:52,509 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(175)) - Downloaded file edits_tmp_0000000000000000028-0000000000000000038_0000000000141222797 size 0 bytes.
2020-12-03 07:23:52,524 [Listener at localhost/39628] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:52,528 [Listener at localhost/39628] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:52,529 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 25 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000025
2020-12-03 07:23:52,529 [Listener at localhost/39628] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:52,530 [Listener at localhost/39628] INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(314)) - Checkpointer about to load edits from 2 stream(s).
2020-12-03 07:23:52,530 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_0000000000000000026-0000000000000000027 expecting start txid #26
2020-12-03 07:23:52,530 [Listener at localhost/39628] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_0000000000000000026-0000000000000000027 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:52,531 [Listener at localhost/39628] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_0000000000000000026-0000000000000000027) of total size 42.0, total edits 2.0, total load time 0.0 ms
2020-12-03 07:23:52,548 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000038 using no compression
2020-12-03 07:23:52,558 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000038 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:52,594 [Listener at localhost/39628] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 25
2020-12-03 07:23:52,594 [Listener at localhost/39628] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2020-12-03 07:23:52,729 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000038, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:52,771 [qtp1656318404-1457] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000038 took 0.00s.
2020-12-03 07:23:52,771 [qtp1656318404-1457] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000038 size 653 bytes.
2020-12-03 07:23:52,814 [qtp1656318404-1457] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 25
2020-12-03 07:23:52,814 [qtp1656318404-1457] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2020-12-03 07:23:52,816 [Listener at localhost/39628] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 38 to namenode at http://localhost:44017 in 0.087 seconds
2020-12-03 07:23:52,816 [Listener at localhost/39628] WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(585)) - Checkpoint done. New Image Size: 653
2020-12-03 07:23:52,816 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:52,817 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:52,817 [Listener at localhost/39628] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:52,817 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4f824872] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:52,818 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29) exiting.
2020-12-03 07:23:52,818 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417) exiting.
2020-12-03 07:23:52,843 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71dfcf21{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:52,848 [Listener at localhost/39628] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@b965857{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:52,849 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c8909c3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:52,849 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@363f0ba0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:52,870 [Listener at localhost/39628] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39628
2020-12-03 07:23:52,872 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:52,872 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:52,872 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:52,873 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:38023
2020-12-03 07:23:52,873 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e)
2020-12-03 07:23:52,874 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:52,875 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:52,879 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:52,880 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:52,880 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:52,881 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:52,881 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:52,882 [Listener at localhost/39628] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:52,883 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:52,883 [Listener at localhost/39628] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:52,884 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5) exiting.
2020-12-03 07:23:52,884 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559) exiting.
2020-12-03 07:23:52,886 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6eb82908] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:52,902 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3157e4c0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:52,903 [Listener at localhost/39628] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6eaa21d8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:52,903 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f51431{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:52,904 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bd0b0e5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:52,935 [Listener at localhost/39628] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46503
2020-12-03 07:23:52,939 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:52,940 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:52,940 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:38023
2020-12-03 07:23:52,940 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27)
2020-12-03 07:23:52,940 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:52,942 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:52,967 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:52,968 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:52,968 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:52,968 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:52,969 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:52,970 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:52,971 [Listener at localhost/39628] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:52,971 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:52,972 [Listener at localhost/39628] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:52,972 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@314c8b4a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:52,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db) exiting.
2020-12-03 07:23:52,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d) exiting.
2020-12-03 07:23:53,005 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f672204{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:53,006 [Listener at localhost/39628] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@78b41097{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:53,007 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ff60a8c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:53,007 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d0cc890{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:53,008 [Listener at localhost/39628] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39690
2020-12-03 07:23:53,012 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:53,012 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:53,012 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:53,012 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:38023
2020-12-03 07:23:53,014 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439)
2020-12-03 07:23:53,014 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:38023] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:53,015 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:53,015 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:53,018 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:53,018 [Listener at localhost/39628] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:53,019 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:53,019 [Listener at localhost/39628] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:53,022 [Listener at localhost/39628] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:53,022 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:53,022 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:53,023 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@787f32b7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:53,023 [Listener at localhost/39628] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 39, 39
2020-12-03 07:23:53,023 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6aef4eb8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:53,024 [Listener at localhost/39628] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2020-12-03 07:23:53,025 [Listener at localhost/39628] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000039 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000039-0000000000000000040
2020-12-03 07:23:53,025 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:53,026 [CacheReplicationMonitor(154426308)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:53,040 [Listener at localhost/39628] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38023
2020-12-03 07:23:53,049 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:53,049 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:53,050 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:53,050 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:53,069 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:53,069 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:53,073 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1fde4f40{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:53,076 [Listener at localhost/39628] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49cf9028{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:53,077 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b56f5f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:53,077 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@610df783{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:53,122 [Listener at localhost/39628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:23:53,123 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,123 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:53,124 [Listener at localhost/39628] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:53,124 [Listener at localhost/39628] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:53,124 [Listener at localhost/39628] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:53,137 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f1a45f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:53,138 [Listener at localhost/39628] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:53,138 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,140 [Listener at localhost/39628] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:53,141 [Listener at localhost/39628] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:53,141 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,143 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:53,143 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:53,143 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:53,144 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:53,145 [Listener at localhost/39628] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:53,145 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:53,146 [Listener at localhost/39628] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40475
2020-12-03 07:23:53,146 [Listener at localhost/39628] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:53,148 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58f07f02{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:53,148 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40f8f5a8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:53,154 [Listener at localhost/39628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2264e43c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:53,156 [Listener at localhost/39628] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3bec2275{HTTP/1.1,[http/1.1]}{localhost:40475}
2020-12-03 07:23:53,157 [Listener at localhost/39628] INFO  server.Server (Server.java:doStart(419)) - Started @16503ms
2020-12-03 07:23:53,157 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,157 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:53,158 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,158 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:53,158 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,158 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name in configuration.
2020-12-03 07:23:53,159 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,159 [Listener at localhost/39628] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:53,160 [Listener at localhost/39628] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:53,161 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:53,162 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:53,162 [Listener at localhost/39628] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,163 [Listener at localhost/39628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:53,163 [Listener at localhost/39628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:53,163 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:53,163 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:53
2020-12-03 07:23:53,163 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:53,164 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:53,164 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:53,164 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:53,168 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:53,168 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:53,169 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:53,170 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:53,170 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:53,170 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:53,170 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:53,170 [Listener at localhost/39628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:53,171 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:53,171 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:53,171 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:53,171 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:53,173 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:53,173 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:53,173 [Listener at localhost/39628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:53,174 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:53,175 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:53,175 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:53,176 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:53,177 [Listener at localhost/39628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:53,215 [Listener at localhost/39628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:53,249 [Listener at localhost/39628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:53,282 [Listener at localhost/39628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:53,283 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(301)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits is not formatted.
2020-12-03 07:23:53,283 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(302)) - Formatting ...
2020-12-03 07:23:53,283 [Listener at localhost/39628] WARN  namenode.FSImage (NNStorage.java:readAndInspectDirs(1095)) - Storage directory Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits; location= null contains no VERSION file. Skipping...
2020-12-03 07:23:53,284 [Listener at localhost/39628] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits
2020-12-03 07:23:53,285 [Listener at localhost/39628] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current
2020-12-03 07:23:53,286 [Listener at localhost/39628] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current
2020-12-03 07:23:53,286 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000038, cpktTxId=0000000000000000038)
2020-12-03 07:23:53,290 [Listener at localhost/39628] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:53,292 [Listener at localhost/39628] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:53,292 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 38 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000038
2020-12-03 07:23:53,292 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@281ce6bb expecting start txid #39
2020-12-03 07:23:53,293 [Listener at localhost/39628] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000039-0000000000000000040 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:53,293 [Listener at localhost/39628] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000039-0000000000000000040' to transaction ID 39
2020-12-03 07:23:53,294 [Listener at localhost/39628] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000039-0000000000000000040) of total size 42.0, total edits 2.0, total load time 1.0 ms
2020-12-03 07:23:53,294 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:53,294 [Listener at localhost/39628] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:23:53,306 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000040 using no compression
2020-12-03 07:23:53,306 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000040 using no compression
2020-12-03 07:23:53,314 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000040 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:53,314 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000040 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:53,372 [Listener at localhost/39628] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits
2020-12-03 07:23:53,373 [Listener at localhost/39628] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 38
2020-12-03 07:23:53,373 [Listener at localhost/39628] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2020-12-03 07:23:53,374 [Listener at localhost/39628] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits
2020-12-03 07:23:53,496 [Listener at localhost/39628] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 41
2020-12-03 07:23:53,747 [Listener at localhost/39628] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:53,748 [Listener at localhost/39628] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 570 msecs
2020-12-03 07:23:53,748 [Listener at localhost/39628] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:53,749 [Listener at localhost/39628] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:53,750 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:53,755 [Listener at localhost/34934] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34934 to access this namenode/service.
2020-12-03 07:23:53,756 [Listener at localhost/34934] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:53,756 [Listener at localhost/34934] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits in configuration.
2020-12-03 07:23:53,757 [Listener at localhost/34934] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits in configuration.
2020-12-03 07:23:53,789 [Listener at localhost/34934] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:53,791 [Listener at localhost/34934] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 2.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:53,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:53,797 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:53,810 [Listener at localhost/34934] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34934
2020-12-03 07:23:53,810 [Listener at localhost/34934] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:53,811 [Listener at localhost/34934] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:53,812 [Listener at localhost/34934] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=4
storage space=24576
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:53,815 [CacheReplicationMonitor(1399286940)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:53,817 [Listener at localhost/34934] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:53,819 [Listener at localhost/34934] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:53,819 [Listener at localhost/34934] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:53,821 [Listener at localhost/34934] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:53,824 [Listener at localhost/34934] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,824 [Listener at localhost/34934] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:53,825 [Listener at localhost/34934] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:53,825 [Listener at localhost/34934] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,826 [Listener at localhost/34934] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:53,827 [Listener at localhost/34934] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44214
2020-12-03 07:23:53,827 [Listener at localhost/34934] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:53,827 [Listener at localhost/34934] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:53,828 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,830 [Listener at localhost/34934] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:53,831 [Listener at localhost/34934] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:53,831 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,833 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:53,834 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:53,834 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:53,835 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:53,836 [Listener at localhost/34934] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35103
2020-12-03 07:23:53,836 [Listener at localhost/34934] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:53,838 [Listener at localhost/34934] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bd1111a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:53,839 [Listener at localhost/34934] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1de6932a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:53,846 [Listener at localhost/34934] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b46dd8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:53,849 [Listener at localhost/34934] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39651a82{HTTP/1.1,[http/1.1]}{localhost:35103}
2020-12-03 07:23:53,849 [Listener at localhost/34934] INFO  server.Server (Server.java:doStart(419)) - Started @17195ms
2020-12-03 07:23:53,877 [Listener at localhost/34934] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43730
2020-12-03 07:23:53,878 [Listener at localhost/34934] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:53,878 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@134c370e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:53,878 [Listener at localhost/34934] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:53,878 [Listener at localhost/34934] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:53,879 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:53,883 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44428
2020-12-03 07:23:53,895 [Listener at localhost/44428] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:53,896 [Listener at localhost/44428] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:53,897 [Thread-535] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934 starting to offer service
2020-12-03 07:23:53,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:53,902 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:53,908 [Listener at localhost/44428] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:53,908 [Thread-535] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934
2020-12-03 07:23:53,909 [Thread-535] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:53,910 [Listener at localhost/44428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:53,910 [Listener at localhost/44428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:53,911 [Listener at localhost/44428] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:53,912 [Listener at localhost/44428] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,913 [Listener at localhost/44428] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:53,913 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:53,913 [Listener at localhost/44428] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,913 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:53,914 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40201
2020-12-03 07:23:53,914 [Listener at localhost/44428] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:53,914 [Listener at localhost/44428] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:53,915 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,917 [Listener at localhost/44428] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:53,918 [Listener at localhost/44428] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:53,918 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,921 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:53,921 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:53,921 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:53,922 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:53,922 [Listener at localhost/44428] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43364
2020-12-03 07:23:53,922 [Listener at localhost/44428] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:53,925 [Listener at localhost/44428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c796cc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:53,926 [Listener at localhost/44428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cb7936c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:53,931 [Listener at localhost/44428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e13fa{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:53,932 [Listener at localhost/44428] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ff415ad{HTTP/1.1,[http/1.1]}{localhost:43364}
2020-12-03 07:23:53,935 [Listener at localhost/44428] INFO  server.Server (Server.java:doStart(419)) - Started @17281ms
2020-12-03 07:23:53,953 [Listener at localhost/44428] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44053
2020-12-03 07:23:53,954 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:53,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f9b6ae7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:53,954 [Listener at localhost/44428] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:53,955 [Listener at localhost/44428] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:53,956 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:53,969 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43919
2020-12-03 07:23:53,980 [Thread-535] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:53,985 [Listener at localhost/43919] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:53,986 [Listener at localhost/43919] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:53,986 [Thread-558] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934 starting to offer service
2020-12-03 07:23:53,991 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:53,993 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:53,999 [Thread-558] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934
2020-12-03 07:23:54,001 [Thread-558] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:54,003 [Listener at localhost/43919] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:54,004 [Listener at localhost/43919] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:54,005 [Listener at localhost/43919] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:54,005 [Listener at localhost/43919] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:54,007 [Listener at localhost/43919] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:54,007 [Listener at localhost/43919] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:54,008 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:54,008 [Listener at localhost/43919] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:54,008 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:54,009 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43901
2020-12-03 07:23:54,009 [Listener at localhost/43919] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:54,009 [Listener at localhost/43919] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:54,010 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,012 [Listener at localhost/43919] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:54,013 [Listener at localhost/43919] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:54,013 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,015 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:54,015 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:54,016 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:54,016 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:54,016 [Listener at localhost/43919] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45833
2020-12-03 07:23:54,017 [Listener at localhost/43919] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:54,019 [Listener at localhost/43919] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76f856a8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:54,019 [Listener at localhost/43919] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@174e1b69{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:54,025 [Listener at localhost/43919] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41fed14f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:54,028 [Listener at localhost/43919] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d6ee47{HTTP/1.1,[http/1.1]}{localhost:45833}
2020-12-03 07:23:54,028 [Listener at localhost/43919] INFO  server.Server (Server.java:doStart(419)) - Started @17374ms
2020-12-03 07:23:54,048 [Listener at localhost/43919] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33711
2020-12-03 07:23:54,049 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:54,049 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c6da8bb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:54,049 [Listener at localhost/43919] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:54,050 [Listener at localhost/43919] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:54,051 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:54,052 [Thread-558] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,058 [Listener at localhost/33336] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33336
2020-12-03 07:23:54,072 [Listener at localhost/33336] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:54,072 [Listener at localhost/33336] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:54,073 [Thread-580] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934 starting to offer service
2020-12-03 07:23:54,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:54,076 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:54,080 [Thread-580] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34934
2020-12-03 07:23:54,084 [Thread-580] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:54,091 [IPC Server handler 3 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,092 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,092 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,144 [Thread-580] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,144 [Thread-535] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,196 [Thread-558] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,196 [IPC Server handler 4 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,198 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,199 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,232 [Thread-535] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,233 [Thread-535] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,274 [Thread-558] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,274 [Thread-558] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,307 [IPC Server handler 5 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,309 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,309 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,319 [Thread-580] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,332 [Thread-535] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,332 [Thread-535] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,375 [Thread-558] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,376 [Thread-558] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,398 [Thread-535] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:54,402 [Thread-535] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a942f057-deae-4f03-9702-7f6ecd90f93d
2020-12-03 07:23:54,404 [Thread-535] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:54,406 [Thread-535] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-479312ef-eeb1-4c34-b587-263125ea57db
2020-12-03 07:23:54,419 [Thread-535] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:54,420 [Thread-535] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:54,420 [IPC Server handler 6 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,421 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,421 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,422 [Thread-558] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:54,422 [Thread-535] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:54,425 [Thread-580] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,425 [Thread-580] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,426 [Thread-535] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:54,426 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5
2020-12-03 07:23:54,429 [Thread-558] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:54,426 [Thread-535] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:54,429 [Thread-535] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:54,435 [Thread-535] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,436 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:54,436 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:54,437 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da04c649-932f-40d5-9a46-2ab5df792559
2020-12-03 07:23:54,438 [Thread-558] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:54,439 [Thread-558] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:54,439 [Thread-596] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,439 [Thread-595] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,440 [Thread-558] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:54,440 [Thread-558] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:54,441 [Thread-558] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:54,441 [Thread-558] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:54,441 [Thread-558] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,441 [Thread-598] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:54,449 [Thread-599] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:54,450 [Thread-599] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,450 [Thread-598] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,455 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 18ms
2020-12-03 07:23:54,455 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 19ms
2020-12-03 07:23:54,455 [Thread-535] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 20ms
2020-12-03 07:23:54,456 [Thread-600] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:54,456 [Thread-601] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:54,459 [Thread-601] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,459 [Thread-600] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,459 [Thread-601] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-12-03 07:23:54,459 [Thread-600] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:23:54,467 [Thread-535] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 11ms
2020-12-03 07:23:54,469 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db): no suitable block pools found to scan.  Waiting 1814388227 ms.
2020-12-03 07:23:54,469 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d): no suitable block pools found to scan.  Waiting 1814388227 ms.
2020-12-03 07:23:54,469 [Thread-535] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:10 AM with interval of 21600000ms
2020-12-03 07:23:54,471 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:34934 beginning handshake with NN
2020-12-03 07:23:54,473 [Thread-599] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 23ms
2020-12-03 07:23:54,473 [IPC Server handler 7 on default port 34934] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44214, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43730, infoSecurePort=0, ipcPort=44428, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:54,473 [IPC Server handler 7 on default port 34934] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44214
2020-12-03 07:23:54,474 [IPC Server handler 7 on default port 34934] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bb9904b-e086-4883-b13d-90a0b829e439 (127.0.0.1:44214).
2020-12-03 07:23:54,478 [Thread-598] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 29ms
2020-12-03 07:23:54,478 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:34934 successfully registered with NN
2020-12-03 07:23:54,478 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 37ms
2020-12-03 07:23:54,478 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34934 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:54,479 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:54,479 [Thread-606] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:54,483 [Thread-605] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,483 [Thread-606] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,483 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:23:54,483 [Thread-606] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:23:54,483 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 5ms
2020-12-03 07:23:54,485 [IPC Server handler 8 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a942f057-deae-4f03-9702-7f6ecd90f93d for DN 127.0.0.1:44214
2020-12-03 07:23:54,485 [IPC Server handler 8 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-479312ef-eeb1-4c34-b587-263125ea57db for DN 127.0.0.1:44214
2020-12-03 07:23:54,489 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5): no suitable block pools found to scan.  Waiting 1814388207 ms.
2020-12-03 07:23:54,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6e126402f0c3ccc: Processing first storage report for DS-a942f057-deae-4f03-9702-7f6ecd90f93d from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:54,490 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:54,492 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:54,492 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:54,492 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:54,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559): no suitable block pools found to scan.  Waiting 1814388204 ms.
2020-12-03 07:23:54,492 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:54,493 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6e126402f0c3ccc: from storage DS-a942f057-deae-4f03-9702-7f6ecd90f93d node DatanodeRegistration(127.0.0.1:44214, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43730, infoSecurePort=0, ipcPort=44428, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,493 [Thread-558] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:05 PM with interval of 21600000ms
2020-12-03 07:23:54,505 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 2
2020-12-03 07:23:54,505 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:34934 beginning handshake with NN
2020-12-03 07:23:54,505 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:54,505 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:23:54,505 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:54,505 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:54,506 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2020-12-03 07:23:54,506 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6e126402f0c3ccc: Processing first storage report for DS-479312ef-eeb1-4c34-b587-263125ea57db from datanode 9bb9904b-e086-4883-b13d-90a0b829e439
2020-12-03 07:23:54,510 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6e126402f0c3ccc: from storage DS-479312ef-eeb1-4c34-b587-263125ea57db node DatanodeRegistration(127.0.0.1:44214, datanodeUuid=9bb9904b-e086-4883-b13d-90a0b829e439, infoPort=43730, infoSecurePort=0, ipcPort=44428, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,510 [IPC Server handler 0 on default port 34934] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40201, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44053, infoSecurePort=0, ipcPort=43919, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:54,510 [Thread-580] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,510 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6e126402f0c3ccc,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 1 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:54,510 [IPC Server handler 0 on default port 34934] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40201
2020-12-03 07:23:54,511 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,511 [Thread-580] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,511 [IPC Server handler 0 on default port 34934] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7b6bc5ce-f019-43bd-9069-f15868efab27 (127.0.0.1:40201).
2020-12-03 07:23:54,512 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:34934 successfully registered with NN
2020-12-03 07:23:54,512 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34934 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:54,517 [IPC Server handler 1 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 for DN 127.0.0.1:40201
2020-12-03 07:23:54,522 [IPC Server handler 1 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da04c649-932f-40d5-9a46-2ab5df792559 for DN 127.0.0.1:40201
2020-12-03 07:23:54,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa71996cbf5971f64: Processing first storage report for DS-da04c649-932f-40d5-9a46-2ab5df792559 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:54,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa71996cbf5971f64: from storage DS-da04c649-932f-40d5-9a46-2ab5df792559 node DatanodeRegistration(127.0.0.1:40201, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44053, infoSecurePort=0, ipcPort=43919, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa71996cbf5971f64: Processing first storage report for DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 from datanode 7b6bc5ce-f019-43bd-9069-f15868efab27
2020-12-03 07:23:54,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa71996cbf5971f64: from storage DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5 node DatanodeRegistration(127.0.0.1:40201, datanodeUuid=7b6bc5ce-f019-43bd-9069-f15868efab27, infoPort=44053, infoSecurePort=0, ipcPort=43919, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,531 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa71996cbf5971f64,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:54,531 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,532 [IPC Server handler 3 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,532 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,533 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,558 [Thread-580] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=198152275;bpid=BP-1775645091-172.17.0.11-1606980218489;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=198152275;c=1606980218489;bpid=BP-1775645091-172.17.0.11-1606980218489;dnuuid=0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:54,561 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29
2020-12-03 07:23:54,561 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:54,566 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20ea579c-cd28-4269-9aea-b545c0a7f417
2020-12-03 07:23:54,566 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:54,566 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:54,567 [Thread-580] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:54,570 [Thread-580] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:54,570 [Thread-580] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:54,570 [Thread-580] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:54,571 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,571 [Thread-613] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:54,572 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:54,573 [Thread-613] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,573 [Thread-614] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current: 36981
2020-12-03 07:23:54,581 [Thread-613] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 9ms
2020-12-03 07:23:54,582 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1775645091-172.17.0.11-1606980218489 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 11ms
2020-12-03 07:23:54,582 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1775645091-172.17.0.11-1606980218489: 11ms
2020-12-03 07:23:54,583 [Thread-615] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:54,583 [Thread-616] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:54,585 [Thread-615] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,585 [Thread-616] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489/current/replicas
2020-12-03 07:23:54,586 [Thread-615] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:23:54,586 [Thread-616] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:23:54,587 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1775645091-172.17.0.11-1606980218489: 5ms
2020-12-03 07:23:54,588 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417): no suitable block pools found to scan.  Waiting 1814388108 ms.
2020-12-03 07:23:54,588 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29): no suitable block pools found to scan.  Waiting 1814388108 ms.
2020-12-03 07:23:54,588 [Thread-580] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:53 PM with interval of 21600000ms
2020-12-03 07:23:54,594 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:34934 beginning handshake with NN
2020-12-03 07:23:54,595 [IPC Server handler 4 on default port 34934] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43901, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=33711, infoSecurePort=0, ipcPort=33336, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489) storage 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:54,595 [IPC Server handler 4 on default port 34934] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43901
2020-12-03 07:23:54,596 [IPC Server handler 4 on default port 34934] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0a9dab0c-df25-451f-9d45-48227165f30e (127.0.0.1:43901).
2020-12-03 07:23:54,598 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:34934 successfully registered with NN
2020-12-03 07:23:54,598 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34934 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:54,603 [IPC Server handler 5 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 for DN 127.0.0.1:43901
2020-12-03 07:23:54,603 [IPC Server handler 5 on default port 34934] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20ea579c-cd28-4269-9aea-b545c0a7f417 for DN 127.0.0.1:43901
2020-12-03 07:23:54,605 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc935613f2ecf4763: Processing first storage report for DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:54,605 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc935613f2ecf4763: from storage DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29 node DatanodeRegistration(127.0.0.1:43901, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=33711, infoSecurePort=0, ipcPort=33336, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc935613f2ecf4763: Processing first storage report for DS-20ea579c-cd28-4269-9aea-b545c0a7f417 from datanode 0a9dab0c-df25-451f-9d45-48227165f30e
2020-12-03 07:23:54,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc935613f2ecf4763: from storage DS-20ea579c-cd28-4269-9aea-b545c0a7f417 node DatanodeRegistration(127.0.0.1:43901, datanodeUuid=0a9dab0c-df25-451f-9d45-48227165f30e, infoPort=33711, infoSecurePort=0, ipcPort=33336, storageInfo=lv=-57;cid=testClusterID;nsid=198152275;c=1606980218489), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,606 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc935613f2ecf4763,  containing 2 storage report(s), of which we sent 2. The reports had 6 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:54,607 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:54,634 [IPC Server handler 7 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,635 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:54,638 [IPC Server handler 8 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,639 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:54,640 [Listener at localhost/33336] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - SecondaryNameNode metrics system started (again)
2020-12-03 07:23:54,654 [Listener at localhost/33336] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname in configuration.
2020-12-03 07:23:54,654 [Listener at localhost/33336] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:54,654 [Listener at localhost/33336] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits in configuration.
2020-12-03 07:23:54,655 [Listener at localhost/33336] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits in configuration.
2020-12-03 07:23:54,656 [Listener at localhost/33336] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:54,691 [Listener at localhost/33336] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,725 [Listener at localhost/33336] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,767 [Listener at localhost/33336] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/in_use.lock acquired by nodename 6811@2173cf0f5f64
2020-12-03 07:23:54,768 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:54,768 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:54,768 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:54,768 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:54,769 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:54,769 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:54,769 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:54,769 [Listener at localhost/33336] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:54,770 [Listener at localhost/33336] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:54,770 [Listener at localhost/33336] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:54,770 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:54,771 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:54
2020-12-03 07:23:54,771 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:54,771 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,771 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:54,771 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:54,793 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:54,794 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:54,794 [Listener at localhost/33336] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:54,794 [Listener at localhost/33336] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:54,794 [Listener at localhost/33336] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:54,795 [Listener at localhost/33336] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:54,796 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:54,796 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,796 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:54,796 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:54,808 [Listener at localhost/33336] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:54,809 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:54,809 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,809 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:54,809 [Listener at localhost/33336] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:54,812 [Listener at localhost/33336] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:54,812 [Listener at localhost/33336] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:54,812 [Listener at localhost/33336] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:54,812 [Listener at localhost/33336] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(261)) - Checkpoint Period   :3600 secs (60 min)
2020-12-03 07:23:54,813 [Listener at localhost/33336] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(263)) - Log Size Trigger    :1000000 txns
2020-12-03 07:23:54,815 [IPC Server handler 9 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,816 [IPC Server handler 0 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs2	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,817 [IPC Server handler 1 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,819 [IPC Server handler 2 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,820 [IPC Server handler 3 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,821 [IPC Server handler 4 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/user/root/TestNameEditsConfigs3	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,902 [IPC Server handler 5 on default port 34934] INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(4740)) - Roll Edit Log from 127.0.0.1
2020-12-03 07:23:54,903 [IPC Server handler 5 on default port 34934] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:54,903 [IPC Server handler 5 on default port 34934] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 41, 41
2020-12-03 07:23:54,905 [IPC Server handler 5 on default port 34934] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 40 Number of syncs: 3 SyncTimes(ms): 2 3 
2020-12-03 07:23:54,993 [IPC Server handler 5 on default port 34934] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000041 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000041-0000000000000000042
2020-12-03 07:23:54,996 [IPC Server handler 5 on default port 34934] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000041 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000041-0000000000000000042
2020-12-03 07:23:54,996 [IPC Server handler 5 on default port 34934] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 43
2020-12-03 07:23:55,445 [IPC Server handler 5 on default port 34934] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rollEditLog	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:55,448 [Listener at localhost/33336] INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(421)) - Image has changed. Downloading updated image from NN.
2020-12-03 07:23:55,449 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:40475/imagetransfer?getimage=1&txid=40&storageInfo=-65:198152275:1606980218489:testClusterID&bootstrapstandby=false
2020-12-03 07:23:55,457 [qtp81505591-2146] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage_0000000000000000040, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,619 [Listener at localhost/33336] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000040 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000040 took 0.00s.
2020-12-03 07:23:55,619 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(122)) - Downloaded file fsimage.ckpt_0000000000000000040 size 653 bytes.
2020-12-03 07:23:55,787 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(416)) - Opening connection to http://localhost:40475/imagetransfer?getedit=1&startTxId=41&endTxId=42&storageInfo=-65:198152275:1606980218489:testClusterID
2020-12-03 07:23:55,789 [qtp81505591-2134] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000041-0000000000000000042, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,932 [Listener at localhost/33336] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_tmp_0000000000000000041-0000000000000000042_0000000000141226116 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondedits/current/edits_tmp_0000000000000000041-0000000000000000042_0000000000141226116 took 0.00s.
2020-12-03 07:23:55,933 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(175)) - Downloaded file edits_tmp_0000000000000000041-0000000000000000042_0000000000141226116 size 0 bytes.
2020-12-03 07:23:55,948 [Listener at localhost/33336] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:55,950 [Listener at localhost/33336] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:55,950 [Listener at localhost/33336] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 40 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000040
2020-12-03 07:23:55,950 [Listener at localhost/33336] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:55,951 [Listener at localhost/33336] INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(314)) - Checkpointer about to load edits from 1 stream(s).
2020-12-03 07:23:55,951 [Listener at localhost/33336] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000041-0000000000000000042 expecting start txid #41
2020-12-03 07:23:55,951 [Listener at localhost/33336] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000041-0000000000000000042 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:55,952 [Listener at localhost/33336] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/edits_0000000000000000041-0000000000000000042) of total size 42.0, total edits 2.0, total load time 0.0 ms
2020-12-03 07:23:55,967 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000042 using no compression
2020-12-03 07:23:55,967 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000042 using no compression
2020-12-03 07:23:55,982 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits/current/fsimage.ckpt_0000000000000000042 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:55,983 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname of type IMAGE] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage.ckpt_0000000000000000042 of size 653 bytes saved in 0 seconds .
2020-12-03 07:23:56,027 [Listener at localhost/33336] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits
2020-12-03 07:23:56,028 [Listener at localhost/33336] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 40
2020-12-03 07:23:56,028 [Listener at localhost/33336] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000038, cpktTxId=0000000000000000038)
2020-12-03 07:23:56,029 [Listener at localhost/33336] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2020-12-03 07:23:56,030 [Listener at localhost/33336] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/second_name_and_edits
2020-12-03 07:23:56,283 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/secondname/current/fsimage_0000000000000000042, fileSize: 653. Sent total: 653 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:56,388 [qtp81505591-2805] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/fsimage.ckpt_0000000000000000042 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage.ckpt_0000000000000000042 took 0.00s.
2020-12-03 07:23:56,389 [qtp81505591-2805] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000042 size 653 bytes.
2020-12-03 07:23:56,532 [qtp81505591-2805] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 40
2020-12-03 07:23:56,532 [qtp81505591-2805] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(226)) - Purging old image FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name/current/fsimage_0000000000000000038, cpktTxId=0000000000000000038)
2020-12-03 07:23:56,534 [Listener at localhost/33336] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 42 to namenode at http://localhost:40475 in 0.253 seconds
2020-12-03 07:23:56,535 [Listener at localhost/33336] WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(585)) - Checkpoint done. New Image Size: 653
2020-12-03 07:23:56,535 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:56,535 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:56,535 [Listener at localhost/33336] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:56,535 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@dab48d3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:56,536 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-20ea579c-cd28-4269-9aea-b545c0a7f417) exiting.
2020-12-03 07:23:56,536 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c2353b68-5861-4e6c-9b39-1ab141ab6e29) exiting.
2020-12-03 07:23:56,550 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41fed14f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:56,550 [Listener at localhost/33336] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d6ee47{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,551 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@174e1b69{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,551 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76f856a8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,552 [Listener at localhost/33336] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33336
2020-12-03 07:23:56,553 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,553 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,554 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:56,554 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e) service to localhost/127.0.0.1:34934
2020-12-03 07:23:56,554 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 0a9dab0c-df25-451f-9d45-48227165f30e)
2020-12-03 07:23:56,554 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:56,555 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,556 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,557 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:56,558 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:56,558 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:56,558 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:56,561 [Listener at localhost/33336] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:56,561 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:56,562 [Listener at localhost/33336] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:56,562 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a7a965d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:56,563 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-6bf79e2e-3bf3-419f-a423-ceb2d39979e5) exiting.
2020-12-03 07:23:56,563 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-da04c649-932f-40d5-9a46-2ab5df792559) exiting.
2020-12-03 07:23:56,578 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70e13fa{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:56,579 [Listener at localhost/33336] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ff415ad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,579 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cb7936c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,579 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c796cc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,580 [Listener at localhost/33336] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43919
2020-12-03 07:23:56,582 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,582 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,583 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:56,583 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27) service to localhost/127.0.0.1:34934
2020-12-03 07:23:56,583 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 7b6bc5ce-f019-43bd-9069-f15868efab27)
2020-12-03 07:23:56,583 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:56,584 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,584 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,587 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:56,587 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:56,588 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:56,588 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:56,588 [Listener at localhost/33336] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:56,588 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:56,589 [Listener at localhost/33336] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:56,589 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@167279d1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:56,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a942f057-deae-4f03-9702-7f6ecd90f93d) exiting.
2020-12-03 07:23:56,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-479312ef-eeb1-4c34-b587-263125ea57db) exiting.
2020-12-03 07:23:56,605 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b46dd8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:56,606 [Listener at localhost/33336] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39651a82{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,607 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1de6932a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,607 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bd1111a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,608 [Listener at localhost/33336] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44428
2020-12-03 07:23:56,610 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,610 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,611 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:56,611 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439) service to localhost/127.0.0.1:34934
2020-12-03 07:23:56,611 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775645091-172.17.0.11-1606980218489 (Datanode Uuid 9bb9904b-e086-4883-b13d-90a0b829e439)
2020-12-03 07:23:56,611 [BP-1775645091-172.17.0.11-1606980218489 heartbeating to localhost/127.0.0.1:34934] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1775645091-172.17.0.11-1606980218489
2020-12-03 07:23:56,612 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,612 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775645091-172.17.0.11-1606980218489] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:56,616 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:56,616 [Listener at localhost/33336] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:56,617 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:56,617 [Listener at localhost/33336] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:56,617 [Listener at localhost/33336] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:56,618 [Listener at localhost/33336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:56,618 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,618 [Listener at localhost/33336] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 43, 43
2020-12-03 07:23:56,618 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@14ac77b9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:56,618 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3f4cd155] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:56,619 [Listener at localhost/33336] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 2 
2020-12-03 07:23:56,620 [Listener at localhost/33336] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_inprogress_0000000000000000043 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/name_and_edits/current/edits_0000000000000000043-0000000000000000044
2020-12-03 07:23:56,620 [Listener at localhost/33336] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_inprogress_0000000000000000043 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/h6w6YrghvC/TestNameEditsConfigs/dfs/edits/current/edits_0000000000000000043-0000000000000000044
2020-12-03 07:23:56,621 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:56,621 [CacheReplicationMonitor(1399286940)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:56,631 [Listener at localhost/33336] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34934
2020-12-03 07:23:56,633 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,633 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,634 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:56,634 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:56,644 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,644 [Listener at localhost/33336] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:56,646 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2264e43c{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:56,647 [Listener at localhost/33336] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3bec2275{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,648 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40f8f5a8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,648 [Listener at localhost/33336] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58f07f02{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
msx-rc 0
