2020-12-03 07:20:45,512 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=12
Formatting using clusterid: testClusterID
2020-12-03 07:20:46,247 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:46,267 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:46,270 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:46,271 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:46,280 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:46,281 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:46,281 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:46,283 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:46,301 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:46,380 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:46,398 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:46,399 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:46,399 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:46,412 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:46,413 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:46
2020-12-03 07:20:46,418 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:46,418 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:46,420 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:46,421 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:46,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:46,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:46,451 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:46,452 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:46,452 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:46,452 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:46,453 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:46,453 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:46,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:46,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:46,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:46,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:46,455 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:46,499 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:46,500 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:46,500 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:46,500 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:46,519 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:46,520 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:46,520 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:46,520 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:46,526 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:46,527 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:46,527 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:46,528 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:46,535 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:46,539 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:46,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:46,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:46,546 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:46,546 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:46,557 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:46,558 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:46,558 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:46,563 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:46,564 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:46,566 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:46,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:46,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:46,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:46,606 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:46,776 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:46,953 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:47,000 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:47,000 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:47,143 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:47,143 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:47,290 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:47,294 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:47,367 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:20:47,629 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:20:47,630 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:47,659 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:47,707 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@41f69e84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:47,723 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:47,743 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3177ms
2020-12-03 07:20:47,858 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:47,863 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:47,873 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:47,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:47,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:47,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:47,904 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:47,904 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:47,915 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35237
2020-12-03 07:20:47,916 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:47,967 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@571c5681{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:47,971 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d278d2b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:48,278 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34158c08{/,file:///tmp/jetty-localhost-35237-hdfs-_-any-4562519319135996947.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:48,286 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@b7c4869{HTTP/1.1,[http/1.1]}{localhost:35237}
2020-12-03 07:20:48,287 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3721ms
2020-12-03 07:20:48,297 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:48,298 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:48,298 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:48,298 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:48,299 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:48,299 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:48,299 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:48,300 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:48,300 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:48,301 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:48,302 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:48,302 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:48,303 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:48,303 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:48
2020-12-03 07:20:48,303 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:48,304 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,304 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:48,304 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:48,309 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:48,309 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:48,310 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:48,310 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:48,311 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:48,311 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:48,311 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:48,311 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:48,312 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:48,312 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:48,312 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:48,312 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:48,313 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:48,313 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:48,314 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,314 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:48,314 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:48,317 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:48,317 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:48,318 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:48,318 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:48,319 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:48,319 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:48,319 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:48,319 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:48,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:48,321 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:48,322 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:48,322 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:48,322 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:48,322 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:48,322 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:48,322 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,323 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:48,323 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:48,408 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:48,476 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:48,481 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:48,482 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:48,483 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:48,483 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:48,531 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:48,540 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:48,540 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:48,546 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:48,547 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:48,699 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:48,699 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 374 msecs
2020-12-03 07:20:48,933 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:48,974 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:49,004 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:49,307 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34576 to access this namenode/service.
2020-12-03 07:20:49,311 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:49,329 [Listener at 0.0.0.0/34576] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:49,345 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:49,346 [Listener at 0.0.0.0/34576] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:49,346 [Listener at 0.0.0.0/34576] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:49,346 [Listener at 0.0.0.0/34576] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:49,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:49,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:49,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:49,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:49,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:49,351 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:49,385 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:49,385 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:49,388 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34576
2020-12-03 07:20:49,390 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:49,391 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:49,399 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:49,406 [CacheReplicationMonitor(2008463836)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
Formatting using clusterid: testClusterID
2020-12-03 07:20:49,410 [Listener at 0.0.0.0/34576] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:49,411 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:49,412 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:49,412 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:49,413 [Listener at 0.0.0.0/34576] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,414 [Listener at 0.0.0.0/34576] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:49,414 [Listener at 0.0.0.0/34576] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:49,414 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:49,415 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:49
2020-12-03 07:20:49,415 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:49,415 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,416 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:49,416 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:49,432 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:49,432 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:49,433 [Listener at 0.0.0.0/34576] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:49,433 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:49,433 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:49,434 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:49,434 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:49,434 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:49,434 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:49,434 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:49,435 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:49,435 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:49,435 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:49,436 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:49,436 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,437 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:49,437 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:49,444 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:49,445 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:49,445 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:49,445 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:49,446 [Listener at 0.0.0.0/34576] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:49,446 [Listener at 0.0.0.0/34576] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:49,446 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:49,446 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,447 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:49,447 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:49,449 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:49,450 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:49,450 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:49,450 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:49,450 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:49,450 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:49,451 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,451 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:49,451 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:49,454 [Listener at 0.0.0.0/34576] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:49,613 [Listener at 0.0.0.0/34576] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 has been successfully formatted.
2020-12-03 07:20:49,843 [Listener at 0.0.0.0/34576] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 has been successfully formatted.
2020-12-03 07:20:49,855 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:49,857 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:49,860 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:49,863 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:49,964 [Listener at 0.0.0.0/34576] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:49,970 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:49,971 [Listener at 0.0.0.0/34576] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:49,972 [Listener at 0.0.0.0/34576] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:49,992 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@681aad3b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:49,993 [Listener at 0.0.0.0/34576] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:49,996 [Listener at 0.0.0.0/34576] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,001 [Listener at 0.0.0.0/34576] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:50,005 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,006 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:50,006 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,006 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,008 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:50,009 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:50,010 [Listener at 0.0.0.0/34576] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36288
2020-12-03 07:20:50,010 [Listener at 0.0.0.0/34576] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,015 [Listener at 0.0.0.0/34576] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:50,016 [Listener at 0.0.0.0/34576] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56b78e55{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:50,209 [Listener at 0.0.0.0/34576] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13006998{/,file:///tmp/jetty-localhost-36288-hdfs-_-any-8604046084757663897.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:50,211 [Listener at 0.0.0.0/34576] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37fbe4a8{HTTP/1.1,[http/1.1]}{localhost:36288}
2020-12-03 07:20:50,212 [Listener at 0.0.0.0/34576] INFO  server.Server (Server.java:doStart(419)) - Started @5646ms
2020-12-03 07:20:50,216 [Listener at 0.0.0.0/34576] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:50,217 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:50,217 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:50,218 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:50,218 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:50,218 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:50,218 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:50,219 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:50,219 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:50,219 [Listener at 0.0.0.0/34576] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,220 [Listener at 0.0.0.0/34576] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:50,220 [Listener at 0.0.0.0/34576] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:50,221 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:50,221 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:50
2020-12-03 07:20:50,221 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:50,222 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,222 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:50,222 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:50,234 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:50,235 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:50,235 [Listener at 0.0.0.0/34576] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:50,235 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:50,236 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:50,237 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:50,237 [Listener at 0.0.0.0/34576] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:50,238 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:50,238 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,238 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:50,239 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:50,245 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:50,245 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:50,245 [Listener at 0.0.0.0/34576] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:50,246 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:50,246 [Listener at 0.0.0.0/34576] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:50,246 [Listener at 0.0.0.0/34576] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:50,247 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:50,247 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,247 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:50,247 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:50,250 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:50,251 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,251 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:50,251 [Listener at 0.0.0.0/34576] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:50,404 [Listener at 0.0.0.0/34576] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:50,529 [Listener at 0.0.0.0/34576] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:50,533 [Listener at 0.0.0.0/34576] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current
2020-12-03 07:20:50,533 [Listener at 0.0.0.0/34576] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current
2020-12-03 07:20:50,533 [Listener at 0.0.0.0/34576] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:50,534 [Listener at 0.0.0.0/34576] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:50,537 [Listener at 0.0.0.0/34576] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:50,540 [Listener at 0.0.0.0/34576] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:50,540 [Listener at 0.0.0.0/34576] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000
2020-12-03 07:20:50,541 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:50,541 [Listener at 0.0.0.0/34576] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:50,913 [Listener at 0.0.0.0/34576] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:50,913 [Listener at 0.0.0.0/34576] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 660 msecs
2020-12-03 07:20:50,914 [Listener at 0.0.0.0/34576] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:50,915 [Listener at 0.0.0.0/34576] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,917 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,924 [Listener at 0.0.0.0/38547] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38547 to access this namenode/service.
2020-12-03 07:20:50,925 [Listener at 0.0.0.0/38547] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:50,938 [Listener at 0.0.0.0/38547] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:50,940 [Listener at 0.0.0.0/38547] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:50,940 [Listener at 0.0.0.0/38547] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:50,940 [Listener at 0.0.0.0/38547] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:50,941 [Listener at 0.0.0.0/38547] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:50,944 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:50,944 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:50,945 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:50,945 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:50,945 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:50,945 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:50,949 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,949 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,951 [Listener at 0.0.0.0/38547] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38547
2020-12-03 07:20:50,952 [Listener at 0.0.0.0/38547] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:50,952 [Listener at 0.0.0.0/38547] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:50,953 [Listener at 0.0.0.0/38547] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:50,954 [CacheReplicationMonitor(525205097)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:50,965 [Listener at 0.0.0.0/38547] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:51,031 [Listener at 0.0.0.0/38547] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:51,046 [Listener at 0.0.0.0/38547] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:51,346 [Listener at 0.0.0.0/38547] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,352 [Listener at 0.0.0.0/38547] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,356 [Listener at 0.0.0.0/38547] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,361 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,362 [Listener at 0.0.0.0/38547] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,367 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,376 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46323
2020-12-03 07:20:51,378 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,379 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,400 [Listener at 0.0.0.0/38547] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,401 [Listener at 0.0.0.0/38547] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,403 [Listener at 0.0.0.0/38547] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,404 [Listener at 0.0.0.0/38547] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,404 [Listener at 0.0.0.0/38547] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,405 [Listener at 0.0.0.0/38547] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,408 [Listener at 0.0.0.0/38547] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40358
2020-12-03 07:20:51,410 [Listener at 0.0.0.0/38547] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,417 [Listener at 0.0.0.0/38547] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fc08eec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:51,418 [Listener at 0.0.0.0/38547] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b02e036{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:51,829 [Listener at 0.0.0.0/38547] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e27ba81{/,file:///tmp/jetty-localhost-40358-datanode-_-any-1557451435322862409.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,831 [Listener at 0.0.0.0/38547] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{localhost:40358}
2020-12-03 07:20:51,833 [Listener at 0.0.0.0/38547] INFO  server.Server (Server.java:doStart(419)) - Started @7267ms
2020-12-03 07:20:52,330 [Listener at 0.0.0.0/38547] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33712
2020-12-03 07:20:52,330 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61942c1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,332 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,332 [Listener at 0.0.0.0/38547] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,348 [Listener at 0.0.0.0/38547] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,349 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,357 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39467
2020-12-03 07:20:52,373 [Listener at localhost/39467] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,374 [Listener at localhost/39467] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,387 [Thread-100] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:52,388 [Thread-101] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:52,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,395 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,399 [Listener at localhost/39467] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:52,402 [Listener at localhost/39467] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:52,402 [Listener at localhost/39467] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:52,404 [Listener at localhost/39467] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,405 [Listener at localhost/39467] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,405 [Listener at localhost/39467] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,406 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,406 [Listener at localhost/39467] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,406 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,407 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46052
2020-12-03 07:20:52,407 [Listener at localhost/39467] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,407 [Listener at localhost/39467] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,433 [Listener at localhost/39467] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,434 [Listener at localhost/39467] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,436 [Listener at localhost/39467] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,437 [Listener at localhost/39467] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,437 [Listener at localhost/39467] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,437 [Listener at localhost/39467] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,438 [Listener at localhost/39467] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44913
2020-12-03 07:20:52,438 [Listener at localhost/39467] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,441 [Listener at localhost/39467] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@781a9412{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,441 [Listener at localhost/39467] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13e698c7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,618 [Listener at localhost/39467] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@577f9109{/,file:///tmp/jetty-localhost-44913-datanode-_-any-8237434984696029367.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,619 [Listener at localhost/39467] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4303b7f0{HTTP/1.1,[http/1.1]}{localhost:44913}
2020-12-03 07:20:52,619 [Listener at localhost/39467] INFO  server.Server (Server.java:doStart(419)) - Started @8054ms
2020-12-03 07:20:52,651 [Thread-100] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:52,651 [Thread-101] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:52,653 [Thread-101] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,665 [Listener at localhost/39467] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45204
2020-12-03 07:20:52,666 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,666 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@779de014] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,667 [Listener at localhost/39467] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,668 [Listener at localhost/39467] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,669 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,676 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44167
2020-12-03 07:20:52,681 [Listener at localhost/44167] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,682 [Listener at localhost/44167] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,683 [Thread-125] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:52,683 [Thread-126] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:52,685 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,685 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,688 [Thread-126] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:52,688 [Thread-125] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:52,688 [Thread-126] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,689 [Listener at localhost/44167] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:52,690 [Listener at localhost/44167] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:52,691 [Listener at localhost/44167] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:52,692 [Listener at localhost/44167] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,693 [Listener at localhost/44167] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,693 [Listener at localhost/44167] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,694 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,694 [Listener at localhost/44167] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,694 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,695 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37006
2020-12-03 07:20:52,695 [Listener at localhost/44167] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,695 [Listener at localhost/44167] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,698 [Listener at localhost/44167] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,698 [Listener at localhost/44167] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,700 [Listener at localhost/44167] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,701 [Listener at localhost/44167] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,701 [Listener at localhost/44167] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,701 [Listener at localhost/44167] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,702 [Listener at localhost/44167] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35541
2020-12-03 07:20:52,702 [Listener at localhost/44167] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,704 [Listener at localhost/44167] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3068b369{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,705 [Listener at localhost/44167] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5491f68b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,830 [Thread-126] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:52,831 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:52,831 [Thread-126] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:52,831 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:52,834 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:20:52,834 [Thread-126] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:20:52,874 [Listener at localhost/44167] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@648ee871{/,file:///tmp/jetty-localhost-35541-datanode-_-any-7813018176891154927.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,876 [Listener at localhost/44167] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@375b5b7f{HTTP/1.1,[http/1.1]}{localhost:35541}
2020-12-03 07:20:52,876 [Listener at localhost/44167] INFO  server.Server (Server.java:doStart(419)) - Started @8310ms
2020-12-03 07:20:52,895 [Listener at localhost/44167] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33813
2020-12-03 07:20:52,895 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,895 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28cb9120] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,895 [Listener at localhost/44167] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,896 [Listener at localhost/44167] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,896 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,900 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33779
2020-12-03 07:20:52,904 [Listener at localhost/33779] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,904 [Listener at localhost/33779] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,905 [Thread-148] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:52,906 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:52,908 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,908 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,910 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:52,910 [Thread-148] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:52,910 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,911 [Listener at localhost/33779] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:52,912 [Listener at localhost/33779] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:52,912 [Listener at localhost/33779] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:52,914 [Listener at localhost/33779] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,914 [Listener at localhost/33779] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,914 [Listener at localhost/33779] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,915 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,915 [Listener at localhost/33779] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,915 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,916 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46833
2020-12-03 07:20:52,916 [Listener at localhost/33779] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,916 [Listener at localhost/33779] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,919 [Listener at localhost/33779] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,925 [Listener at localhost/33779] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,927 [Listener at localhost/33779] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,928 [Listener at localhost/33779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,928 [Listener at localhost/33779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,929 [Listener at localhost/33779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,929 [Listener at localhost/33779] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37144
2020-12-03 07:20:52,930 [Listener at localhost/33779] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,932 [Listener at localhost/33779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18fdb6cf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,933 [Listener at localhost/33779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60baef24{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,087 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,088 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,091 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-67ab8674-bdb4-4cdd-9773-97d32732c99b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:20:53,124 [Listener at localhost/33779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d7e1102{/,file:///tmp/jetty-localhost-37144-datanode-_-any-3063062208272611347.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,125 [Listener at localhost/33779] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65327f5{HTTP/1.1,[http/1.1]}{localhost:37144}
2020-12-03 07:20:53,126 [Listener at localhost/33779] INFO  server.Server (Server.java:doStart(419)) - Started @8560ms
2020-12-03 07:20:53,175 [Listener at localhost/33779] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44603
2020-12-03 07:20:53,176 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,176 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@301d8120] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,176 [Listener at localhost/33779] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,177 [Listener at localhost/33779] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,178 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,200 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40840
2020-12-03 07:20:53,204 [Listener at localhost/40840] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,204 [Listener at localhost/40840] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,205 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:53,205 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:53,207 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,207 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,214 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:53,214 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:53,214 [Listener at localhost/40840] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:53,214 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,216 [Listener at localhost/40840] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:53,216 [Listener at localhost/40840] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:53,217 [Listener at localhost/40840] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,218 [Listener at localhost/40840] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,218 [Listener at localhost/40840] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,218 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,218 [Listener at localhost/40840] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,219 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,220 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41925
2020-12-03 07:20:53,220 [Listener at localhost/40840] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,220 [Listener at localhost/40840] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,223 [Listener at localhost/40840] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,223 [Listener at localhost/40840] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,225 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,226 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,226 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,226 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,227 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39293
2020-12-03 07:20:53,227 [Listener at localhost/40840] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,229 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29182679{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,229 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cbb84b1{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,417 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7808fb9{/,file:///tmp/jetty-localhost-39293-datanode-_-any-578097175163728484.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,417 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,418 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,421 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fa85ac79-6260-46f5-be7e-0b16362358ad for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:20:53,428 [Listener at localhost/40840] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@773bd77b{HTTP/1.1,[http/1.1]}{localhost:39293}
2020-12-03 07:20:53,429 [Listener at localhost/40840] INFO  server.Server (Server.java:doStart(419)) - Started @8863ms
2020-12-03 07:20:53,443 [Listener at localhost/40840] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34427
2020-12-03 07:20:53,443 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,443 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d91790b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,443 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,444 [Listener at localhost/40840] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,445 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,448 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41861
2020-12-03 07:20:53,453 [Listener at localhost/41861] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,453 [Listener at localhost/41861] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,454 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:53,454 [Thread-195] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:53,457 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,457 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,460 [Thread-195] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:53,461 [Thread-195] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,461 [Listener at localhost/41861] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:53,461 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:53,463 [Listener at localhost/41861] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:53,463 [Listener at localhost/41861] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:53,465 [Listener at localhost/41861] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,465 [Listener at localhost/41861] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,466 [Listener at localhost/41861] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,467 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,467 [Listener at localhost/41861] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,467 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,468 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41176
2020-12-03 07:20:53,468 [Listener at localhost/41861] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,468 [Listener at localhost/41861] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,471 [Listener at localhost/41861] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,472 [Listener at localhost/41861] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,473 [Listener at localhost/41861] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,474 [Listener at localhost/41861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,474 [Listener at localhost/41861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,474 [Listener at localhost/41861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,475 [Listener at localhost/41861] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37316
2020-12-03 07:20:53,475 [Listener at localhost/41861] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,477 [Listener at localhost/41861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a1c0752{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,477 [Listener at localhost/41861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b32cd16{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,670 [Listener at localhost/41861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fedfe27{/,file:///tmp/jetty-localhost-37316-datanode-_-any-3748574838414297652.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,671 [Listener at localhost/41861] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f879bab{HTTP/1.1,[http/1.1]}{localhost:37316}
2020-12-03 07:20:53,671 [Listener at localhost/41861] INFO  server.Server (Server.java:doStart(419)) - Started @9106ms
2020-12-03 07:20:53,685 [Listener at localhost/41861] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32867
2020-12-03 07:20:53,686 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,686 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46c00568] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,686 [Listener at localhost/41861] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,687 [Listener at localhost/41861] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,687 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,691 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35324
2020-12-03 07:20:53,695 [Listener at localhost/35324] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,696 [Listener at localhost/35324] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,696 [Thread-217] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:53,696 [Thread-218] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:53,699 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,700 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,702 [Thread-218] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:53,702 [Thread-217] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:53,702 [Thread-218] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,703 [Listener at localhost/35324] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:53,705 [Listener at localhost/35324] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:53,706 [Listener at localhost/35324] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:53,707 [Listener at localhost/35324] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,707 [Listener at localhost/35324] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,707 [Listener at localhost/35324] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,708 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,708 [Listener at localhost/35324] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,708 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,709 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43583
2020-12-03 07:20:53,709 [Listener at localhost/35324] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,709 [Listener at localhost/35324] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,712 [Listener at localhost/35324] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,712 [Listener at localhost/35324] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,714 [Listener at localhost/35324] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,715 [Listener at localhost/35324] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,715 [Listener at localhost/35324] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,715 [Listener at localhost/35324] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,716 [Listener at localhost/35324] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41403
2020-12-03 07:20:53,716 [Listener at localhost/35324] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,720 [Listener at localhost/35324] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22fba58c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,720 [Listener at localhost/35324] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fe88a09{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,781 [Thread-195] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,781 [Thread-126] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,781 [Thread-195] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,781 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,782 [Thread-126] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,782 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,785 [Thread-195] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 
2020-12-03 07:20:53,785 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6572ee60-04a3-4144-b245-c9434eff49ec for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:20:53,785 [Thread-126] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:20:53,889 [Listener at localhost/35324] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7051777c{/,file:///tmp/jetty-localhost-41403-datanode-_-any-6059858336895164968.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,891 [Listener at localhost/35324] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3241713e{HTTP/1.1,[http/1.1]}{localhost:41403}
2020-12-03 07:20:53,891 [Listener at localhost/35324] INFO  server.Server (Server.java:doStart(419)) - Started @9325ms
2020-12-03 07:20:53,905 [Listener at localhost/35324] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41219
2020-12-03 07:20:53,906 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,906 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@512d4583] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,906 [Listener at localhost/35324] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,906 [Listener at localhost/35324] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,907 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,911 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38559
2020-12-03 07:20:53,916 [Listener at localhost/38559] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,917 [Listener at localhost/38559] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,917 [Thread-240] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:53,920 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:53,922 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,922 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,923 [Thread-241] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:53,923 [Thread-240] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:53,926 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,927 [Listener at localhost/38559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:53,928 [Listener at localhost/38559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:53,928 [Listener at localhost/38559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:53,930 [Listener at localhost/38559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,930 [Listener at localhost/38559] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,930 [Listener at localhost/38559] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,931 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,931 [Listener at localhost/38559] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,931 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,932 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41802
2020-12-03 07:20:53,932 [Listener at localhost/38559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,932 [Listener at localhost/38559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,935 [Listener at localhost/38559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,935 [Listener at localhost/38559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,937 [Listener at localhost/38559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,938 [Listener at localhost/38559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,938 [Listener at localhost/38559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,938 [Listener at localhost/38559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,939 [Listener at localhost/38559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40168
2020-12-03 07:20:53,939 [Listener at localhost/38559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,942 [Listener at localhost/38559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d6aca33{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,942 [Listener at localhost/38559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29314cc9{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,968 [Thread-218] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:53,968 [Thread-218] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:53,968 [Thread-218] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-db90c408-d1ba-40e6-9415-9688e16bc3ed for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 
2020-12-03 07:20:54,113 [Listener at localhost/38559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@273842a6{/,file:///tmp/jetty-localhost-40168-datanode-_-any-6940812473561320538.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:54,115 [Listener at localhost/38559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a969fb8{HTTP/1.1,[http/1.1]}{localhost:40168}
2020-12-03 07:20:54,115 [Listener at localhost/38559] INFO  server.Server (Server.java:doStart(419)) - Started @9550ms
2020-12-03 07:20:54,136 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,136 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:54,136 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,137 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:54,140 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:20:54,140 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-104f9448-35f9-4074-9366-84c2ea93c76d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 
2020-12-03 07:20:54,163 [Listener at localhost/38559] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33607
2020-12-03 07:20:54,164 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:54,164 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3028e50e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:54,164 [Listener at localhost/38559] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:54,164 [Listener at localhost/38559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:54,165 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:54,168 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33863
2020-12-03 07:20:54,174 [Listener at localhost/33863] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:54,174 [Listener at localhost/33863] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:54,175 [Thread-263] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:54,175 [Thread-264] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:54,177 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:54,178 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:54,181 [Thread-264] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:54,181 [Thread-263] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:54,184 [Listener at localhost/33863] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:54,184 [Thread-264] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,186 [Listener at localhost/33863] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:54,186 [Listener at localhost/33863] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:54,188 [Listener at localhost/33863] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:54,189 [Listener at localhost/33863] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,189 [Listener at localhost/33863] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:54,190 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:54,190 [Listener at localhost/33863] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,190 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:54,191 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40633
2020-12-03 07:20:54,191 [Listener at localhost/33863] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:54,191 [Listener at localhost/33863] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:54,194 [Listener at localhost/33863] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:54,195 [Listener at localhost/33863] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:54,197 [Listener at localhost/33863] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:54,197 [Listener at localhost/33863] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:54,197 [Listener at localhost/33863] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:54,198 [Listener at localhost/33863] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:54,198 [Listener at localhost/33863] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33400
2020-12-03 07:20:54,198 [Listener at localhost/33863] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:54,200 [Listener at localhost/33863] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37095ded{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:54,201 [Listener at localhost/33863] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ca6546f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:54,371 [Listener at localhost/33863] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4e8e8621{/,file:///tmp/jetty-localhost-33400-datanode-_-any-3796729874140683924.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:54,372 [Listener at localhost/33863] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c446b14{HTTP/1.1,[http/1.1]}{localhost:33400}
2020-12-03 07:20:54,373 [Listener at localhost/33863] INFO  server.Server (Server.java:doStart(419)) - Started @9807ms
2020-12-03 07:20:54,388 [Listener at localhost/33863] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40839
2020-12-03 07:20:54,389 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4443ef6f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:54,389 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:54,389 [Listener at localhost/33863] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:54,390 [Listener at localhost/33863] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:54,390 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:54,394 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43509
2020-12-03 07:20:54,399 [Listener at localhost/43509] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:54,399 [Listener at localhost/43509] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:54,400 [Thread-286] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:54,400 [Thread-287] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:54,403 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:54,403 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:54,407 [Listener at localhost/43509] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:20:54,408 [Thread-286] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:54,408 [Listener at localhost/43509] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:20:54,408 [Thread-287] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:54,408 [Thread-286] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,409 [Listener at localhost/43509] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:20:54,412 [Listener at localhost/43509] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:54,413 [Listener at localhost/43509] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,413 [Listener at localhost/43509] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:54,413 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:54,414 [Listener at localhost/43509] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,414 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:54,414 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45090
2020-12-03 07:20:54,415 [Listener at localhost/43509] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:54,415 [Listener at localhost/43509] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:54,417 [Listener at localhost/43509] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:54,418 [Listener at localhost/43509] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:54,419 [Listener at localhost/43509] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:54,420 [Listener at localhost/43509] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:54,420 [Listener at localhost/43509] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:54,420 [Listener at localhost/43509] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:54,421 [Listener at localhost/43509] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35824
2020-12-03 07:20:54,421 [Listener at localhost/43509] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:54,423 [Listener at localhost/43509] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76954a33{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:54,423 [Listener at localhost/43509] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@982bb90{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:54,513 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,513 [Thread-264] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,513 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:54,514 [Thread-264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:54,517 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:20:54,517 [Thread-264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-490263f6-b489-4d85-8d6d-619abd0eb77c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 
2020-12-03 07:20:54,525 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,525 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,525 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,525 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,526 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:54,526 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:54,526 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:54,526 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:54,595 [Listener at localhost/43509] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5c92166b{/,file:///tmp/jetty-localhost-35824-datanode-_-any-3407068555077947386.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:54,595 [Listener at localhost/43509] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@659925f4{HTTP/1.1,[http/1.1]}{localhost:35824}
2020-12-03 07:20:54,596 [Listener at localhost/43509] INFO  server.Server (Server.java:doStart(419)) - Started @10031ms
2020-12-03 07:20:54,611 [Listener at localhost/43509] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38133
2020-12-03 07:20:54,611 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:54,611 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47f08b81] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:54,611 [Listener at localhost/43509] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:54,612 [Listener at localhost/43509] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:54,612 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:54,616 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42208
2020-12-03 07:20:54,621 [Listener at localhost/42208] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:54,622 [Listener at localhost/42208] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:54,623 [Thread-309] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:54,623 [Thread-310] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:54,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:54,628 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:54,632 [Thread-309] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:54,632 [Thread-310] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:54,632 [Thread-309] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,633 [Listener at localhost/42208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:54,634 [Listener at localhost/42208] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:54,634 [Listener at localhost/42208] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:54,636 [Listener at localhost/42208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:54,636 [Listener at localhost/42208] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,636 [Listener at localhost/42208] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:54,637 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:54,637 [Listener at localhost/42208] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,637 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:54,638 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42779
2020-12-03 07:20:54,638 [Listener at localhost/42208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:54,638 [Listener at localhost/42208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:54,640 [Listener at localhost/42208] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:54,641 [Listener at localhost/42208] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:54,643 [Listener at localhost/42208] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:54,643 [Listener at localhost/42208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:54,643 [Listener at localhost/42208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:54,643 [Listener at localhost/42208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:54,644 [Listener at localhost/42208] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39606
2020-12-03 07:20:54,644 [Listener at localhost/42208] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:54,645 [Listener at localhost/42208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f404594{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:54,646 [Listener at localhost/42208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b2a3ff8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:54,724 [Thread-286] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,725 [Thread-286] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:54,729 [Thread-286] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 
2020-12-03 07:20:54,812 [Listener at localhost/42208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a9486c0{/,file:///tmp/jetty-localhost-39606-datanode-_-any-1482170218862577002.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:54,813 [Listener at localhost/42208] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c27d39d{HTTP/1.1,[http/1.1]}{localhost:39606}
2020-12-03 07:20:54,814 [Listener at localhost/42208] INFO  server.Server (Server.java:doStart(419)) - Started @10249ms
2020-12-03 07:20:54,833 [Listener at localhost/42208] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41808
2020-12-03 07:20:54,833 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:54,833 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bde1f3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:54,833 [Listener at localhost/42208] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:54,834 [Listener at localhost/42208] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:54,835 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:54,838 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41616
2020-12-03 07:20:54,846 [Listener at localhost/41616] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:54,846 [Listener at localhost/41616] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:54,848 [Thread-332] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:54,848 [Thread-333] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:54,850 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:54,850 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:54,854 [Thread-332] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:54,854 [Thread-333] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:54,855 [Thread-332] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,855 [Listener at localhost/41616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 11 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:20:54,856 [Listener at localhost/41616] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:20:54,857 [Listener at localhost/41616] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:20:54,858 [Listener at localhost/41616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:54,859 [Listener at localhost/41616] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,859 [Listener at localhost/41616] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:54,859 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:54,859 [Listener at localhost/41616] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:54,859 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:54,860 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46683
2020-12-03 07:20:54,860 [Listener at localhost/41616] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:54,860 [Listener at localhost/41616] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:54,863 [Listener at localhost/41616] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:54,863 [Listener at localhost/41616] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:54,865 [Listener at localhost/41616] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:54,866 [Listener at localhost/41616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:54,866 [Listener at localhost/41616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:54,866 [Listener at localhost/41616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:54,867 [Listener at localhost/41616] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35163
2020-12-03 07:20:54,867 [Listener at localhost/41616] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:54,868 [Listener at localhost/41616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55b8dbda{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:54,869 [Listener at localhost/41616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a022576{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:54,932 [Thread-309] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,933 [Thread-309] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:54,938 [Thread-309] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 
2020-12-03 07:20:54,938 [Thread-195] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:54,939 [Thread-195] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:54,939 [Thread-195] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a0294ff5-4792-4f07-9e75-bc48981f9647 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 
2020-12-03 07:20:54,955 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,955 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:54,956 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:54,956 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,040 [Listener at localhost/41616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55cff952{/,file:///tmp/jetty-localhost-35163-datanode-_-any-7083700292714875357.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:55,040 [Listener at localhost/41616] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@660591fb{HTTP/1.1,[http/1.1]}{localhost:35163}
2020-12-03 07:20:55,042 [Listener at localhost/41616] INFO  server.Server (Server.java:doStart(419)) - Started @10476ms
2020-12-03 07:20:55,062 [Listener at localhost/41616] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38472
2020-12-03 07:20:55,063 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8c46918] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:55,063 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:55,063 [Listener at localhost/41616] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:55,064 [Listener at localhost/41616] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:55,065 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:55,069 [Listener at localhost/40957] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40957
2020-12-03 07:20:55,076 [Listener at localhost/40957] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:55,076 [Listener at localhost/40957] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:55,077 [Thread-355] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576 starting to offer service
2020-12-03 07:20:55,079 [Thread-356] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547 starting to offer service
2020-12-03 07:20:55,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:55,081 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:55,084 [Thread-355] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34576
2020-12-03 07:20:55,085 [Thread-355] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:55,085 [Thread-356] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38547
2020-12-03 07:20:55,117 [Thread-218] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,118 [Thread-332] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,118 [Thread-218] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:55,118 [Thread-332] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:55,122 [Thread-332] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 
2020-12-03 07:20:55,122 [Thread-218] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 
2020-12-03 07:20:55,317 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,317 [Thread-355] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,317 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:55,317 [Thread-355] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:55,322 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-87660179-8c87-4ea8-9e15-12fc6f176a8d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 
2020-12-03 07:20:55,322 [Thread-355] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-48c74591-6525-4cf5-bf14-26e1e18997ab for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 
2020-12-03 07:20:55,327 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,328 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,328 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,328 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,328 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,328 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,328 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,328 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,337 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,337 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,338 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,338 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,539 [IPC Server handler 0 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,547 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,548 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,651 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,652 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,652 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,703 [Thread-264] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,703 [Thread-264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 is not formatted for namespace 1592339003. Formatting...
2020-12-03 07:20:55,709 [Thread-264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9fb619af-536d-4526-8e85-573d79f09dda for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 
2020-12-03 07:20:55,714 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,714 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,715 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,715 [Thread-195] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,715 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,715 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,715 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,715 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,755 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,755 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,756 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,858 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,859 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,859 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,910 [Thread-286] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:55,910 [Thread-286] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:55,916 [Thread-286] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 
2020-12-03 07:20:55,922 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,923 [Thread-218] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:55,923 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:55,923 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:55,962 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,963 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,963 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,066 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,066 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,067 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,096 [Thread-309] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:56,099 [Thread-100] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:56,099 [Thread-101] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:56,100 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:20:56,100 [Thread-125] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:56,100 [Thread-309] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:56,100 [Thread-125] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:20:56,100 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:20:56,100 [Thread-125] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:20:56,102 [Thread-126] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:56,102 [Thread-309] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-07835acc-9771-4b47-ae0d-18b8fa630194 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 
2020-12-03 07:20:56,111 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,111 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,111 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:56,112 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:56,112 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,112 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,112 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,112 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,112 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,112 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,112 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:56,113 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:56,113 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:56,113 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:56,113 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:56,113 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:56,169 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,170 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,170 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,273 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,274 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,274 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,376 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,376 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,377 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,404 [Thread-332] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:56,404 [Thread-332] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:56,411 [Thread-332] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 
2020-12-03 07:20:56,479 [IPC Server handler 0 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,480 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,480 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,582 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,583 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,583 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,617 [Thread-355] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/in_use.lock acquired by nodename 2414@b120fe239ee9
2020-12-03 07:20:56,618 [Thread-355] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 is not formatted for namespace 1155480158. Formatting...
2020-12-03 07:20:56,618 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:56,624 [Thread-355] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9ea86b1a-04b1-421c-a202-657e276c1da5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 
2020-12-03 07:20:56,628 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,628 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,628 [Thread-264] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,628 [Thread-195] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,628 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:56,629 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:56,629 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:56,629 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:56,686 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,686 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,687 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,789 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,790 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,790 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,875 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,875 [Thread-286] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:56,876 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:56,876 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:56,876 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,877 [Thread-218] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:56,877 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:56,877 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:56,892 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,893 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,893 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,996 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,997 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,997 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,106 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,107 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,106 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:57,108 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,109 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,108 [Thread-171] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:20:57,109 [Thread-171] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:20:57,119 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:57,120 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,120 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:57,120 [Thread-309] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,120 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,120 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,120 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,120 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:57,120 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,120 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,121 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,121 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,120 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:57,121 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,121 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,121 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,123 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,123 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,123 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,124 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,210 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,211 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,211 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,312 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,313 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,313 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,361 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,362 [Thread-332] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,362 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,362 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,415 [IPC Server handler 0 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,416 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,416 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,517 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,518 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,519 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,575 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:57,577 [Thread-148] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,577 [Thread-148] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:20:57,577 [Thread-148] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:20:57,578 [Thread-195] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:57,579 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,579 [Thread-194] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 has already been used.
2020-12-03 07:20:57,579 [Thread-194] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 has already been used.
2020-12-03 07:20:57,589 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:57,589 [Thread-264] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:57,589 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:57,589 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:57,590 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,590 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,591 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,591 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,591 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,591 [Thread-355] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,591 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,592 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,592 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,592 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,592 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,592 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,620 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,621 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,621 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,722 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,723 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,723 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,824 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,825 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,825 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,898 [Thread-218] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:57,899 [Thread-217] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,900 [Thread-217] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 has already been used.
2020-12-03 07:20:57,901 [Thread-217] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 has already been used.
2020-12-03 07:20:57,927 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,927 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,927 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,930 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,931 [Thread-286] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,931 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,931 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:57,931 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,932 [Thread-217] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:57,932 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:57,932 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,029 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,030 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,030 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,067 [Thread-125] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:58,068 [Thread-100] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:58,068 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:58,077 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,077 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,077 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,078 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,081 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,081 [Thread-309] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,082 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,082 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,131 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,132 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,132 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,234 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,234 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,235 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,284 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,284 [Thread-332] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,285 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,285 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,336 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,337 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,337 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,439 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,440 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,440 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,492 [Thread-264] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:20:58,493 [Thread-263] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:58,493 [Thread-263] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 has already been used.
2020-12-03 07:20:58,493 [Thread-263] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 has already been used.
2020-12-03 07:20:58,504 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,504 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,504 [Thread-263] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,504 [Thread-355] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,505 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,505 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,505 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,505 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,506 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,506 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,506 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,506 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,507 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,507 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,507 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,507 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,541 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,542 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,542 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,643 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,644 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,644 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,746 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,746 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,747 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,750 [Thread-286] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:58,760 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,761 [Thread-217] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:58,761 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:58,761 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:58,848 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,849 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,849 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,950 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,951 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,951 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,958 [Thread-126] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:58,960 [Thread-310] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:58,958 [Thread-101] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:58,958 [Thread-241] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:20:58,958 [Thread-309] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:58,960 [Thread-310] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 has already been used.
2020-12-03 07:20:58,960 [Thread-310] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 has already been used.
2020-12-03 07:20:58,960 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:58,970 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:58,971 [Thread-310] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:58,971 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:58,971 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:59,053 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,053 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,054 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,083 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58
2020-12-03 07:20:59,085 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:59,083 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f
2020-12-03 07:20:59,083 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-104f9448-35f9-4074-9366-84c2ea93c76d
2020-12-03 07:20:59,086 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:59,086 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:59,087 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6572ee60-04a3-4144-b245-c9434eff49ec
2020-12-03 07:20:59,087 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:59,089 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-87660179-8c87-4ea8-9e15-12fc6f176a8d
2020-12-03 07:20:59,090 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:59,091 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43
2020-12-03 07:20:59,092 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:59,098 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,098 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,099 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,105 [Thread-126] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,105 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,108 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,109 [Thread-100] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,109 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:59,109 [Thread-240] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:59,110 [Thread-240] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 has already been used.
2020-12-03 07:20:59,110 [Thread-240] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 has already been used.
2020-12-03 07:20:59,111 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:59,112 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:59,124 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,125 [Thread-126] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,126 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:59,125 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,129 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,129 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:59,129 [Thread-126] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,129 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,130 [Thread-126] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,129 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:59,129 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,131 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,130 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,131 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,131 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,132 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,132 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:59,132 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:59,141 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,141 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,141 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,142 [Thread-240] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,142 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:59,142 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:59,155 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,156 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,156 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,182 [Thread-332] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:59,206 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 94ms
2020-12-03 07:20:59,206 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 65ms
2020-12-03 07:20:59,206 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 94ms
2020-12-03 07:20:59,206 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 65ms
2020-12-03 07:20:59,213 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 103ms
2020-12-03 07:20:59,213 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 81ms
2020-12-03 07:20:59,213 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 81ms
2020-12-03 07:20:59,216 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 84ms
2020-12-03 07:20:59,216 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 84ms
2020-12-03 07:20:59,217 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:59,217 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:59,217 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:59,218 [Thread-391] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,218 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,220 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:59,220 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:59,220 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,218 [Thread-394] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,221 [Thread-395] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,218 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:59,218 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:59,221 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:20:59,220 [Thread-389] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,220 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:59,221 [Thread-397] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,220 [Thread-390] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,221 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:20:59,221 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:20:59,223 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 2ms
2020-12-03 07:20:59,222 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:20:59,223 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 7ms
2020-12-03 07:20:59,223 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 7ms
2020-12-03 07:20:59,224 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 4ms
2020-12-03 07:20:59,225 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 8ms
2020-12-03 07:20:59,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,229 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:59,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-104f9448-35f9-4074-9366-84c2ea93c76d): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-87660179-8c87-4ea8-9e15-12fc6f176a8d): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-6572ee60-04a3-4144-b245-c9434eff49ec): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,262 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,264 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,264 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,277 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 56ms
2020-12-03 07:20:59,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:20:59,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:20:59,278 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 58ms
2020-12-03 07:20:59,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:20:59,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-6572ee60-04a3-4144-b245-c9434eff49ec): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:20:59,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-87660179-8c87-4ea8-9e15-12fc6f176a8d): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:20:59,278 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 62ms
2020-12-03 07:20:59,279 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-104f9448-35f9-4074-9366-84c2ea93c76d): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:20:59,279 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 62ms
2020-12-03 07:20:59,279 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:59,280 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,280 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:59,280 [Thread-407] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,280 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:59,280 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:59,280 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 59ms
2020-12-03 07:20:59,281 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:20:59,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:59,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:59,281 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 65ms
2020-12-03 07:20:59,282 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,282 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,282 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:59,282 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:59,282 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:20:59,283 [Thread-100] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:11 PM with interval of 21600000ms
2020-12-03 07:20:59,282 [Thread-408] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,282 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:20:59,282 [Thread-409] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,284 [Thread-125] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:11 PM with interval of 21600000ms
2020-12-03 07:20:59,287 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 5ms
2020-12-03 07:20:59,287 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 5ms
2020-12-03 07:20:59,287 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 6ms
2020-12-03 07:20:59,288 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:59,288 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:59,288 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-6572ee60-04a3-4144-b245-c9434eff49ec): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,288 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,289 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-6572ee60-04a3-4144-b245-c9434eff49ec): no suitable block pools found to scan.  Waiting 1814399939 ms.
2020-12-03 07:20:59,289 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58): no suitable block pools found to scan.  Waiting 1814399939 ms.
2020-12-03 07:20:59,297 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:20:59,297 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:20:59,297 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:20:59,297 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:20:59,309 [IPC Server handler 0 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,309 [IPC Server handler 1 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,311 [IPC Server handler 1 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46052
2020-12-03 07:20:59,311 [IPC Server handler 0 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46323
2020-12-03 07:20:59,311 [IPC Server handler 1 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4e29ef4e-84c8-49b4-899e-3aaf799ac135 (127.0.0.1:46052).
2020-12-03 07:20:59,311 [IPC Server handler 0 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bbd9e0a-d2fa-46bd-8418-9e16bd434905 (127.0.0.1:46323).
2020-12-03 07:20:59,314 [IPC Server handler 2 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,314 [IPC Server handler 2 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,314 [IPC Server handler 2 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46052
2020-12-03 07:20:59,315 [IPC Server handler 2 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46323
2020-12-03 07:20:59,315 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4e29ef4e-84c8-49b4-899e-3aaf799ac135 (127.0.0.1:46052).
2020-12-03 07:20:59,315 [IPC Server handler 2 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9bbd9e0a-d2fa-46bd-8418-9e16bd434905 (127.0.0.1:46323).
2020-12-03 07:20:59,318 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:20:59,318 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:20:59,318 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:20:59,318 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:20:59,318 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,318 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,318 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,318 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,341 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f for DN 127.0.0.1:46052
2020-12-03 07:20:59,341 [IPC Server handler 3 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f for DN 127.0.0.1:46052
2020-12-03 07:20:59,343 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 for DN 127.0.0.1:46052
2020-12-03 07:20:59,343 [IPC Server handler 3 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 for DN 127.0.0.1:46052
2020-12-03 07:20:59,349 [IPC Server handler 5 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 for DN 127.0.0.1:46323
2020-12-03 07:20:59,349 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 for DN 127.0.0.1:46323
2020-12-03 07:20:59,349 [IPC Server handler 5 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6572ee60-04a3-4144-b245-c9434eff49ec for DN 127.0.0.1:46323
2020-12-03 07:20:59,351 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6572ee60-04a3-4144-b245-c9434eff49ec for DN 127.0.0.1:46323
2020-12-03 07:20:59,367 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,374 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,375 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,384 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x18b3a09104d3feac: Processing first storage report for DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 from datanode 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,384 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44937111dfe8766f: Processing first storage report for DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 from datanode 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44937111dfe8766f: from storage DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 node DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x18b3a09104d3feac: from storage DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43 node DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc3282eeb23865b63: Processing first storage report for DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 from datanode 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x88fd9c754e01be87: Processing first storage report for DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 from datanode 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc3282eeb23865b63: from storage DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 node DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,387 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x88fd9c754e01be87: from storage DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58 node DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44937111dfe8766f: Processing first storage report for DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f from datanode 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x18b3a09104d3feac: Processing first storage report for DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f from datanode 4e29ef4e-84c8-49b4-899e-3aaf799ac135
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44937111dfe8766f: from storage DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f node DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x18b3a09104d3feac: from storage DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f node DatanodeRegistration(127.0.0.1:46052, datanodeUuid=4e29ef4e-84c8-49b4-899e-3aaf799ac135, infoPort=45204, infoSecurePort=0, ipcPort=44167, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc3282eeb23865b63: Processing first storage report for DS-6572ee60-04a3-4144-b245-c9434eff49ec from datanode 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x88fd9c754e01be87: Processing first storage report for DS-6572ee60-04a3-4144-b245-c9434eff49ec from datanode 9bbd9e0a-d2fa-46bd-8418-9e16bd434905
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc3282eeb23865b63: from storage DS-6572ee60-04a3-4144-b245-c9434eff49ec node DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,388 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x88fd9c754e01be87: from storage DS-6572ee60-04a3-4144-b245-c9434eff49ec node DatanodeRegistration(127.0.0.1:46323, datanodeUuid=9bbd9e0a-d2fa-46bd-8418-9e16bd434905, infoPort=33712, infoSecurePort=0, ipcPort=39467, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,412 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x44937111dfe8766f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,412 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x18b3a09104d3feac,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,412 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,412 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc3282eeb23865b63,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,412 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x88fd9c754e01be87,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,412 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,412 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,412 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,419 [Thread-148] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,419 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:59,420 [Thread-355] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:59,421 [Thread-356] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:59,425 [Thread-356] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 has already been used.
2020-12-03 07:20:59,425 [Thread-356] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 has already been used.
2020-12-03 07:20:59,427 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-67ab8674-bdb4-4cdd-9773-97d32732c99b
2020-12-03 07:20:59,427 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:59,430 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8
2020-12-03 07:20:59,430 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:59,431 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,432 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:59,432 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,433 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:59,433 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:59,433 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:59,434 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:59,434 [Thread-415] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:59,437 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,443 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,443 [Thread-263] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,443 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:59,444 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:59,444 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,444 [Thread-356] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,444 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:59,444 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:59,476 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,478 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,478 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,483 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 50ms
2020-12-03 07:20:59,483 [Thread-415] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 49ms
2020-12-03 07:20:59,485 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 53ms
2020-12-03 07:20:59,489 [Thread-419] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:59,489 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:59,489 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:59,489 [Thread-418] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,490 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:20:59,495 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:59,496 [Thread-420] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,496 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:20:59,497 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 12ms
2020-12-03 07:20:59,498 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:59,498 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:59,498 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-67ab8674-bdb4-4cdd-9773-97d32732c99b): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,499 [Thread-148] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:15 AM with interval of 21600000ms
2020-12-03 07:20:59,498 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,500 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:20:59,502 [IPC Server handler 9 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,502 [IPC Server handler 9 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37006
2020-12-03 07:20:59,503 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7e442781-5b97-4945-8d62-c89aed5f8563 (127.0.0.1:37006).
2020-12-03 07:20:59,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:20:59,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-67ab8674-bdb4-4cdd-9773-97d32732c99b): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:20:59,503 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:20:59,504 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,511 [IPC Server handler 1 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-67ab8674-bdb4-4cdd-9773-97d32732c99b for DN 127.0.0.1:37006
2020-12-03 07:20:59,511 [IPC Server handler 1 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 for DN 127.0.0.1:37006
2020-12-03 07:20:59,534 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 45ms
2020-12-03 07:20:59,537 [Thread-419] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 48ms
2020-12-03 07:20:59,537 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 52ms
2020-12-03 07:20:59,538 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:59,538 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:59,538 [Thread-427] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,538 [Thread-428] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,538 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:20:59,538 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:20:59,539 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 1ms
2020-12-03 07:20:59,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:59,539 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:20:59,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:59,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-67ab8674-bdb4-4cdd-9773-97d32732c99b): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-67ab8674-bdb4-4cdd-9773-97d32732c99b): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:20:59,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:20:59,540 [IPC Server handler 9 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc9fb055839bc60: Processing first storage report for DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 from datanode 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,541 [IPC Server handler 9 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37006
2020-12-03 07:20:59,541 [IPC Server handler 9 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7e442781-5b97-4945-8d62-c89aed5f8563 (127.0.0.1:37006).
2020-12-03 07:20:59,541 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc9fb055839bc60: from storage DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 node DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,541 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc9fb055839bc60: Processing first storage report for DS-67ab8674-bdb4-4cdd-9773-97d32732c99b from datanode 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,541 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc9fb055839bc60: from storage DS-67ab8674-bdb4-4cdd-9773-97d32732c99b node DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,542 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:20:59,542 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdc9fb055839bc60,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 25 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,542 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,542 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,544 [IPC Server handler 8 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-67ab8674-bdb4-4cdd-9773-97d32732c99b for DN 127.0.0.1:37006
2020-12-03 07:20:59,545 [IPC Server handler 8 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 for DN 127.0.0.1:37006
2020-12-03 07:20:59,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf7580648fd857a1f: Processing first storage report for DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 from datanode 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf7580648fd857a1f: from storage DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8 node DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,548 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf7580648fd857a1f: Processing first storage report for DS-67ab8674-bdb4-4cdd-9773-97d32732c99b from datanode 7e442781-5b97-4945-8d62-c89aed5f8563
2020-12-03 07:20:59,548 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf7580648fd857a1f: from storage DS-67ab8674-bdb4-4cdd-9773-97d32732c99b node DatanodeRegistration(127.0.0.1:37006, datanodeUuid=7e442781-5b97-4945-8d62-c89aed5f8563, infoPort=33813, infoSecurePort=0, ipcPort=33779, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,549 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf7580648fd857a1f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,550 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,579 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,580 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,581 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,616 [Thread-286] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:20:59,616 [Thread-217] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:20:59,619 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68
2020-12-03 07:20:59,619 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:59,626 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186
2020-12-03 07:20:59,627 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:59,628 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,630 [Thread-286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,630 [Thread-287] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:59,630 [Thread-287] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 has already been used.
2020-12-03 07:20:59,630 [Thread-287] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 has already been used.
2020-12-03 07:20:59,631 [Thread-286] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,632 [Thread-286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,632 [Thread-286] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,632 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,633 [Thread-431] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,633 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,640 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,640 [Thread-287] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,640 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:59,640 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:59,678 [Thread-431] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 45ms
2020-12-03 07:20:59,678 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 45ms
2020-12-03 07:20:59,678 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 46ms
2020-12-03 07:20:59,678 [Thread-435] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,679 [Thread-436] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,679 [Thread-435] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,679 [Thread-436] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,679 [Thread-435] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:20:59,679 [Thread-436] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 0ms
2020-12-03 07:20:59,679 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 1ms
2020-12-03 07:20:59,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,681 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:59,681 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:59,682 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,683 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,683 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,785 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,787 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,787 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,794 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,797 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fa85ac79-6260-46f5-be7e-0b16362358ad
2020-12-03 07:20:59,799 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:59,801 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da77b6e3-0a04-44ed-9c23-09d41dd64822
2020-12-03 07:20:59,802 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:59,802 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,804 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:59,804 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,805 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:59,807 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:59,807 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:59,807 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:59,807 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,808 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:59,808 [Thread-310] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,808 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,808 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:59,808 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:59,808 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,809 [Thread-240] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,809 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 and block pool id BP-1319985285-172.17.0.8-1606980046593 is not formatted. Formatting ...
2020-12-03 07:20:59,809 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1319985285-172.17.0.8-1606980046593 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1319985285-172.17.0.8-1606980046593/current
2020-12-03 07:20:59,845 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 38ms
2020-12-03 07:20:59,846 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 39ms
2020-12-03 07:20:59,846 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 42ms
2020-12-03 07:20:59,847 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:59,847 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:59,847 [Thread-443] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,847 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:59,852 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:59,852 [Thread-445] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,852 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 5ms
2020-12-03 07:20:59,853 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:59,853 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 7ms
2020-12-03 07:20:59,854 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:59,854 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:59,855 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-da77b6e3-0a04-44ed-9c23-09d41dd64822): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,855 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-fa85ac79-6260-46f5-be7e-0b16362358ad): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,855 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:09 AM with interval of 21600000ms
2020-12-03 07:20:59,856 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-fa85ac79-6260-46f5-be7e-0b16362358ad): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:59,856 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-da77b6e3-0a04-44ed-9c23-09d41dd64822): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:59,856 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:20:59,858 [IPC Server handler 4 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,858 [IPC Server handler 4 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46833
2020-12-03 07:20:59,858 [IPC Server handler 4 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a08005a9-751b-49d1-97e1-da4735e0e8c0 (127.0.0.1:46833).
2020-12-03 07:20:59,859 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:20:59,859 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,867 [IPC Server handler 6 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa85ac79-6260-46f5-be7e-0b16362358ad for DN 127.0.0.1:46833
2020-12-03 07:20:59,868 [IPC Server handler 6 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 for DN 127.0.0.1:46833
2020-12-03 07:20:59,888 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,890 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,890 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,894 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 42ms
2020-12-03 07:20:59,897 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 50ms
2020-12-03 07:20:59,898 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 52ms
2020-12-03 07:20:59,899 [Thread-452] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:59,903 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:59,904 [Thread-453] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,904 [Thread-452] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:20:59,908 [Thread-452] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 8ms
2020-12-03 07:20:59,908 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 5ms
2020-12-03 07:20:59,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xca2dc67a4cc394ab: Processing first storage report for DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 from datanode a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,908 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 10ms
2020-12-03 07:20:59,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xca2dc67a4cc394ab: from storage DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 node DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xca2dc67a4cc394ab: Processing first storage report for DS-fa85ac79-6260-46f5-be7e-0b16362358ad from datanode a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,908 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:59,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xca2dc67a4cc394ab: from storage DS-fa85ac79-6260-46f5-be7e-0b16362358ad node DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,908 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:59,909 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-da77b6e3-0a04-44ed-9c23-09d41dd64822): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,909 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-fa85ac79-6260-46f5-be7e-0b16362358ad): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,909 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-da77b6e3-0a04-44ed-9c23-09d41dd64822): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:20:59,910 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-fa85ac79-6260-46f5-be7e-0b16362358ad): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:20:59,909 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:20:59,909 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xca2dc67a4cc394ab,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 30 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,911 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,913 [IPC Server handler 0 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,913 [IPC Server handler 0 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46833
2020-12-03 07:20:59,913 [IPC Server handler 0 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a08005a9-751b-49d1-97e1-da4735e0e8c0 (127.0.0.1:46833).
2020-12-03 07:20:59,914 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:20:59,914 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,918 [IPC Server handler 2 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa85ac79-6260-46f5-be7e-0b16362358ad for DN 127.0.0.1:46833
2020-12-03 07:20:59,918 [IPC Server handler 2 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 for DN 127.0.0.1:46833
2020-12-03 07:20:59,921 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x919b3e90c267391d: Processing first storage report for DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 from datanode a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,921 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x919b3e90c267391d: from storage DS-da77b6e3-0a04-44ed-9c23-09d41dd64822 node DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x919b3e90c267391d: Processing first storage report for DS-fa85ac79-6260-46f5-be7e-0b16362358ad from datanode a08005a9-751b-49d1-97e1-da4735e0e8c0
2020-12-03 07:20:59,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x919b3e90c267391d: from storage DS-fa85ac79-6260-46f5-be7e-0b16362358ad node DatanodeRegistration(127.0.0.1:46833, datanodeUuid=a08005a9-751b-49d1-97e1-da4735e0e8c0, infoPort=44603, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,923 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x919b3e90c267391d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,923 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,939 [Thread-332] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:20:59,942 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d
2020-12-03 07:20:59,942 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:20:59,943 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa
2020-12-03 07:20:59,943 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:20:59,944 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,945 [Thread-332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:59,946 [Thread-332] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:59,946 [Thread-332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:59,946 [Thread-332] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:59,946 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,947 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:20:59,947 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:20:59,949 [Thread-333] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:59,951 [Thread-333] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 has already been used.
2020-12-03 07:20:59,951 [Thread-333] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 has already been used.
2020-12-03 07:20:59,966 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,966 [Thread-333] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:20:59,967 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:20:59,967 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:20:59,985 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 38ms
2020-12-03 07:20:59,988 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 41ms
2020-12-03 07:20:59,988 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 42ms
2020-12-03 07:20:59,989 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:20:59,989 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:20:59,989 [Thread-460] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,989 [Thread-461] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:20:59,989 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 0ms
2020-12-03 07:20:59,989 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 0ms
2020-12-03 07:20:59,991 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 2ms
2020-12-03 07:20:59,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:59,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:59,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:20:59,992 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:59,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:59,993 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,993 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,095 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,096 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,096 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,151 [Thread-263] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=null
2020-12-03 07:21:00,151 [Thread-195] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,157 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4a73e00-fa69-476c-b811-e9e0c3e42855
2020-12-03 07:21:00,158 [Thread-195] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:21:00,160 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a0294ff5-4792-4f07-9e75-bc48981f9647
2020-12-03 07:21:00,160 [Thread-195] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:21:00,163 [Thread-195] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:00,163 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,163 [Thread-356] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,163 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:21:00,164 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:21:00,164 [Thread-195] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:21:00,164 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,165 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:21:00,165 [Thread-195] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:21:00,165 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:21:00,165 [Thread-195] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:21:00,165 [Thread-195] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:21:00,167 [Thread-195] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,198 [IPC Server handler 0 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,199 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,199 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,202 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 37ms
2020-12-03 07:21:00,202 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 37ms
2020-12-03 07:21:00,202 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 38ms
2020-12-03 07:21:00,203 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:21:00,203 [Thread-469] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:21:00,203 [Thread-468] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,203 [Thread-470] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:21:00,203 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:21:00,204 [Thread-470] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,204 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:21:00,204 [Thread-470] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:21:00,204 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 1ms
2020-12-03 07:21:00,206 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:21:00,206 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:21:00,206 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:46 AM with interval of 21600000ms
2020-12-03 07:21:00,206 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-f4a73e00-fa69-476c-b811-e9e0c3e42855): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,206 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-a0294ff5-4792-4f07-9e75-bc48981f9647): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,207 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:00,208 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-a0294ff5-4792-4f07-9e75-bc48981f9647): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:00,208 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-f4a73e00-fa69-476c-b811-e9e0c3e42855): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:00,209 [IPC Server handler 2 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,209 [IPC Server handler 2 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41925
2020-12-03 07:21:00,209 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7 (127.0.0.1:41925).
2020-12-03 07:21:00,210 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:00,210 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,213 [IPC Server handler 3 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 for DN 127.0.0.1:41925
2020-12-03 07:21:00,213 [IPC Server handler 3 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a0294ff5-4792-4f07-9e75-bc48981f9647 for DN 127.0.0.1:41925
2020-12-03 07:21:00,242 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 38ms
2020-12-03 07:21:00,244 [Thread-469] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 41ms
2020-12-03 07:21:00,244 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 41ms
2020-12-03 07:21:00,245 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:21:00,245 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:21:00,245 [Thread-477] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,245 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,245 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 0ms
2020-12-03 07:21:00,245 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 0ms
2020-12-03 07:21:00,246 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:21:00,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:21:00,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:21:00,246 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:00,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-a0294ff5-4792-4f07-9e75-bc48981f9647): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-f4a73e00-fa69-476c-b811-e9e0c3e42855): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-a0294ff5-4792-4f07-9e75-bc48981f9647): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:21:00,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-f4a73e00-fa69-476c-b811-e9e0c3e42855): no suitable block pools found to scan.  Waiting 1814399959 ms.
2020-12-03 07:21:00,247 [IPC Server handler 4 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,248 [IPC Server handler 4 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41925
2020-12-03 07:21:00,248 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7 (127.0.0.1:41925).
2020-12-03 07:21:00,249 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:00,249 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,249 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66766bc13fee9b5e: Processing first storage report for DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 from datanode 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,249 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66766bc13fee9b5e: from storage DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,249 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66766bc13fee9b5e: Processing first storage report for DS-a0294ff5-4792-4f07-9e75-bc48981f9647 from datanode 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,249 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66766bc13fee9b5e: from storage DS-a0294ff5-4792-4f07-9e75-bc48981f9647 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,251 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 for DN 127.0.0.1:41925
2020-12-03 07:21:00,251 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x66766bc13fee9b5e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 31 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,251 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a0294ff5-4792-4f07-9e75-bc48981f9647 for DN 127.0.0.1:41925
2020-12-03 07:21:00,251 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,254 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x433cd84de0ce7e63: Processing first storage report for DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 from datanode 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,254 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x433cd84de0ce7e63: from storage DS-f4a73e00-fa69-476c-b811-e9e0c3e42855 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,254 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x433cd84de0ce7e63: Processing first storage report for DS-a0294ff5-4792-4f07-9e75-bc48981f9647 from datanode 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7
2020-12-03 07:21:00,254 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x433cd84de0ce7e63: from storage DS-a0294ff5-4792-4f07-9e75-bc48981f9647 node DatanodeRegistration(127.0.0.1:41925, datanodeUuid=9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7, infoPort=34427, infoSecurePort=0, ipcPort=41861, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,256 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x433cd84de0ce7e63,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,256 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,301 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,302 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,302 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,340 [Thread-218] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,343 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-db90c408-d1ba-40e6-9415-9688e16bc3ed
2020-12-03 07:21:00,343 [Thread-218] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:21:00,354 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810
2020-12-03 07:21:00,357 [Thread-218] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:21:00,364 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,364 [Thread-287] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,364 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:21:00,364 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:21:00,367 [Thread-218] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:00,369 [Thread-218] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:21:00,369 [Thread-217] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,370 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:21:00,370 [Thread-218] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:21:00,370 [Thread-218] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:21:00,370 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:21:00,370 [Thread-218] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:21:00,370 [Thread-218] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,404 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,406 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,406 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,416 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 46ms
2020-12-03 07:21:00,425 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 55ms
2020-12-03 07:21:00,425 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 56ms
2020-12-03 07:21:00,426 [Thread-485] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:21:00,426 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:21:00,426 [Thread-485] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,426 [Thread-486] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,426 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:21:00,426 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:21:00,427 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:21:00,426 [Thread-485] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:21:00,430 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 5ms
2020-12-03 07:21:00,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:21:00,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:21:00,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,432 [Thread-217] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:18 AM with interval of 21600000ms
2020-12-03 07:21:00,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-db90c408-d1ba-40e6-9415-9688e16bc3ed): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:21:00,434 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:00,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-db90c408-d1ba-40e6-9415-9688e16bc3ed): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:00,437 [IPC Server handler 7 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,438 [IPC Server handler 7 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41176
2020-12-03 07:21:00,438 [IPC Server handler 7 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b035270b-dd2b-4525-844b-557ea89a8d2a (127.0.0.1:41176).
2020-12-03 07:21:00,439 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:00,439 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,462 [IPC Server handler 8 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-db90c408-d1ba-40e6-9415-9688e16bc3ed for DN 127.0.0.1:41176
2020-12-03 07:21:00,463 [IPC Server handler 8 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 for DN 127.0.0.1:41176
2020-12-03 07:21:00,475 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 49ms
2020-12-03 07:21:00,475 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 49ms
2020-12-03 07:21:00,477 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 51ms
2020-12-03 07:21:00,478 [Thread-494] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:21:00,478 [Thread-495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:21:00,478 [Thread-494] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,478 [Thread-495] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,478 [Thread-494] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:21:00,479 [Thread-495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:21:00,479 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:21:00,479 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:21:00,479 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:21:00,479 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:00,480 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-db90c408-d1ba-40e6-9415-9688e16bc3ed): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,480 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,480 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x332dbb202fa8d537: Processing first storage report for DS-db90c408-d1ba-40e6-9415-9688e16bc3ed from datanode b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,480 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-db90c408-d1ba-40e6-9415-9688e16bc3ed): no suitable block pools found to scan.  Waiting 1814399952 ms.
2020-12-03 07:21:00,480 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-12-03 07:21:00,480 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x332dbb202fa8d537: from storage DS-db90c408-d1ba-40e6-9415-9688e16bc3ed node DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,480 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x332dbb202fa8d537: Processing first storage report for DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 from datanode b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,481 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x332dbb202fa8d537: from storage DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 node DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,481 [IPC Server handler 9 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,481 [IPC Server handler 9 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41176
2020-12-03 07:21:00,481 [IPC Server handler 9 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b035270b-dd2b-4525-844b-557ea89a8d2a (127.0.0.1:41176).
2020-12-03 07:21:00,481 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x332dbb202fa8d537,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,481 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,482 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:00,482 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,485 [IPC Server handler 8 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-db90c408-d1ba-40e6-9415-9688e16bc3ed for DN 127.0.0.1:41176
2020-12-03 07:21:00,485 [IPC Server handler 8 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 for DN 127.0.0.1:41176
2020-12-03 07:21:00,487 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98481b62fd942f10: Processing first storage report for DS-db90c408-d1ba-40e6-9415-9688e16bc3ed from datanode b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98481b62fd942f10: from storage DS-db90c408-d1ba-40e6-9415-9688e16bc3ed node DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98481b62fd942f10: Processing first storage report for DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 from datanode b035270b-dd2b-4525-844b-557ea89a8d2a
2020-12-03 07:21:00,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98481b62fd942f10: from storage DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810 node DatanodeRegistration(127.0.0.1:41176, datanodeUuid=b035270b-dd2b-4525-844b-557ea89a8d2a, infoPort=32867, infoSecurePort=0, ipcPort=35324, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,489 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x98481b62fd942f10,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,489 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,494 [Thread-310] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:21:00,494 [Thread-240] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1155480158;bpid=BP-1319985285-172.17.0.8-1606980046593;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1155480158;c=1606980046593;bpid=BP-1319985285-172.17.0.8-1606980046593;dnuuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,495 [Thread-241] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:22 AM with interval of 21600000ms
2020-12-03 07:21:00,495 [Thread-240] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,497 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:00,497 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:21:00,497 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:21:00,499 [IPC Server handler 0 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,499 [IPC Server handler 0 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43583
2020-12-03 07:21:00,499 [IPC Server handler 0 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 04e77c52-ba0c-4f60-9524-8f9591c6b3e2 (127.0.0.1:43583).
2020-12-03 07:21:00,500 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:00,500 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,506 [IPC Server handler 2 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-104f9448-35f9-4074-9366-84c2ea93c76d for DN 127.0.0.1:43583
2020-12-03 07:21:00,507 [IPC Server handler 2 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-87660179-8c87-4ea8-9e15-12fc6f176a8d for DN 127.0.0.1:43583
2020-12-03 07:21:00,508 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,509 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,509 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,543 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 46ms
2020-12-03 07:21:00,543 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 46ms
2020-12-03 07:21:00,544 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 47ms
2020-12-03 07:21:00,545 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:21:00,545 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:21:00,545 [Thread-503] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,545 [Thread-504] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,546 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:21:00,546 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:21:00,546 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 1ms
2020-12-03 07:21:00,548 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:21:00,549 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:21:00,549 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:00,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd78fa920169522cf: Processing first storage report for DS-104f9448-35f9-4074-9366-84c2ea93c76d from datanode 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd78fa920169522cf: from storage DS-104f9448-35f9-4074-9366-84c2ea93c76d node DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd78fa920169522cf: Processing first storage report for DS-87660179-8c87-4ea8-9e15-12fc6f176a8d from datanode 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,549 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd78fa920169522cf: from storage DS-87660179-8c87-4ea8-9e15-12fc6f176a8d node DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,549 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-104f9448-35f9-4074-9366-84c2ea93c76d): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,550 [IPC Server handler 0 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,550 [IPC Server handler 0 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43583
2020-12-03 07:21:00,551 [IPC Server handler 0 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 04e77c52-ba0c-4f60-9524-8f9591c6b3e2 (127.0.0.1:43583).
2020-12-03 07:21:00,551 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-104f9448-35f9-4074-9366-84c2ea93c76d): no suitable block pools found to scan.  Waiting 1814398676 ms.
2020-12-03 07:21:00,552 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:00,552 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,549 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-87660179-8c87-4ea8-9e15-12fc6f176a8d): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,550 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd78fa920169522cf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 38 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,554 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-87660179-8c87-4ea8-9e15-12fc6f176a8d): no suitable block pools found to scan.  Waiting 1814398672 ms.
2020-12-03 07:21:00,557 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-104f9448-35f9-4074-9366-84c2ea93c76d for DN 127.0.0.1:43583
2020-12-03 07:21:00,557 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-87660179-8c87-4ea8-9e15-12fc6f176a8d for DN 127.0.0.1:43583
2020-12-03 07:21:00,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe5a30340db32a71: Processing first storage report for DS-104f9448-35f9-4074-9366-84c2ea93c76d from datanode 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe5a30340db32a71: from storage DS-104f9448-35f9-4074-9366-84c2ea93c76d node DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe5a30340db32a71: Processing first storage report for DS-87660179-8c87-4ea8-9e15-12fc6f176a8d from datanode 04e77c52-ba0c-4f60-9524-8f9591c6b3e2
2020-12-03 07:21:00,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe5a30340db32a71: from storage DS-87660179-8c87-4ea8-9e15-12fc6f176a8d node DatanodeRegistration(127.0.0.1:43583, datanodeUuid=04e77c52-ba0c-4f60-9524-8f9591c6b3e2, infoPort=41219, infoSecurePort=0, ipcPort=38559, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,569 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfe5a30340db32a71,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,569 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,611 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,612 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,613 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,675 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,675 [Thread-333] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,675 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 and block pool id BP-1662406970-172.17.0.8-1606980049454 is not formatted. Formatting ...
2020-12-03 07:21:00,675 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1662406970-172.17.0.8-1606980049454 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1662406970-172.17.0.8-1606980049454/current
2020-12-03 07:21:00,715 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,716 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,717 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,819 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,821 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,821 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,832 [Thread-264] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,835 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-490263f6-b489-4d85-8d6d-619abd0eb77c
2020-12-03 07:21:00,835 [Thread-356] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=null
2020-12-03 07:21:00,835 [Thread-264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:21:00,838 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9fb619af-536d-4526-8e85-573d79f09dda
2020-12-03 07:21:00,838 [Thread-264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:21:00,845 [Thread-264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:00,846 [Thread-264] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:21:00,847 [Thread-263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,847 [Thread-507] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:21:00,847 [Thread-264] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:21:00,848 [Thread-264] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:21:00,848 [Thread-508] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:21:00,848 [Thread-264] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:21:00,850 [Thread-264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,898 [Thread-508] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 50ms
2020-12-03 07:21:00,899 [Thread-507] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 52ms
2020-12-03 07:21:00,901 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 53ms
2020-12-03 07:21:00,901 [Thread-511] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:21:00,901 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:21:00,901 [Thread-511] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,901 [Thread-513] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:00,902 [Thread-511] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:21:00,902 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:21:00,902 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:21:00,903 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 2ms
2020-12-03 07:21:00,913 [Thread-514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:21:00,915 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:21:00,915 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:21:00,915 [Thread-263] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:34 PM with interval of 21600000ms
2020-12-03 07:21:00,916 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-490263f6-b489-4d85-8d6d-619abd0eb77c): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,916 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-9fb619af-536d-4526-8e85-573d79f09dda): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,917 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:00,918 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-490263f6-b489-4d85-8d6d-619abd0eb77c): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:00,918 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-9fb619af-536d-4526-8e85-573d79f09dda): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:00,919 [IPC Server handler 7 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,919 [IPC Server handler 7 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41802
2020-12-03 07:21:00,919 [IPC Server handler 7 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bcab5577-9c92-4525-8cc1-40a31d4db587 (127.0.0.1:41802).
2020-12-03 07:21:00,920 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:00,920 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,930 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,930 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-490263f6-b489-4d85-8d6d-619abd0eb77c for DN 127.0.0.1:41802
2020-12-03 07:21:00,930 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fb619af-536d-4526-8e85-573d79f09dda for DN 127.0.0.1:41802
2020-12-03 07:21:00,932 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,932 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,964 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 61ms
2020-12-03 07:21:00,964 [Thread-514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 51ms
2020-12-03 07:21:00,965 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 64ms
2020-12-03 07:21:00,965 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:21:00,965 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:21:00,965 [Thread-520] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,965 [Thread-521] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:00,966 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:21:00,966 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:21:00,967 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:21:00,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:21:00,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:21:00,968 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:00,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x33844043fb88b56e: Processing first storage report for DS-490263f6-b489-4d85-8d6d-619abd0eb77c from datanode bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-490263f6-b489-4d85-8d6d-619abd0eb77c): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x33844043fb88b56e: from storage DS-490263f6-b489-4d85-8d6d-619abd0eb77c node DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-9fb619af-536d-4526-8e85-573d79f09dda): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:00,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x33844043fb88b56e: Processing first storage report for DS-9fb619af-536d-4526-8e85-573d79f09dda from datanode bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x33844043fb88b56e: from storage DS-9fb619af-536d-4526-8e85-573d79f09dda node DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,969 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-490263f6-b489-4d85-8d6d-619abd0eb77c): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-12-03 07:21:00,969 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-9fb619af-536d-4526-8e85-573d79f09dda): no suitable block pools found to scan.  Waiting 1814399946 ms.
2020-12-03 07:21:00,969 [IPC Server handler 4 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,969 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x33844043fb88b56e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 34 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,969 [IPC Server handler 4 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41802
2020-12-03 07:21:00,970 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:00,970 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bcab5577-9c92-4525-8cc1-40a31d4db587 (127.0.0.1:41802).
2020-12-03 07:21:00,970 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:00,971 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,974 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-490263f6-b489-4d85-8d6d-619abd0eb77c for DN 127.0.0.1:41802
2020-12-03 07:21:00,974 [IPC Server handler 3 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fb619af-536d-4526-8e85-573d79f09dda for DN 127.0.0.1:41802
2020-12-03 07:21:00,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc417040ba037d07d: Processing first storage report for DS-490263f6-b489-4d85-8d6d-619abd0eb77c from datanode bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc417040ba037d07d: from storage DS-490263f6-b489-4d85-8d6d-619abd0eb77c node DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc417040ba037d07d: Processing first storage report for DS-9fb619af-536d-4526-8e85-573d79f09dda from datanode bcab5577-9c92-4525-8cc1-40a31d4db587
2020-12-03 07:21:00,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc417040ba037d07d: from storage DS-9fb619af-536d-4526-8e85-573d79f09dda node DatanodeRegistration(127.0.0.1:41802, datanodeUuid=bcab5577-9c92-4525-8cc1-40a31d4db587, infoPort=33607, infoSecurePort=0, ipcPort=33863, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,983 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc417040ba037d07d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,984 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,011 [Thread-287] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,012 [Thread-286] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:09 AM with interval of 21600000ms
2020-12-03 07:21:01,012 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,014 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:01,014 [Thread-525] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:21:01,014 [Thread-526] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:21:01,016 [IPC Server handler 0 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,016 [IPC Server handler 0 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40633
2020-12-03 07:21:01,017 [IPC Server handler 0 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 91238f5d-8cc8-47ab-af13-7aff633773bb (127.0.0.1:40633).
2020-12-03 07:21:01,018 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:01,018 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,024 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 for DN 127.0.0.1:40633
2020-12-03 07:21:01,025 [IPC Server handler 2 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 for DN 127.0.0.1:40633
2020-12-03 07:21:01,034 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,055 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,056 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,076 [Thread-525] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 61ms
2020-12-03 07:21:01,082 [Thread-526] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 68ms
2020-12-03 07:21:01,083 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 69ms
2020-12-03 07:21:01,098 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:21:01,099 [Thread-529] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,099 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:21:01,099 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:21:01,099 [Thread-530] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,100 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd786992db7e2cfa8: Processing first storage report for DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 from datanode 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,100 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd786992db7e2cfa8: from storage DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 node DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd786992db7e2cfa8: Processing first storage report for DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 from datanode 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,101 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd786992db7e2cfa8: from storage DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 node DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,103 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd786992db7e2cfa8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 60 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,103 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,100 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:21:01,104 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 21ms
2020-12-03 07:21:01,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:21:01,106 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:01,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68): no suitable block pools found to scan.  Waiting 1814398573 ms.
2020-12-03 07:21:01,109 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:21:01,109 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186): no suitable block pools found to scan.  Waiting 1814398570 ms.
2020-12-03 07:21:01,111 [IPC Server handler 7 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,111 [IPC Server handler 7 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40633
2020-12-03 07:21:01,111 [IPC Server handler 7 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 91238f5d-8cc8-47ab-af13-7aff633773bb (127.0.0.1:40633).
2020-12-03 07:21:01,112 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:01,112 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,116 [IPC Server handler 9 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 for DN 127.0.0.1:40633
2020-12-03 07:21:01,116 [IPC Server handler 9 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 for DN 127.0.0.1:40633
2020-12-03 07:21:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa884fb3eb56b5b39: Processing first storage report for DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 from datanode 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa884fb3eb56b5b39: from storage DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186 node DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa884fb3eb56b5b39: Processing first storage report for DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 from datanode 91238f5d-8cc8-47ab-af13-7aff633773bb
2020-12-03 07:21:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa884fb3eb56b5b39: from storage DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68 node DatanodeRegistration(127.0.0.1:40633, datanodeUuid=91238f5d-8cc8-47ab-af13-7aff633773bb, infoPort=40839, infoSecurePort=0, ipcPort=43509, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,119 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa884fb3eb56b5b39,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,119 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,158 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,159 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,160 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,192 [Thread-310] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,197 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55
2020-12-03 07:21:01,198 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:21:01,200 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07835acc-9771-4b47-ae0d-18b8fa630194
2020-12-03 07:21:01,201 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:21:01,204 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:01,205 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:01,205 [Thread-309] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,206 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:01,206 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:01,206 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:01,206 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:01,206 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:01,206 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,245 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 39ms
2020-12-03 07:21:01,256 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 49ms
2020-12-03 07:21:01,256 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 51ms
2020-12-03 07:21:01,256 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:01,256 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:01,257 [Thread-538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:01,257 [Thread-539] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:01,257 [Thread-537] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:01,257 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:21:01,264 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 8ms
2020-12-03 07:21:01,265 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 9ms
2020-12-03 07:21:01,267 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:01,268 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,268 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:01,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:01,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-07835acc-9771-4b47-ae0d-18b8fa630194): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,269 [Thread-309] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:04 AM with interval of 21600000ms
2020-12-03 07:21:01,271 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:01,271 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,271 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:01,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-07835acc-9771-4b47-ae0d-18b8fa630194): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:01,272 [IPC Server handler 7 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,277 [IPC Server handler 7 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45090
2020-12-03 07:21:01,277 [IPC Server handler 7 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b (127.0.0.1:45090).
2020-12-03 07:21:01,279 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:01,279 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,287 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 for DN 127.0.0.1:45090
2020-12-03 07:21:01,289 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07835acc-9771-4b47-ae0d-18b8fa630194 for DN 127.0.0.1:45090
2020-12-03 07:21:01,313 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 46ms
2020-12-03 07:21:01,314 [Thread-538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 57ms
2020-12-03 07:21:01,315 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 59ms
2020-12-03 07:21:01,315 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:01,315 [Thread-546] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,316 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:21:01,316 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:01,316 [Thread-547] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,317 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:21:01,317 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:21:01,318 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:01,318 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:01,319 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,319 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:01,319 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:21:01,320 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-07835acc-9771-4b47-ae0d-18b8fa630194): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,320 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-07835acc-9771-4b47-ae0d-18b8fa630194): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:21:01,323 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcdff4f3ff217ae7: Processing first storage report for DS-07835acc-9771-4b47-ae0d-18b8fa630194 from datanode 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcdff4f3ff217ae7: from storage DS-07835acc-9771-4b47-ae0d-18b8fa630194 node DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcdff4f3ff217ae7: Processing first storage report for DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 from datanode 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,324 [IPC Server handler 6 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,324 [IPC Server handler 6 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45090
2020-12-03 07:21:01,324 [IPC Server handler 6 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b (127.0.0.1:45090).
2020-12-03 07:21:01,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcdff4f3ff217ae7: from storage DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 node DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,327 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcdff4f3ff217ae7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 25 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,327 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,328 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:01,328 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,331 [IPC Server handler 0 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 for DN 127.0.0.1:45090
2020-12-03 07:21:01,331 [IPC Server handler 0 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07835acc-9771-4b47-ae0d-18b8fa630194 for DN 127.0.0.1:45090
2020-12-03 07:21:01,333 [Thread-332] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:51 AM with interval of 21600000ms
2020-12-03 07:21:01,333 [Thread-333] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1592339003;bpid=BP-1662406970-172.17.0.8-1606980049454;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1592339003;c=1606980049454;bpid=BP-1662406970-172.17.0.8-1606980049454;dnuuid=40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,334 [Thread-333] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,334 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe26db18989bc5ea: Processing first storage report for DS-07835acc-9771-4b47-ae0d-18b8fa630194 from datanode 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,335 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe26db18989bc5ea: from storage DS-07835acc-9771-4b47-ae0d-18b8fa630194 node DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,335 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe26db18989bc5ea: Processing first storage report for DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 from datanode 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b
2020-12-03 07:21:01,335 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe26db18989bc5ea: from storage DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55 node DatanodeRegistration(127.0.0.1:45090, datanodeUuid=2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b, infoPort=38133, infoSecurePort=0, ipcPort=42208, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,336 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfe26db18989bc5ea,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,336 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,343 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:21:01,349 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:01,353 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:21:01,357 [IPC Server handler 1 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,357 [IPC Server handler 1 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42779
2020-12-03 07:21:01,358 [IPC Server handler 1 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 40f73f16-9edd-4398-9aa1-221d39bf787f (127.0.0.1:42779).
2020-12-03 07:21:01,359 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:01,359 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,364 [IPC Server handler 0 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d for DN 127.0.0.1:42779
2020-12-03 07:21:01,365 [IPC Server handler 0 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa for DN 127.0.0.1:42779
2020-12-03 07:21:01,373 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,375 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,375 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,400 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 57ms
2020-12-03 07:21:01,410 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 57ms
2020-12-03 07:21:01,411 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 76ms
2020-12-03 07:21:01,411 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:21:01,411 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:21:01,412 [Thread-555] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,412 [Thread-556] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,412 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 0ms
2020-12-03 07:21:01,412 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 1ms
2020-12-03 07:21:01,412 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 1ms
2020-12-03 07:21:01,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x908213b38563722c: Processing first storage report for DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d from datanode 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:21:01,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:21:01,415 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:01,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x908213b38563722c: from storage DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d node DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x908213b38563722c: Processing first storage report for DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa from datanode 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x908213b38563722c: from storage DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa node DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,416 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa): no suitable block pools found to scan.  Waiting 1814398575 ms.
2020-12-03 07:21:01,416 [IPC Server handler 1 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,416 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x908213b38563722c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 45 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,416 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,416 [IPC Server handler 1 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42779
2020-12-03 07:21:01,417 [IPC Server handler 1 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 40f73f16-9edd-4398-9aa1-221d39bf787f (127.0.0.1:42779).
2020-12-03 07:21:01,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d): no suitable block pools found to scan.  Waiting 1814398574 ms.
2020-12-03 07:21:01,418 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:01,418 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,426 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d for DN 127.0.0.1:42779
2020-12-03 07:21:01,426 [IPC Server handler 4 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa for DN 127.0.0.1:42779
2020-12-03 07:21:01,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x81345510c2b8cdd2: Processing first storage report for DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d from datanode 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x81345510c2b8cdd2: from storage DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d node DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x81345510c2b8cdd2: Processing first storage report for DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa from datanode 40f73f16-9edd-4398-9aa1-221d39bf787f
2020-12-03 07:21:01,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x81345510c2b8cdd2: from storage DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa node DatanodeRegistration(127.0.0.1:42779, datanodeUuid=40f73f16-9edd-4398-9aa1-221d39bf787f, infoPort=41808, infoSecurePort=0, ipcPort=41616, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,430 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x81345510c2b8cdd2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,430 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,477 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,478 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,478 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,499 [Thread-355] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,502 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-48c74591-6525-4cf5-bf14-26e1e18997ab
2020-12-03 07:21:01,502 [Thread-355] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, StorageType: DISK
2020-12-03 07:21:01,503 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9ea86b1a-04b1-421c-a202-657e276c1da5
2020-12-03 07:21:01,503 [Thread-355] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, StorageType: DISK
2020-12-03 07:21:01,504 [Thread-355] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:01,505 [Thread-355] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:01,509 [Thread-356] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,580 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,584 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,584 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,613 [Thread-355] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:01,614 [Thread-355] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:01,614 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:01,615 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:01,617 [Thread-355] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:01,623 [Thread-355] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,665 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 50ms
2020-12-03 07:21:01,676 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1662406970-172.17.0.8-1606980049454 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 61ms
2020-12-03 07:21:01,676 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1662406970-172.17.0.8-1606980049454: 167ms
2020-12-03 07:21:01,676 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:01,677 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:01,677 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:01,677 [Thread-563] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,677 [Thread-565] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1662406970-172.17.0.8-1606980049454/current/replicas doesn't exist 
2020-12-03 07:21:01,677 [Thread-566] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:01,677 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 1ms
2020-12-03 07:21:01,677 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 0ms
2020-12-03 07:21:01,678 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1662406970-172.17.0.8-1606980049454: 2ms
2020-12-03 07:21:01,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:01,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1662406970-172.17.0.8-1606980049454 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:01,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-48c74591-6525-4cf5-bf14-26e1e18997ab): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,680 [Thread-356] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:06 AM with interval of 21600000ms
2020-12-03 07:21:01,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-9ea86b1a-04b1-421c-a202-657e276c1da5): finished scanning block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,682 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:38547 beginning handshake with NN
2020-12-03 07:21:01,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-9ea86b1a-04b1-421c-a202-657e276c1da5): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:01,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-48c74591-6525-4cf5-bf14-26e1e18997ab): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:01,684 [IPC Server handler 5 on default port 38547] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454) storage f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,684 [IPC Server handler 5 on default port 38547] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46683
2020-12-03 07:21:01,684 [IPC Server handler 5 on default port 38547] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f (127.0.0.1:46683).
2020-12-03 07:21:01,685 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:38547 successfully registered with NN
2020-12-03 07:21:01,685 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38547 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,686 [IPC Server handler 6 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,691 [IPC Server handler 7 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-48c74591-6525-4cf5-bf14-26e1e18997ab for DN 127.0.0.1:46683
2020-12-03 07:21:01,691 [IPC Server handler 7 on default port 38547] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9ea86b1a-04b1-421c-a202-657e276c1da5 for DN 127.0.0.1:46683
2020-12-03 07:21:01,692 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,692 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,724 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 47ms
2020-12-03 07:21:01,729 [Thread-566] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1319985285-172.17.0.8-1606980046593 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 52ms
2020-12-03 07:21:01,729 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1319985285-172.17.0.8-1606980046593: 53ms
2020-12-03 07:21:01,730 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:01,730 [Thread-572] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:01,730 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:01,730 [Thread-573] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1319985285-172.17.0.8-1606980046593/current/replicas doesn't exist 
2020-12-03 07:21:01,731 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 0ms
2020-12-03 07:21:01,731 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 1ms
2020-12-03 07:21:01,731 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1319985285-172.17.0.8-1606980046593: 2ms
2020-12-03 07:21:01,731 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:01,731 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1319985285-172.17.0.8-1606980046593 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:01,731 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:34576 beginning handshake with NN
2020-12-03 07:21:01,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-48c74591-6525-4cf5-bf14-26e1e18997ab): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-9ea86b1a-04b1-421c-a202-657e276c1da5): finished scanning block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-9ea86b1a-04b1-421c-a202-657e276c1da5): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:21:01,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-48c74591-6525-4cf5-bf14-26e1e18997ab): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:21:01,733 [IPC Server handler 7 on default port 34576] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593) storage f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,734 [IPC Server handler 7 on default port 34576] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46683
2020-12-03 07:21:01,734 [IPC Server handler 7 on default port 34576] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f (127.0.0.1:46683).
2020-12-03 07:21:01,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x38291bac6ac3a5f9: Processing first storage report for DS-48c74591-6525-4cf5-bf14-26e1e18997ab from datanode f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x38291bac6ac3a5f9: from storage DS-48c74591-6525-4cf5-bf14-26e1e18997ab node DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x38291bac6ac3a5f9: Processing first storage report for DS-9ea86b1a-04b1-421c-a202-657e276c1da5 from datanode f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,735 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x38291bac6ac3a5f9: from storage DS-9ea86b1a-04b1-421c-a202-657e276c1da5 node DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1592339003;c=1606980049454), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,735 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:34576 successfully registered with NN
2020-12-03 07:21:01,735 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34576 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:01,735 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x38291bac6ac3a5f9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 41 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,735 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:01,738 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-48c74591-6525-4cf5-bf14-26e1e18997ab for DN 127.0.0.1:46683
2020-12-03 07:21:01,738 [IPC Server handler 9 on default port 34576] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9ea86b1a-04b1-421c-a202-657e276c1da5 for DN 127.0.0.1:46683
2020-12-03 07:21:01,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfd5fbbae773d47b7: Processing first storage report for DS-48c74591-6525-4cf5-bf14-26e1e18997ab from datanode f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd5fbbae773d47b7: from storage DS-48c74591-6525-4cf5-bf14-26e1e18997ab node DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfd5fbbae773d47b7: Processing first storage report for DS-9ea86b1a-04b1-421c-a202-657e276c1da5 from datanode f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f
2020-12-03 07:21:01,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd5fbbae773d47b7: from storage DS-9ea86b1a-04b1-421c-a202-657e276c1da5 node DatanodeRegistration(127.0.0.1:46683, datanodeUuid=f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f, infoPort=38472, infoSecurePort=0, ipcPort=40957, storageInfo=lv=-57;cid=testClusterID;nsid=1155480158;c=1606980046593), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:01,742 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfd5fbbae773d47b7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:01,742 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:01,794 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,809 [IPC Server handler 8 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,818 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:01,831 [IPC Server handler 0 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,851 [IPC Server handler 6 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,860 [Listener at localhost/40957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:01,917 [Listener at localhost/40957] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:01,919 [Listener at localhost/40957] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:01,920 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:01,933 [Listener at 0.0.0.0/46225] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:01,934 [Listener at 0.0.0.0/46225] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:01,934 [Listener at 0.0.0.0/46225] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:01,945 [Listener at 0.0.0.0/46225] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:01,953 [Listener at 0.0.0.0/46225] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:21:01,980 [Listener at 0.0.0.0/46225] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:01,982 [Listener at 0.0.0.0/46225] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:01,983 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:01,994 [Listener at 0.0.0.0/41003] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:01,994 [Listener at 0.0.0.0/41003] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:01,994 [Listener at 0.0.0.0/41003] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:01,995 [Listener at 0.0.0.0/41003] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:01,996 [Listener at 0.0.0.0/41003] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:21:02,009 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@45e22def] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:02,011 [Listener at 0.0.0.0/41003] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:46225
2020-12-03 07:21:02,009 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,017 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,023 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-2
2020-12-03 07:21:02,024 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-2
2020-12-03 07:21:02,025 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-2
2020-12-03 07:21:02,026 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-2
2020-12-03 07:21:02,034 [Listener at 0.0.0.0/41003] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:21:02,034 [Listener at 0.0.0.0/41003] ERROR metrics.FederationMetrics (FederationMetrics.java:<init>(137)) - State store not available
2020-12-03 07:21:02,035 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@548d5ed3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:02,035 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,037 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,041 [Listener at 0.0.0.0/41003] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:41003
2020-12-03 07:21:02,041 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-3
2020-12-03 07:21:02,042 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-3
2020-12-03 07:21:02,042 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-3
2020-12-03 07:21:02,042 [Listener at 0.0.0.0/41003] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-3
2020-12-03 07:21:02,042 [Listener at 0.0.0.0/41003] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:21:02,043 [Listener at 0.0.0.0/41003] ERROR metrics.FederationMetrics (FederationMetrics.java:<init>(137)) - State store not available
2020-12-03 07:21:02,097 [IPC Server handler 2 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,104 [IPC Server handler 3 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,110 [IPC Server handler 0 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,112 [IPC Server handler 2 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,128 [IPC Server handler 5 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/target-ns0/testdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:02,171 [IPC Server handler 4 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns0/testdir	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,187 [IPC Server handler 1 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/target-ns1/testdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:02,195 [IPC Server handler 4 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns1/testdir	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,297 [Listener at 0.0.0.0/41003] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(249)) - Connecting to router at hdfs://0.0.0.0:41003
2020-12-03 07:21:02,396 [Listener at 0.0.0.0/41003] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(357)) - Connecting to namenode at hdfs://localhost:34576
2020-12-03 07:21:02,452 [IPC Server handler 9 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/target-ns0/testdir/testfile-1618617767	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-12-03 07:21:02,515 [IPC Server handler 8 on default port 34576] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43583 for /target-ns0/testdir/testfile-1618617767
2020-12-03 07:21:02,534 [Thread-603] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,655 [DataXceiver for client DFSClient_NONMAPREDUCE_206774976_1 at /127.0.0.1:48426 [Receiving block BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001 src: /127.0.0.1:48426 dest: /127.0.0.1:43583
2020-12-03 07:21:02,766 [PacketResponder: BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48426, dest: /127.0.0.1:43583, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_206774976_1, offset: 0, srvID: 04e77c52-ba0c-4f60-9524-8f9591c6b3e2, blockid: BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001, duration(ns): 24667873
2020-12-03 07:21:02,766 [PacketResponder: BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1319985285-172.17.0.8-1606980046593:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:02,777 [IPC Server handler 2 on default port 34576] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /target-ns0/testdir/testfile-1618617767
2020-12-03 07:21:03,184 [IPC Server handler 6 on default port 34576] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /target-ns0/testdir/testfile-1618617767 is closed by DFSClient_NONMAPREDUCE_206774976_1
2020-12-03 07:21:03,190 [IPC Server handler 7 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns0/testdir/testfile-1618617767	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,254 [IPC Server handler 1 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,256 [IPC Server handler 3 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,265 [IPC Server handler 8 on default port 34576] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,266 [Listener at 0.0.0.0/41003] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(357)) - Connecting to namenode at hdfs://localhost:38547
2020-12-03 07:21:03,269 [IPC Server handler 7 on default port 38547] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,271 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:03,272 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 11
2020-12-03 07:21:03,272 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,273 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@441cc260] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,285 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-48c74591-6525-4cf5-bf14-26e1e18997ab) exiting.
2020-12-03 07:21:03,285 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-9ea86b1a-04b1-421c-a202-657e276c1da5) exiting.
2020-12-03 07:21:03,453 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55cff952{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,458 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@660591fb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,459 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a022576{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,459 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55b8dbda{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,466 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40957
2020-12-03 07:21:03,469 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,477 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,477 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,477 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:38547
2020-12-03 07:21:03,478 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f)
2020-12-03 07:21:03,478 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:03,478 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,479 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,481 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,483 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f) service to localhost/127.0.0.1:34576
2020-12-03 07:21:03,483 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid f0cb71d5-7dae-47d5-a0f3-6616b1e33c1f)
2020-12-03 07:21:03,483 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:03,483 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,485 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,491 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,492 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,494 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,494 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,507 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,507 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:21:03,507 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,507 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@392a04e7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,511 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-2a88f493-ea9b-446a-b8fb-3140226ee6fa) exiting.
2020-12-03 07:21:03,511 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-332baef8-3a91-40a2-9d8b-0c63d7a5e49d) exiting.
2020-12-03 07:21:03,558 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a9486c0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,559 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c27d39d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,560 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b2a3ff8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,561 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f404594{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,566 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41616
2020-12-03 07:21:03,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,606 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,606 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:34576
2020-12-03 07:21:03,606 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f)
2020-12-03 07:21:03,606 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:03,607 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,607 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,607 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,608 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,607 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f) service to localhost/127.0.0.1:38547
2020-12-03 07:21:03,608 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 40f73f16-9edd-4398-9aa1-221d39bf787f)
2020-12-03 07:21:03,608 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:03,609 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,609 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,628 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,628 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,630 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,630 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,634 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,634 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:21:03,634 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,634 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@52fc5eb1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,637 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-d2a806b6-7e1e-47cf-bc4c-8ed9713cec55) exiting.
2020-12-03 07:21:03,637 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-07835acc-9771-4b47-ae0d-18b8fa630194) exiting.
2020-12-03 07:21:03,666 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5c92166b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,667 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@659925f4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,667 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@982bb90{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,668 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76954a33{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,669 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42208
2020-12-03 07:21:03,673 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,680 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,680 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,680 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:34576
2020-12-03 07:21:03,680 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b) service to localhost/127.0.0.1:38547
2020-12-03 07:21:03,680 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b)
2020-12-03 07:21:03,680 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 2b2fd62e-2cb4-4a8c-894d-07b15f8beb5b)
2020-12-03 07:21:03,680 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:03,681 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,681 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:03,681 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,691 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,694 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,696 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,697 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,700 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,700 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,718 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,719 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:21:03,719 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,726 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6dd93a21] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-35ee8783-ed75-4a91-b3b5-aa91aa1c0186) exiting.
2020-12-03 07:21:03,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-2d21aa63-4364-48c9-aee2-40d34c7b9b68) exiting.
2020-12-03 07:21:03,768 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4e8e8621{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,769 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c446b14{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,770 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ca6546f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,770 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37095ded{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,781 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43509
2020-12-03 07:21:03,785 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,785 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,789 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,789 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:34576
2020-12-03 07:21:03,790 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb)
2020-12-03 07:21:03,790 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:03,790 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,793 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,796 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,796 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb) service to localhost/127.0.0.1:38547
2020-12-03 07:21:03,796 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 91238f5d-8cc8-47ab-af13-7aff633773bb)
2020-12-03 07:21:03,796 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:03,801 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,802 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,831 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,831 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,834 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,834 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,840 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,840 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:21:03,841 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,841 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@aced190] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,841 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-490263f6-b489-4d85-8d6d-619abd0eb77c) exiting.
2020-12-03 07:21:03,847 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-9fb619af-536d-4526-8e85-573d79f09dda) exiting.
2020-12-03 07:21:03,873 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@273842a6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,874 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a969fb8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,874 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29314cc9{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,875 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d6aca33{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,883 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33863
2020-12-03 07:21:03,900 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,900 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,907 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,907 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:34576
2020-12-03 07:21:03,907 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587)
2020-12-03 07:21:03,908 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:03,908 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,909 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587) service to localhost/127.0.0.1:38547
2020-12-03 07:21:03,909 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid bcab5577-9c92-4525-8cc1-40a31d4db587)
2020-12-03 07:21:03,955 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,970 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,981 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,982 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,982 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:03,987 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,987 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,987 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,987 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,997 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,998 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:21:03,998 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,998 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@52a36910] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,007 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-87660179-8c87-4ea8-9e15-12fc6f176a8d) exiting.
2020-12-03 07:21:04,009 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-104f9448-35f9-4074-9366-84c2ea93c76d) exiting.
2020-12-03 07:21:04,034 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7051777c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,036 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3241713e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,036 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fe88a09{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,037 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22fba58c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,067 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38559
2020-12-03 07:21:04,075 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,084 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,085 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,085 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2)
2020-12-03 07:21:04,085 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,091 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,091 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,091 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 04e77c52-ba0c-4f60-9524-8f9591c6b3e2)
2020-12-03 07:21:04,091 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,093 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,105 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,136 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,136 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,139 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,140 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,145 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,146 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:21:04,146 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,146 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@278f8425] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-db90c408-d1ba-40e6-9415-9688e16bc3ed) exiting.
2020-12-03 07:21:04,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-8a5d17f5-e1d2-4cf0-b7ce-0b1321097810) exiting.
2020-12-03 07:21:04,188 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fedfe27{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,191 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f879bab{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,191 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b32cd16{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,192 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a1c0752{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,197 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35324
2020-12-03 07:21:04,204 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,204 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,208 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,208 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,208 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,208 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,208 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a)
2020-12-03 07:21:04,208 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid b035270b-dd2b-4525-844b-557ea89a8d2a)
2020-12-03 07:21:04,208 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,209 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,209 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,216 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,228 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,229 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,230 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,230 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,235 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,235 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,242 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,242 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:21:04,242 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,242 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42f22995] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,243 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-a0294ff5-4792-4f07-9e75-bc48981f9647) exiting.
2020-12-03 07:21:04,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-f4a73e00-fa69-476c-b811-e9e0c3e42855) exiting.
2020-12-03 07:21:04,366 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7808fb9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,367 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@773bd77b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,367 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cbb84b1{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,368 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29182679{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,375 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41861
2020-12-03 07:21:04,377 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,387 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,387 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,388 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,388 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7)
2020-12-03 07:21:04,388 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,389 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,389 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,391 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,391 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,391 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9eb1ccbf-f7e2-47a5-a53a-4cefb2cc09b7)
2020-12-03 07:21:04,391 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,392 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,392 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,417 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,418 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,421 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,422 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,433 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,433 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:21:04,435 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,435 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ee29c84] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,437 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-da77b6e3-0a04-44ed-9c23-09d41dd64822) exiting.
2020-12-03 07:21:04,437 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-fa85ac79-6260-46f5-be7e-0b16362358ad) exiting.
2020-12-03 07:21:04,457 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d7e1102{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,458 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65327f5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,459 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60baef24{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,459 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18fdb6cf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,463 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40840
2020-12-03 07:21:04,469 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,476 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,476 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,476 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,476 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,476 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,476 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0)
2020-12-03 07:21:04,477 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid a08005a9-751b-49d1-97e1-da4735e0e8c0)
2020-12-03 07:21:04,477 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,477 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,477 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,477 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,478 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,489 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,557 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,557 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,565 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,565 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,575 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,575 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:04,601 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,601 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@534ca02b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,602 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-a6fde6e4-158f-4916-b3e5-c3c5614cf2a8) exiting.
2020-12-03 07:21:04,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-67ab8674-bdb4-4cdd-9773-97d32732c99b) exiting.
2020-12-03 07:21:04,641 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@648ee871{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,642 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@375b5b7f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,643 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5491f68b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,643 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3068b369{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,645 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33779
2020-12-03 07:21:04,653 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,656 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,654 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,653 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,661 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,661 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563)
2020-12-03 07:21:04,661 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,661 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,668 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,668 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 7e442781-5b97-4945-8d62-c89aed5f8563)
2020-12-03 07:21:04,668 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,669 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,674 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,675 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,681 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,681 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,687 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,688 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,711 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,712 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:04,712 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,712 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@73d69c0f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,713 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-98ff0d7f-3fb2-49f2-a266-47ae95d77b43) exiting.
2020-12-03 07:21:04,715 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b2d1a99f-57ae-46d9-99b0-efebc1377b6f) exiting.
2020-12-03 07:21:04,808 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@577f9109{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,809 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4303b7f0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,809 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13e698c7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,809 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@781a9412{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,821 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44167
2020-12-03 07:21:04,835 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,836 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,836 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,836 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,836 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135)
2020-12-03 07:21:04,836 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,836 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,837 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,837 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 4e29ef4e-84c8-49b4-899e-3aaf799ac135)
2020-12-03 07:21:04,837 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,837 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,857 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,857 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,847 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,837 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,866 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,890 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,890 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,891 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,891 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:04,891 [Listener at 0.0.0.0/41003] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:04,891 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@106faf11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:04,892 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-6572ee60-04a3-4144-b245-c9434eff49ec) exiting.
2020-12-03 07:21:04,892 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8ee3b812-f66a-406a-a7ab-6baaec75cf58) exiting.
2020-12-03 07:21:04,925 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e27ba81{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:04,925 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,926 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b02e036{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,926 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fc08eec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,928 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39467
2020-12-03 07:21:04,937 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,947 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,947 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:04,947 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:34576
2020-12-03 07:21:04,947 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905) service to localhost/127.0.0.1:38547
2020-12-03 07:21:04,947 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1319985285-172.17.0.8-1606980046593 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905)
2020-12-03 07:21:04,948 [BP-1319985285-172.17.0.8-1606980046593 heartbeating to localhost/127.0.0.1:34576] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1319985285-172.17.0.8-1606980046593
2020-12-03 07:21:04,948 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1662406970-172.17.0.8-1606980049454 (Datanode Uuid 9bbd9e0a-d2fa-46bd-8418-9e16bd434905)
2020-12-03 07:21:04,948 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,948 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1319985285-172.17.0.8-1606980046593] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,948 [BP-1662406970-172.17.0.8-1606980049454 heartbeating to localhost/127.0.0.1:38547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1662406970-172.17.0.8-1606980049454
2020-12-03 07:21:04,957 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,958 [Listener at 0.0.0.0/41003] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,966 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,967 [Listener at 0.0.0.0/41003] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,967 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,967 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1662406970-172.17.0.8-1606980049454] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,969 [Listener at 0.0.0.0/41003] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,970 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:04,970 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:04,983 [Listener at 0.0.0.0/41003] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:21:04,983 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5ef8df1e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:04,983 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@62d363ab] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:04,984 [Listener at 0.0.0.0/41003] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 3 3 
2020-12-03 07:21:04,985 [Listener at 0.0.0.0/41003] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:21:04,986 [Listener at 0.0.0.0/41003] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:21:04,987 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:04,987 [CacheReplicationMonitor(2008463836)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:05,088 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34576
2020-12-03 07:21:05,111 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:05,121 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:05,122 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:05,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:05,186 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:05,187 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:05,190 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34158c08{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:05,465 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@b7c4869{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:05,480 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d278d2b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:05,481 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@571c5681{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:05,539 [Listener at 0.0.0.0/41003] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:05,539 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:05,552 [Listener at 0.0.0.0/41003] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 3
2020-12-03 07:21:05,552 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3676ac27] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:05,552 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5489c777] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:05,553 [Listener at 0.0.0.0/41003] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 1 Number of syncs: 4 SyncTimes(ms): 7 3 
2020-12-03 07:21:05,564 [Listener at 0.0.0.0/41003] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:21:05,662 [Listener at 0.0.0.0/41003] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:21:05,663 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:05,676 [CacheReplicationMonitor(525205097)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:05,784 [Listener at 0.0.0.0/41003] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38547
2020-12-03 07:21:05,942 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:05,961 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:05,961 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:05,961 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:06,026 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:06,026 [Listener at 0.0.0.0/41003] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:06,028 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13006998{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:06,029 [Listener at 0.0.0.0/41003] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@37fbe4a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:06,030 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56b78e55{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:06,030 [Listener at 0.0.0.0/41003] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:06,106 [Thread-611] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46225
2020-12-03 07:21:06,155 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:06,171 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,080 [Thread-612] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:21:07,083 [Thread-612] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:21:07,083 [Thread-612] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:21:07,085 [Thread-612] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41003
2020-12-03 07:21:07,086 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,086 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
msx-rc 0
