2020-12-03 07:21:12,506 [Thread-0] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-12-03 07:21:13,509 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:13,526 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:13,529 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:13,529 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:13,539 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:13,540 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:13,540 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:13,541 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:13,600 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:13,606 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:21:13,607 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:13,607 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:13,616 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:13,617 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:13
2020-12-03 07:21:13,619 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:13,621 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:13,624 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:21:13,624 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:13,649 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:13,657 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:13,658 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:13,658 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:13,659 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:13,660 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:13,661 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:13,661 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:13,661 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:13,661 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:13,661 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:13,662 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:13,711 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:21:13,711 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:13,711 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:13,712 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:13,735 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:13,736 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:13,736 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:21:13,736 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:13,746 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:13,747 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:13,747 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:13,748 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:13,757 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:13,768 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:13,776 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:13,776 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:13,777 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:21:13,777 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:13,789 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:13,789 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:13,789 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:13,794 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:13,794 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:13,798 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:13,798 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:13,799 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:21:13,799 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:13,847 [Thread-0] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:14,035 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:21:14,190 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:21:14,242 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:14,243 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:14,410 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:14,411 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:14,525 [Thread-0] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:14,530 [Thread-0] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:14,680 [Thread-0] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:15,102 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:15,103 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:15,149 [Thread-0] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:15,215 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@650c2241] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:15,239 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:15,245 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:15,267 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4163ms
2020-12-03 07:21:15,422 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:15,427 [Thread-0] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:15,428 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:15,440 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:15,444 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:15,444 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:15,445 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:15,480 [Thread-0] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:15,480 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:15,494 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39280
2020-12-03 07:21:15,497 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:15,557 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e86a22b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:15,558 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11b26ef7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:15,605 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69e7280{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:15,616 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5d7b9188{HTTP/1.1,[http/1.1]}{localhost:39280}
2020-12-03 07:21:15,617 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @4514ms
2020-12-03 07:21:15,636 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:15,637 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:15,638 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:15,638 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:15,639 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:15,639 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:15,639 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:15,640 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:15,641 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:15,642 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:15,642 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:15,643 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:15,644 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:15
2020-12-03 07:21:15,644 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:15,644 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:15,645 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:15,645 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:15,652 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:15,653 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:15,653 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:15,654 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:15,654 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:15,654 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:15,655 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:15,655 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:15,655 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:15,655 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:15,656 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:15,656 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:15,656 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:15,657 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:15,657 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:15,657 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:15,660 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:15,661 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:15,661 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:15,661 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:15,662 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:15,662 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:15,662 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:15,662 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:15,663 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:15,663 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:15,665 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:15,665 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:15,665 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:15,666 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:15,666 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:15,666 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:15,667 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:15,667 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:15,668 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:15,757 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:15,847 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:15,852 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:15,852 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:15,853 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:15,854 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:15,897 [Thread-0] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:15,907 [Thread-0] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:15,908 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:15,915 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:15,917 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:16,148 [Thread-0] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:16,148 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 478 msecs
2020-12-03 07:21:16,362 [Thread-0] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:16,431 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:16,453 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:16,824 [Listener at localhost/44463] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:44463 to access this namenode/service.
2020-12-03 07:21:16,827 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:16,862 [Listener at localhost/44463] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:16,882 [Listener at localhost/44463] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:16,889 [Listener at localhost/44463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:16,890 [Listener at localhost/44463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:16,890 [Listener at localhost/44463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:16,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:16,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:16,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:16,894 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:16,895 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:16,895 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:21:16,940 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:16,954 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:16,963 [Listener at localhost/44463] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44463
2020-12-03 07:21:16,968 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:16,969 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:16,999 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 30 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:17,005 [CacheReplicationMonitor(1734448472)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:17,005 [Listener at localhost/44463] INFO  sps.StoragePolicySatisfyManager (StoragePolicySatisfyManager.java:start(108)) - Storage policy satisfier is configured as external, please start external sps service explicitly to satisfy policy
2020-12-03 07:21:17,016 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,[SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:17,088 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:17,105 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:17,106 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:17,153 [Listener at localhost/44463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:17,159 [Listener at localhost/44463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:17,163 [Listener at localhost/44463] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:17,168 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:17,170 [Listener at localhost/44463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:17,175 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:17,182 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41434
2020-12-03 07:21:17,185 [Listener at localhost/44463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:17,185 [Listener at localhost/44463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:17,210 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:17,212 [Listener at localhost/44463] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:17,213 [Listener at localhost/44463] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:17,213 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:17,216 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:17,217 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:17,217 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:17,218 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:17,223 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33211
2020-12-03 07:21:17,223 [Listener at localhost/44463] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:17,225 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30c7383e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:17,226 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b512b16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:17,235 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7c8065d3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:17,236 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@36e67abd{HTTP/1.1,[http/1.1]}{localhost:33211}
2020-12-03 07:21:17,236 [Listener at localhost/44463] INFO  server.Server (Server.java:doStart(419)) - Started @6132ms
2020-12-03 07:21:17,646 [Listener at localhost/44463] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41037
2020-12-03 07:21:17,647 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b3fe6e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:17,648 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:17,648 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:17,866 [Listener at localhost/44463] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:17,868 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:17,881 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46794
2020-12-03 07:21:17,905 [Listener at localhost/46794] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:17,907 [Listener at localhost/46794] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:17,921 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:17,929 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:17,929 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:17,935 [Listener at localhost/46794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:17,938 [Listener at localhost/46794] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:17,939 [Listener at localhost/46794] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:17,940 [Listener at localhost/46794] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:17,942 [Listener at localhost/46794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:17,942 [Listener at localhost/46794] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:17,943 [Listener at localhost/46794] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:17,943 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:17,943 [Listener at localhost/46794] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:17,944 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:17,944 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36642
2020-12-03 07:21:17,945 [Listener at localhost/46794] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:17,945 [Listener at localhost/46794] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:17,946 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:17,947 [Listener at localhost/46794] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:17,948 [Listener at localhost/46794] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:17,948 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:17,951 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:17,954 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:17,955 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:17,955 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:17,956 [Listener at localhost/46794] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40366
2020-12-03 07:21:17,956 [Listener at localhost/46794] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:17,958 [Listener at localhost/46794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f363959{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:17,959 [Listener at localhost/46794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76e683bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:17,966 [Listener at localhost/46794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5062dc65{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:17,967 [Listener at localhost/46794] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b9f288{HTTP/1.1,[http/1.1]}{localhost:40366}
2020-12-03 07:21:17,968 [Listener at localhost/46794] INFO  server.Server (Server.java:doStart(419)) - Started @6864ms
2020-12-03 07:21:18,054 [Listener at localhost/46794] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43750
2020-12-03 07:21:18,056 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@417fa1d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:18,056 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:18,056 [Listener at localhost/46794] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:18,058 [Listener at localhost/46794] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:18,059 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:18,072 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43473
2020-12-03 07:21:18,080 [Listener at localhost/43473] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:18,081 [Listener at localhost/43473] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:18,082 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:18,086 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:18,087 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:18,091 [Listener at localhost/43473] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8,[SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:18,094 [Listener at localhost/43473] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:18,095 [Listener at localhost/43473] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:18,096 [Listener at localhost/43473] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:18,098 [Listener at localhost/43473] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:18,098 [Listener at localhost/43473] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:18,098 [Listener at localhost/43473] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:18,099 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:18,099 [Listener at localhost/43473] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:18,099 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:18,100 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40696
2020-12-03 07:21:18,101 [Listener at localhost/43473] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:18,101 [Listener at localhost/43473] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:18,103 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:18,105 [Listener at localhost/43473] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:18,107 [Listener at localhost/43473] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:18,107 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:18,109 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:18,110 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:18,110 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:18,110 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:18,111 [Listener at localhost/43473] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36027
2020-12-03 07:21:18,112 [Listener at localhost/43473] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:18,115 [Listener at localhost/43473] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d24827e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:18,116 [Listener at localhost/43473] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@287b322a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:18,126 [Listener at localhost/43473] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c273d1a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:18,129 [Listener at localhost/43473] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25d21441{HTTP/1.1,[http/1.1]}{localhost:36027}
2020-12-03 07:21:18,129 [Listener at localhost/43473] INFO  server.Server (Server.java:doStart(419)) - Started @7026ms
2020-12-03 07:21:18,152 [Listener at localhost/43473] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35411
2020-12-03 07:21:18,153 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:18,153 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@184a732c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:18,153 [Listener at localhost/43473] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:18,154 [Listener at localhost/43473] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:18,155 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:18,159 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36764
2020-12-03 07:21:18,164 [Listener at localhost/36764] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:18,164 [Listener at localhost/36764] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:18,165 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:18,166 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:18,167 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:18,262 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:18,262 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:18,262 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:18,266 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:18,266 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:18,266 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:18,383 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,383 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,383 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,385 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,385 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,385 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,386 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:21:18,386 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ae775029-a61b-4f26-a0e5-6277905b7a36 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:18,386 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf2f2b30-defe-47c4-80cc-453742547de7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:18,628 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:18,636 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:18,636 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:18,738 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:18,740 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:18,740 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:18,830 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,830 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,830 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:18,831 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,831 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,831 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:18,831 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:21:18,831 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-80bce346-a7b9-4fd3-86e3-15549db32030 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:18,832 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e319569f-16de-4b3a-aa67-1022e111f90c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:18,842 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:18,843 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:18,843 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:18,945 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:18,946 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:18,946 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,052 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,053 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,053 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,068 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:19,069 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:19,068 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:19,070 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:19,070 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:21:19,068 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:19,069 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a6cf745c-b5df-4590-95aa-93005bed4894 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:19,071 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1399999547. Formatting...
2020-12-03 07:21:19,072 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:19,164 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,172 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,172 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,229 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,229 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,230 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,230 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,231 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,232 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,232 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,232 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,232 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,235 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,236 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,236 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,276 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,277 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,277 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,380 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,380 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,381 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,413 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,414 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,414 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,414 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,416 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,417 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,417 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,417 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,421 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,422 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,422 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,422 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,483 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,484 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,484 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,586 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,587 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,588 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,616 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,616 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,617 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,617 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,617 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,617 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,617 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,618 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,618 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,618 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:19,618 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1996015613-172.17.0.5-1606980073827 is not formatted. Formatting ...
2020-12-03 07:21:19,618 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1996015613-172.17.0.5-1606980073827 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current
2020-12-03 07:21:19,690 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,691 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,691 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,793 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,794 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,794 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:19,814 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=null
2020-12-03 07:21:19,814 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=null
2020-12-03 07:21:19,815 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=null
2020-12-03 07:21:19,896 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:19,898 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:19,898 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,000 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,001 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:20,001 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,103 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,104 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:20,104 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,179 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:20,179 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:20,181 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:20,211 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,212 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:20,212 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,315 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,315 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bf2f2b30-defe-47c4-80cc-453742547de7
2020-12-03 07:21:20,315 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ae775029-a61b-4f26-a0e5-6277905b7a36
2020-12-03 07:21:20,315 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b0428128-ad9c-4be8-b69b-3946ab4726e2
2020-12-03 07:21:20,316 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:20,316 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:20,317 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:20,317 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,316 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:20,318 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-80bce346-a7b9-4fd3-86e3-15549db32030
2020-12-03 07:21:20,319 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: ARCHIVE
2020-12-03 07:21:20,320 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673
2020-12-03 07:21:20,320 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:20,322 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e319569f-16de-4b3a-aa67-1022e111f90c
2020-12-03 07:21:20,322 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:20,323 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9
2020-12-03 07:21:20,323 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: SSD
2020-12-03 07:21:20,324 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66
2020-12-03 07:21:20,325 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: SSD
2020-12-03 07:21:20,326 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a6cf745c-b5df-4590-95aa-93005bed4894
2020-12-03 07:21:20,326 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: SSD
2020-12-03 07:21:20,328 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:20,328 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:20,328 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:20,334 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:20,334 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:20,335 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:20,341 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:20,341 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:20,341 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:20,342 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:20,342 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:20,342 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:20,343 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:20,343 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:20,343 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:20,344 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:20,343 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:20,344 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:20,344 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:20,344 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:20,344 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,344 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:20,344 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,344 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,345 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:20,345 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:20,345 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:20,345 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:20,345 [Thread-133] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:20,345 [Thread-134] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:20,346 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:20,346 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:20,346 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:20,399 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 54ms
2020-12-03 07:21:20,399 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 54ms
2020-12-03 07:21:20,399 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 54ms
2020-12-03 07:21:20,403 [Thread-133] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 57ms
2020-12-03 07:21:20,405 [Thread-134] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 59ms
2020-12-03 07:21:20,405 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 58ms
2020-12-03 07:21:20,405 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 59ms
2020-12-03 07:21:20,405 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 60ms
2020-12-03 07:21:20,405 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 61ms
2020-12-03 07:21:20,405 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 61ms
2020-12-03 07:21:20,406 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 61ms
2020-12-03 07:21:20,406 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 62ms
2020-12-03 07:21:20,408 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:20,408 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:20,408 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:20,408 [Thread-149] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,408 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:20,409 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:20,409 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:20,409 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:20,409 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:20,411 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:20,408 [Thread-147] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,408 [Thread-148] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,409 [Thread-150] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,409 [Thread-155] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,411 [Thread-152] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,409 [Thread-151] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,409 [Thread-153] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,409 [Thread-154] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:20,413 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 6ms
2020-12-03 07:21:20,413 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 3ms
2020-12-03 07:21:20,414 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:21:20,414 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 6ms
2020-12-03 07:21:20,414 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 6ms
2020-12-03 07:21:20,414 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-12-03 07:21:20,415 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 6ms
2020-12-03 07:21:20,415 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-12-03 07:21:20,415 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 6ms
2020-12-03 07:21:20,415 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 9ms
2020-12-03 07:21:20,415 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 9ms
2020-12-03 07:21:20,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:20,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:20,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:20,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:20,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:20,418 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 12ms
2020-12-03 07:21:20,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:20,419 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,419 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,421 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:20,421 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:20,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,422 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c): finished scanning block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,441 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:04 AM with interval of 21600000ms
2020-12-03 07:21:20,443 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:36 AM with interval of 21600000ms
2020-12-03 07:21:20,441 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:33 AM with interval of 21600000ms
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:21:20,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:21:20,449 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:20,449 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:20,449 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:20,460 [IPC Server handler 7 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36642, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=43750, infoSecurePort=0, ipcPort=43473, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:20,463 [IPC Server handler 7 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36642
2020-12-03 07:21:20,463 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9d698ef-926b-4d95-bc80-d0e616a324a2 (127.0.0.1:36642).
2020-12-03 07:21:20,465 [IPC Server handler 8 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41434, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=41037, infoSecurePort=0, ipcPort=46794, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:20,465 [IPC Server handler 8 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41434
2020-12-03 07:21:20,466 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82 (127.0.0.1:41434).
2020-12-03 07:21:20,466 [IPC Server handler 6 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40696, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=35411, infoSecurePort=0, ipcPort=36764, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:20,466 [IPC Server handler 6 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40696
2020-12-03 07:21:20,466 [IPC Server handler 6 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6d14ddac-f131-49f3-9dd2-444db68ba3d9 (127.0.0.1:40696).
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:20,468 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:20,490 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf2f2b30-defe-47c4-80cc-453742547de7 for DN 127.0.0.1:36642
2020-12-03 07:21:20,491 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80bce346-a7b9-4fd3-86e3-15549db32030 for DN 127.0.0.1:36642
2020-12-03 07:21:20,491 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6cf745c-b5df-4590-95aa-93005bed4894 for DN 127.0.0.1:36642
2020-12-03 07:21:20,492 [IPC Server handler 9 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae775029-a61b-4f26-a0e5-6277905b7a36 for DN 127.0.0.1:41434
2020-12-03 07:21:20,493 [IPC Server handler 9 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e319569f-16de-4b3a-aa67-1022e111f90c for DN 127.0.0.1:41434
2020-12-03 07:21:20,493 [IPC Server handler 9 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 for DN 127.0.0.1:41434
2020-12-03 07:21:20,494 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 for DN 127.0.0.1:40696
2020-12-03 07:21:20,494 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 for DN 127.0.0.1:40696
2020-12-03 07:21:20,494 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 for DN 127.0.0.1:40696
2020-12-03 07:21:20,527 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x93bd20473a035131: Processing first storage report for DS-80bce346-a7b9-4fd3-86e3-15549db32030 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:20,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x93bd20473a035131: from storage DS-80bce346-a7b9-4fd3-86e3-15549db32030 node DatanodeRegistration(127.0.0.1:36642, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=43750, infoSecurePort=0, ipcPort=43473, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x435d42bcb9253a3d: Processing first storage report for DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x435d42bcb9253a3d: from storage DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 node DatanodeRegistration(127.0.0.1:40696, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=35411, infoSecurePort=0, ipcPort=36764, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x99089dc90fff1cad: Processing first storage report for DS-ae775029-a61b-4f26-a0e5-6277905b7a36 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x99089dc90fff1cad: from storage DS-ae775029-a61b-4f26-a0e5-6277905b7a36 node DatanodeRegistration(127.0.0.1:41434, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=41037, infoSecurePort=0, ipcPort=46794, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x93bd20473a035131: Processing first storage report for DS-a6cf745c-b5df-4590-95aa-93005bed4894 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x93bd20473a035131: from storage DS-a6cf745c-b5df-4590-95aa-93005bed4894 node DatanodeRegistration(127.0.0.1:36642, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=43750, infoSecurePort=0, ipcPort=43473, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x435d42bcb9253a3d: Processing first storage report for DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:20,530 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x435d42bcb9253a3d: from storage DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 node DatanodeRegistration(127.0.0.1:40696, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=35411, infoSecurePort=0, ipcPort=36764, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x99089dc90fff1cad: Processing first storage report for DS-e319569f-16de-4b3a-aa67-1022e111f90c from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:20,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x99089dc90fff1cad: from storage DS-e319569f-16de-4b3a-aa67-1022e111f90c node DatanodeRegistration(127.0.0.1:41434, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=41037, infoSecurePort=0, ipcPort=46794, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x93bd20473a035131: Processing first storage report for DS-bf2f2b30-defe-47c4-80cc-453742547de7 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:20,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x93bd20473a035131: from storage DS-bf2f2b30-defe-47c4-80cc-453742547de7 node DatanodeRegistration(127.0.0.1:36642, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=43750, infoSecurePort=0, ipcPort=43473, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x435d42bcb9253a3d: Processing first storage report for DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:20,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x435d42bcb9253a3d: from storage DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 node DatanodeRegistration(127.0.0.1:40696, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=35411, infoSecurePort=0, ipcPort=36764, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x99089dc90fff1cad: Processing first storage report for DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:20,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x99089dc90fff1cad: from storage DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 node DatanodeRegistration(127.0.0.1:41434, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=41037, infoSecurePort=0, ipcPort=46794, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:20,537 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:20,546 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,547 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x93bd20473a035131,  containing 3 storage report(s), of which we sent 3. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x435d42bcb9253a3d,  containing 3 storage report(s), of which we sent 3. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x99089dc90fff1cad,  containing 3 storage report(s), of which we sent 3. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,552 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:20,630 [Listener at localhost/36764] INFO  sps.StoragePolicySatisfier (StoragePolicySatisfier.java:start(159)) - Starting external StoragePolicySatisfier.
2020-12-03 07:21:20,631 [SPSPathIdProcessor] INFO  sps.BlockStorageMovementNeeded (BlockStorageMovementNeeded.java:run(234)) - Starting SPSPathIdProcessor!.
2020-12-03 07:21:20,632 [Listener at localhost/36764] INFO  sps.DatanodeCacheManager (DatanodeCacheManager.java:<init>(65)) - DatanodeCacheManager refresh interval is 1000 milliseconds
2020-12-03 07:21:20,634 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,634 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,641 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:20,651 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:20,691 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:20,744 [IPC Server handler 0 on default port 44463] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40696, 127.0.0.1:36642, 127.0.0.1:41434 for /testFile
2020-12-03 07:21:20,759 [Thread-171] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:20,818 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:52578 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001 src: /127.0.0.1:52578 dest: /127.0.0.1:40696
2020-12-03 07:21:20,838 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:52578 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:20,840 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33670 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001 src: /127.0.0.1:33670 dest: /127.0.0.1:36642
2020-12-03 07:21:20,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33670 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:20,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:50570 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001 src: /127.0.0.1:50570 dest: /127.0.0.1:41434
2020-12-03 07:21:20,892 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50570, dest: /127.0.0.1:41434, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, duration(ns): 16422651
2020-12-03 07:21:20,893 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:20,896 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41434]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33670, dest: /127.0.0.1:36642, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: e9d698ef-926b-4d95-bc80-d0e616a324a2, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, duration(ns): 40464764
2020-12-03 07:21:20,898 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41434]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41434] terminating
2020-12-03 07:21:20,901 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36642, 127.0.0.1:41434]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52578, dest: /127.0.0.1:40696, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 6d14ddac-f131-49f3-9dd2-444db68ba3d9, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, duration(ns): 42706260
2020-12-03 07:21:20,901 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36642, 127.0.0.1:41434]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36642, 127.0.0.1:41434] terminating
2020-12-03 07:21:20,909 [IPC Server handler 8 on default port 44463] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /testFile
2020-12-03 07:21:21,318 [IPC Server handler 9 on default port 44463] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testFile is closed by DFSClient_NONMAPREDUCE_-831999747_24
2020-12-03 07:21:21,321 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/parentDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:21,323 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/parentDir/parentFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:21,327 [IPC Server handler 4 on default port 44463] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:36642, 127.0.0.1:41434, 127.0.0.1:40696 for /parentDir/parentFile
2020-12-03 07:21:21,329 [Thread-180] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,330 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33674 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 src: /127.0.0.1:33674 dest: /127.0.0.1:36642
2020-12-03 07:21:21,331 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33674 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,333 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:50574 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 src: /127.0.0.1:50574 dest: /127.0.0.1:41434
2020-12-03 07:21:21,334 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:50574 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,334 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:52588 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 src: /127.0.0.1:52588 dest: /127.0.0.1:40696
2020-12-03 07:21:21,344 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52588, dest: /127.0.0.1:40696, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 6d14ddac-f131-49f3-9dd2-444db68ba3d9, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, duration(ns): 7626480
2020-12-03 07:21:21,345 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:21,347 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50574, dest: /127.0.0.1:41434, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, duration(ns): 10036485
2020-12-03 07:21:21,347 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696] terminating
2020-12-03 07:21:21,349 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33674, dest: /127.0.0.1:36642, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: e9d698ef-926b-4d95-bc80-d0e616a324a2, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, duration(ns): 12625764
2020-12-03 07:21:21,350 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696] terminating
2020-12-03 07:21:21,351 [IPC Server handler 1 on default port 44463] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /parentDir/parentFile is closed by DFSClient_NONMAPREDUCE_-831999747_24
2020-12-03 07:21:21,353 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/parentDir/childDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:21,355 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/parentDir/childDir/childFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:21,359 [IPC Server handler 9 on default port 44463] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:36642, 127.0.0.1:41434, 127.0.0.1:40696 for /parentDir/childDir/childFile
2020-12-03 07:21:21,361 [Thread-188] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,362 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33680 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 src: /127.0.0.1:33680 dest: /127.0.0.1:36642
2020-12-03 07:21:21,363 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:33680 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,365 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:50580 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 src: /127.0.0.1:50580 dest: /127.0.0.1:41434
2020-12-03 07:21:21,366 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:50580 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:21,367 [DataXceiver for client DFSClient_NONMAPREDUCE_-831999747_24 at /127.0.0.1:52594 [Receiving block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 src: /127.0.0.1:52594 dest: /127.0.0.1:40696
2020-12-03 07:21:21,379 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52594, dest: /127.0.0.1:40696, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 6d14ddac-f131-49f3-9dd2-444db68ba3d9, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, duration(ns): 9413729
2020-12-03 07:21:21,379 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:21,382 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50580, dest: /127.0.0.1:41434, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, duration(ns): 13081930
2020-12-03 07:21:21,382 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40696] terminating
2020-12-03 07:21:21,384 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33680, dest: /127.0.0.1:36642, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-831999747_24, offset: 0, srvID: e9d698ef-926b-4d95-bc80-d0e616a324a2, blockid: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, duration(ns): 13905254
2020-12-03 07:21:21,384 [PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41434, 127.0.0.1:40696] terminating
2020-12-03 07:21:21,386 [IPC Server handler 3 on default port 44463] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /parentDir/childDir/childFile is closed by DFSClient_NONMAPREDUCE_-831999747_24
2020-12-03 07:21:21,392 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:21,401 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
All blocks of file /testFile verified to have replication factor 3
2020-12-03 07:21:21,410 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:21,412 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
All blocks of file /parentDir/parentFile verified to have replication factor 3
2020-12-03 07:21:21,415 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/parentDir/childDir/childFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:21,417 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/childDir/childFile	dst=null	perm=null	proto=rpc
All blocks of file /parentDir/childDir/childFile verified to have replication factor 3
2020-12-03 07:21:21,424 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/testFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:21,429 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=satisfyStoragePolicy	src=/testFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:21,432 [Listener at localhost/36764] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:40696 from a total of 3 datanodes.
2020-12-03 07:21:21,433 [Listener at localhost/36764] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:21,433 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4c11fec3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:21,435 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9) exiting.
2020-12-03 07:21:21,435 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673) exiting.
2020-12-03 07:21:21,435 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2) exiting.
2020-12-03 07:21:21,463 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c273d1a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:21,470 [Listener at localhost/36764] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25d21441{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:21,484 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@287b322a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:21,485 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d24827e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:21,505 [Listener at localhost/36764] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36764
2020-12-03 07:21:21,508 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:21,508 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:21,511 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:21,511 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,511 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9)
2020-12-03 07:21:21,511 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:21,513 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,514 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,515 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,518 [Listener at localhost/36764] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:21,518 [Listener at localhost/36764] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:21,518 [Listener at localhost/36764] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:21,518 [Listener at localhost/36764] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:21,524 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:21,526 [Listener at localhost/36764] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:21,526 [Listener at localhost/36764] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:21,526 [Listener at localhost/36764] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:21,528 [Listener at localhost/36764] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:21,528 [Listener at localhost/36764] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,528 [Listener at localhost/36764] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:21,529 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:21,529 [Listener at localhost/36764] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,529 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:21,530 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41087
2020-12-03 07:21:21,530 [Listener at localhost/36764] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:21,530 [Listener at localhost/36764] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:21,531 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,533 [Listener at localhost/36764] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:21,533 [Listener at localhost/36764] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:21,534 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,535 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:21,536 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:21,537 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:21,537 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:21,538 [Listener at localhost/36764] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42979
2020-12-03 07:21:21,538 [Listener at localhost/36764] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:21,540 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28068176{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:21,540 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b19de0a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:21,546 [Listener at localhost/36764] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2b39af71{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:21,547 [Listener at localhost/36764] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79fd4513{HTTP/1.1,[http/1.1]}{localhost:42979}
2020-12-03 07:21:21,548 [Listener at localhost/36764] INFO  server.Server (Server.java:doStart(419)) - Started @10444ms
2020-12-03 07:21:21,590 [Listener at localhost/36764] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46799
2020-12-03 07:21:21,591 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@bbd36e6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:21,591 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:21,591 [Listener at localhost/36764] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:21,592 [Listener at localhost/36764] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:21,592 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:21,598 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36941
2020-12-03 07:21:21,606 [Listener at localhost/36941] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:21,606 [Listener at localhost/36941] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:21,607 [Thread-207] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:21,608 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:21,608 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:21,611 [Listener at localhost/36941] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 2
2020-12-03 07:21:21,612 [Listener at localhost/36941] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:36642 from a total of 3 datanodes.
2020-12-03 07:21:21,612 [Listener at localhost/36941] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:21,613 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ac1923d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:21,613 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030) exiting.
2020-12-03 07:21:21,613 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894) exiting.
2020-12-03 07:21:21,613 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7) exiting.
2020-12-03 07:21:21,616 [Thread-207] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,617 [Thread-207] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:21,690 [Thread-207] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:21,703 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5062dc65{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:21,714 [Listener at localhost/36941] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b9f288{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:21,715 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76e683bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:21,716 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f363959{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:21,726 [Listener at localhost/36941] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43473
2020-12-03 07:21:21,733 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:21,738 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:21,752 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:21,754 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,754 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2)
2020-12-03 07:21:21,754 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:21,755 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,756 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,756 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,765 [Listener at localhost/36941] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:21,766 [Listener at localhost/36941] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:21,766 [Listener at localhost/36941] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:21,767 [Listener at localhost/36941] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:21,769 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:21,771 [Listener at localhost/36941] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:21,775 [Listener at localhost/36941] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:21,776 [Listener at localhost/36941] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:21,778 [Listener at localhost/36941] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:21,779 [Listener at localhost/36941] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,779 [Listener at localhost/36941] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:21,780 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:21,780 [Listener at localhost/36941] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,780 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:21,781 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36124
2020-12-03 07:21:21,781 [Listener at localhost/36941] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:21,781 [Listener at localhost/36941] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:21,782 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,784 [Listener at localhost/36941] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:21,785 [Listener at localhost/36941] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:21,785 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,787 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:21,788 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:21,788 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:21,789 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:21,790 [Listener at localhost/36941] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43312
2020-12-03 07:21:21,790 [Listener at localhost/36941] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:21,792 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ee5bc25{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:21,793 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f8406e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:21,801 [Listener at localhost/36941] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@15fb0d33{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:21,803 [Listener at localhost/36941] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25b2f2ea{HTTP/1.1,[http/1.1]}{localhost:43312}
2020-12-03 07:21:21,803 [Listener at localhost/36941] INFO  server.Server (Server.java:doStart(419)) - Started @10700ms
2020-12-03 07:21:21,827 [Listener at localhost/36941] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36385
2020-12-03 07:21:21,827 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:21,827 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15bcd4a9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:21,828 [Listener at localhost/36941] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:21,828 [Listener at localhost/36941] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:21,829 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:21,833 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43415
2020-12-03 07:21:21,846 [Listener at localhost/43415] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:21,846 [Listener at localhost/43415] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:21,847 [Thread-229] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:21,851 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:21,851 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:21,855 [Listener at localhost/43415] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 1
2020-12-03 07:21:21,855 [Listener at localhost/43415] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:41434 from a total of 3 datanodes.
2020-12-03 07:21:21,855 [Listener at localhost/43415] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:21,855 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68e39081] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:21,857 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66) exiting.
2020-12-03 07:21:21,857 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36) exiting.
2020-12-03 07:21:21,857 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c) exiting.
2020-12-03 07:21:21,857 [Thread-229] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,858 [Thread-229] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:21,880 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7c8065d3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:21,881 [Listener at localhost/43415] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@36e67abd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:21,881 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b512b16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:21,882 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30c7383e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:21,883 [Listener at localhost/43415] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46794
2020-12-03 07:21:21,887 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:21,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:21,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:21,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82)
2020-12-03 07:21:21,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:21,891 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,891 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,891 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:21,900 [Listener at localhost/43415] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:21,900 [Listener at localhost/43415] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:21,902 [Listener at localhost/43415] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:21,903 [Listener at localhost/43415] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:21,907 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:21,909 [Listener at localhost/43415] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:21,910 [Listener at localhost/43415] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:21,910 [Listener at localhost/43415] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:21,912 [Listener at localhost/43415] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:21,912 [Listener at localhost/43415] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,913 [Listener at localhost/43415] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:21,913 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:21,913 [Listener at localhost/43415] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:21,913 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:21,914 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36186
2020-12-03 07:21:21,914 [Listener at localhost/43415] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:21,914 [Listener at localhost/43415] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:21,916 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,918 [Listener at localhost/43415] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:21,918 [Listener at localhost/43415] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:21,918 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:21,920 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:21,921 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:21,921 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:21,921 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:21,922 [Listener at localhost/43415] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42103
2020-12-03 07:21:21,922 [Listener at localhost/43415] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:21,924 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62ad106c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:21,924 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6361bf51{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:21,931 [Listener at localhost/43415] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7250c047{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:21,934 [Listener at localhost/43415] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c033b68{HTTP/1.1,[http/1.1]}{localhost:42103}
2020-12-03 07:21:21,934 [Listener at localhost/43415] INFO  server.Server (Server.java:doStart(419)) - Started @10830ms
2020-12-03 07:21:21,952 [Listener at localhost/43415] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38296
2020-12-03 07:21:21,953 [Thread-207] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:21,953 [Thread-229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:21,953 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3eb5b7dd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:21,953 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:21,953 [Listener at localhost/43415] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:21,954 [Listener at localhost/43415] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:21,954 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:21,958 [Listener at localhost/43378] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43378
2020-12-03 07:21:21,972 [Listener at localhost/43378] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:21,972 [Listener at localhost/43378] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:21,973 [Thread-251] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:21,978 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:21,978 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:21,981 [Listener at localhost/43378] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 0
2020-12-03 07:21:21,981 [Listener at localhost/43378] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:21,981 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:21,981 [Thread-251] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:21,984 [Thread-251] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:21,984 [Listener at localhost/43378] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 20
2020-12-03 07:21:21,984 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@31491659] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:21,984 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5f222cdc] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:21,985 [Listener at localhost/43378] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 21 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 2 Number of syncs: 20 SyncTimes(ms): 5 3 
2020-12-03 07:21:21,987 [Listener at localhost/43378] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021
2020-12-03 07:21:21,988 [Listener at localhost/43378] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021
2020-12-03 07:21:21,988 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:21,989 [CacheReplicationMonitor(1734448472)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:22,003 [Listener at localhost/43378] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44463
2020-12-03 07:21:22,005 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:22,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:22,006 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:22,006 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:22,051 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:22,051 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:22,054 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69e7280{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:22,060 [Listener at localhost/43378] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5d7b9188{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:22,060 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11b26ef7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:22,060 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e86a22b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:22,068 [Thread-251] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,070 [Listener at localhost/43378] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:22,070 [Listener at localhost/43378] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:22,071 [Listener at localhost/43378] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:44463
2020-12-03 07:21:22,071 [Listener at localhost/43378] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:44463 to access this namenode/service.
2020-12-03 07:21:22,087 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47acb77a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:22,087 [Listener at localhost/43378] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:39280
2020-12-03 07:21:22,087 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:22,088 [Listener at localhost/43378] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:22,089 [Listener at localhost/43378] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:22,089 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:22,092 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:22,092 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:22,092 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:22,093 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:22,094 [Listener at localhost/43378] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:22,095 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:22,095 [Listener at localhost/43378] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39280
2020-12-03 07:21:22,095 [Listener at localhost/43378] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:22,101 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32871097{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:22,102 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3bb3576f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:22,109 [Listener at localhost/43378] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f4896cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:22,112 [Listener at localhost/43378] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5e403670{HTTP/1.1,[http/1.1]}{localhost:39280}
2020-12-03 07:21:22,112 [Listener at localhost/43378] INFO  server.Server (Server.java:doStart(419)) - Started @11008ms
2020-12-03 07:21:22,115 [Listener at localhost/43378] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:22,115 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:22,115 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:22,116 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:22,116 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:22,116 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:22,116 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:22,116 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:22,117 [Listener at localhost/43378] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:22,117 [Listener at localhost/43378] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:22,117 [Listener at localhost/43378] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:22,117 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:22,118 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:22
2020-12-03 07:21:22,118 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:22,118 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,118 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.2 MB
2020-12-03 07:21:22,119 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:22,123 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:22,124 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:22,125 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,126 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.1 MB
2020-12-03 07:21:22,126 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:22,128 [Listener at localhost/43378] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:22,128 [Listener at localhost/43378] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,129 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.8 MB
2020-12-03 07:21:22,130 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:22,130 [Listener at localhost/43378] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,131 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 586.8 KB
2020-12-03 07:21:22,132 [Listener at localhost/43378] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:22,209 [Thread-207] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,209 [Listener at localhost/43378] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,211 [Thread-229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,376 [Listener at localhost/43378] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,376 [Thread-251] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,379 [Listener at localhost/43378] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:22,380 [Listener at localhost/43378] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:22,384 [Thread-207] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,385 [Thread-207] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,386 [Listener at localhost/43378] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:22,391 [Listener at localhost/43378] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:22,392 [Listener at localhost/43378] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:22,393 [Listener at localhost/43378] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:22,396 [Listener at localhost/43378] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5ec523e4 expecting start txid #1
2020-12-03 07:21:22,396 [Listener at localhost/43378] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:22,397 [Listener at localhost/43378] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021' to transaction ID 1
2020-12-03 07:21:22,439 [Listener at localhost/43378] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021) of total size 1497.0, total edits 21.0, total load time 18.0 ms
2020-12-03 07:21:22,440 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:22,441 [Listener at localhost/43378] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 22
2020-12-03 07:21:22,498 [Thread-229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,507 [Thread-207] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,507 [Thread-207] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,649 [Thread-251] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:22,657 [Thread-207] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,658 [Thread-207] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,659 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,659 [Thread-229] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,704 [Listener at localhost/43378] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:22,704 [Listener at localhost/43378] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 571 msecs
2020-12-03 07:21:22,704 [Listener at localhost/43378] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:44463
2020-12-03 07:21:22,705 [Listener at localhost/43378] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:22,706 [Socket Reader #1 for port 44463] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 44463
2020-12-03 07:21:22,711 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:22,757 [Listener at localhost/44463] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:22,767 [Thread-207] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:22,769 [Listener at localhost/44463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:22,781 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b0428128-ad9c-4be8-b69b-3946ab4726e2
2020-12-03 07:21:22,785 [Thread-207] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:22,788 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,788 [Thread-251] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,788 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:22,788 [IPC Server listener on 44463] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 44463: starting
2020-12-03 07:21:22,795 [Listener at localhost/44463] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44463
2020-12-03 07:21:22,795 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,795 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673
2020-12-03 07:21:22,797 [Thread-229] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,795 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:22,798 [Thread-207] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:22,798 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:22,801 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9
2020-12-03 07:21:22,806 [Thread-207] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: SSD
2020-12-03 07:21:22,807 [Thread-207] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:22,808 [Thread-207] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:22,809 [Thread-207] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:22,809 [Thread-207] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:22,809 [Thread-207] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:22,809 [Thread-207] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:22,810 [Thread-207] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:22,810 [Thread-207] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,810 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:22,810 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:22,810 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:22,813 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 15 milliseconds
name space=6
storage space=9216
storage types=RAM_DISK=0, SSD=1024, DISK=2048, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:22,816 [Thread-298] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:22,819 [Listener at localhost/44463] INFO  sps.StoragePolicySatisfyManager (StoragePolicySatisfyManager.java:start(108)) - Storage policy satisfier is configured as external, please start external sps service explicitly to satisfy policy
2020-12-03 07:21:22,822 [CacheReplicationMonitor(411598322)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:22,825 [Thread-299] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:22,827 [Thread-297] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current: 27693
2020-12-03 07:21:22,842 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:22,855 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 44ms
2020-12-03 07:21:22,859 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:22,859 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:22,856 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 46ms
2020-12-03 07:21:22,855 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 45ms
2020-12-03 07:21:22,862 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 52ms
2020-12-03 07:21:22,862 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:22,862 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:22,862 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:22,862 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:22,863 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:22,863 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:21:22,863 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-12-03 07:21:22,867 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:22,870 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 7ms
2020-12-03 07:21:22,870 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 8ms
2020-12-03 07:21:22,882 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673): no suitable block pools found to scan.  Waiting 1814397535 ms.
2020-12-03 07:21:22,883 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2): no suitable block pools found to scan.  Waiting 1814397534 ms.
2020-12-03 07:21:22,883 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9): no suitable block pools found to scan.  Waiting 1814397534 ms.
2020-12-03 07:21:22,883 [Thread-207] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:24 AM with interval of 21600000ms
2020-12-03 07:21:22,886 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:22,887 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(777)) - Problem connecting to server: localhost/127.0.0.1:44463 :End of File Exception between local host is: "50abf8f67126/172.17.0.5"; destination host is: "localhost":44463; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:22,925 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,926 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,926 [Thread-251] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,926 [Thread-229] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:22,964 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:22,967 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:22,967 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,057 [Thread-229] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:23,065 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bf2f2b30-defe-47c4-80cc-453742547de7
2020-12-03 07:21:23,067 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:23,068 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,069 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,069 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,069 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-80bce346-a7b9-4fd3-86e3-15549db32030
2020-12-03 07:21:23,071 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: ARCHIVE
2020-12-03 07:21:23,069 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,071 [Thread-251] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,072 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a6cf745c-b5df-4590-95aa-93005bed4894
2020-12-03 07:21:23,074 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: SSD
2020-12-03 07:21:23,074 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:23,076 [Thread-229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:23,077 [Thread-229] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:23,077 [Thread-229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:23,077 [Thread-229] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:23,077 [Thread-229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:23,079 [Thread-229] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:23,079 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,079 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:23,079 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:23,079 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:23,081 [Thread-317] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:23,081 [Thread-315] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current: 27693
2020-12-03 07:21:23,088 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 9ms
2020-12-03 07:21:23,089 [Thread-316] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:23,089 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 10ms
2020-12-03 07:21:23,103 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 23ms
2020-12-03 07:21:23,103 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 25ms
2020-12-03 07:21:23,104 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:23,128 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:23,129 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 25ms
2020-12-03 07:21:23,136 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:23,137 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:23,137 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:21:23,141 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:23,141 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:23,142 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:21:23,142 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 39ms
2020-12-03 07:21:23,143 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030): no suitable block pools found to scan.  Waiting 1814397274 ms.
2020-12-03 07:21:23,144 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894): no suitable block pools found to scan.  Waiting 1814397273 ms.
2020-12-03 07:21:23,145 [Thread-229] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:43 PM with interval of 21600000ms
2020-12-03 07:21:23,145 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7): no suitable block pools found to scan.  Waiting 1814397272 ms.
2020-12-03 07:21:23,151 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:23,161 [IPC Server handler 4 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36124, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36385, infoSecurePort=0, ipcPort=43415, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:23,161 [IPC Server handler 4 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36124
2020-12-03 07:21:23,161 [IPC Server handler 4 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9d698ef-926b-4d95-bc80-d0e616a324a2 (127.0.0.1:36124).
2020-12-03 07:21:23,166 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:23,166 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:23,172 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf2f2b30-defe-47c4-80cc-453742547de7 for DN 127.0.0.1:36124
2020-12-03 07:21:23,173 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80bce346-a7b9-4fd3-86e3-15549db32030 for DN 127.0.0.1:36124
2020-12-03 07:21:23,173 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6cf745c-b5df-4590-95aa-93005bed4894 for DN 127.0.0.1:36124
2020-12-03 07:21:23,176 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,179 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,179 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,184 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3532580550016790: Processing first storage report for DS-80bce346-a7b9-4fd3-86e3-15549db32030 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:23,185 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3532580550016790: from storage DS-80bce346-a7b9-4fd3-86e3-15549db32030 node DatanodeRegistration(127.0.0.1:36124, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36385, infoSecurePort=0, ipcPort=43415, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,186 [Thread-251] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:23,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3532580550016790: Processing first storage report for DS-a6cf745c-b5df-4590-95aa-93005bed4894 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:23,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3532580550016790: from storage DS-a6cf745c-b5df-4590-95aa-93005bed4894 node DatanodeRegistration(127.0.0.1:36124, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36385, infoSecurePort=0, ipcPort=43415, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3532580550016790: Processing first storage report for DS-bf2f2b30-defe-47c4-80cc-453742547de7 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:23,187 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:23,189 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:23,189 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:23,189 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:23,189 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:23,193 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ae775029-a61b-4f26-a0e5-6277905b7a36
2020-12-03 07:21:23,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3532580550016790: from storage DS-bf2f2b30-defe-47c4-80cc-453742547de7 node DatanodeRegistration(127.0.0.1:36124, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36385, infoSecurePort=0, ipcPort=43415, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 3, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,194 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:23,197 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e319569f-16de-4b3a-aa67-1022e111f90c
2020-12-03 07:21:23,197 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:23,202 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2020-12-03 07:21:23,205 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3532580550016790,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:23,205 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,207 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66
2020-12-03 07:21:23,210 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: SSD
2020-12-03 07:21:23,211 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:23,213 [Thread-251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:23,214 [Thread-251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:23,214 [Thread-251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:23,214 [Thread-251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:23,215 [Thread-251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:23,215 [Thread-251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:23,215 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,219 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:23,220 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:23,220 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:23,221 [Thread-329] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current: 27693
2020-12-03 07:21:23,222 [Thread-331] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:23,223 [Thread-330] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:23,229 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 9ms
2020-12-03 07:21:23,232 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-12-03 07:21:23,232 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 12ms
2020-12-03 07:21:23,233 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 17ms
2020-12-03 07:21:23,233 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:23,233 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:23,233 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:23,233 [Thread-333] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:23,236 [Thread-334] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:23,236 [Thread-332] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:23,236 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:21:23,236 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-12-03 07:21:23,238 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-12-03 07:21:23,239 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 6ms
2020-12-03 07:21:23,239 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66): no suitable block pools found to scan.  Waiting 1814397180 ms.
2020-12-03 07:21:23,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36): no suitable block pools found to scan.  Waiting 1814397180 ms.
2020-12-03 07:21:23,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c): no suitable block pools found to scan.  Waiting 1814397180 ms.
2020-12-03 07:21:23,240 [Thread-251] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:47 AM with interval of 21600000ms
2020-12-03 07:21:23,243 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:23,244 [IPC Server handler 7 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36186, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=38296, infoSecurePort=0, ipcPort=43378, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:23,244 [IPC Server handler 7 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36186
2020-12-03 07:21:23,245 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82 (127.0.0.1:36186).
2020-12-03 07:21:23,245 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:23,246 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:23,250 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae775029-a61b-4f26-a0e5-6277905b7a36 for DN 127.0.0.1:36186
2020-12-03 07:21:23,253 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e319569f-16de-4b3a-aa67-1022e111f90c for DN 127.0.0.1:36186
2020-12-03 07:21:23,253 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 for DN 127.0.0.1:36186
2020-12-03 07:21:23,258 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x25e96ca73041d2d2: Processing first storage report for DS-ae775029-a61b-4f26-a0e5-6277905b7a36 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:23,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x25e96ca73041d2d2: from storage DS-ae775029-a61b-4f26-a0e5-6277905b7a36 node DatanodeRegistration(127.0.0.1:36186, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=38296, infoSecurePort=0, ipcPort=43378, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 3, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x25e96ca73041d2d2: Processing first storage report for DS-e319569f-16de-4b3a-aa67-1022e111f90c from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:23,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x25e96ca73041d2d2: from storage DS-e319569f-16de-4b3a-aa67-1022e111f90c node DatanodeRegistration(127.0.0.1:36186, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=38296, infoSecurePort=0, ipcPort=43378, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x25e96ca73041d2d2: Processing first storage report for DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:23,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x25e96ca73041d2d2: from storage DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 node DatanodeRegistration(127.0.0.1:36186, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=38296, infoSecurePort=0, ipcPort=43378, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,262 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x25e96ca73041d2d2,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:23,263 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,281 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,282 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,283 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,384 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,385 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,385 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,487 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,488 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,488 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,590 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,591 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,591 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,653 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,653 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,674 [SPSPathIdProcessor] WARN  sps.ExternalSPSContext (ExternalSPSContext.java:getNextSPSPath(171)) - Exception while getting next sps path id from Namenode.
java.io.EOFException: End of File Exception between local host is: "50abf8f67126/172.17.0.5"; destination host is: "localhost":44463; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy27.getNextSPSPath(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getNextSPSPath(NamenodeProtocolTranslatorPB.java:275)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy28.getNextSPSPath(Unknown Source)
	at org.apache.hadoop.hdfs.server.sps.ExternalSPSContext.getNextSPSPath(ExternalSPSContext.java:169)
	at org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded$SPSPathIdProcessor.run(BlockStorageMovementNeeded.java:240)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:21:23,685 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,692 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,693 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,693 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,794 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,795 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:23,796 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:23,888 [IPC Server handler 9 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41087, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=46799, infoSecurePort=0, ipcPort=36941, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:23,889 [IPC Server handler 9 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41087
2020-12-03 07:21:23,889 [IPC Server handler 9 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6d14ddac-f131-49f3-9dd2-444db68ba3d9 (127.0.0.1:41087).
2020-12-03 07:21:23,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:23,890 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:23,893 [IPC Server handler 0 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 for DN 127.0.0.1:41087
2020-12-03 07:21:23,893 [IPC Server handler 0 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 for DN 127.0.0.1:41087
2020-12-03 07:21:23,893 [IPC Server handler 0 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 for DN 127.0.0.1:41087
2020-12-03 07:21:23,896 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a9b63adba82380a: Processing first storage report for DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:23,896 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a9b63adba82380a: from storage DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 node DatanodeRegistration(127.0.0.1:41087, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=46799, infoSecurePort=0, ipcPort=36941, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,896 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a9b63adba82380a: Processing first storage report for DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:23,896 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a9b63adba82380a: from storage DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 node DatanodeRegistration(127.0.0.1:41087, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=46799, infoSecurePort=0, ipcPort=36941, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a9b63adba82380a: Processing first storage report for DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:23,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a9b63adba82380a: from storage DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 node DatanodeRegistration(127.0.0.1:41087, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=46799, infoSecurePort=0, ipcPort=36941, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:23,897 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:23,899 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6a9b63adba82380a,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:23,899 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:23,900 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:23,901 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:24,205 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:24,207 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:24,709 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:24,711 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:25,213 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:25,215 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:25,717 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:25,720 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:26,222 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,223 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:26,680 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,688 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,688 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,689 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,692 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,725 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:26,727 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:27,230 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:27,232 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:27,734 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:27,736 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:28,239 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:28,242 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:28,744 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:28,746 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:29,247 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,249 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=0
2020-12-03 07:21:29,691 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,695 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,700 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,700 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,710 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36124
2020-12-03 07:21:29,711 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36186
2020-12-03 07:21:29,711 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41087
2020-12-03 07:21:29,716 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741825_1001 from src:DatanodeInfoWithStorage[127.0.0.1:36124,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:36124,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:SSD
2020-12-03 07:21:29,717 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,721 [BlockMoverTask-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:29,729 [DataXceiver for client /127.0.0.1:39538 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001 from e9d698ef-926b-4d95-bc80-d0e616a324a2]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741825_1001 from StorageType DISK to SSD
2020-12-03 07:21:29,730 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741825_1001 from src:DatanodeInfoWithStorage[127.0.0.1:36124,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:36124,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] for satisfying storageType:SSD
2020-12-03 07:21:29,732 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType SSD on node 127.0.0.1:36124
2020-12-03 07:21:29,734 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:29,751 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,753 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - SSD replica count, expected=1 and actual=1
2020-12-03 07:21:29,755 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,756 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - DISK replica count, expected=2 and actual=2
2020-12-03 07:21:29,758 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/parentDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:29,760 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=satisfyStoragePolicy	src=/parentDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:29,760 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:36186 from a total of 3 datanodes.
2020-12-03 07:21:29,760 [Listener at localhost/44463] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:29,760 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@602c57ee] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:29,761 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36) exiting.
2020-12-03 07:21:29,761 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66) exiting.
2020-12-03 07:21:29,761 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c) exiting.
2020-12-03 07:21:29,778 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7250c047{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:29,779 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c033b68{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:29,779 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6361bf51{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:29,779 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62ad106c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:29,780 [Listener at localhost/44463] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43378
2020-12-03 07:21:29,783 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:29,783 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:29,786 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:29,786 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463
2020-12-03 07:21:29,786 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82)
2020-12-03 07:21:29,786 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:29,787 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,787 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,787 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,792 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:29,792 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:29,793 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:29,793 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:29,794 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:29,796 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:29,796 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:29,796 [Listener at localhost/44463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:29,798 [Listener at localhost/44463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:29,798 [Listener at localhost/44463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:29,798 [Listener at localhost/44463] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:29,798 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:29,799 [Listener at localhost/44463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:29,799 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:29,799 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43314
2020-12-03 07:21:29,800 [Listener at localhost/44463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:29,800 [Listener at localhost/44463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:29,800 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:29,802 [Listener at localhost/44463] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:29,803 [Listener at localhost/44463] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:29,803 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:29,804 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:29,805 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:29,805 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:29,805 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:29,806 [Listener at localhost/44463] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35644
2020-12-03 07:21:29,806 [Listener at localhost/44463] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:29,807 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15bc0297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:29,808 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f5155d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:29,821 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d39c660{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:29,826 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3df7d7af{HTTP/1.1,[http/1.1]}{localhost:35644}
2020-12-03 07:21:29,826 [Listener at localhost/44463] INFO  server.Server (Server.java:doStart(419)) - Started @18722ms
2020-12-03 07:21:29,841 [Listener at localhost/44463] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42880
2020-12-03 07:21:29,841 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25f00158] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:29,841 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:29,841 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:29,842 [Listener at localhost/44463] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:29,843 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:29,847 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35881
2020-12-03 07:21:29,854 [Listener at localhost/35881] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:29,854 [Listener at localhost/35881] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:29,855 [Thread-352] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:29,857 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:29,857 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:29,860 [Listener at localhost/35881] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 2
2020-12-03 07:21:29,860 [Listener at localhost/35881] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:36124 from a total of 3 datanodes.
2020-12-03 07:21:29,860 [Listener at localhost/35881] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:29,860 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21035d6d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:29,862 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030) exiting.
2020-12-03 07:21:29,862 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7) exiting.
2020-12-03 07:21:29,862 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894) exiting.
2020-12-03 07:21:29,863 [Thread-352] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:29,864 [Thread-352] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:29,883 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@15fb0d33{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:29,884 [Listener at localhost/35881] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25b2f2ea{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:29,884 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f8406e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:29,884 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ee5bc25{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:29,885 [Listener at localhost/35881] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43415
2020-12-03 07:21:29,891 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:29,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:29,902 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:29,902 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463
2020-12-03 07:21:29,902 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2)
2020-12-03 07:21:29,903 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:29,904 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,904 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,904 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:29,907 [Listener at localhost/35881] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:29,908 [Listener at localhost/35881] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:29,908 [Listener at localhost/35881] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:29,909 [Listener at localhost/35881] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:29,912 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:29,913 [Thread-352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:29,914 [Listener at localhost/35881] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:29,915 [Listener at localhost/35881] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:29,915 [Listener at localhost/35881] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:29,917 [Listener at localhost/35881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:29,917 [Listener at localhost/35881] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:29,918 [Listener at localhost/35881] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:29,918 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:29,919 [Listener at localhost/35881] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:29,919 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:29,920 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44049
2020-12-03 07:21:29,920 [Listener at localhost/35881] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:29,921 [Listener at localhost/35881] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:29,922 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:29,923 [Listener at localhost/35881] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:29,924 [Listener at localhost/35881] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:29,924 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:29,926 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:29,927 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:29,927 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:29,927 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:29,928 [Listener at localhost/35881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46847
2020-12-03 07:21:29,928 [Listener at localhost/35881] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:29,930 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@345c7b6e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:29,930 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77fe80c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:29,935 [Listener at localhost/35881] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ec3581d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:29,937 [Listener at localhost/35881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59c6a8f2{HTTP/1.1,[http/1.1]}{localhost:46847}
2020-12-03 07:21:29,938 [Listener at localhost/35881] INFO  server.Server (Server.java:doStart(419)) - Started @18834ms
2020-12-03 07:21:29,959 [Listener at localhost/35881] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36631
2020-12-03 07:21:29,959 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62ea12ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:29,959 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:29,960 [Listener at localhost/35881] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:29,960 [Listener at localhost/35881] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:29,961 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:29,965 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40995
2020-12-03 07:21:29,974 [Listener at localhost/40995] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:29,974 [Listener at localhost/40995] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:29,975 [Thread-374] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:29,978 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:29,978 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:29,981 [Thread-374] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:29,982 [Thread-374] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:29,982 [Listener at localhost/40995] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 1
2020-12-03 07:21:29,982 [Listener at localhost/40995] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:41087 from a total of 3 datanodes.
2020-12-03 07:21:29,982 [Listener at localhost/40995] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:29,982 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b38f72e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:29,984 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673) exiting.
2020-12-03 07:21:29,984 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2) exiting.
2020-12-03 07:21:29,984 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9) exiting.
2020-12-03 07:21:30,004 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2b39af71{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:30,005 [Listener at localhost/40995] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79fd4513{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:30,005 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b19de0a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:30,005 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28068176{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:30,007 [Listener at localhost/40995] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36941
2020-12-03 07:21:30,010 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:30,010 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:30,011 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:30,011 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463
2020-12-03 07:21:30,011 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9)
2020-12-03 07:21:30,011 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,012 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:30,013 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:30,013 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:30,024 [Listener at localhost/40995] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:30,024 [Listener at localhost/40995] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:30,025 [Listener at localhost/40995] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:30,025 [Listener at localhost/40995] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:30,029 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:30,031 [Listener at localhost/40995] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:30,032 [Listener at localhost/40995] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:30,033 [Listener at localhost/40995] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:30,035 [Listener at localhost/40995] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:30,035 [Listener at localhost/40995] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:30,035 [Listener at localhost/40995] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:30,036 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:30,036 [Listener at localhost/40995] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:30,038 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:30,038 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43580
2020-12-03 07:21:30,038 [Listener at localhost/40995] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:30,039 [Listener at localhost/40995] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:30,044 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:30,045 [Listener at localhost/40995] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:30,046 [Listener at localhost/40995] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:30,046 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:30,048 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:30,048 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:30,048 [Thread-374] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,049 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:30,049 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:30,050 [Listener at localhost/40995] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40783
2020-12-03 07:21:30,050 [Listener at localhost/40995] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:30,052 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36f0052d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:30,052 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@606b7fc7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:30,058 [Listener at localhost/40995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a121f2e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:30,061 [Listener at localhost/40995] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73bc1d6d{HTTP/1.1,[http/1.1]}{localhost:40783}
2020-12-03 07:21:30,061 [Listener at localhost/40995] INFO  server.Server (Server.java:doStart(419)) - Started @18957ms
2020-12-03 07:21:30,081 [Listener at localhost/40995] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41290
2020-12-03 07:21:30,081 [Thread-352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,082 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:30,082 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@138a50a1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:30,082 [Listener at localhost/40995] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:30,082 [Listener at localhost/40995] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,083 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,088 [Listener at localhost/45062] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45062
2020-12-03 07:21:30,101 [Listener at localhost/45062] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:30,101 [Listener at localhost/45062] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:30,102 [Thread-396] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463 starting to offer service
2020-12-03 07:21:30,115 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:30,115 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:30,120 [Listener at localhost/45062] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 0
2020-12-03 07:21:30,120 [Listener at localhost/45062] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:30,120 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:30,121 [Thread-396] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44463
2020-12-03 07:21:30,122 [Thread-396] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 3 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=3, dataDirs=3)
2020-12-03 07:21:30,122 [Listener at localhost/45062] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 22, 24
2020-12-03 07:21:30,131 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@67682904] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:30,123 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@55bc2533] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:30,132 [Listener at localhost/45062] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 21 Number of syncs: 5 SyncTimes(ms): 3 2 
2020-12-03 07:21:30,133 [Listener at localhost/45062] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000022 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000022-0000000000000000025
2020-12-03 07:21:30,134 [Listener at localhost/45062] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000022 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000022-0000000000000000025
2020-12-03 07:21:30,134 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:30,134 [CacheReplicationMonitor(411598322)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:30,135 [Listener at localhost/45062] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44463
2020-12-03 07:21:30,137 [IPC Server listener on 44463] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 44463
2020-12-03 07:21:30,137 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:30,138 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:30,138 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:30,152 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:30,152 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:30,154 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f4896cb{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:30,156 [Listener at localhost/45062] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5e403670{HTTP/1.1,[http/1.1]}{localhost:39280}
2020-12-03 07:21:30,156 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3bb3576f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:30,157 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32871097{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:30,161 [Listener at localhost/45062] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:30,162 [Listener at localhost/45062] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:30,162 [Listener at localhost/45062] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:44463
2020-12-03 07:21:30,162 [Listener at localhost/45062] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:44463 to access this namenode/service.
2020-12-03 07:21:30,177 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78b4eb3d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:30,177 [Listener at localhost/45062] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:39280
2020-12-03 07:21:30,177 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:30,179 [Listener at localhost/45062] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:30,180 [Listener at localhost/45062] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:30,180 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:30,182 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:30,182 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:30,182 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:30,182 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:30,184 [Listener at localhost/45062] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:30,184 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:30,184 [Listener at localhost/45062] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39280
2020-12-03 07:21:30,185 [Listener at localhost/45062] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:30,187 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12eaa7fd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:30,188 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a847820{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:30,193 [Listener at localhost/45062] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68ebb357{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:30,196 [Listener at localhost/45062] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15df63f1{HTTP/1.1,[http/1.1]}{localhost:39280}
2020-12-03 07:21:30,196 [Listener at localhost/45062] INFO  server.Server (Server.java:doStart(419)) - Started @19093ms
2020-12-03 07:21:30,198 [Listener at localhost/45062] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:30,199 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:30,200 [Listener at localhost/45062] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:30,200 [Listener at localhost/45062] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:30,200 [Listener at localhost/45062] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:30,201 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:30,201 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:30
2020-12-03 07:21:30,201 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:30,201 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:30,201 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.2 MB
2020-12-03 07:21:30,202 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:30,209 [Thread-396] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,209 [Thread-374] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,215 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:30,216 [Listener at localhost/45062] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:30,216 [Listener at localhost/45062] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:30,216 [Listener at localhost/45062] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:30,220 [Listener at localhost/45062] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:30,221 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:30,221 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:30,221 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.1 MB
2020-12-03 07:21:30,221 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:30,227 [Listener at localhost/45062] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:30,227 [Listener at localhost/45062] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:30,227 [Listener at localhost/45062] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:30,227 [Listener at localhost/45062] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.8 MB
2020-12-03 07:21:30,228 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:30,230 [Listener at localhost/45062] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:30,230 [Listener at localhost/45062] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:30,230 [Listener at localhost/45062] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:30,230 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:30,230 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:30,231 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:30,231 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:30,231 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 586.8 KB
2020-12-03 07:21:30,231 [Listener at localhost/45062] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:30,268 [Thread-352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,295 [Listener at localhost/45062] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,355 [Thread-352] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,355 [Thread-352] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,393 [Listener at localhost/45062] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,393 [Thread-374] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,393 [Thread-396] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,396 [Listener at localhost/45062] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:30,396 [Listener at localhost/45062] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:30,397 [Listener at localhost/45062] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:30,400 [Listener at localhost/45062] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:30,401 [Listener at localhost/45062] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:30,401 [Listener at localhost/45062] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:30,401 [Listener at localhost/45062] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7557ee4e expecting start txid #1
2020-12-03 07:21:30,402 [Listener at localhost/45062] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:30,402 [Listener at localhost/45062] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021' to transaction ID 1
2020-12-03 07:21:30,406 [Listener at localhost/45062] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021) of total size 1497.0, total edits 21.0, total load time 4.0 ms
2020-12-03 07:21:30,406 [Listener at localhost/45062] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000022-0000000000000000025' to transaction ID 1
2020-12-03 07:21:30,407 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:30,408 [Listener at localhost/45062] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 26
2020-12-03 07:21:30,468 [Thread-352] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,469 [Thread-352] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,496 [Thread-374] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,496 [Thread-374] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,538 [Thread-352] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,538 [Thread-352] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,567 [Thread-396] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 3452@50abf8f67126
2020-12-03 07:21:30,568 [Listener at localhost/45062] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:30,568 [Listener at localhost/45062] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 336 msecs
2020-12-03 07:21:30,569 [Listener at localhost/45062] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:44463
2020-12-03 07:21:30,569 [Listener at localhost/45062] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,570 [Socket Reader #1 for port 44463] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 44463
2020-12-03 07:21:30,577 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:30,577 [Thread-374] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,578 [Thread-374] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,620 [Listener at localhost/44463] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:30,622 [Listener at localhost/44463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:30,622 [Thread-352] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:30,628 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:30,628 [IPC Server listener on 44463] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 44463: starting
2020-12-03 07:21:30,628 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ae775029-a61b-4f26-a0e5-6277905b7a36
2020-12-03 07:21:30,632 [Thread-352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:30,635 [Listener at localhost/44463] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44463
2020-12-03 07:21:30,635 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:30,636 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e319569f-16de-4b3a-aa67-1022e111f90c
2020-12-03 07:21:30,636 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:30,648 [Thread-352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:30,649 [Listener at localhost/44463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=6
storage space=9216
storage types=RAM_DISK=0, SSD=1024, DISK=2048, ARCHIVE=6144, PROVIDED=0
2020-12-03 07:21:30,653 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66
2020-12-03 07:21:30,653 [Thread-352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: SSD
2020-12-03 07:21:30,654 [Listener at localhost/44463] INFO  sps.StoragePolicySatisfyManager (StoragePolicySatisfyManager.java:start(108)) - Storage policy satisfier is configured as external, please start external sps service explicitly to satisfy policy
2020-12-03 07:21:30,658 [CacheReplicationMonitor(1734151962)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:30,660 [Thread-352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:30,661 [Thread-352] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:30,662 [Thread-352] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:30,662 [Thread-352] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:30,667 [Thread-352] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:30,667 [Thread-352] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:30,667 [Thread-352] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:30,671 [Thread-352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,672 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,672 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:30,672 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:30,673 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:30,673 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,673 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,674 [Thread-449] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:30,674 [Thread-450] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:30,674 [Thread-448] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current: 27693
2020-12-03 07:21:30,675 [Thread-374] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,676 [Thread-374] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,676 [Thread-396] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,677 [Thread-396] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,683 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 10ms
2020-12-03 07:21:30,694 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 22ms
2020-12-03 07:21:30,695 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 23ms
2020-12-03 07:21:30,696 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 23ms
2020-12-03 07:21:30,696 [Thread-451] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:30,696 [Thread-452] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:30,702 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:30,702 [Thread-452] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:30,704 [Thread-453] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:30,704 [Thread-451] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:30,704 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:21:30,704 [Thread-451] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:21:30,704 [Thread-452] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-12-03 07:21:30,704 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 9ms
2020-12-03 07:21:30,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66): no suitable block pools found to scan.  Waiting 1814389714 ms.
2020-12-03 07:21:30,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36): no suitable block pools found to scan.  Waiting 1814389715 ms.
2020-12-03 07:21:30,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c): no suitable block pools found to scan.  Waiting 1814389715 ms.
2020-12-03 07:21:30,706 [Thread-352] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:44 PM with interval of 21600000ms
2020-12-03 07:21:30,707 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:30,708 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(777)) - Problem connecting to server: localhost/127.0.0.1:44463 :End of File Exception between local host is: "50abf8f67126/172.17.0.5"; destination host is: "localhost":44463; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:30,723 [Thread-374] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:30,725 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bf2f2b30-defe-47c4-80cc-453742547de7
2020-12-03 07:21:30,725 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:30,728 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-80bce346-a7b9-4fd3-86e3-15549db32030
2020-12-03 07:21:30,728 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: ARCHIVE
2020-12-03 07:21:30,730 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a6cf745c-b5df-4590-95aa-93005bed4894
2020-12-03 07:21:30,730 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: SSD
2020-12-03 07:21:30,732 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:30,733 [Thread-374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:30,734 [Thread-374] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:30,734 [Thread-374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:30,734 [Thread-374] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:30,734 [Thread-374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:30,734 [Thread-374] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:30,734 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,735 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:30,735 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,735 [Thread-462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,735 [Thread-396] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,736 [Thread-396] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,736 [Thread-460] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current: 26669
2020-12-03 07:21:30,736 [Thread-461] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:30,736 [Thread-462] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current: 25615
2020-12-03 07:21:30,745 [Thread-462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 9ms
2020-12-03 07:21:30,745 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 10ms
2020-12-03 07:21:30,745 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 10ms
2020-12-03 07:21:30,748 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 13ms
2020-12-03 07:21:30,748 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:30,748 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,748 [Thread-464] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:30,748 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,750 [Thread-463] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:30,750 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:21:30,752 [Thread-465] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:30,752 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:21:30,752 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:21:30,752 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 5ms
2020-12-03 07:21:30,753 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030): no suitable block pools found to scan.  Waiting 1814389664 ms.
2020-12-03 07:21:30,753 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894): no suitable block pools found to scan.  Waiting 1814389664 ms.
2020-12-03 07:21:30,753 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7): no suitable block pools found to scan.  Waiting 1814389664 ms.
2020-12-03 07:21:30,754 [Thread-374] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:14 AM with interval of 21600000ms
2020-12-03 07:21:30,756 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:30,761 [IPC Server handler 1 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44049, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36631, infoSecurePort=0, ipcPort=40995, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:30,761 [IPC Server handler 1 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44049
2020-12-03 07:21:30,762 [IPC Server handler 1 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9d698ef-926b-4d95-bc80-d0e616a324a2 (127.0.0.1:44049).
2020-12-03 07:21:30,765 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:30,765 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,769 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf2f2b30-defe-47c4-80cc-453742547de7 for DN 127.0.0.1:44049
2020-12-03 07:21:30,769 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80bce346-a7b9-4fd3-86e3-15549db32030 for DN 127.0.0.1:44049
2020-12-03 07:21:30,770 [IPC Server handler 2 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6cf745c-b5df-4590-95aa-93005bed4894 for DN 127.0.0.1:44049
2020-12-03 07:21:30,775 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3111f31894c7b3c2: Processing first storage report for DS-80bce346-a7b9-4fd3-86e3-15549db32030 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:30,777 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3111f31894c7b3c2: from storage DS-80bce346-a7b9-4fd3-86e3-15549db32030 node DatanodeRegistration(127.0.0.1:44049, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36631, infoSecurePort=0, ipcPort=40995, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,777 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,777 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,777 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3111f31894c7b3c2: Processing first storage report for DS-a6cf745c-b5df-4590-95aa-93005bed4894 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:30,778 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3111f31894c7b3c2: from storage DS-a6cf745c-b5df-4590-95aa-93005bed4894 node DatanodeRegistration(127.0.0.1:44049, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36631, infoSecurePort=0, ipcPort=40995, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,778 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3111f31894c7b3c2: Processing first storage report for DS-bf2f2b30-defe-47c4-80cc-453742547de7 from datanode e9d698ef-926b-4d95-bc80-d0e616a324a2
2020-12-03 07:21:30,778 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:30,779 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:30,779 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:30,780 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:30,780 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:30,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3111f31894c7b3c2: from storage DS-bf2f2b30-defe-47c4-80cc-453742547de7 node DatanodeRegistration(127.0.0.1:44049, datanodeUuid=e9d698ef-926b-4d95-bc80-d0e616a324a2, infoPort=36631, infoSecurePort=0, ipcPort=40995, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 2, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:30,788 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:21:30,789 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3111f31894c7b3c2,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:30,790 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,847 [Thread-396] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,847 [Thread-396] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,879 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,880 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,880 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,896 [Thread-396] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1399999547;bpid=BP-1996015613-172.17.0.5-1606980073827;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1399999547;c=1606980073827;bpid=BP-1996015613-172.17.0.5-1606980073827;dnuuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:30,899 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b0428128-ad9c-4be8-b69b-3946ab4726e2
2020-12-03 07:21:30,899 [Thread-396] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:30,902 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673
2020-12-03 07:21:30,902 [Thread-396] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:30,904 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9
2020-12-03 07:21:30,904 [Thread-396] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [SSD]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: SSD
2020-12-03 07:21:30,906 [Thread-396] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:30,907 [Thread-396] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:30,908 [Thread-396] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:30,908 [Thread-396] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:30,908 [Thread-396] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:30,909 [Thread-396] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:30,910 [Thread-396] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:30,910 [Thread-396] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,910 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,911 [Thread-474] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current: 27693
2020-12-03 07:21:30,912 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,912 [Thread-476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:30,912 [Thread-475] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:30,913 [Thread-476] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current: 24576
2020-12-03 07:21:30,919 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 9ms
2020-12-03 07:21:30,920 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 8ms
2020-12-03 07:21:30,920 [Thread-476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1996015613-172.17.0.5-1606980073827 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 7ms
2020-12-03 07:21:30,920 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1996015613-172.17.0.5-1606980073827: 11ms
2020-12-03 07:21:30,920 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,920 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,921 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:30,921 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:30,922 [Thread-479] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas doesn't exist 
2020-12-03 07:21:30,922 [Thread-477] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827/current/replicas
2020-12-03 07:21:30,929 [Thread-477] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 8ms
2020-12-03 07:21:30,929 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 8ms
2020-12-03 07:21:30,929 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 8ms
2020-12-03 07:21:30,931 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1996015613-172.17.0.5-1606980073827: 10ms
2020-12-03 07:21:30,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673): no suitable block pools found to scan.  Waiting 1814389485 ms.
2020-12-03 07:21:30,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2): no suitable block pools found to scan.  Waiting 1814389485 ms.
2020-12-03 07:21:30,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9): no suitable block pools found to scan.  Waiting 1814389485 ms.
2020-12-03 07:21:30,933 [Thread-396] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:04 AM with interval of 21600000ms
2020-12-03 07:21:30,934 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 beginning handshake with NN
2020-12-03 07:21:30,936 [IPC Server handler 6 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43580, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=41290, infoSecurePort=0, ipcPort=45062, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:30,936 [IPC Server handler 6 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43580
2020-12-03 07:21:30,936 [IPC Server handler 6 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6d14ddac-f131-49f3-9dd2-444db68ba3d9 (127.0.0.1:43580).
2020-12-03 07:21:30,937 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:30,937 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,940 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 for DN 127.0.0.1:43580
2020-12-03 07:21:30,942 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 for DN 127.0.0.1:43580
2020-12-03 07:21:30,942 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 for DN 127.0.0.1:43580
2020-12-03 07:21:30,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14a796a38a4634c4: Processing first storage report for DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:30,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14a796a38a4634c4: from storage DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673 node DatanodeRegistration(127.0.0.1:43580, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=41290, infoSecurePort=0, ipcPort=45062, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14a796a38a4634c4: Processing first storage report for DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:30,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14a796a38a4634c4: from storage DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9 node DatanodeRegistration(127.0.0.1:43580, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=41290, infoSecurePort=0, ipcPort=45062, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,945 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14a796a38a4634c4: Processing first storage report for DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 from datanode 6d14ddac-f131-49f3-9dd2-444db68ba3d9
2020-12-03 07:21:30,945 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14a796a38a4634c4: from storage DS-b0428128-ad9c-4be8-b69b-3946ab4726e2 node DatanodeRegistration(127.0.0.1:43580, datanodeUuid=6d14ddac-f131-49f3-9dd2-444db68ba3d9, infoPort=41290, infoSecurePort=0, ipcPort=45062, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,946 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x14a796a38a4634c4,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:30,946 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:30,981 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,982 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,982 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,083 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,084 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,085 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,186 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,187 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,187 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,289 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,290 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,290 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,392 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,393 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,393 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,494 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,495 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,495 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,597 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,598 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,598 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,700 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,701 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:31,701 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:31,709 [IPC Server handler 7 on default port 44463] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43314, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=42880, infoSecurePort=0, ipcPort=35881, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827) storage 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:31,710 [IPC Server handler 7 on default port 44463] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43314
2020-12-03 07:21:31,710 [IPC Server handler 7 on default port 44463] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82 (127.0.0.1:43314).
2020-12-03 07:21:31,711 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463 successfully registered with NN
2020-12-03 07:21:31,711 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44463 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:31,718 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae775029-a61b-4f26-a0e5-6277905b7a36 for DN 127.0.0.1:43314
2020-12-03 07:21:31,718 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e319569f-16de-4b3a-aa67-1022e111f90c for DN 127.0.0.1:43314
2020-12-03 07:21:31,718 [IPC Server handler 8 on default port 44463] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 for DN 127.0.0.1:43314
2020-12-03 07:21:31,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x905f14d0a61da88b: Processing first storage report for DS-ae775029-a61b-4f26-a0e5-6277905b7a36 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:31,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x905f14d0a61da88b: from storage DS-ae775029-a61b-4f26-a0e5-6277905b7a36 node DatanodeRegistration(127.0.0.1:43314, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=42880, infoSecurePort=0, ipcPort=35881, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 3, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:31,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x905f14d0a61da88b: Processing first storage report for DS-e319569f-16de-4b3a-aa67-1022e111f90c from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:31,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x905f14d0a61da88b: from storage DS-e319569f-16de-4b3a-aa67-1022e111f90c node DatanodeRegistration(127.0.0.1:43314, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=42880, infoSecurePort=0, ipcPort=35881, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:31,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x905f14d0a61da88b: Processing first storage report for DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 from datanode 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82
2020-12-03 07:21:31,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x905f14d0a61da88b: from storage DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66 node DatanodeRegistration(127.0.0.1:43314, datanodeUuid=22eb02c9-4536-4ca1-99bb-a5d1a73a6a82, infoPort=42880, infoSecurePort=0, ipcPort=35881, storageInfo=lv=-57;cid=testClusterID;nsid=1399999547;c=1606980073827), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:31,722 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x905f14d0a61da88b,  containing 3 storage report(s), of which we sent 3. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:31,722 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:31,802 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,803 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:31,805 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,806 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:32,108 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,110 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:32,612 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,615 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:32,702 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,704 [SPSPathIdProcessor] WARN  sps.ExternalSPSContext (ExternalSPSContext.java:getNextSPSPath(171)) - Exception while getting next sps path id from Namenode.
java.io.EOFException: End of File Exception between local host is: "50abf8f67126/172.17.0.5"; destination host is: "localhost":44463; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy27.getNextSPSPath(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getNextSPSPath(NamenodeProtocolTranslatorPB.java:275)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy28.getNextSPSPath(Unknown Source)
	at org.apache.hadoop.hdfs.server.sps.ExternalSPSContext.getNextSPSPath(ExternalSPSContext.java:169)
	at org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded$SPSPathIdProcessor.run(BlockStorageMovementNeeded.java:240)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:21:32,718 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,720 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,724 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:32,725 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36124
2020-12-03 07:21:32,725 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36186
2020-12-03 07:21:32,725 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41087
2020-12-03 07:21:32,725 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43314
2020-12-03 07:21:32,725 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43580
2020-12-03 07:21:32,726 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44049
2020-12-03 07:21:32,726 [StoragePolicySatisfier] INFO  sps.StoragePolicySatisfier (StoragePolicySatisfier.java:run(301)) - Block analysis status:BLOCKS_ALREADY_SATISFIED for the file id:16386. So, Cleaning up the Xattrs.
2020-12-03 07:21:32,732 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/.inodes/16386	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:32,735 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,117 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,119 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:33,621 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,626 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:34,128 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:34,130 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:34,632 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:34,634 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:35,136 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,138 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:35,640 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,642 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=0
2020-12-03 07:21:35,706 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,712 [IPC Server handler 2 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,714 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,717 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/.reserved/.inodes/16387	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,719 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/.reserved/.inodes/16387/childDir/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,721 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,737 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,739 [IPC Server handler 0 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,743 [IPC Server handler 1 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,745 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36124
2020-12-03 07:21:35,745 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36186
2020-12-03 07:21:35,745 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41087
2020-12-03 07:21:35,745 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43314
2020-12-03 07:21:35,746 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43580
2020-12-03 07:21:35,746 [StoragePolicySatisfier] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44049
2020-12-03 07:21:35,746 [StoragePolicySatisfier] INFO  sps.StoragePolicySatisfier (StoragePolicySatisfier.java:run(301)) - Block analysis status:BLOCKS_ALREADY_SATISFIED for the file id:16386. So, Cleaning up the Xattrs.
2020-12-03 07:21:35,748 [IPC Server handler 2 on default port 44463] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 44463, call Call#195 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:45404
java.io.IOException: No matching attributes found for remove operation
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.removeXAttr(FSDirXAttrOp.java:185)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeXAttr(FSNamesystem.java:7879)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeXAttr(NameNodeRpcServer.java:2272)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1661)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:35,755 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/.inodes/16386	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,760 [StoragePolicySatisfier] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:removeSPSHint(130)) - SPS hint already removed for the inodeId:16386. Ignoring exception:No matching attributes found for remove operation
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.removeXAttr(FSDirXAttrOp.java:185)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeXAttr(FSNamesystem.java:7879)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeXAttr(NameNodeRpcServer.java:2272)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1661)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

2020-12-03 07:21:35,761 [IPC Server handler 3 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,765 [IPC Server handler 5 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,768 [IPC Server handler 6 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/.reserved/.inodes/16390	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,770 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,771 [BlockMoverTask-1] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,773 [BlockMoverTask-2] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,773 [BlockMoverTask-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,774 [BlockMoverTask-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,775 [BlockMoverTask-2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,776 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,779 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,779 [DataXceiver for client /127.0.0.1:49874 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from e9d698ef-926b-4d95-bc80-d0e616a324a2]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,780 [DataXceiver for client /127.0.0.1:46054 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from 6d14ddac-f131-49f3-9dd2-444db68ba3d9]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,780 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,781 [BlockMoverTask-1] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,781 [DataXceiver for client /127.0.0.1:48742 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,781 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,781 [BlockMoverTask-2] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741827_1003 from src:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,782 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,782 [IPC Server handler 9 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/.reserved/.inodes/16388	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,783 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,785 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:44049
2020-12-03 07:21:35,785 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:43314
2020-12-03 07:21:35,785 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,785 [BlockMoverTask-2] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,785 [BlockMoverTask-1] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(105)) - Start moving block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to satisfy storageType, sourceStoragetype:DISK and destinStoragetype:ARCHIVE
2020-12-03 07:21:35,786 [BlockMoverTask-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,786 [BlockMoverTask-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,786 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:43580
2020-12-03 07:21:35,786 [BlockMoverTask-2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:35,787 [IPC Server handler 4 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:35,789 [DataXceiver for client /127.0.0.1:46060 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from 6d14ddac-f131-49f3-9dd2-444db68ba3d9]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,789 [BlockMoverTask-2] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43580,DS-b0428128-ad9c-4be8-b69b-3946ab4726e2,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,789 [DataXceiver for client /127.0.0.1:49880 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from e9d698ef-926b-4d95-bc80-d0e616a324a2]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,790 [DataXceiver for client /127.0.0.1:48748 [Replacing block BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1996015613-172.17.0.5-1606980073827:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:35,790 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,790 [BlockMoverTask-0] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:44049,DS-bf2f2b30-defe-47c4-80cc-453742547de7,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,790 [BlockMoverTask-1] INFO  sps.BlockDispatcher (BlockDispatcher.java:moveBlock(140)) - Successfully moved block:blk_1073741826_1002 from src:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] to destin:DatanodeInfoWithStorage[127.0.0.1:43314,DS-ae775029-a61b-4f26-a0e5-6277905b7a36,DISK] for satisfying storageType:ARCHIVE
2020-12-03 07:21:35,790 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:43580
2020-12-03 07:21:35,791 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,791 [BlockStorageMovementTracker] INFO  sps.ExternalSPSContext (ExternalSPSContext.java:notifyMovementTriedBlocks(208)) - Movement attempted blocks
2020-12-03 07:21:35,791 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:44049
2020-12-03 07:21:35,791 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:43314
2020-12-03 07:21:36,144 [IPC Server handler 7 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/parentFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:36,145 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=3
2020-12-03 07:21:36,147 [IPC Server handler 8 on default port 44463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/parentDir/childDir/childFile	dst=null	perm=null	proto=rpc
2020-12-03 07:21:36,151 [Listener at localhost/44463] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2461)) - ARCHIVE replica count, expected=3 and actual=3
2020-12-03 07:21:36,151 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:36,152 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:36,152 [Listener at localhost/44463] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:36,152 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@46a82f75] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:36,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7ea0e881-6f69-43c4-85a4-d400c3ff9673) exiting.
2020-12-03 07:21:36,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-b0428128-ad9c-4be8-b69b-3946ab4726e2) exiting.
2020-12-03 07:21:36,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f4b912cd-1f5c-49c3-b056-4c2806d3b1b9) exiting.
2020-12-03 07:21:36,179 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a121f2e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:36,180 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73bc1d6d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:36,180 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@606b7fc7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:36,181 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36f0052d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:36,182 [Listener at localhost/44463] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45062
2020-12-03 07:21:36,184 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:36,184 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,185 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:36,185 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9) service to localhost/127.0.0.1:44463
2020-12-03 07:21:36,185 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 6d14ddac-f131-49f3-9dd2-444db68ba3d9)
2020-12-03 07:21:36,185 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:36,186 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,187 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,188 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,192 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:36,192 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:36,193 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:36,193 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:36,198 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:36,198 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:36,198 [Listener at localhost/44463] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:36,198 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55ff9023] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:36,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-80bce346-a7b9-4fd3-86e3-15549db32030) exiting.
2020-12-03 07:21:36,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a6cf745c-b5df-4590-95aa-93005bed4894) exiting.
2020-12-03 07:21:36,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bf2f2b30-defe-47c4-80cc-453742547de7) exiting.
2020-12-03 07:21:36,223 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ec3581d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:36,224 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59c6a8f2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:36,224 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77fe80c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:36,225 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@345c7b6e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:36,226 [Listener at localhost/44463] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40995
2020-12-03 07:21:36,228 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:36,228 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:36,229 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2) service to localhost/127.0.0.1:44463
2020-12-03 07:21:36,228 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,229 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid e9d698ef-926b-4d95-bc80-d0e616a324a2)
2020-12-03 07:21:36,229 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:36,231 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,231 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,232 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,240 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:36,240 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:36,241 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:36,241 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:36,243 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:36,243 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:36,244 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54cc2d2b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:36,244 [Listener at localhost/44463] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:36,246 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-1fb4d5a9-6c04-4984-92ca-c4ab9858dc66) exiting.
2020-12-03 07:21:36,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae775029-a61b-4f26-a0e5-6277905b7a36) exiting.
2020-12-03 07:21:36,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e319569f-16de-4b3a-aa67-1022e111f90c) exiting.
2020-12-03 07:21:36,271 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d39c660{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:36,272 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3df7d7af{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:36,272 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f5155d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:36,273 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15bc0297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:36,274 [Listener at localhost/44463] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35881
2020-12-03 07:21:36,275 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:36,307 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,308 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:36,308 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82) service to localhost/127.0.0.1:44463
2020-12-03 07:21:36,308 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1996015613-172.17.0.5-1606980073827 (Datanode Uuid 22eb02c9-4536-4ca1-99bb-a5d1a73a6a82)
2020-12-03 07:21:36,308 [BP-1996015613-172.17.0.5-1606980073827 heartbeating to localhost/127.0.0.1:44463] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1996015613-172.17.0.5-1606980073827
2020-12-03 07:21:36,309 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,309 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,314 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1996015613-172.17.0.5-1606980073827] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:36,315 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:36,316 [Listener at localhost/44463] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:36,317 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:36,317 [Listener at localhost/44463] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:36,318 [Listener at localhost/44463] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:36,319 [Listener at localhost/44463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:36,319 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:36,319 [Listener at localhost/44463] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 26, 27
2020-12-03 07:21:36,319 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@79c4af44] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:36,320 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4dbd5272] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:36,320 [Listener at localhost/44463] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 3 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 25 Number of syncs: 4 SyncTimes(ms): 2 2 
2020-12-03 07:21:36,321 [Listener at localhost/44463] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000026 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000026-0000000000000000028
2020-12-03 07:21:36,323 [Listener at localhost/44463] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000026 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000026-0000000000000000028
2020-12-03 07:21:36,324 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:36,324 [CacheReplicationMonitor(1734151962)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:36,324 [Listener at localhost/44463] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44463
2020-12-03 07:21:36,328 [IPC Server listener on 44463] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 44463
2020-12-03 07:21:36,331 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:36,334 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:36,334 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,345 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:36,346 [Listener at localhost/44463] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:36,347 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68ebb357{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:36,348 [Listener at localhost/44463] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15df63f1{HTTP/1.1,[http/1.1]}{localhost:39280}
2020-12-03 07:21:36,349 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a847820{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:36,349 [Listener at localhost/44463] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12eaa7fd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:36,351 [Listener at localhost/44463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:21:36,360 [Listener at localhost/44463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:21:36,362 [Listener at localhost/44463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
2020-12-03 07:21:36,392 [Listener at localhost/44463] INFO  sps.StoragePolicySatisfier (StoragePolicySatisfier.java:stop(184)) - Stopping StoragePolicySatisfier.
2020-12-03 07:21:36,392 [BlocksStorageMovementAttemptMonitor] INFO  sps.BlockStorageMovementAttemptedItems (BlockStorageMovementAttemptedItems.java:run(235)) - BlocksStorageMovementAttemptMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementAttemptedItems$BlocksStorageMovementAttemptMonitor.run(BlockStorageMovementAttemptedItems.java:233)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:36,392 [SPSPathIdProcessor] INFO  sps.BlockStorageMovementNeeded (BlockStorageMovementNeeded.java:run(261)) - SPSPathIdProcessor thread is interrupted. Stopping..
msx-rc 0
