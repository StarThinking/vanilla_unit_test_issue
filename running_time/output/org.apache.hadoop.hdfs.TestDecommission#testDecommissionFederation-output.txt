2020-12-03 07:22:04,322 [Thread-4] INFO  hdfs.TestDecommission (TestDecommission.java:testDecommission(364)) - Starting test testDecommission
2020-12-03 07:22:04,342 [Thread-4] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=2
Formatting using clusterid: testClusterID
2020-12-03 07:22:05,021 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:05,042 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:05,045 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:05,045 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:05,048 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:05,049 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:05,049 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:05,050 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:05,051 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:05,122 [Thread-4] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,131 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:05,132 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,132 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:05,133 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:05,134 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,135 [Thread-4] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:05,140 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:05,141 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:05
2020-12-03 07:22:05,144 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:05,144 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:05,147 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:05,148 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:05,169 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,170 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,174 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:05,174 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:05,178 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:05,179 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,184 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:05,185 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:05,185 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:05,185 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:05,186 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:05,187 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:05,187 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:05,187 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:05,187 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:05,188 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:05,188 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:05,236 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:05,237 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:05,237 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:05,237 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:05,255 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:05,255 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:05,256 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:05,256 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:05,262 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:05,262 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:05,263 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:05,263 [Thread-4] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:05,269 [Thread-4] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:05,272 [Thread-4] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:05,277 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:05,278 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:05,278 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:05,278 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:05,290 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:05,290 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:05,290 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:05,295 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:05,296 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:05,298 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:05,299 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:05,299 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:05,299 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:05,334 [Thread-4] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:05,512 [Thread-4] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:05,589 [Thread-4] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:05,627 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:05,628 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:05,776 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:05,776 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:05,883 [Thread-4] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:05,888 [Thread-4] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:06,325 [Thread-4] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:06,427 [Thread-4] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:06,428 [Thread-4] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:06,441 [Thread-4] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:06,487 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@226d3514] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:06,503 [Thread-4] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:06,508 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:06,524 [Thread-4] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3788ms
2020-12-03 07:22:06,668 [Thread-4] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:06,673 [Thread-4] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:06,673 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:06,684 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:06,687 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:06,687 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:06,687 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:06,732 [Thread-4] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:06,733 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:06,747 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39560
2020-12-03 07:22:06,750 [Thread-4] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:06,812 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23d28440{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:06,815 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ae61ea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:06,864 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7883f3c8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:06,872 [Thread-4] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5182b53c{HTTP/1.1,[http/1.1]}{localhost:39560}
2020-12-03 07:22:06,873 [Thread-4] INFO  server.Server (Server.java:doStart(419)) - Started @4137ms
2020-12-03 07:22:06,884 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:06,884 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:06,885 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:06,885 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:06,885 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:06,885 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:06,886 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:06,886 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:06,886 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:06,887 [Thread-4] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:06,888 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,888 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:06,888 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:06,888 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,889 [Thread-4] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:06,889 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:06,890 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:06
2020-12-03 07:22:06,890 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:06,890 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:06,891 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:06,891 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:06,904 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,905 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,905 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:06,906 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:06,906 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:06,906 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,907 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:06,907 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:06,908 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:06,908 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:06,908 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:06,909 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:06,909 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:06,909 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:06,910 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:06,910 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:06,910 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:06,911 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:06,911 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:06,912 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:06,912 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:06,915 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:06,915 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:06,916 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:06,916 [Thread-4] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:06,916 [Thread-4] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:06,917 [Thread-4] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:06,917 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:06,917 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:06,918 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:06,918 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:06,922 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:06,923 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:06,923 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:06,923 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:06,924 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:06,924 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:06,924 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:06,924 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:06,925 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:06,983 [Thread-4] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:07,025 [Thread-4] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:07,029 [Thread-4] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:07,029 [Thread-4] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:07,030 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:07,030 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:07,065 [Thread-4] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:07,071 [Thread-4] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:07,073 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:07,078 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:07,078 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:07,193 [Thread-4] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:07,194 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 265 msecs
2020-12-03 07:22:07,381 [Thread-4] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:07,430 [Thread-4] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:07,445 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:07,733 [Listener at localhost/39451] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:39451 to access this namenode/service.
2020-12-03 07:22:07,737 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:07,752 [Listener at localhost/39451] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:07,764 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:07,764 [Listener at localhost/39451] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:07,765 [Listener at localhost/39451] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:07,765 [Listener at localhost/39451] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:07,768 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:07,768 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:07,769 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:07,769 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:07,769 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:07,769 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:22:07,799 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:07,799 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:07,803 [Listener at localhost/39451] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:39451
2020-12-03 07:22:07,806 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:07,806 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:07,813 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:07,818 [CacheReplicationMonitor(1905531299)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
Formatting using clusterid: testClusterID
2020-12-03 07:22:07,822 [Listener at localhost/39451] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:07,822 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:07,823 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns2
2020-12-03 07:22:07,824 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:07,824 [Listener at localhost/39451] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:07,825 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:07,825 [Listener at localhost/39451] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:07,825 [Listener at localhost/39451] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:07,825 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:07,825 [Listener at localhost/39451] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:07,826 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:07,826 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:07
2020-12-03 07:22:07,826 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:07,826 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:07,827 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:07,827 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:07,838 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:07,839 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:07,839 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:07,839 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:07,839 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:07,839 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:07,840 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:07,841 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:07,841 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:07,841 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:07,841 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:07,841 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:07,842 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:07,842 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:07,842 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:07,842 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:07,848 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:07,848 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:07,848 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:07,849 [Listener at localhost/39451] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:07,849 [Listener at localhost/39451] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:07,849 [Listener at localhost/39451] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:07,849 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:07,849 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:07,850 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:07,850 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:07,852 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:07,852 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:07,852 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:07,852 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:07,852 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:07,853 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:07,853 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:07,853 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:07,853 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:07,855 [Listener at localhost/39451] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:07,939 [Listener at localhost/39451] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 has been successfully formatted.
2020-12-03 07:22:08,014 [Listener at localhost/39451] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 has been successfully formatted.
2020-12-03 07:22:08,031 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:08,034 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:08,042 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:08,047 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:08,102 [Listener at localhost/39451] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:08,104 [Listener at localhost/39451] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:08,104 [Listener at localhost/39451] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:08,105 [Listener at localhost/39451] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:08,121 [Listener at localhost/39451] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:08,121 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:08,123 [Listener at localhost/39451] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:08,124 [Listener at localhost/39451] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:08,124 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:08,124 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22c9988a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:08,128 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:08,129 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:08,129 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:08,129 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:08,132 [Listener at localhost/39451] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:08,132 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:08,133 [Listener at localhost/39451] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42632
2020-12-03 07:22:08,133 [Listener at localhost/39451] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:08,137 [Listener at localhost/39451] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26534855{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:08,137 [Listener at localhost/39451] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56e718bc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:08,150 [Listener at localhost/39451] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13771c74{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:08,156 [Listener at localhost/39451] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4132f6e4{HTTP/1.1,[http/1.1]}{localhost:42632}
2020-12-03 07:22:08,156 [Listener at localhost/39451] INFO  server.Server (Server.java:doStart(419)) - Started @5420ms
2020-12-03 07:22:08,160 [Listener at localhost/39451] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:08,160 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:08,160 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:08,160 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:08,161 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:08,161 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:08,161 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:08,162 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns2
2020-12-03 07:22:08,162 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:08,163 [Listener at localhost/39451] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:08,163 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,164 [Listener at localhost/39451] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:08,164 [Listener at localhost/39451] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:08,164 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,164 [Listener at localhost/39451] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:08,165 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:08,165 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:08
2020-12-03 07:22:08,165 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:08,165 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:08,166 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:08,166 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:08,178 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,178 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,179 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:08,179 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:08,179 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:08,179 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:08,180 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:08,181 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:08,181 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:08,181 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:08,181 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:08,181 [Listener at localhost/39451] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:08,182 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:08,182 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:08,182 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:08,182 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:08,189 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:08,189 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:08,189 [Listener at localhost/39451] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:08,190 [Listener at localhost/39451] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:08,190 [Listener at localhost/39451] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:08,190 [Listener at localhost/39451] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:08,191 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:08,191 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:08,192 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:08,192 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:08,195 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:08,195 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:08,195 [Listener at localhost/39451] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:08,196 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:08,196 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:08,197 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:08,197 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:08,197 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:08,197 [Listener at localhost/39451] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:08,232 [Listener at localhost/39451] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:08,266 [Listener at localhost/39451] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:08,270 [Listener at localhost/39451] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current
2020-12-03 07:22:08,270 [Listener at localhost/39451] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current
2020-12-03 07:22:08,270 [Listener at localhost/39451] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:08,271 [Listener at localhost/39451] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:08,275 [Listener at localhost/39451] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:08,277 [Listener at localhost/39451] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:08,277 [Listener at localhost/39451] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000
2020-12-03 07:22:08,278 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:08,278 [Listener at localhost/39451] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:08,359 [Listener at localhost/39451] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:08,360 [Listener at localhost/39451] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 153 msecs
2020-12-03 07:22:08,361 [Listener at localhost/39451] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:08,362 [Listener at localhost/39451] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:08,365 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:08,370 [Listener at localhost/39390] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:39390 to access this namenode/service.
2020-12-03 07:22:08,371 [Listener at localhost/39390] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:08,384 [Listener at localhost/39390] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:08,385 [Listener at localhost/39390] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:08,385 [Listener at localhost/39390] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:08,386 [Listener at localhost/39390] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:08,386 [Listener at localhost/39390] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:08,389 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:08,389 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:08,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:08,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:08,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:08,390 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-12-03 07:22:08,395 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:08,395 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:08,401 [Listener at localhost/39390] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:39390
2020-12-03 07:22:08,401 [Listener at localhost/39390] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:08,401 [Listener at localhost/39390] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:08,403 [Listener at localhost/39390] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:08,407 [CacheReplicationMonitor(710772217)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:08,411 [Listener at localhost/39390] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:08,432 [Listener at localhost/39390] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:08,448 [Listener at localhost/39390] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:08,454 [Listener at localhost/39390] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:08,460 [Listener at localhost/39390] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:08,464 [Listener at localhost/39390] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:08,469 [Listener at localhost/39390] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:08,471 [Listener at localhost/39390] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:08,471 [Listener at localhost/39390] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,471 [Listener at localhost/39390] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:08,477 [Listener at localhost/39390] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:08,486 [Listener at localhost/39390] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43098
2020-12-03 07:22:08,489 [Listener at localhost/39390] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:08,489 [Listener at localhost/39390] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:08,509 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:08,511 [Listener at localhost/39390] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:08,512 [Listener at localhost/39390] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:08,512 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:08,514 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:08,515 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:08,515 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:08,515 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:08,518 [Listener at localhost/39390] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38329
2020-12-03 07:22:08,519 [Listener at localhost/39390] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:08,520 [Listener at localhost/39390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6483e13{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:08,521 [Listener at localhost/39390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79034044{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:08,528 [Listener at localhost/39390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1db26eef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:08,529 [Listener at localhost/39390] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e27888{HTTP/1.1,[http/1.1]}{localhost:38329}
2020-12-03 07:22:08,530 [Listener at localhost/39390] INFO  server.Server (Server.java:doStart(419)) - Started @5794ms
2020-12-03 07:22:09,049 [Listener at localhost/39390] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33276
2020-12-03 07:22:09,049 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47dd41e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:09,051 [Listener at localhost/39390] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:09,051 [Listener at localhost/39390] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:09,068 [Listener at localhost/39390] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:09,069 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:09,075 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36420
2020-12-03 07:22:09,090 [Listener at localhost/36420] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1,ns2
2020-12-03 07:22:09,091 [Listener at localhost/36420] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1,ns2
2020-12-03 07:22:09,101 [Thread-102] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39451 starting to offer service
2020-12-03 07:22:09,101 [Thread-103] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39390 starting to offer service
2020-12-03 07:22:09,108 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:09,108 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:09,113 [Listener at localhost/36420] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:09,115 [Listener at localhost/36420] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:09,116 [Listener at localhost/36420] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:09,118 [Listener at localhost/36420] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:09,119 [Listener at localhost/36420] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:09,119 [Listener at localhost/36420] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:09,120 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:09,120 [Listener at localhost/36420] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:09,120 [Listener at localhost/36420] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:09,120 [Listener at localhost/36420] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:09,121 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:09,122 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36575
2020-12-03 07:22:09,122 [Listener at localhost/36420] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:09,122 [Listener at localhost/36420] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:09,124 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:09,126 [Listener at localhost/36420] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:09,128 [Listener at localhost/36420] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:09,128 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:09,131 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:09,132 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:09,132 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:09,132 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:09,133 [Listener at localhost/36420] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34448
2020-12-03 07:22:09,133 [Listener at localhost/36420] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:09,136 [Listener at localhost/36420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75b5b77d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:09,136 [Listener at localhost/36420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16d8fb3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:09,143 [Listener at localhost/36420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@311c328b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:09,144 [Listener at localhost/36420] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2ddae456{HTTP/1.1,[http/1.1]}{localhost:34448}
2020-12-03 07:22:09,144 [Listener at localhost/36420] INFO  server.Server (Server.java:doStart(419)) - Started @6409ms
2020-12-03 07:22:09,216 [Listener at localhost/36420] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37144
2020-12-03 07:22:09,217 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:09,217 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f2ce5a5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:09,217 [Listener at localhost/36420] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:09,217 [Listener at localhost/36420] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:09,218 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:09,223 [Listener at localhost/36267] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36267
2020-12-03 07:22:09,230 [Listener at localhost/36267] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1,ns2
2020-12-03 07:22:09,231 [Listener at localhost/36267] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1,ns2
2020-12-03 07:22:09,231 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39451 starting to offer service
2020-12-03 07:22:09,232 [Thread-129] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39390 starting to offer service
2020-12-03 07:22:09,233 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:09,233 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:09,397 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39451
2020-12-03 07:22:09,397 [Thread-129] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39390
2020-12-03 07:22:09,397 [Thread-102] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39451
2020-12-03 07:22:09,397 [Thread-103] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39390
2020-12-03 07:22:09,400 [Thread-103] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:09,400 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:09,458 [Thread-103] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:09,458 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:09,460 [Thread-103] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 343177521. Formatting...
2020-12-03 07:22:09,460 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1324868641. Formatting...
2020-12-03 07:22:09,461 [Thread-103] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:09,461 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-346988f8-cfa7-47d5-8f87-084b1f013d4f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:09,660 [Thread-103] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:09,660 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:09,661 [Thread-103] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 343177521. Formatting...
2020-12-03 07:22:09,661 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1324868641. Formatting...
2020-12-03 07:22:09,661 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2a647400-54ee-447e-90de-ccea72b118ab for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:09,661 [Thread-103] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-56168ab9-1727-40bb-ae05-299e8d785343 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:09,746 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:09,747 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:09,748 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1929819664-172.17.0.11-1606980125323 is not formatted. Formatting ...
2020-12-03 07:22:09,748 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929819664-172.17.0.11-1606980125323 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929819664-172.17.0.11-1606980125323/current
2020-12-03 07:22:09,751 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:09,752 [Thread-103] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:09,752 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2141226848-172.17.0.11-1606980127855 is not formatted. Formatting ...
2020-12-03 07:22:09,752 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2141226848-172.17.0.11-1606980127855 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855/current
2020-12-03 07:22:09,798 [IPC Server handler 1 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:09,806 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:09,806 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:09,861 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:09,862 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:09,862 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1929819664-172.17.0.11-1606980125323 is not formatted. Formatting ...
2020-12-03 07:22:09,862 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929819664-172.17.0.11-1606980125323 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929819664-172.17.0.11-1606980125323/current
2020-12-03 07:22:09,899 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:09,899 [Thread-103] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:09,899 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2141226848-172.17.0.11-1606980127855 is not formatted. Formatting ...
2020-12-03 07:22:09,900 [Thread-103] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2141226848-172.17.0.11-1606980127855 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855/current
2020-12-03 07:22:09,908 [IPC Server handler 0 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:09,909 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:09,909 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:09,985 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1324868641;bpid=BP-1929819664-172.17.0.11-1606980125323;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1324868641;c=1606980125323;bpid=BP-1929819664-172.17.0.11-1606980125323;dnuuid=null
2020-12-03 07:22:09,986 [Thread-129] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:09,986 [Thread-129] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:22:09,987 [Thread-129] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:22:09,999 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,000 [Thread-129] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,000 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2141226848-172.17.0.11-1606980127855 is not formatted. Formatting ...
2020-12-03 07:22:10,000 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2141226848-172.17.0.11-1606980127855 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2141226848-172.17.0.11-1606980127855/current
2020-12-03 07:22:10,001 [Thread-103] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=343177521;bpid=BP-2141226848-172.17.0.11-1606980127855;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=343177521;c=1606980127855;bpid=BP-2141226848-172.17.0.11-1606980127855;dnuuid=null
2020-12-03 07:22:10,001 [Thread-102] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:10,001 [Thread-102] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:22:10,001 [Thread-102] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:22:10,011 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,011 [Thread-102] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,012 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1929819664-172.17.0.11-1606980125323 is not formatted. Formatting ...
2020-12-03 07:22:10,012 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929819664-172.17.0.11-1606980125323 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929819664-172.17.0.11-1606980125323/current
2020-12-03 07:22:10,012 [IPC Server handler 2 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,013 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,013 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,115 [IPC Server handler 3 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,116 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,117 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,117 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,117 [Thread-129] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,117 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2141226848-172.17.0.11-1606980127855 is not formatted. Formatting ...
2020-12-03 07:22:10,117 [Thread-129] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2141226848-172.17.0.11-1606980127855 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2141226848-172.17.0.11-1606980127855/current
2020-12-03 07:22:10,150 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,150 [Thread-102] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,150 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1929819664-172.17.0.11-1606980125323 is not formatted. Formatting ...
2020-12-03 07:22:10,151 [Thread-102] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1929819664-172.17.0.11-1606980125323 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929819664-172.17.0.11-1606980125323/current
2020-12-03 07:22:10,219 [IPC Server handler 4 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,220 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,220 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,258 [Thread-129] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=343177521;bpid=BP-2141226848-172.17.0.11-1606980127855;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=343177521;c=1606980127855;bpid=BP-2141226848-172.17.0.11-1606980127855;dnuuid=null
2020-12-03 07:22:10,294 [Thread-102] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1324868641;bpid=BP-1929819664-172.17.0.11-1606980125323;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1324868641;c=1606980125323;bpid=BP-1929819664-172.17.0.11-1606980125323;dnuuid=null
2020-12-03 07:22:10,322 [IPC Server handler 5 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,323 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,323 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,411 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,426 [IPC Server handler 1 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,427 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,427 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,431 [Thread-103] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,530 [IPC Server handler 0 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,530 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,531 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,543 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-346988f8-cfa7-47d5-8f87-084b1f013d4f
2020-12-03 07:22:10,543 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042
2020-12-03 07:22:10,544 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:10,544 [Thread-103] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:10,546 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-56168ab9-1727-40bb-ae05-299e8d785343
2020-12-03 07:22:10,547 [Thread-103] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:10,548 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2a647400-54ee-447e-90de-ccea72b118ab
2020-12-03 07:22:10,548 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:10,552 [Thread-103] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:10,552 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:10,558 [Thread-103] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,558 [Thread-102] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,559 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:10,559 [Thread-129] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,560 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:10,560 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:10,567 [Thread-103] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,567 [Thread-102] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,567 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:10,570 [Thread-102] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:10,570 [Thread-102] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:10,570 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:10,570 [Thread-103] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:10,570 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:10,571 [Thread-103] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,571 [Thread-102] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,571 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,571 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:10,572 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:10,605 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2141226848-172.17.0.11-1606980127855 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 33ms
2020-12-03 07:22:10,606 [Thread-147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2141226848-172.17.0.11-1606980127855 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 46ms
2020-12-03 07:22:10,607 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2141226848-172.17.0.11-1606980127855 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 36ms
2020-12-03 07:22:10,607 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2141226848-172.17.0.11-1606980127855 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 47ms
2020-12-03 07:22:10,607 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2141226848-172.17.0.11-1606980127855: 48ms
2020-12-03 07:22:10,608 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2141226848-172.17.0.11-1606980127855: 38ms
2020-12-03 07:22:10,610 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:10,610 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:10,610 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:10,611 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:10,611 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:10,611 [Thread-158] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855/current/replicas doesn't exist 
2020-12-03 07:22:10,611 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:10,615 [Thread-161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:10,615 [Thread-162] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2141226848-172.17.0.11-1606980127855/current/replicas doesn't exist 
2020-12-03 07:22:10,615 [Thread-160] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:10,611 [Thread-157] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2141226848-172.17.0.11-1606980127855/current/replicas doesn't exist 
2020-12-03 07:22:10,616 [Thread-161] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855/current/replicas doesn't exist 
2020-12-03 07:22:10,620 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 10ms
2020-12-03 07:22:10,620 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-12-03 07:22:10,628 [Thread-161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 13ms
2020-12-03 07:22:10,628 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855: 19ms
2020-12-03 07:22:10,629 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 14ms
2020-12-03 07:22:10,633 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2141226848-172.17.0.11-1606980127855: 23ms
2020-12-03 07:22:10,645 [IPC Server handler 2 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,645 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:10,645 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:10,645 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,646 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:10,646 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:10,647 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-346988f8-cfa7-47d5-8f87-084b1f013d4f): finished scanning block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,647 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042): finished scanning block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,647 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2a647400-54ee-447e-90de-ccea72b118ab): finished scanning block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,648 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2141226848-172.17.0.11-1606980127855 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:10,649 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56168ab9-1727-40bb-ae05-299e8d785343): finished scanning block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,656 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1929819664-172.17.0.11-1606980125323 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 45ms
2020-12-03 07:22:10,656 [Thread-160] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1929819664-172.17.0.11-1606980125323 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 40ms
2020-12-03 07:22:10,656 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1929819664-172.17.0.11-1606980125323: 47ms
2020-12-03 07:22:10,656 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:10,657 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929819664-172.17.0.11-1606980125323/current/replicas doesn't exist 
2020-12-03 07:22:10,657 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:10,657 [Thread-172] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929819664-172.17.0.11-1606980125323/current/replicas doesn't exist 
2020-12-03 07:22:10,657 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:22:10,658 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:22:10,658 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323: 2ms
2020-12-03 07:22:10,659 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1929819664-172.17.0.11-1606980125323 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 49ms
2020-12-03 07:22:10,661 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1929819664-172.17.0.11-1606980125323 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 50ms
2020-12-03 07:22:10,661 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1929819664-172.17.0.11-1606980125323: 51ms
2020-12-03 07:22:10,661 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:10,661 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:10,662 [Thread-173] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929819664-172.17.0.11-1606980125323/current/replicas doesn't exist 
2020-12-03 07:22:10,662 [Thread-174] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929819664-172.17.0.11-1606980125323/current/replicas doesn't exist 
2020-12-03 07:22:10,662 [Thread-173] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:22:10,662 [Thread-174] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:22:10,662 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1929819664-172.17.0.11-1606980125323: 1ms
2020-12-03 07:22:10,673 [Thread-129] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:03 AM with interval of 21600000ms
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1929819664-172.17.0.11-1606980125323 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56168ab9-1727-40bb-ae05-299e8d785343): finished scanning block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2a647400-54ee-447e-90de-ccea72b118ab): finished scanning block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,674 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-346988f8-cfa7-47d5-8f87-084b1f013d4f): finished scanning block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042): finished scanning block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,673 [Thread-103] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:08 PM with interval of 21600000ms
2020-12-03 07:22:10,675 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56168ab9-1727-40bb-ae05-299e8d785343): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:10,675 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-346988f8-cfa7-47d5-8f87-084b1f013d4f): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:10,675 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:10,675 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2a647400-54ee-447e-90de-ccea72b118ab): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:10,680 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39451 beginning handshake with NN
2020-12-03 07:22:10,680 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39451 beginning handshake with NN
2020-12-03 07:22:10,680 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39390 beginning handshake with NN
2020-12-03 07:22:10,680 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39390 beginning handshake with NN
2020-12-03 07:22:10,691 [IPC Server handler 3 on default port 39390] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855) storage 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,691 [IPC Server handler 3 on default port 39451] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323) storage 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,694 [IPC Server handler 3 on default port 39390] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36575
2020-12-03 07:22:10,694 [IPC Server handler 3 on default port 39451] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36575
2020-12-03 07:22:10,694 [IPC Server handler 3 on default port 39390] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3eb1236f-9e26-41d5-8575-36980a5a90dc (127.0.0.1:36575).
2020-12-03 07:22:10,694 [IPC Server handler 3 on default port 39451] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3eb1236f-9e26-41d5-8575-36980a5a90dc (127.0.0.1:36575).
2020-12-03 07:22:10,697 [IPC Server handler 2 on default port 39451] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323) storage e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,697 [IPC Server handler 4 on default port 39390] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855) storage e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,697 [IPC Server handler 2 on default port 39451] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43098
2020-12-03 07:22:10,697 [IPC Server handler 4 on default port 39390] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43098
2020-12-03 07:22:10,697 [IPC Server handler 2 on default port 39451] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e170c33c-2867-4544-854b-2114caf8cf6f (127.0.0.1:43098).
2020-12-03 07:22:10,698 [IPC Server handler 4 on default port 39390] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e170c33c-2867-4544-854b-2114caf8cf6f (127.0.0.1:43098).
2020-12-03 07:22:10,700 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39451 successfully registered with NN
2020-12-03 07:22:10,700 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39390 successfully registered with NN
2020-12-03 07:22:10,700 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39451 successfully registered with NN
2020-12-03 07:22:10,700 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39451 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:10,700 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39390 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:10,700 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39390 successfully registered with NN
2020-12-03 07:22:10,701 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39390 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:10,701 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39451 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:10,720 [IPC Server handler 6 on default port 39390] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 for DN 127.0.0.1:43098
2020-12-03 07:22:10,720 [IPC Server handler 4 on default port 39451] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-346988f8-cfa7-47d5-8f87-084b1f013d4f for DN 127.0.0.1:36575
2020-12-03 07:22:10,721 [IPC Server handler 4 on default port 39451] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a647400-54ee-447e-90de-ccea72b118ab for DN 127.0.0.1:36575
2020-12-03 07:22:10,721 [IPC Server handler 6 on default port 39390] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56168ab9-1727-40bb-ae05-299e8d785343 for DN 127.0.0.1:43098
2020-12-03 07:22:10,722 [IPC Server handler 5 on default port 39390] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-346988f8-cfa7-47d5-8f87-084b1f013d4f for DN 127.0.0.1:36575
2020-12-03 07:22:10,722 [IPC Server handler 5 on default port 39451] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 for DN 127.0.0.1:43098
2020-12-03 07:22:10,722 [IPC Server handler 5 on default port 39390] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a647400-54ee-447e-90de-ccea72b118ab for DN 127.0.0.1:36575
2020-12-03 07:22:10,723 [IPC Server handler 5 on default port 39451] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56168ab9-1727-40bb-ae05-299e8d785343 for DN 127.0.0.1:43098
2020-12-03 07:22:10,752 [IPC Server handler 7 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,760 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x57115d5a4b6b0ca: Processing first storage report for DS-2a647400-54ee-447e-90de-ccea72b118ab from datanode 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,762 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0ca: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,764 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x57115d5a4b6b0ca: Processing first storage report for DS-346988f8-cfa7-47d5-8f87-084b1f013d4f from datanode 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,764 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0ca: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb4be99db7e460991: Processing first storage report for DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 from datanode e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6fef82d7891aee51: Processing first storage report for DS-2a647400-54ee-447e-90de-ccea72b118ab from datanode 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460991: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee51: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb4be99db7e460991: Processing first storage report for DS-56168ab9-1727-40bb-ae05-299e8d785343 from datanode e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7396ed4c28289e52: Processing first storage report for DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 from datanode e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460991: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e52: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6fef82d7891aee51: Processing first storage report for DS-346988f8-cfa7-47d5-8f87-084b1f013d4f from datanode 3eb1236f-9e26-41d5-8575-36980a5a90dc
2020-12-03 07:22:10,769 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee51: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7396ed4c28289e52: Processing first storage report for DS-56168ab9-1727-40bb-ae05-299e8d785343 from datanode e170c33c-2867-4544-854b-2114caf8cf6f
2020-12-03 07:22:10,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e52: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,788 [IPC Server handler 8 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,790 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:10,800 [IPC Server handler 1 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,807 [IPC Server handler 0 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,807 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460991,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 63 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,807 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e52,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 63 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,808 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,807 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0ca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 63 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,807 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee51,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 63 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,809 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,809 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:10,809 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:10,809 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:10,824 [IPC Server handler 0 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,829 [IPC Server handler 1 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,896 [IPC Server handler 2 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/testDecommission.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:10,935 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:writeFile(143)) - Created file testDecommission.dat with 1 replicas.
2020-12-03 07:22:10,952 [IPC Server handler 4 on default port 39390] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43098 for /user/root/testDecommission.dat
2020-12-03 07:22:10,974 [Thread-178] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:11,043 [DataXceiver for client DFSClient_NONMAPREDUCE_-1242339265_28 at /127.0.0.1:46158 [Receiving block BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001 src: /127.0.0.1:46158 dest: /127.0.0.1:43098
2020-12-03 07:22:11,098 [PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46158, dest: /127.0.0.1:43098, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1242339265_28, offset: 0, srvID: e170c33c-2867-4544-854b-2114caf8cf6f, blockid: BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001, duration(ns): 16644207
2020-12-03 07:22:11,099 [PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:11,108 [IPC Server handler 6 on default port 39390] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43098 for /user/root/testDecommission.dat
2020-12-03 07:22:11,110 [DataStreamer for file /user/root/testDecommission.dat] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:11,119 [DataXceiver for client DFSClient_NONMAPREDUCE_-1242339265_28 at /127.0.0.1:46160 [Receiving block BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002 src: /127.0.0.1:46160 dest: /127.0.0.1:43098
2020-12-03 07:22:11,142 [PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46160, dest: /127.0.0.1:43098, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1242339265_28, offset: 0, srvID: e170c33c-2867-4544-854b-2114caf8cf6f, blockid: BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002, duration(ns): 19710547
2020-12-03 07:22:11,145 [PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:11,152 [IPC Server handler 8 on default port 39390] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/testDecommission.dat is closed by DFSClient_NONMAPREDUCE_-1242339265_28
2020-12-03 07:22:11,162 [IPC Server handler 9 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:11,163 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:takeNodeOutofService(259)) - Taking node: [127.0.0.1:36575] out of service
2020-12-03 07:22:11,166 [Listener at localhost/36267] INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(100)) - Adding a node "127.0.0.1:36575" to the list of excluded hosts from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/exclude
2020-12-03 07:22:11,167 [Listener at localhost/36267] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:36575 [DISK]DS-2a647400-54ee-447e-90de-ccea72b118ab:NORMAL:127.0.0.1:36575 with 0 blocks
2020-12-03 07:22:11,167 [Listener at localhost/36267] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:36575 [DISK]DS-346988f8-cfa7-47d5-8f87-084b1f013d4f:NORMAL:127.0.0.1:36575 with 0 blocks
2020-12-03 07:22:11,167 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:36575 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:11,388 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:36575
2020-12-03 07:22:11,389 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 0 blocks and 1 nodes this tick
2020-12-03 07:22:11,667 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(352)) - node 127.0.0.1:36575 reached the state Decommissioned
2020-12-03 07:22:11,672 [IPC Server handler 0 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:11,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cb: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cb: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,725 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0cb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 19 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:11,726 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:11,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee52: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee52: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,728 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee52,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:11,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460992: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,728 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:11,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460992: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,729 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460992,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:11,729 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:11,730 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e53: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,730 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e53: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:11,731 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e53,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:11,731 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:12,684 [IPC Server handler 4 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,705 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-2141226848-172.17.0.11-1606980127855:blk_1073741825_1001 has 0 decommissioned replica.
2020-12-03 07:22:12,705 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-2141226848-172.17.0.11-1606980127855:blk_1073741826_1002 has 0 decommissioned replica.
2020-12-03 07:22:12,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cc: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cc: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0cc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:12,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:12,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460993: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee53: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460993: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee53: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,713 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460993,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:12,713 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee53,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:12,713 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:12,713 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:12,713 [IPC Server handler 5 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e54: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:12,727 [IPC Server handler 7 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e54: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 1
2020-12-03 07:22:12,728 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e54,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 5 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:12,728 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:12,732 [IPC Server handler 8 on default port 39390] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,738 [IPC Server handler 7 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/testDecommission.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:12,745 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:writeFile(143)) - Created file testDecommission.dat with 1 replicas.
2020-12-03 07:22:12,750 [IPC Server handler 9 on default port 39451] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43098 for /user/root/testDecommission.dat
2020-12-03 07:22:12,753 [Thread-186] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:12,761 [DataXceiver for client DFSClient_NONMAPREDUCE_-1746844549_28 at /127.0.0.1:46172 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 src: /127.0.0.1:46172 dest: /127.0.0.1:43098
2020-12-03 07:22:12,787 [PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46172, dest: /127.0.0.1:43098, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746844549_28, offset: 0, srvID: e170c33c-2867-4544-854b-2114caf8cf6f, blockid: BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001, duration(ns): 9631523
2020-12-03 07:22:12,788 [PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:12,792 [IPC Server handler 2 on default port 39451] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43098 for /user/root/testDecommission.dat
2020-12-03 07:22:12,795 [DataStreamer for file /user/root/testDecommission.dat] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:12,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-1746844549_28 at /127.0.0.1:46176 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 src: /127.0.0.1:46176 dest: /127.0.0.1:43098
2020-12-03 07:22:12,810 [PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46176, dest: /127.0.0.1:43098, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746844549_28, offset: 0, srvID: e170c33c-2867-4544-854b-2114caf8cf6f, blockid: BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002, duration(ns): 10339498
2020-12-03 07:22:12,810 [PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:12,813 [IPC Server handler 5 on default port 39451] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/testDecommission.dat is closed by DFSClient_NONMAPREDUCE_-1746844549_28
2020-12-03 07:22:12,816 [IPC Server handler 8 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,817 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:takeNodeOutofService(259)) - Taking node: [127.0.0.1:43098] out of service
2020-12-03 07:22:12,822 [Listener at localhost/36267] INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(100)) - Adding a node "127.0.0.1:43098" to the list of excluded hosts from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/exclude
2020-12-03 07:22:12,822 [Listener at localhost/36267] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:43098 [DISK]DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042:NORMAL:127.0.0.1:43098 with 1 blocks
2020-12-03 07:22:12,822 [Listener at localhost/36267] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:43098 [DISK]DS-56168ab9-1727-40bb-ae05-299e8d785343:NORMAL:127.0.0.1:43098 with 1 blocks
2020-12-03 07:22:12,823 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:13,323 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:13,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee54: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cd: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee54: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cd: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee54,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0cd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:13,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:13,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460994: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460994: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,710 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460994,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,710 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:13,718 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-12-03 07:22:13,720 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2020-12-03 07:22:13,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e55: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,720 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-2141226848-172.17.0.11-1606980127855 blk_1073741826_1002 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:22:13,720 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-2141226848-172.17.0.11-1606980127855 blk_1073741825_1001 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-03 07:22:13,725 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e55: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,727 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e55,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,727 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:13,762 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(407)) - Block: blk_1073741825_1001, Expected Replicas: 1, live replicas: 0, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 0, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:43098 , Current Datanode: 127.0.0.1:43098, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-12-03 07:22:13,763 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 2 blocks and 1 nodes this tick
2020-12-03 07:22:13,823 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:14,324 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:14,706 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0ce: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,706 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0ce: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee55: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee55: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e56: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e56: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,709 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee55,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,709 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:14,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e56,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:14,717 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0ce,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,718 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:14,724 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323) Starting thread to transfer BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 to 127.0.0.1:36575 
2020-12-03 07:22:14,727 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323) Starting thread to transfer BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 to 127.0.0.1:36575 
2020-12-03 07:22:14,749 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1e11e686] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:14,749 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460995: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460995: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:14,751 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460995,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:14,752 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:14,752 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@25248711] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:14,773 [DataXceiver for client  at /127.0.0.1:42958 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 src: /127.0.0.1:42958 dest: /127.0.0.1:36575
2020-12-03 07:22:14,774 [DataXceiver for client  at /127.0.0.1:42960 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 src: /127.0.0.1:42960 dest: /127.0.0.1:36575
2020-12-03 07:22:14,779 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@25248711] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:43098: Transmitted BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 (numBytes=8192) to /127.0.0.1:36575
2020-12-03 07:22:14,783 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1e11e686] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:43098: Transmitted BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 (numBytes=8192) to /127.0.0.1:36575
2020-12-03 07:22:14,785 [DataXceiver for client  at /127.0.0.1:42960 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 src: /127.0.0.1:42960 dest: /127.0.0.1:36575 of size 8192
2020-12-03 07:22:14,785 [DataXceiver for client  at /127.0.0.1:42958 [Receiving block BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 src: /127.0.0.1:42958 dest: /127.0.0.1:36575 of size 8192
2020-12-03 07:22:14,827 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:15,327 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:15,706 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cf: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0cf: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,707 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0cf,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:15,707 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:15,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee56: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e57: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee56: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e57: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee56,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:15,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e57,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:15,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:15,710 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:15,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460996: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460996: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:15,712 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460996,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:15,712 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:15,828 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:16,328 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:43098 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:16,706 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0d0: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0d0: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee57: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee57: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e58: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,707 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0d0,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e58: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:16,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee57,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:16,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e58,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,708 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:16,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460997: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460997: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,710 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460997,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,710 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:16,762 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:43098
2020-12-03 07:22:16,762 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 4 blocks and 1 nodes this tick
2020-12-03 07:22:16,828 [Listener at localhost/36267] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(352)) - node 127.0.0.1:43098 reached the state Decommissioned
2020-12-03 07:22:16,831 [IPC Server handler 6 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0d1: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,707 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x57115d5a4b6b0d1: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x57115d5a4b6b0d1,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,708 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:17,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e59: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460998: from storage DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee58: from storage DS-2a647400-54ee-447e-90de-ccea72b118ab node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7396ed4c28289e59: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4be99db7e460998: from storage DS-56168ab9-1727-40bb-ae05-299e8d785343 node DatanodeRegistration(127.0.0.1:43098, datanodeUuid=e170c33c-2867-4544-854b-2114caf8cf6f, infoPort=33276, infoSecurePort=0, ipcPort=36420, storageInfo=lv=-57;cid=testClusterID;nsid=1324868641;c=1606980125323), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6fef82d7891aee58: from storage DS-346988f8-cfa7-47d5-8f87-084b1f013d4f node DatanodeRegistration(127.0.0.1:36575, datanodeUuid=3eb1236f-9e26-41d5-8575-36980a5a90dc, infoPort=37144, infoSecurePort=0, ipcPort=36267, storageInfo=lv=-57;cid=testClusterID;nsid=343177521;c=1606980127855), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,711 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4be99db7e460998,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,711 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7396ed4c28289e59,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,711 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6fef82d7891aee58,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,711 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:17,711 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:17,711 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:17,835 [IPC Server handler 9 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,839 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(129)) - Block BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 replica on DatanodeInfoWithStorage[127.0.0.1:43098,DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042,DISK] is decommissioned.
2020-12-03 07:22:17,839 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-1929819664-172.17.0.11-1606980125323:blk_1073741825_1001 has 1 decommissioned replica.
2020-12-03 07:22:17,839 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(129)) - Block BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 replica on DatanodeInfoWithStorage[127.0.0.1:43098,DS-56168ab9-1727-40bb-ae05-299e8d785343,DISK] is decommissioned.
2020-12-03 07:22:17,839 [Listener at localhost/36267] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-1929819664-172.17.0.11-1606980125323:blk_1073741826_1002 has 1 decommissioned replica.
2020-12-03 07:22:17,841 [IPC Server handler 4 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,843 [IPC Server handler 7 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,845 [IPC Server handler 0 on default port 39451] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,845 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:17,846 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:17,847 [Listener at localhost/36267] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:17,847 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7650494b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:17,848 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-346988f8-cfa7-47d5-8f87-084b1f013d4f) exiting.
2020-12-03 07:22:17,848 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2a647400-54ee-447e-90de-ccea72b118ab) exiting.
2020-12-03 07:22:18,233 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@311c328b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:18,238 [Listener at localhost/36267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2ddae456{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,238 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16d8fb3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,240 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75b5b77d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,244 [Listener at localhost/36267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36267
2020-12-03 07:22:18,247 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,249 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,252 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,252 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,252 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39390
2020-12-03 07:22:18,253 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc) service to localhost/127.0.0.1:39451
2020-12-03 07:22:18,253 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc)
2020-12-03 07:22:18,253 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:18,253 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid 3eb1236f-9e26-41d5-8575-36980a5a90dc)
2020-12-03 07:22:18,254 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2141226848-172.17.0.11-1606980127855] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,254 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:18,254 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2141226848-172.17.0.11-1606980127855] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,261 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1929819664-172.17.0.11-1606980125323] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,263 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1929819664-172.17.0.11-1606980125323] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,265 [Listener at localhost/36267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,266 [Listener at localhost/36267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,266 [Listener at localhost/36267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,266 [Listener at localhost/36267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,272 [Listener at localhost/36267] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,272 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:18,272 [Listener at localhost/36267] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:18,272 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@44ea2b81] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:18,274 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56168ab9-1727-40bb-ae05-299e8d785343) exiting.
2020-12-03 07:22:18,274 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c2e6e5f5-23ea-4241-a3e9-f9ec5a998042) exiting.
2020-12-03 07:22:18,303 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1db26eef{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:18,304 [Listener at localhost/36267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e27888{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,306 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79034044{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,306 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6483e13{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,311 [Listener at localhost/36267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36420
2020-12-03 07:22:18,329 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,331 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,331 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,332 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39390
2020-12-03 07:22:18,332 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f) service to localhost/127.0.0.1:39451
2020-12-03 07:22:18,332 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2141226848-172.17.0.11-1606980127855 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f)
2020-12-03 07:22:18,333 [BP-2141226848-172.17.0.11-1606980127855 heartbeating to localhost/127.0.0.1:39390] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2141226848-172.17.0.11-1606980127855
2020-12-03 07:22:18,333 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1929819664-172.17.0.11-1606980125323 (Datanode Uuid e170c33c-2867-4544-854b-2114caf8cf6f)
2020-12-03 07:22:18,333 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2141226848-172.17.0.11-1606980127855] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,334 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2141226848-172.17.0.11-1606980127855] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,333 [BP-1929819664-172.17.0.11-1606980125323 heartbeating to localhost/127.0.0.1:39451] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1929819664-172.17.0.11-1606980125323
2020-12-03 07:22:18,344 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1929819664-172.17.0.11-1606980125323] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,344 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1929819664-172.17.0.11-1606980125323] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,348 [Listener at localhost/36267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,349 [Listener at localhost/36267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,350 [Listener at localhost/36267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,350 [Listener at localhost/36267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,353 [Listener at localhost/36267] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,353 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:18,354 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,359 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 12
2020-12-03 07:22:18,359 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@45d2e4e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:18,360 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@46722cf2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:18,360 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 13 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 3 Number of syncs: 11 SyncTimes(ms): 2 2 
2020-12-03 07:22:18,362 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:18,362 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:18,363 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:18,363 [CacheReplicationMonitor(710772217)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:18,364 [Listener at localhost/36267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39390
2020-12-03 07:22:18,366 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,367 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,367 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:18,367 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:18,407 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,407 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:18,409 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13771c74{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:18,410 [Listener at localhost/36267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4132f6e4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,411 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56e718bc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,411 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26534855{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,423 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:18,423 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,423 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 12
2020-12-03 07:22:18,423 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@237d5b4d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:18,423 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@394c434d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:18,424 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 13 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 5 Number of syncs: 9 SyncTimes(ms): 3 3 
2020-12-03 07:22:18,424 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:18,425 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:18,425 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:18,425 [CacheReplicationMonitor(1905531299)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:18,425 [Listener at localhost/36267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39451
2020-12-03 07:22:18,428 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,428 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:18,432 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:18,432 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,440 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,440 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:18,441 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7883f3c8{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:18,443 [Listener at localhost/36267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5182b53c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,443 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ae61ea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,443 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23d28440{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,445 [Listener at localhost/36267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:18,449 [Listener at localhost/36267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:18,449 [Listener at localhost/36267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:22:18,466 [Listener at localhost/36267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=2
Formatting using clusterid: testClusterID
2020-12-03 07:22:18,469 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:18,469 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:18,469 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:18,469 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:18,470 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:18,470 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:18,470 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:18,470 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:18,470 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:18,471 [Listener at localhost/36267] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:18,472 [Listener at localhost/36267] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:737)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1184)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:422)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1072)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:419)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation(TestDecommission.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:18,474 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,474 [Listener at localhost/36267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:18,474 [Listener at localhost/36267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:18,474 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,474 [Listener at localhost/36267] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:18,475 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:18,475 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:18
2020-12-03 07:22:18,475 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:18,475 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:18,476 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:18,476 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:18,489 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,490 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,491 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:18,491 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:18,491 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:18,491 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:18,492 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:18,493 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:18,493 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:18,493 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:18,493 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:18,493 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:18,494 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:18,494 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:18,494 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:18,494 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:18,500 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:18,500 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:18,500 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:18,501 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:18,502 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:18,503 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:18,503 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:18,503 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:18,504 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:18,504 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:18,504 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:18,504 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:18,504 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:18,505 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:18,506 [Listener at localhost/36267] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:18,695 [Listener at localhost/36267] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:18,856 [Listener at localhost/36267] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:19,011 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:19,011 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:19,017 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:19,018 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:19,083 [Listener at localhost/36267] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:19,086 [Listener at localhost/36267] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:19,090 [Listener at localhost/36267] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:19,092 [Listener at localhost/36267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:19,092 [Listener at localhost/36267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:19,094 [Listener at localhost/36267] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:19,101 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3536c614] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:19,102 [Listener at localhost/36267] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:19,102 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,104 [Listener at localhost/36267] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:19,105 [Listener at localhost/36267] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:19,105 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,107 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:19,108 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:19,108 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:19,108 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:19,109 [Listener at localhost/36267] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:19,110 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:19,110 [Listener at localhost/36267] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41109
2020-12-03 07:22:19,110 [Listener at localhost/36267] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:19,113 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@199705c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:19,113 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@315f547b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:19,119 [Listener at localhost/36267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@205017ed{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:19,122 [Listener at localhost/36267] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d910a48{HTTP/1.1,[http/1.1]}{localhost:41109}
2020-12-03 07:22:19,122 [Listener at localhost/36267] INFO  server.Server (Server.java:doStart(419)) - Started @16387ms
2020-12-03 07:22:19,124 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:19,125 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:19,125 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:19,125 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:19,125 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:19,126 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:19,126 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:19,126 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:19,126 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:19,127 [Listener at localhost/36267] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:19,127 [Listener at localhost/36267] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:648)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:710)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:926)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1692)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1314)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1083)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:419)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation(TestDecommission.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:19,128 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,129 [Listener at localhost/36267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:19,129 [Listener at localhost/36267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:19,129 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,129 [Listener at localhost/36267] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:19,129 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:19,130 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:19
2020-12-03 07:22:19,130 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:19,131 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,131 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:19,131 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:19,140 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,140 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,141 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:19,141 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:19,141 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:19,141 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,141 [Listener at localhost/36267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:19,142 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:19,143 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:19,143 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:19,143 [Listener at localhost/36267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:19,143 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:19,143 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,144 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:19,144 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:19,148 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:19,148 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:19,148 [Listener at localhost/36267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:19,148 [Listener at localhost/36267] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:19,148 [Listener at localhost/36267] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:19,149 [Listener at localhost/36267] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:19,149 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:19,149 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,150 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:19,150 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:19,152 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:19,153 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,153 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:19,153 [Listener at localhost/36267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:19,231 [Listener at localhost/36267] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:19,264 [Listener at localhost/36267] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:19,266 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:19,267 [Listener at localhost/36267] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:19,267 [Listener at localhost/36267] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:19,267 [Listener at localhost/36267] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:19,270 [Listener at localhost/36267] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:19,271 [Listener at localhost/36267] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:19,271 [Listener at localhost/36267] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:19,271 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:19,272 [Listener at localhost/36267] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:19,341 [Listener at localhost/36267] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:19,341 [Listener at localhost/36267] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 187 msecs
2020-12-03 07:22:19,342 [Listener at localhost/36267] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:19,343 [Listener at localhost/36267] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:19,344 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:19,351 [Listener at localhost/33294] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33294 to access this namenode/service.
2020-12-03 07:22:19,353 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:19,379 [Listener at localhost/33294] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:19,381 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:19,381 [Listener at localhost/33294] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:19,381 [Listener at localhost/33294] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:19,381 [Listener at localhost/33294] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:19,388 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:19,389 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:19,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:19,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:19,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:19,390 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:22:19,393 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:19,393 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:19,398 [Listener at localhost/33294] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33294
2020-12-03 07:22:19,399 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:19,399 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:19,400 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:19,403 [CacheReplicationMonitor(1227342320)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
Formatting using clusterid: testClusterID
2020-12-03 07:22:19,407 [Listener at localhost/33294] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:19,408 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:19,408 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:19,408 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:19,408 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:19,409 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:19,409 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:19,409 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns2
2020-12-03 07:22:19,409 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:19,410 [Listener at localhost/33294] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:19,410 [Listener at localhost/33294] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:737)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1184)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:422)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1072)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:419)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation(TestDecommission.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:19,411 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,411 [Listener at localhost/33294] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:19,411 [Listener at localhost/33294] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:19,411 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,411 [Listener at localhost/33294] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:19,412 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:19,412 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:19
2020-12-03 07:22:19,412 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:19,412 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,412 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:19,413 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:19,416 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,417 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,417 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:19,417 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:19,417 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:19,417 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:19,418 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:19,419 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,420 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:19,420 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:19,422 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:19,422 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:19,423 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,424 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:19,424 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:19,424 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:19,425 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,426 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:19,426 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:19,427 [Listener at localhost/33294] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:19,519 [Listener at localhost/33294] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 has been successfully formatted.
2020-12-03 07:22:19,587 [Listener at localhost/33294] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 has been successfully formatted.
2020-12-03 07:22:19,599 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:19,603 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:19,604 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:19,611 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:19,656 [Listener at localhost/33294] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:19,658 [Listener at localhost/33294] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:19,658 [Listener at localhost/33294] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:19,659 [Listener at localhost/33294] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:19,667 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@354e6ae1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:19,668 [Listener at localhost/33294] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:19,668 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,670 [Listener at localhost/33294] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:19,670 [Listener at localhost/33294] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:19,670 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,673 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:19,673 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:19,673 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:19,673 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:19,675 [Listener at localhost/33294] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:19,675 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:19,675 [Listener at localhost/33294] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38874
2020-12-03 07:22:19,676 [Listener at localhost/33294] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:19,678 [Listener at localhost/33294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43b6ba05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:19,678 [Listener at localhost/33294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e84f4bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:19,685 [Listener at localhost/33294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7b31d4f6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:19,687 [Listener at localhost/33294] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@78eccfcc{HTTP/1.1,[http/1.1]}{localhost:38874}
2020-12-03 07:22:19,687 [Listener at localhost/33294] INFO  server.Server (Server.java:doStart(419)) - Started @16951ms
2020-12-03 07:22:19,688 [Listener at localhost/33294] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:19,689 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:19,690 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns2
2020-12-03 07:22:19,690 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:19,690 [Listener at localhost/33294] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:19,690 [Listener at localhost/33294] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:648)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:710)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:926)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1692)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1314)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1083)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:419)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation(TestDecommission.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:19,691 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,691 [Listener at localhost/33294] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:19,691 [Listener at localhost/33294] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:19,691 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,691 [Listener at localhost/33294] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:19,692 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:19,692 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:19
2020-12-03 07:22:19,692 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:19,692 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,693 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:19,693 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:19,697 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,697 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,698 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:19,698 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:19,698 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:19,698 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:22:19,699 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:19,700 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:19,700 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:19,700 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:19,700 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:19,700 [Listener at localhost/33294] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:19,701 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:19,701 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,702 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:19,702 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:19,704 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:19,704 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:19,704 [Listener at localhost/33294] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:19,704 [Listener at localhost/33294] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:19,705 [Listener at localhost/33294] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:19,705 [Listener at localhost/33294] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:19,705 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:19,705 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,705 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:19,706 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:19,706 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:19,707 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:19,707 [Listener at localhost/33294] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:19,707 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:19,707 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:19,707 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:19,708 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:19,708 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:19,708 [Listener at localhost/33294] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:19,731 [Listener at localhost/33294] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:19,786 [Listener at localhost/33294] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:19,788 [Listener at localhost/33294] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current
2020-12-03 07:22:19,788 [Listener at localhost/33294] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current
2020-12-03 07:22:19,788 [Listener at localhost/33294] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:19,789 [Listener at localhost/33294] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:19,791 [Listener at localhost/33294] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:19,792 [Listener at localhost/33294] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:19,792 [Listener at localhost/33294] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000
2020-12-03 07:22:19,792 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:19,793 [Listener at localhost/33294] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:19,866 [Listener at localhost/33294] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:19,867 [Listener at localhost/33294] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 157 msecs
2020-12-03 07:22:19,867 [Listener at localhost/33294] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:19,868 [Listener at localhost/33294] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:19,869 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:19,873 [Listener at localhost/34155] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34155 to access this namenode/service.
2020-12-03 07:22:19,874 [Listener at localhost/34155] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:19,893 [Listener at localhost/34155] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:19,898 [Listener at localhost/34155] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:19,899 [Listener at localhost/34155] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:19,899 [Listener at localhost/34155] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:19,899 [Listener at localhost/34155] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:19,903 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:19,904 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:19,904 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:19,904 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:19,904 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:19,904 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:22:19,907 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:19,907 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:19,912 [Listener at localhost/34155] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34155
2020-12-03 07:22:19,912 [Listener at localhost/34155] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:19,912 [Listener at localhost/34155] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:19,913 [Listener at localhost/34155] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:19,917 [CacheReplicationMonitor(2024862082)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:19,919 [Listener at localhost/34155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:19,920 [Listener at localhost/34155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:19,921 [Listener at localhost/34155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:19,922 [Listener at localhost/34155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:19,923 [Listener at localhost/34155] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:19,923 [Listener at localhost/34155] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:19,923 [Listener at localhost/34155] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:19,923 [Listener at localhost/34155] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:19,924 [Listener at localhost/34155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,924 [Listener at localhost/34155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:19,924 [Listener at localhost/34155] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:19,925 [Listener at localhost/34155] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37622
2020-12-03 07:22:19,925 [Listener at localhost/34155] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:19,925 [Listener at localhost/34155] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:19,926 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,927 [Listener at localhost/34155] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:19,928 [Listener at localhost/34155] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:19,928 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:19,930 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:19,930 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:19,931 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:19,931 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:19,931 [Listener at localhost/34155] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46441
2020-12-03 07:22:19,932 [Listener at localhost/34155] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:19,933 [Listener at localhost/34155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4634c767{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:19,933 [Listener at localhost/34155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a133a68{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:19,939 [Listener at localhost/34155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e1a62e7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:19,941 [Listener at localhost/34155] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bf1273e{HTTP/1.1,[http/1.1]}{localhost:46441}
2020-12-03 07:22:19,941 [Listener at localhost/34155] INFO  server.Server (Server.java:doStart(419)) - Started @17206ms
2020-12-03 07:22:19,959 [Listener at localhost/34155] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38179
2020-12-03 07:22:19,960 [Listener at localhost/34155] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:19,960 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4aa9ce18] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:19,960 [Listener at localhost/34155] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:19,960 [Listener at localhost/34155] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:19,961 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:19,965 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43591
2020-12-03 07:22:19,972 [Listener at localhost/43591] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1,ns2
2020-12-03 07:22:19,976 [Listener at localhost/43591] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1,ns2
2020-12-03 07:22:19,978 [Thread-298] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33294 starting to offer service
2020-12-03 07:22:19,978 [Thread-299] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34155 starting to offer service
2020-12-03 07:22:19,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:19,988 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:19,999 [Listener at localhost/43591] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:20,009 [Listener at localhost/43591] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:20,010 [Thread-299] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34155
2020-12-03 07:22:20,010 [Thread-298] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33294
2020-12-03 07:22:20,012 [Listener at localhost/43591] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:20,012 [Thread-299] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:20,014 [Listener at localhost/43591] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:20,014 [Listener at localhost/43591] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:20,015 [Listener at localhost/43591] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:20,015 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:20,015 [Listener at localhost/43591] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:20,015 [Listener at localhost/43591] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:20,015 [Listener at localhost/43591] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:20,017 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:20,018 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40311
2020-12-03 07:22:20,018 [Listener at localhost/43591] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:20,018 [Listener at localhost/43591] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:20,019 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:20,021 [Listener at localhost/43591] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:20,021 [Listener at localhost/43591] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:20,021 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:20,023 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:20,024 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:20,024 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:20,024 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:20,025 [Listener at localhost/43591] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44093
2020-12-03 07:22:20,025 [Listener at localhost/43591] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:20,027 [Listener at localhost/43591] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69e934d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:20,028 [Listener at localhost/43591] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4cd12e96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:20,034 [Thread-299] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:20,035 [Thread-299] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1110722234. Formatting...
2020-12-03 07:22:20,036 [Thread-299] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:20,037 [Listener at localhost/43591] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f2f053b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:20,040 [Listener at localhost/43591] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@478b0527{HTTP/1.1,[http/1.1]}{localhost:44093}
2020-12-03 07:22:20,040 [Listener at localhost/43591] INFO  server.Server (Server.java:doStart(419)) - Started @17304ms
2020-12-03 07:22:20,087 [Listener at localhost/43591] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34055
2020-12-03 07:22:20,087 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:20,087 [Listener at localhost/43591] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:20,088 [Listener at localhost/43591] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:20,088 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@341621ff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:20,092 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:20,098 [Listener at localhost/40560] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40560
2020-12-03 07:22:20,107 [Listener at localhost/40560] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1,ns2
2020-12-03 07:22:20,108 [Listener at localhost/40560] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1,ns2
2020-12-03 07:22:20,108 [Thread-323] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33294 starting to offer service
2020-12-03 07:22:20,108 [Thread-324] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34155 starting to offer service
2020-12-03 07:22:20,114 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:20,121 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:20,126 [Thread-324] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34155
2020-12-03 07:22:20,128 [Thread-324] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:20,128 [Thread-323] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33294
2020-12-03 07:22:20,137 [IPC Server handler 2 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,138 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,138 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,153 [Thread-299] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:20,153 [Thread-299] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1110722234. Formatting...
2020-12-03 07:22:20,154 [Thread-299] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:20,180 [Thread-324] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:20,181 [Thread-324] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1110722234. Formatting...
2020-12-03 07:22:20,181 [Thread-324] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2e14823-cb8f-459c-a345-e62728d707b8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:20,243 [IPC Server handler 3 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,245 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,245 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,297 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,297 [Thread-299] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,298 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-996288588-172.17.0.11-1606980139427 is not formatted. Formatting ...
2020-12-03 07:22:20,298 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-996288588-172.17.0.11-1606980139427 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-996288588-172.17.0.11-1606980139427/current
2020-12-03 07:22:20,349 [IPC Server handler 4 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,350 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,350 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,391 [Thread-324] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5610@fcc2a2860216
2020-12-03 07:22:20,392 [Thread-324] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1110722234. Formatting...
2020-12-03 07:22:20,392 [Thread-324] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-448dc060-b0c6-4548-9d02-3e195e2d7952 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:20,434 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,435 [Thread-299] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,435 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-996288588-172.17.0.11-1606980139427 is not formatted. Formatting ...
2020-12-03 07:22:20,435 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-996288588-172.17.0.11-1606980139427 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-996288588-172.17.0.11-1606980139427/current
2020-12-03 07:22:20,451 [IPC Server handler 5 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,452 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,452 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,533 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,534 [Thread-324] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,534 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-996288588-172.17.0.11-1606980139427 is not formatted. Formatting ...
2020-12-03 07:22:20,534 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-996288588-172.17.0.11-1606980139427 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-996288588-172.17.0.11-1606980139427/current
2020-12-03 07:22:20,541 [Thread-299] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1110722234;bpid=BP-996288588-172.17.0.11-1606980139427;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1110722234;c=1606980139427;bpid=BP-996288588-172.17.0.11-1606980139427;dnuuid=null
2020-12-03 07:22:20,553 [IPC Server handler 6 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,554 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,554 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,648 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,648 [Thread-324] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,648 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-996288588-172.17.0.11-1606980139427 is not formatted. Formatting ...
2020-12-03 07:22:20,648 [Thread-324] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-996288588-172.17.0.11-1606980139427 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-996288588-172.17.0.11-1606980139427/current
2020-12-03 07:22:20,655 [IPC Server handler 7 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,656 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,656 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,667 [Thread-299] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,669 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54
2020-12-03 07:22:20,670 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:20,672 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58
2020-12-03 07:22:20,672 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:20,673 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:20,675 [Thread-299] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:20,675 [Thread-298] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:20,675 [Thread-298] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:22:20,675 [Thread-299] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:20,676 [Thread-298] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:22:20,676 [Thread-299] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:20,676 [Thread-299] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:20,677 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,677 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:20,678 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:20,687 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,688 [Thread-298] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,688 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1086596637-172.17.0.11-1606980138506 is not formatted. Formatting ...
2020-12-03 07:22:20,688 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1086596637-172.17.0.11-1606980138506 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1086596637-172.17.0.11-1606980138506/current
2020-12-03 07:22:20,691 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-996288588-172.17.0.11-1606980139427 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 14ms
2020-12-03 07:22:20,692 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-996288588-172.17.0.11-1606980139427 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 13ms
2020-12-03 07:22:20,692 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-996288588-172.17.0.11-1606980139427: 15ms
2020-12-03 07:22:20,692 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:20,692 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:20,692 [Thread-342] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-996288588-172.17.0.11-1606980139427/current/replicas doesn't exist 
2020-12-03 07:22:20,692 [Thread-343] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-996288588-172.17.0.11-1606980139427/current/replicas doesn't exist 
2020-12-03 07:22:20,693 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:22:20,693 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:22:20,693 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-996288588-172.17.0.11-1606980139427: 2ms
2020-12-03 07:22:20,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:20,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:20,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58): finished scanning block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54): finished scanning block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,695 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:20,695 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:20,758 [IPC Server handler 8 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,758 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,758 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,759 [Thread-324] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1110722234;bpid=BP-996288588-172.17.0.11-1606980139427;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1110722234;c=1606980139427;bpid=BP-996288588-172.17.0.11-1606980139427;dnuuid=null
2020-12-03 07:22:20,760 [Thread-323] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:20,760 [Thread-323] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:22:20,760 [Thread-323] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:22:20,770 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,770 [Thread-323] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,770 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1086596637-172.17.0.11-1606980138506 is not formatted. Formatting ...
2020-12-03 07:22:20,770 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1086596637-172.17.0.11-1606980138506 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1086596637-172.17.0.11-1606980138506/current
2020-12-03 07:22:20,788 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,788 [Thread-298] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,788 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1086596637-172.17.0.11-1606980138506 is not formatted. Formatting ...
2020-12-03 07:22:20,788 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1086596637-172.17.0.11-1606980138506 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1086596637-172.17.0.11-1606980138506/current
2020-12-03 07:22:20,860 [IPC Server handler 9 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,860 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,861 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,918 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,919 [Thread-323] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,919 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1086596637-172.17.0.11-1606980138506 is not formatted. Formatting ...
2020-12-03 07:22:20,919 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1086596637-172.17.0.11-1606980138506 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1086596637-172.17.0.11-1606980138506/current
2020-12-03 07:22:20,943 [Thread-298] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1289973594;bpid=BP-1086596637-172.17.0.11-1606980138506;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1289973594;c=1606980138506;bpid=BP-1086596637-172.17.0.11-1606980138506;dnuuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,943 [Thread-299] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:06 AM with interval of 21600000ms
2020-12-03 07:22:20,943 [Thread-298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,944 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:34155 beginning handshake with NN
2020-12-03 07:22:20,945 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:20,945 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:20,946 [IPC Server handler 0 on default port 34155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427) storage 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,947 [IPC Server handler 0 on default port 34155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37622
2020-12-03 07:22:20,947 [IPC Server handler 0 on default port 34155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1180e988-31a1-4c49-81c2-b1d22afe8aa4 (127.0.0.1:37622).
2020-12-03 07:22:20,949 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:34155 successfully registered with NN
2020-12-03 07:22:20,949 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34155 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:20,955 [IPC Server handler 1 on default port 34155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 for DN 127.0.0.1:37622
2020-12-03 07:22:20,955 [IPC Server handler 1 on default port 34155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 for DN 127.0.0.1:37622
2020-12-03 07:22:20,962 [IPC Server handler 2 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:20,962 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1086596637-172.17.0.11-1606980138506 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 18ms
2020-12-03 07:22:20,962 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:20,963 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:20,963 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1086596637-172.17.0.11-1606980138506 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 18ms
2020-12-03 07:22:20,963 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1086596637-172.17.0.11-1606980138506: 18ms
2020-12-03 07:22:20,963 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:20,963 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:20,964 [Thread-351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1086596637-172.17.0.11-1606980138506/current/replicas doesn't exist 
2020-12-03 07:22:20,964 [Thread-352] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1086596637-172.17.0.11-1606980138506/current/replicas doesn't exist 
2020-12-03 07:22:20,964 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:22:20,964 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:22:20,964 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506: 1ms
2020-12-03 07:22:20,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd0f0c62fcc40c82d: Processing first storage report for DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 from datanode 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd0f0c62fcc40c82d: from storage DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 node DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:20,965 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:20,965 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:20,965 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:33294 beginning handshake with NN
2020-12-03 07:22:20,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd0f0c62fcc40c82d: Processing first storage report for DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 from datanode 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54): finished scanning block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58): finished scanning block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:20,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd0f0c62fcc40c82d: from storage DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 node DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:20,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54): no suitable block pools found to scan.  Waiting 1814399728 ms.
2020-12-03 07:22:20,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58): no suitable block pools found to scan.  Waiting 1814399728 ms.
2020-12-03 07:22:20,966 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd0f0c62fcc40c82d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:20,967 [IPC Server handler 0 on default port 33294] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506) storage 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,967 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:20,967 [IPC Server handler 0 on default port 33294] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37622
2020-12-03 07:22:20,968 [IPC Server handler 0 on default port 33294] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1180e988-31a1-4c49-81c2-b1d22afe8aa4 (127.0.0.1:37622).
2020-12-03 07:22:20,969 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:33294 successfully registered with NN
2020-12-03 07:22:20,969 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33294 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:20,971 [IPC Server handler 1 on default port 33294] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 for DN 127.0.0.1:37622
2020-12-03 07:22:20,971 [IPC Server handler 1 on default port 33294] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 for DN 127.0.0.1:37622
2020-12-03 07:22:20,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8b439d23b38a689e: Processing first storage report for DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 from datanode 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8b439d23b38a689e: from storage DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54 node DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:20,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8b439d23b38a689e: Processing first storage report for DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 from datanode 1180e988-31a1-4c49-81c2-b1d22afe8aa4
2020-12-03 07:22:20,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8b439d23b38a689e: from storage DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58 node DatanodeRegistration(127.0.0.1:37622, datanodeUuid=1180e988-31a1-4c49-81c2-b1d22afe8aa4, infoPort=38179, infoSecurePort=0, ipcPort=43591, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:20,975 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8b439d23b38a689e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:20,975 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,000 [Thread-323] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1289973594;bpid=BP-1086596637-172.17.0.11-1606980138506;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1289973594;c=1606980138506;bpid=BP-1086596637-172.17.0.11-1606980138506;dnuuid=null
2020-12-03 07:22:21,064 [IPC Server handler 4 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,065 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:21,065 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:21,067 [Thread-324] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,069 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2e14823-cb8f-459c-a345-e62728d707b8
2020-12-03 07:22:21,070 [Thread-324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:21,072 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-448dc060-b0c6-4548-9d02-3e195e2d7952
2020-12-03 07:22:21,072 [Thread-324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:21,073 [Thread-324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:21,074 [Thread-324] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,074 [Thread-323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,075 [Thread-323] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,075 [Thread-323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:21,075 [Thread-324] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,075 [Thread-323] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:21,076 [Thread-324] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:21,076 [Thread-323] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,076 [Thread-324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,076 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:21,077 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:21,091 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1086596637-172.17.0.11-1606980138506 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 15ms
2020-12-03 07:22:21,094 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1086596637-172.17.0.11-1606980138506 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 17ms
2020-12-03 07:22:21,094 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1086596637-172.17.0.11-1606980138506: 17ms
2020-12-03 07:22:21,094 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:21,095 [Thread-359] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1086596637-172.17.0.11-1606980138506/current/replicas doesn't exist 
2020-12-03 07:22:21,095 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:21,095 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:22:21,095 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:21,095 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:21,095 [Thread-361] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1086596637-172.17.0.11-1606980138506/current/replicas doesn't exist 
2020-12-03 07:22:21,096 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:22:21,096 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1086596637-172.17.0.11-1606980138506: 2ms
2020-12-03 07:22:21,098 [Thread-323] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:12 AM with interval of 21600000ms
2020-12-03 07:22:21,098 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:33294 beginning handshake with NN
2020-12-03 07:22:21,100 [IPC Server handler 3 on default port 33294] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506) storage 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:21,105 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1086596637-172.17.0.11-1606980138506 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,117 [IPC Server handler 3 on default port 33294] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40311
2020-12-03 07:22:21,119 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-448dc060-b0c6-4548-9d02-3e195e2d7952): finished scanning block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,120 [IPC Server handler 3 on default port 33294] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 404d8cc1-3118-4e6b-bc99-d5d96dabc888 (127.0.0.1:40311).
2020-12-03 07:22:21,120 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d2e14823-cb8f-459c-a345-e62728d707b8): finished scanning block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,120 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-448dc060-b0c6-4548-9d02-3e195e2d7952): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:21,120 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d2e14823-cb8f-459c-a345-e62728d707b8): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:21,121 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:33294 successfully registered with NN
2020-12-03 07:22:21,124 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33294 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:21,128 [IPC Server handler 4 on default port 33294] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2e14823-cb8f-459c-a345-e62728d707b8 for DN 127.0.0.1:40311
2020-12-03 07:22:21,129 [IPC Server handler 4 on default port 33294] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-448dc060-b0c6-4548-9d02-3e195e2d7952 for DN 127.0.0.1:40311
2020-12-03 07:22:21,131 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-996288588-172.17.0.11-1606980139427 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 35ms
2020-12-03 07:22:21,132 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-996288588-172.17.0.11-1606980139427 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 38ms
2020-12-03 07:22:21,132 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-996288588-172.17.0.11-1606980139427: 38ms
2020-12-03 07:22:21,133 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:21,133 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:21,133 [Thread-368] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-996288588-172.17.0.11-1606980139427/current/replicas doesn't exist 
2020-12-03 07:22:21,133 [Thread-369] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-996288588-172.17.0.11-1606980139427/current/replicas doesn't exist 
2020-12-03 07:22:21,134 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:22:21,134 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:22:21,135 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-996288588-172.17.0.11-1606980139427: 2ms
2020-12-03 07:22:21,135 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d6b4df9a3edfc8c: Processing first storage report for DS-d2e14823-cb8f-459c-a345-e62728d707b8 from datanode 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,135 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d6b4df9a3edfc8c: from storage DS-d2e14823-cb8f-459c-a345-e62728d707b8 node DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:21,135 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:21,135 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-996288588-172.17.0.11-1606980139427 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:21,135 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d6b4df9a3edfc8c: Processing first storage report for DS-448dc060-b0c6-4548-9d02-3e195e2d7952 from datanode 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,135 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:34155 beginning handshake with NN
2020-12-03 07:22:21,135 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d2e14823-cb8f-459c-a345-e62728d707b8): finished scanning block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,135 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-448dc060-b0c6-4548-9d02-3e195e2d7952): finished scanning block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,135 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d6b4df9a3edfc8c: from storage DS-448dc060-b0c6-4548-9d02-3e195e2d7952 node DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1289973594;c=1606980138506), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:21,136 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d2e14823-cb8f-459c-a345-e62728d707b8): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:22:21,136 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-448dc060-b0c6-4548-9d02-3e195e2d7952): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:22:21,136 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6d6b4df9a3edfc8c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:21,136 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,136 [IPC Server handler 5 on default port 34155] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427) storage 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,137 [IPC Server handler 5 on default port 34155] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40311
2020-12-03 07:22:21,137 [IPC Server handler 5 on default port 34155] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 404d8cc1-3118-4e6b-bc99-d5d96dabc888 (127.0.0.1:40311).
2020-12-03 07:22:21,138 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:34155 successfully registered with NN
2020-12-03 07:22:21,138 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34155 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:21,140 [IPC Server handler 6 on default port 34155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2e14823-cb8f-459c-a345-e62728d707b8 for DN 127.0.0.1:40311
2020-12-03 07:22:21,141 [IPC Server handler 6 on default port 34155] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-448dc060-b0c6-4548-9d02-3e195e2d7952 for DN 127.0.0.1:40311
2020-12-03 07:22:21,142 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf4218f8062a781ee: Processing first storage report for DS-d2e14823-cb8f-459c-a345-e62728d707b8 from datanode 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf4218f8062a781ee: from storage DS-d2e14823-cb8f-459c-a345-e62728d707b8 node DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:21,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf4218f8062a781ee: Processing first storage report for DS-448dc060-b0c6-4548-9d02-3e195e2d7952 from datanode 404d8cc1-3118-4e6b-bc99-d5d96dabc888
2020-12-03 07:22:21,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf4218f8062a781ee: from storage DS-448dc060-b0c6-4548-9d02-3e195e2d7952 node DatanodeRegistration(127.0.0.1:40311, datanodeUuid=404d8cc1-3118-4e6b-bc99-d5d96dabc888, infoPort=34055, infoSecurePort=0, ipcPort=40560, storageInfo=lv=-57;cid=testClusterID;nsid=1110722234;c=1606980139427), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:21,144 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf4218f8062a781ee,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:21,144 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,167 [IPC Server handler 8 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,172 [IPC Server handler 6 on default port 33294] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,173 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:21,176 [IPC Server handler 9 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,179 [IPC Server handler 7 on default port 33294] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,181 [Listener at localhost/40560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:21,183 [IPC Server handler 0 on default port 34155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,185 [IPC Server handler 8 on default port 33294] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:21,191 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:21,191 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:21,191 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:21,191 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4cf27c10] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:21,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d2e14823-cb8f-459c-a345-e62728d707b8) exiting.
2020-12-03 07:22:21,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-448dc060-b0c6-4548-9d02-3e195e2d7952) exiting.
2020-12-03 07:22:21,212 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f2f053b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:21,213 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@478b0527{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:21,214 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4cd12e96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:21,215 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69e934d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:21,231 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40560
2020-12-03 07:22:21,234 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:21,247 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:21,248 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:21,248 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:21,248 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:33294
2020-12-03 07:22:21,248 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888)
2020-12-03 07:22:21,248 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,249 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1086596637-172.17.0.11-1606980138506] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,248 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888) service to localhost/127.0.0.1:34155
2020-12-03 07:22:21,249 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1086596637-172.17.0.11-1606980138506] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,250 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 404d8cc1-3118-4e6b-bc99-d5d96dabc888)
2020-12-03 07:22:21,250 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,251 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-996288588-172.17.0.11-1606980139427] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,253 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-996288588-172.17.0.11-1606980139427] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,256 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:21,256 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:21,256 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:21,257 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:21,259 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:21,259 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:21,259 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:21,259 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7c61cdc2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:21,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5bf6daae-17f9-40ff-b6ef-5b981e1eae58) exiting.
2020-12-03 07:22:21,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-b505fda6-bb06-4cc9-ad98-09b326aa4f54) exiting.
2020-12-03 07:22:21,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e1a62e7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:21,283 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1bf1273e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:21,284 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a133a68{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:21,285 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4634c767{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:21,288 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43591
2020-12-03 07:22:21,294 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:21,295 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:21,300 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:21,300 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:21,300 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:33294
2020-12-03 07:22:21,300 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4) service to localhost/127.0.0.1:34155
2020-12-03 07:22:21,300 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1086596637-172.17.0.11-1606980138506 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4)
2020-12-03 07:22:21,301 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-996288588-172.17.0.11-1606980139427 (Datanode Uuid 1180e988-31a1-4c49-81c2-b1d22afe8aa4)
2020-12-03 07:22:21,301 [BP-1086596637-172.17.0.11-1606980138506 heartbeating to localhost/127.0.0.1:33294] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1086596637-172.17.0.11-1606980138506
2020-12-03 07:22:21,301 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1086596637-172.17.0.11-1606980138506] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,301 [BP-996288588-172.17.0.11-1606980139427 heartbeating to localhost/127.0.0.1:34155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-996288588-172.17.0.11-1606980139427
2020-12-03 07:22:21,301 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1086596637-172.17.0.11-1606980138506] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,305 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:21,305 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-996288588-172.17.0.11-1606980139427] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,306 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-996288588-172.17.0.11-1606980139427] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:21,306 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:21,307 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:21,307 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:21,309 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:21,309 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:21,309 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:21,310 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:22:21,311 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@49b6dbc2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:21,311 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7140652b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:21,314 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-12-03 07:22:21,315 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:21,317 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:21,317 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:21,317 [CacheReplicationMonitor(2024862082)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:21,324 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34155
2020-12-03 07:22:21,326 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:21,326 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:21,331 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:21,331 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:21,343 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:21,343 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:21,351 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7b31d4f6{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:21,352 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@78eccfcc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:21,353 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e84f4bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:21,354 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43b6ba05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:21,359 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:21,359 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:21,359 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:22:21,359 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1f596166] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:21,359 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@213ce8be] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:21,362 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 1 
2020-12-03 07:22:21,363 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:21,364 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:21,364 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:21,365 [CacheReplicationMonitor(1227342320)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:21,371 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33294
2020-12-03 07:22:21,373 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:21,375 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:21,376 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:21,376 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:21,385 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:21,385 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:21,399 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@205017ed{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:21,401 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d910a48{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:21,402 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@315f547b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:21,403 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@199705c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:21,403 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:21,409 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:21,409 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
