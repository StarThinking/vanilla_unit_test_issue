2020-12-03 07:20:57,181 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-12-03 07:20:57,842 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:57,861 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:57,863 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:57,864 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:57,865 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:57,865 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:57,865 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:57,866 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:57,933 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:57,963 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:57,965 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:57,966 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:20:57,966 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:57,966 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:57,975 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:57,979 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:57
2020-12-03 07:20:57,984 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:57,985 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:57,988 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:57,989 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:58,014 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,016 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,020 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:58,021 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:58,025 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:20:58,025 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,032 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:58,033 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:58,033 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:58,033 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:58,034 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:58,035 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:58,035 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:58,035 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:58,036 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:20:58,036 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:58,036 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:58,076 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:58,077 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:58,077 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:58,077 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:58,099 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:58,099 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,100 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:58,100 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:58,108 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:58,108 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:58,108 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:58,109 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:58,117 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:58,121 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:58,127 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:58,127 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,128 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:58,128 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:58,138 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:58,139 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:58,139 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:58,145 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:58,145 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:58,148 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:58,149 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,149 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:58,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:58,190 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:20:58,381 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:58,476 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:58,520 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:58,520 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:58,681 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:58,683 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:58,797 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:58,802 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:59,388 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:59,513 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:59,513 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:59,524 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:59,591 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1530c739] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:59,615 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:59,623 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:59,642 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4099ms
2020-12-03 07:20:59,787 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:59,791 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:59,792 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:59,802 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:59,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:59,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:59,807 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:59,840 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:59,841 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:59,851 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40729
2020-12-03 07:20:59,855 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:59,919 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3cce57c7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:59,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33f676f6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:59,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e403b4a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:59,980 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e6f3f28{HTTP/1.1,[http/1.1]}{localhost:40729}
2020-12-03 07:20:59,980 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4438ms
2020-12-03 07:21:00,010 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:00,010 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:00,011 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:00,011 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:00,012 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:00,012 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:00,012 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:00,013 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:00,013 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:00,015 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,016 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:00,016 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:00,016 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,017 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:00,017 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:00
2020-12-03 07:21:00,017 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:00,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:00,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:00,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:00,023 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,023 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,024 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:00,024 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:00,024 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:21:00,025 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,025 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:00,026 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:00,026 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:00,026 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:00,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:00,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:00,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:00,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:00,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:21:00,028 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:00,028 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:00,029 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:00,029 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:00,030 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:00,030 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:00,033 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:00,033 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:00,033 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:00,034 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:00,034 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:00,034 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:00,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:00,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:00,036 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:00,036 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:00,037 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:00,037 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:00,037 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:00,038 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:00,038 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:00,038 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:00,039 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:00,039 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:00,040 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:00,097 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:00,148 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:00,152 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:00,152 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:00,153 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:00,153 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:00,187 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:00,194 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:00,194 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:00,201 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:00,203 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:00,476 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:00,477 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 434 msecs
2020-12-03 07:21:00,687 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:00,746 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,762 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:01,073 [Listener at localhost/35464] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35464 to access this namenode/service.
2020-12-03 07:21:01,076 [Listener at localhost/35464] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:01,096 [Listener at localhost/35464] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:01,110 [Listener at localhost/35464] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:01,111 [Listener at localhost/35464] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:01,111 [Listener at localhost/35464] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:01,112 [Listener at localhost/35464] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:01,120 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:01,120 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:01,120 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:01,122 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:01,123 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:01,123 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-12-03 07:21:01,167 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:01,167 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:01,172 [Listener at localhost/35464] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35464
2020-12-03 07:21:01,177 [Listener at localhost/35464] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:01,177 [Listener at localhost/35464] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:01,195 [Listener at localhost/35464] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 17 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:01,201 [CacheReplicationMonitor(1635716611)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:01,212 [Listener at localhost/35464] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:01,244 [Listener at localhost/35464] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:01,266 [Listener at localhost/35464] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:01,287 [Listener at localhost/35464] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:01,293 [Listener at localhost/35464] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:01,297 [Listener at localhost/35464] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:01,303 [Listener at localhost/35464] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:01,304 [Listener at localhost/35464] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:01,305 [Listener at localhost/35464] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:01,305 [Listener at localhost/35464] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:01,311 [Listener at localhost/35464] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:01,321 [Listener at localhost/35464] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42709
2020-12-03 07:21:01,323 [Listener at localhost/35464] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:01,323 [Listener at localhost/35464] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:01,345 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:01,348 [Listener at localhost/35464] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:01,349 [Listener at localhost/35464] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:01,349 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:01,352 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:01,354 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:01,354 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:01,355 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:01,378 [Listener at localhost/35464] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42091
2020-12-03 07:21:01,378 [Listener at localhost/35464] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:01,380 [Listener at localhost/35464] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@235f4c10{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:01,382 [Listener at localhost/35464] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c7a975a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:01,396 [Listener at localhost/35464] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d08f3f5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:01,397 [Listener at localhost/35464] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@119f1f2a{HTTP/1.1,[http/1.1]}{localhost:42091}
2020-12-03 07:21:01,397 [Listener at localhost/35464] INFO  server.Server (Server.java:doStart(419)) - Started @5855ms
2020-12-03 07:21:01,795 [Listener at localhost/35464] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44745
2020-12-03 07:21:01,796 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@41beb473] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:01,797 [Listener at localhost/35464] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:01,798 [Listener at localhost/35464] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:02,088 [Listener at localhost/35464] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:02,091 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:02,104 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40567
2020-12-03 07:21:02,137 [Listener at localhost/40567] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:02,138 [Listener at localhost/40567] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:02,150 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464 starting to offer service
2020-12-03 07:21:02,157 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,157 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,163 [Listener at localhost/40567] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:02,166 [Listener at localhost/40567] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:02,166 [Listener at localhost/40567] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:02,174 [Listener at localhost/40567] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:02,175 [Listener at localhost/40567] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,175 [Listener at localhost/40567] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:02,176 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:02,176 [Listener at localhost/40567] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,177 [Listener at localhost/40567] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,177 [Listener at localhost/40567] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,177 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:02,179 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32781
2020-12-03 07:21:02,179 [Listener at localhost/40567] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:02,179 [Listener at localhost/40567] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:02,182 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,184 [Listener at localhost/40567] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:02,185 [Listener at localhost/40567] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:02,186 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,189 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:02,190 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:02,191 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:02,191 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:02,192 [Listener at localhost/40567] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43992
2020-12-03 07:21:02,192 [Listener at localhost/40567] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:02,217 [Listener at localhost/40567] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48e64352{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:02,219 [Listener at localhost/40567] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4362d7df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:02,228 [Listener at localhost/40567] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@473b3b7a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:02,234 [Listener at localhost/40567] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1734f68{HTTP/1.1,[http/1.1]}{localhost:43992}
2020-12-03 07:21:02,234 [Listener at localhost/40567] INFO  server.Server (Server.java:doStart(419)) - Started @6692ms
2020-12-03 07:21:02,374 [Listener at localhost/40567] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40325
2020-12-03 07:21:02,376 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:02,376 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ed190be] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:02,376 [Listener at localhost/40567] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:02,377 [Listener at localhost/40567] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:02,378 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:02,384 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38022
2020-12-03 07:21:02,411 [Listener at localhost/38022] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:02,412 [Listener at localhost/38022] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:02,413 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,413 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,415 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464 starting to offer service
2020-12-03 07:21:02,431 [Listener at localhost/38022] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:02,434 [Listener at localhost/38022] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:02,434 [Listener at localhost/38022] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:02,448 [Listener at localhost/38022] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:02,449 [Listener at localhost/38022] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,449 [Listener at localhost/38022] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:02,450 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:02,450 [Listener at localhost/38022] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,451 [Listener at localhost/38022] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,451 [Listener at localhost/38022] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,451 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:02,452 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39392
2020-12-03 07:21:02,453 [Listener at localhost/38022] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:02,453 [Listener at localhost/38022] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:02,455 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,456 [Listener at localhost/38022] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:02,458 [Listener at localhost/38022] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:02,458 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,460 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:02,461 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:02,462 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:02,462 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:02,463 [Listener at localhost/38022] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34822
2020-12-03 07:21:02,463 [Listener at localhost/38022] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:02,467 [Listener at localhost/38022] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ec2bf82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:02,468 [Listener at localhost/38022] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cc0bcf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:02,474 [Listener at localhost/38022] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@324dcd31{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:02,475 [Listener at localhost/38022] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@503d56b5{HTTP/1.1,[http/1.1]}{localhost:34822}
2020-12-03 07:21:02,476 [Listener at localhost/38022] INFO  server.Server (Server.java:doStart(419)) - Started @6933ms
2020-12-03 07:21:02,500 [Listener at localhost/38022] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40460
2020-12-03 07:21:02,501 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:02,501 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@433ffad1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:02,501 [Listener at localhost/38022] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:02,502 [Listener at localhost/38022] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:02,503 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:02,509 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37850
2020-12-03 07:21:02,517 [Listener at localhost/37850] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:02,518 [Listener at localhost/37850] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:02,519 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464 starting to offer service
2020-12-03 07:21:02,522 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,523 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,527 [Listener at localhost/37850] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:02,529 [Listener at localhost/37850] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:02,529 [Listener at localhost/37850] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:02,531 [Listener at localhost/37850] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:02,531 [Listener at localhost/37850] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,532 [Listener at localhost/37850] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:02,532 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:02,533 [Listener at localhost/37850] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:02,533 [Listener at localhost/37850] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,533 [Listener at localhost/37850] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:02,534 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:02,535 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33600
2020-12-03 07:21:02,535 [Listener at localhost/37850] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:02,535 [Listener at localhost/37850] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:02,538 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,540 [Listener at localhost/37850] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:02,542 [Listener at localhost/37850] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:02,542 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:02,545 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:02,546 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:02,547 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:02,547 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:02,548 [Listener at localhost/37850] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44345
2020-12-03 07:21:02,548 [Listener at localhost/37850] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:02,550 [Listener at localhost/37850] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c074c0c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:02,551 [Listener at localhost/37850] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5949eba8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:02,560 [Listener at localhost/37850] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c8bdd5b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:02,563 [Listener at localhost/37850] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29d2d081{HTTP/1.1,[http/1.1]}{localhost:44345}
2020-12-03 07:21:02,564 [Listener at localhost/37850] INFO  server.Server (Server.java:doStart(419)) - Started @7022ms
2020-12-03 07:21:02,637 [Listener at localhost/37850] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33733
2020-12-03 07:21:02,638 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:02,638 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58783f6c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:02,638 [Listener at localhost/37850] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:02,639 [Listener at localhost/37850] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:02,639 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:02,644 [Listener at localhost/38400] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38400
2020-12-03 07:21:02,655 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464
2020-12-03 07:21:02,655 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464
2020-12-03 07:21:02,655 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464
2020-12-03 07:21:02,658 [Listener at localhost/38400] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:02,659 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:02,659 [Listener at localhost/38400] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:02,659 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:02,659 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:02,660 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464 starting to offer service
2020-12-03 07:21:02,666 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:02,666 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:02,669 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35464
2020-12-03 07:21:02,670 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:02,771 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:02,771 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:02,771 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:02,772 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:02,771 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:02,773 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:02,772 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:02,774 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:02,774 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-87b65d91-a106-4e48-90b9-53e935df9a69 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:02,772 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:02,779 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4e14a717-4079-4694-a34a-4793fba8a545 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:21:02,785 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c49982f5-7fe1-4ecf-b289-8fd44349e746 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:03,107 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:03,108 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:03,108 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:03,107 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:03,108 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:03,107 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3131@6f793ec4780b
2020-12-03 07:21:03,109 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:03,109 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f64cae25-1447-4c9a-9973-6094603523bb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:03,108 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:03,110 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-91d34a39-871b-4ff3-9ac0-53f709647c75 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:03,108 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1002418183. Formatting...
2020-12-03 07:21:03,114 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:21:03,178 [IPC Server handler 4 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,188 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,188 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,282 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,282 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,283 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,283 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,283 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,283 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,284 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,284 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,284 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,284 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,284 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,284 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,290 [IPC Server handler 0 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,291 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,292 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,326 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,326 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,326 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,326 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,395 [IPC Server handler 2 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,396 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,396 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,486 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,487 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,487 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,487 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,490 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,490 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,490 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,490 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,490 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,491 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,491 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,491 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,498 [IPC Server handler 1 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,499 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,499 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,540 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,541 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:03,541 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-2049721092-172.17.0.10-1606980058179 is not formatted. Formatting ...
2020-12-03 07:21:03,541 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049721092-172.17.0.10-1606980058179 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2049721092-172.17.0.10-1606980058179/current
2020-12-03 07:21:03,601 [IPC Server handler 3 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,602 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,603 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,673 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1002418183;bpid=BP-2049721092-172.17.0.10-1606980058179;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1002418183;c=1606980058179;bpid=BP-2049721092-172.17.0.10-1606980058179;dnuuid=null
2020-12-03 07:21:03,673 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1002418183;bpid=BP-2049721092-172.17.0.10-1606980058179;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1002418183;c=1606980058179;bpid=BP-2049721092-172.17.0.10-1606980058179;dnuuid=null
2020-12-03 07:21:03,673 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1002418183;bpid=BP-2049721092-172.17.0.10-1606980058179;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1002418183;c=1606980058179;bpid=BP-2049721092-172.17.0.10-1606980058179;dnuuid=null
2020-12-03 07:21:03,705 [IPC Server handler 5 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,705 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,706 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,727 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1002418183;bpid=BP-2049721092-172.17.0.10-1606980058179;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1002418183;c=1606980058179;bpid=BP-2049721092-172.17.0.10-1606980058179;dnuuid=null
2020-12-03 07:21:03,808 [IPC Server handler 6 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,809 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,809 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,883 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd
2020-12-03 07:21:03,883 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 823f7691-933f-4f8a-bc4a-dd695e1e0315
2020-12-03 07:21:03,883 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bf383aa6-aaa6-4e01-8789-0502814535f0
2020-12-03 07:21:03,911 [IPC Server handler 7 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,912 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:03,912 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:03,916 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 903fc7c6-e04b-4768-ba43-5570b640bc62
2020-12-03 07:21:04,014 [IPC Server handler 8 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,015 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:04,015 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:04,028 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c
2020-12-03 07:21:04,029 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:04,029 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4e14a717-4079-4694-a34a-4793fba8a545
2020-12-03 07:21:04,029 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c49982f5-7fe1-4ecf-b289-8fd44349e746
2020-12-03 07:21:04,029 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-87b65d91-a106-4e48-90b9-53e935df9a69
2020-12-03 07:21:04,032 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:04,032 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:04,032 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:04,035 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f64cae25-1447-4c9a-9973-6094603523bb
2020-12-03 07:21:04,035 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:04,036 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-91d34a39-871b-4ff3-9ac0-53f709647c75
2020-12-03 07:21:04,037 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:04,040 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95
2020-12-03 07:21:04,042 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:04,054 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:04,054 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:04,054 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:04,055 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933
2020-12-03 07:21:04,055 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:21:04,056 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:04,062 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:04,064 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:04,065 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:04,066 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:04,072 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:04,072 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:04,072 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:04,072 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:04,075 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:04,075 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:04,076 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:04,076 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:04,077 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,077 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:04,077 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:04,082 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:04,081 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:04,078 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,091 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,091 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:04,082 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:04,092 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,093 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:04,093 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:04,093 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:04,093 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:04,094 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:04,094 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:04,122 [IPC Server handler 9 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,125 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:04,125 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:04,137 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 43ms
2020-12-03 07:21:04,138 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 45ms
2020-12-03 07:21:04,140 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 57ms
2020-12-03 07:21:04,141 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 47ms
2020-12-03 07:21:04,142 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 50ms
2020-12-03 07:21:04,142 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 48ms
2020-12-03 07:21:04,142 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2049721092-172.17.0.10-1606980058179: 65ms
2020-12-03 07:21:04,142 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2049721092-172.17.0.10-1606980058179: 50ms
2020-12-03 07:21:04,143 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 49ms
2020-12-03 07:21:04,143 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2049721092-172.17.0.10-1606980058179: 51ms
2020-12-03 07:21:04,143 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2049721092-172.17.0.10-1606980058179 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 51ms
2020-12-03 07:21:04,143 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2049721092-172.17.0.10-1606980058179: 52ms
2020-12-03 07:21:04,145 [Thread-165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:04,145 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:04,145 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:04,145 [Thread-168] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,146 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:04,146 [Thread-167] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,146 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:04,146 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:04,146 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:04,147 [Thread-172] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,145 [Thread-165] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,145 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:04,147 [Thread-170] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,147 [Thread-169] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,147 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,148 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:21:04,148 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:21:04,148 [Thread-166] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2049721092-172.17.0.10-1606980058179/current/replicas doesn't exist 
2020-12-03 07:21:04,148 [Thread-165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 4ms
2020-12-03 07:21:04,148 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:21:04,149 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:21:04,149 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 3ms
2020-12-03 07:21:04,149 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 2ms
2020-12-03 07:21:04,149 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:21:04,150 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179: 5ms
2020-12-03 07:21:04,150 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179: 5ms
2020-12-03 07:21:04,149 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179: 5ms
2020-12-03 07:21:04,150 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2049721092-172.17.0.10-1606980058179: 5ms
2020-12-03 07:21:04,152 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:04,152 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:04,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:04,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:04,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:04,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:04,152 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:04,152 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2049721092-172.17.0.10-1606980058179 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f64cae25-1447-4c9a-9973-6094603523bb): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4e14a717-4079-4694-a34a-4793fba8a545): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c49982f5-7fe1-4ecf-b289-8fd44349e746): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-87b65d91-a106-4e48-90b9-53e935df9a69): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-91d34a39-871b-4ff3-9ac0-53f709647c75): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,158 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933): finished scanning block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-87b65d91-a106-4e48-90b9-53e935df9a69): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f64cae25-1447-4c9a-9973-6094603523bb): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c49982f5-7fe1-4ecf-b289-8fd44349e746): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-91d34a39-871b-4ff3-9ac0-53f709647c75): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4e14a717-4079-4694-a34a-4793fba8a545): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:04,179 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:49 AM with interval of 21600000ms
2020-12-03 07:21:04,180 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:05 AM with interval of 21600000ms
2020-12-03 07:21:04,179 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:15 AM with interval of 21600000ms
2020-12-03 07:21:04,179 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:03 PM with interval of 21600000ms
2020-12-03 07:21:04,187 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd) service to localhost/127.0.0.1:35464 beginning handshake with NN
2020-12-03 07:21:04,187 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 823f7691-933f-4f8a-bc4a-dd695e1e0315) service to localhost/127.0.0.1:35464 beginning handshake with NN
2020-12-03 07:21:04,187 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid bf383aa6-aaa6-4e01-8789-0502814535f0) service to localhost/127.0.0.1:35464 beginning handshake with NN
2020-12-03 07:21:04,187 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 903fc7c6-e04b-4768-ba43-5570b640bc62) service to localhost/127.0.0.1:35464 beginning handshake with NN
2020-12-03 07:21:04,199 [IPC Server handler 0 on default port 35464] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32781, datanodeUuid=bf383aa6-aaa6-4e01-8789-0502814535f0, infoPort=40325, infoSecurePort=0, ipcPort=38022, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179) storage bf383aa6-aaa6-4e01-8789-0502814535f0
2020-12-03 07:21:04,202 [IPC Server handler 0 on default port 35464] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32781
2020-12-03 07:21:04,202 [IPC Server handler 0 on default port 35464] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bf383aa6-aaa6-4e01-8789-0502814535f0 (127.0.0.1:32781).
2020-12-03 07:21:04,205 [IPC Server handler 2 on default port 35464] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33600, datanodeUuid=903fc7c6-e04b-4768-ba43-5570b640bc62, infoPort=33733, infoSecurePort=0, ipcPort=38400, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179) storage 903fc7c6-e04b-4768-ba43-5570b640bc62
2020-12-03 07:21:04,205 [IPC Server handler 2 on default port 35464] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33600
2020-12-03 07:21:04,206 [IPC Server handler 2 on default port 35464] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 903fc7c6-e04b-4768-ba43-5570b640bc62 (127.0.0.1:33600).
2020-12-03 07:21:04,206 [IPC Server handler 1 on default port 35464] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39392, datanodeUuid=823f7691-933f-4f8a-bc4a-dd695e1e0315, infoPort=40460, infoSecurePort=0, ipcPort=37850, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179) storage 823f7691-933f-4f8a-bc4a-dd695e1e0315
2020-12-03 07:21:04,207 [IPC Server handler 1 on default port 35464] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39392
2020-12-03 07:21:04,207 [IPC Server handler 1 on default port 35464] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 823f7691-933f-4f8a-bc4a-dd695e1e0315 (127.0.0.1:39392).
2020-12-03 07:21:04,207 [IPC Server handler 3 on default port 35464] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42709, datanodeUuid=b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd, infoPort=44745, infoSecurePort=0, ipcPort=40567, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179) storage b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd
2020-12-03 07:21:04,207 [IPC Server handler 3 on default port 35464] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42709
2020-12-03 07:21:04,207 [IPC Server handler 3 on default port 35464] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd (127.0.0.1:42709).
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid bf383aa6-aaa6-4e01-8789-0502814535f0) service to localhost/127.0.0.1:35464 successfully registered with NN
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35464 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 903fc7c6-e04b-4768-ba43-5570b640bc62) service to localhost/127.0.0.1:35464 successfully registered with NN
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd) service to localhost/127.0.0.1:35464 successfully registered with NN
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 823f7691-933f-4f8a-bc4a-dd695e1e0315) service to localhost/127.0.0.1:35464 successfully registered with NN
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35464 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35464 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:04,209 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35464 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:04,239 [IPC Server handler 6 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e14a717-4079-4694-a34a-4793fba8a545 for DN 127.0.0.1:33600
2020-12-03 07:21:04,241 [IPC Server handler 6 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933 for DN 127.0.0.1:33600
2020-12-03 07:21:04,241 [IPC Server handler 7 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c49982f5-7fe1-4ecf-b289-8fd44349e746 for DN 127.0.0.1:32781
2020-12-03 07:21:04,243 [IPC Server handler 7 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-91d34a39-871b-4ff3-9ac0-53f709647c75 for DN 127.0.0.1:32781
2020-12-03 07:21:04,244 [IPC Server handler 8 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-87b65d91-a106-4e48-90b9-53e935df9a69 for DN 127.0.0.1:39392
2020-12-03 07:21:04,244 [IPC Server handler 8 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95 for DN 127.0.0.1:39392
2020-12-03 07:21:04,244 [IPC Server handler 5 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c for DN 127.0.0.1:42709
2020-12-03 07:21:04,245 [IPC Server handler 9 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,245 [IPC Server handler 5 on default port 35464] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f64cae25-1447-4c9a-9973-6094603523bb for DN 127.0.0.1:42709
2020-12-03 07:21:04,251 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:39392
2020-12-03 07:21:04,252 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:04,282 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4371fd3c7ad4f74b: Processing first storage report for DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95 from datanode 823f7691-933f-4f8a-bc4a-dd695e1e0315
2020-12-03 07:21:04,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4371fd3c7ad4f74b: from storage DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95 node DatanodeRegistration(127.0.0.1:39392, datanodeUuid=823f7691-933f-4f8a-bc4a-dd695e1e0315, infoPort=40460, infoSecurePort=0, ipcPort=37850, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x99dfb1c582d06ca3: Processing first storage report for DS-c49982f5-7fe1-4ecf-b289-8fd44349e746 from datanode bf383aa6-aaa6-4e01-8789-0502814535f0
2020-12-03 07:21:04,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x99dfb1c582d06ca3: from storage DS-c49982f5-7fe1-4ecf-b289-8fd44349e746 node DatanodeRegistration(127.0.0.1:32781, datanodeUuid=bf383aa6-aaa6-4e01-8789-0502814535f0, infoPort=40325, infoSecurePort=0, ipcPort=38022, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb54d5029ab80ae67: Processing first storage report for DS-4e14a717-4079-4694-a34a-4793fba8a545 from datanode 903fc7c6-e04b-4768-ba43-5570b640bc62
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb54d5029ab80ae67: from storage DS-4e14a717-4079-4694-a34a-4793fba8a545 node DatanodeRegistration(127.0.0.1:33600, datanodeUuid=903fc7c6-e04b-4768-ba43-5570b640bc62, infoPort=33733, infoSecurePort=0, ipcPort=38400, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x82baf7077d051cca: Processing first storage report for DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c from datanode b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x82baf7077d051cca: from storage DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c node DatanodeRegistration(127.0.0.1:42709, datanodeUuid=b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd, infoPort=44745, infoSecurePort=0, ipcPort=40567, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4371fd3c7ad4f74b: Processing first storage report for DS-87b65d91-a106-4e48-90b9-53e935df9a69 from datanode 823f7691-933f-4f8a-bc4a-dd695e1e0315
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4371fd3c7ad4f74b: from storage DS-87b65d91-a106-4e48-90b9-53e935df9a69 node DatanodeRegistration(127.0.0.1:39392, datanodeUuid=823f7691-933f-4f8a-bc4a-dd695e1e0315, infoPort=40460, infoSecurePort=0, ipcPort=37850, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,287 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x99dfb1c582d06ca3: Processing first storage report for DS-91d34a39-871b-4ff3-9ac0-53f709647c75 from datanode bf383aa6-aaa6-4e01-8789-0502814535f0
2020-12-03 07:21:04,288 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x99dfb1c582d06ca3: from storage DS-91d34a39-871b-4ff3-9ac0-53f709647c75 node DatanodeRegistration(127.0.0.1:32781, datanodeUuid=bf383aa6-aaa6-4e01-8789-0502814535f0, infoPort=40325, infoSecurePort=0, ipcPort=38022, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,288 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb54d5029ab80ae67: Processing first storage report for DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933 from datanode 903fc7c6-e04b-4768-ba43-5570b640bc62
2020-12-03 07:21:04,288 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb54d5029ab80ae67: from storage DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933 node DatanodeRegistration(127.0.0.1:33600, datanodeUuid=903fc7c6-e04b-4768-ba43-5570b640bc62, infoPort=33733, infoSecurePort=0, ipcPort=38400, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,288 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x82baf7077d051cca: Processing first storage report for DS-f64cae25-1447-4c9a-9973-6094603523bb from datanode b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd
2020-12-03 07:21:04,288 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x82baf7077d051cca: from storage DS-f64cae25-1447-4c9a-9973-6094603523bb node DatanodeRegistration(127.0.0.1:42709, datanodeUuid=b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd, infoPort=44745, infoSecurePort=0, ipcPort=40567, storageInfo=lv=-57;cid=testClusterID;nsid=1002418183;c=1606980058179), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x82baf7077d051cca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x99dfb1c582d06ca3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb54d5029ab80ae67,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4371fd3c7ad4f74b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:04,311 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,310 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,311 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:04,354 [IPC Server handler 1 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,357 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:04,365 [IPC Server handler 9 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,366 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:04,382 [IPC Server handler 8 on default port 35464] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:21:04,384 [IPC Server handler 8 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:21:04,406 [IPC Server handler 7 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:04,422 [IPC Server handler 5 on default port 35464] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:04,594 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - parent: 
2020-12-03 07:21:04,597 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - add: MetricsTag{info=MsInfo{name=ProcessName, description=Process name}, value=NameNode}
2020-12-03 07:21:04,598 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - add: MetricsTag{info=MsInfo{name=SessionId, description=Session ID}, value=null}
2020-12-03 07:21:04,598 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - add: MetricsTag{info=MsInfo{name=Context, description=Metrics context}, value=dfs}
2020-12-03 07:21:04,599 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1sNumOps, description=Number of ops for journal syncs with 1s interval}, 3
2020-12-03 07:21:04,599 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1s50thPercentileLatency, description=50 percentile latency with 1 second interval for journal syncs}, 0
2020-12-03 07:21:04,600 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1s75thPercentileLatency, description=75 percentile latency with 1 second interval for journal syncs}, 0
2020-12-03 07:21:04,600 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1s90thPercentileLatency, description=90 percentile latency with 1 second interval for journal syncs}, 0
2020-12-03 07:21:04,601 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1s95thPercentileLatency, description=95 percentile latency with 1 second interval for journal syncs}, 0
2020-12-03 07:21:04,601 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=Syncs1s99thPercentileLatency, description=99 percentile latency with 1 second interval for journal syncs}, 0
2020-12-03 07:21:04,602 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1sNumOps, description=Number of ops for number of Transactions batched in sync with 1s interval}, 3
2020-12-03 07:21:04,602 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1s50thPercentileCount, description=50 percentile count with 1 second interval for number of Transactions batched in sync}, 0
2020-12-03 07:21:04,603 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1s75thPercentileCount, description=75 percentile count with 1 second interval for number of Transactions batched in sync}, 0
2020-12-03 07:21:04,603 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1s90thPercentileCount, description=90 percentile count with 1 second interval for number of Transactions batched in sync}, 0
2020-12-03 07:21:04,603 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1s95thPercentileCount, description=95 percentile count with 1 second interval for number of Transactions batched in sync}, 0
2020-12-03 07:21:04,604 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumTransactionsBatchedInSync1s99thPercentileCount, description=99 percentile count with 1 second interval for number of Transactions batched in sync}, 0
2020-12-03 07:21:04,604 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1sNumOps, description=Number of ops for storage block report with 1s interval}, 8
2020-12-03 07:21:04,605 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1s50thPercentileLatency, description=50 percentile latency with 1 second interval for storage block report}, 0
2020-12-03 07:21:04,605 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1s75thPercentileLatency, description=75 percentile latency with 1 second interval for storage block report}, 0
2020-12-03 07:21:04,606 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1s90thPercentileLatency, description=90 percentile latency with 1 second interval for storage block report}, 0
2020-12-03 07:21:04,606 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1s95thPercentileLatency, description=95 percentile latency with 1 second interval for storage block report}, 0
2020-12-03 07:21:04,607 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReport1s99thPercentileLatency, description=99 percentile latency with 1 second interval for storage block report}, 0
2020-12-03 07:21:04,607 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1sNumOps, description=Number of ops for cache report with 1s interval}, 0
2020-12-03 07:21:04,607 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1s50thPercentileLatency, description=50 percentile latency with 1 second interval for cache report}, 0
2020-12-03 07:21:04,608 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1s75thPercentileLatency, description=75 percentile latency with 1 second interval for cache report}, 0
2020-12-03 07:21:04,608 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1s90thPercentileLatency, description=90 percentile latency with 1 second interval for cache report}, 0
2020-12-03 07:21:04,609 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1s95thPercentileLatency, description=95 percentile latency with 1 second interval for cache report}, 0
2020-12-03 07:21:04,609 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReport1s99thPercentileLatency, description=99 percentile latency with 1 second interval for cache report}, 0
2020-12-03 07:21:04,610 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1sNumOps, description=Number of ops for generate EDEK time with 1s interval}, 0
2020-12-03 07:21:04,610 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1s50thPercentileLatency, description=50 percentile latency with 1 second interval for generate EDEK time}, 0
2020-12-03 07:21:04,611 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1s75thPercentileLatency, description=75 percentile latency with 1 second interval for generate EDEK time}, 0
2020-12-03 07:21:04,611 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1s90thPercentileLatency, description=90 percentile latency with 1 second interval for generate EDEK time}, 0
2020-12-03 07:21:04,611 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1s95thPercentileLatency, description=95 percentile latency with 1 second interval for generate EDEK time}, 0
2020-12-03 07:21:04,612 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTime1s99thPercentileLatency, description=99 percentile latency with 1 second interval for generate EDEK time}, 0
2020-12-03 07:21:04,612 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1sNumOps, description=Number of ops for warm up EDEK time with 1s interval}, 0
2020-12-03 07:21:04,613 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1s50thPercentileLatency, description=50 percentile latency with 1 second interval for warm up EDEK time}, 0
2020-12-03 07:21:04,613 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1s75thPercentileLatency, description=75 percentile latency with 1 second interval for warm up EDEK time}, 0
2020-12-03 07:21:04,614 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1s90thPercentileLatency, description=90 percentile latency with 1 second interval for warm up EDEK time}, 0
2020-12-03 07:21:04,614 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1s95thPercentileLatency, description=95 percentile latency with 1 second interval for warm up EDEK time}, 0
2020-12-03 07:21:04,615 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmupEDEKTime1s99thPercentileLatency, description=99 percentile latency with 1 second interval for warm up EDEK time}, 0
2020-12-03 07:21:04,615 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1sNumOps, description=Number of ops for resource check time with 1s interval}, 0
2020-12-03 07:21:04,615 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1s50thPercentileLatency, description=50 percentile latency with 1 second interval for resource check time}, 0
2020-12-03 07:21:04,616 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1s75thPercentileLatency, description=75 percentile latency with 1 second interval for resource check time}, 0
2020-12-03 07:21:04,616 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1s90thPercentileLatency, description=90 percentile latency with 1 second interval for resource check time}, 0
2020-12-03 07:21:04,617 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1s95thPercentileLatency, description=95 percentile latency with 1 second interval for resource check time}, 0
2020-12-03 07:21:04,617 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTime1s99thPercentileLatency, description=99 percentile latency with 1 second interval for resource check time}, 0
2020-12-03 07:21:04,618 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1sNumOps, description=Number of ops for edit log tailing time with 1s interval}, 0
2020-12-03 07:21:04,618 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1s50thPercentileLatency, description=50 percentile latency with 1 second interval for edit log tailing time}, 0
2020-12-03 07:21:04,618 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1s75thPercentileLatency, description=75 percentile latency with 1 second interval for edit log tailing time}, 0
2020-12-03 07:21:04,619 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1s90thPercentileLatency, description=90 percentile latency with 1 second interval for edit log tailing time}, 0
2020-12-03 07:21:04,619 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1s95thPercentileLatency, description=95 percentile latency with 1 second interval for edit log tailing time}, 0
2020-12-03 07:21:04,620 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTime1s99thPercentileLatency, description=99 percentile latency with 1 second interval for edit log tailing time}, 0
2020-12-03 07:21:04,620 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1sNumOps, description=Number of ops for edit log fetch time with 1s interval}, 0
2020-12-03 07:21:04,621 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1s50thPercentileLatency, description=50 percentile latency with 1 second interval for edit log fetch time}, 0
2020-12-03 07:21:04,621 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1s75thPercentileLatency, description=75 percentile latency with 1 second interval for edit log fetch time}, 0
2020-12-03 07:21:04,622 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1s90thPercentileLatency, description=90 percentile latency with 1 second interval for edit log fetch time}, 0
2020-12-03 07:21:04,622 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1s95thPercentileLatency, description=95 percentile latency with 1 second interval for edit log fetch time}, 0
2020-12-03 07:21:04,622 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTime1s99thPercentileLatency, description=99 percentile latency with 1 second interval for edit log fetch time}, 0
2020-12-03 07:21:04,623 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1sNumOps, description=Number of ops for number of edits loaded with 1s interval}, 0
2020-12-03 07:21:04,623 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1s50thPercentileCount, description=50 percentile count with 1 second interval for number of edits loaded}, 0
2020-12-03 07:21:04,624 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1s75thPercentileCount, description=75 percentile count with 1 second interval for number of edits loaded}, 0
2020-12-03 07:21:04,624 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1s90thPercentileCount, description=90 percentile count with 1 second interval for number of edits loaded}, 0
2020-12-03 07:21:04,625 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1s95thPercentileCount, description=95 percentile count with 1 second interval for number of edits loaded}, 0
2020-12-03 07:21:04,625 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoaded1s99thPercentileCount, description=99 percentile count with 1 second interval for number of edits loaded}, 0
2020-12-03 07:21:04,626 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1sNumOps, description=Number of ops for edit log tailing interval with 1s interval}, 0
2020-12-03 07:21:04,626 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1s50thPercentileLatency, description=50 percentile latency with 1 second interval for edit log tailing interval}, 0
2020-12-03 07:21:04,626 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1s75thPercentileLatency, description=75 percentile latency with 1 second interval for edit log tailing interval}, 0
2020-12-03 07:21:04,627 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1s90thPercentileLatency, description=90 percentile latency with 1 second interval for edit log tailing interval}, 0
2020-12-03 07:21:04,627 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1s95thPercentileLatency, description=95 percentile latency with 1 second interval for edit log tailing interval}, 0
2020-12-03 07:21:04,628 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailInterval1s99thPercentileLatency, description=99 percentile latency with 1 second interval for edit log tailing interval}, 0
2020-12-03 07:21:04,628 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=CreateFileOps, description=CreateFileOps}, 0
2020-12-03 07:21:04,629 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesCreated, description=FilesCreated}, 1
2020-12-03 07:21:04,629 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesAppended, description=FilesAppended}, 0
2020-12-03 07:21:04,630 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetBlockLocations, description=GetBlockLocations}, 0
2020-12-03 07:21:04,630 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesRenamed, description=FilesRenamed}, 0
2020-12-03 07:21:04,630 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesTruncated, description=FilesTruncated}, 0
2020-12-03 07:21:04,631 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetListingOps, description=GetListingOps}, 0
2020-12-03 07:21:04,631 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=DeleteFileOps, description=DeleteFileOps}, 0
2020-12-03 07:21:04,631 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesDeleted, description=Number of files/dirs deleted by delete or rename operations}, 0
2020-12-03 07:21:04,632 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FileInfoOps, description=FileInfoOps}, 0
2020-12-03 07:21:04,632 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=AddBlockOps, description=AddBlockOps}, 0
2020-12-03 07:21:04,632 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetAdditionalDatanodeOps, description=GetAdditionalDatanodeOps}, 0
2020-12-03 07:21:04,632 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=CreateSymlinkOps, description=CreateSymlinkOps}, 0
2020-12-03 07:21:04,633 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetLinkTargetOps, description=GetLinkTargetOps}, 0
2020-12-03 07:21:04,633 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=FilesInGetListingOps, description=FilesInGetListingOps}, 0
2020-12-03 07:21:04,633 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=SuccessfulReReplications, description=Number of successful re-replications}, 0
2020-12-03 07:21:04,634 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=NumTimesReReplicationNotScheduled, description=Number of times we failed to schedule a block re-replication.}, 0
2020-12-03 07:21:04,634 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=TimeoutReReplications, description=Number of timed out block re-replications}, 0
2020-12-03 07:21:04,634 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=AllowSnapshotOps, description=Number of allowSnapshot operations}, 0
2020-12-03 07:21:04,635 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=DisallowSnapshotOps, description=Number of disallowSnapshot operations}, 0
2020-12-03 07:21:04,635 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=CreateSnapshotOps, description=Number of createSnapshot operations}, 0
2020-12-03 07:21:04,635 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=DeleteSnapshotOps, description=Number of deleteSnapshot operations}, 0
2020-12-03 07:21:04,636 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=RenameSnapshotOps, description=Number of renameSnapshot operations}, 0
2020-12-03 07:21:04,636 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=ListSnapshottableDirOps, description=Number of listSnapshottableDirectory operations}, 0
2020-12-03 07:21:04,636 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=SnapshotDiffReportOps, description=Number of snapshotDiffReport operations}, 0
2020-12-03 07:21:04,637 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=BlockReceivedAndDeletedOps, description=Number of blockReceivedAndDeleted calls}, 0
2020-12-03 07:21:04,637 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=BlockOpsQueued, description=Number of blockReports and blockReceivedAndDeleted queued}, 3
2020-12-03 07:21:04,637 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=BlockOpsBatched, description=Number of blockReports and blockReceivedAndDeleted batch processed}, 6
2020-12-03 07:21:04,638 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=TransactionsNumOps, description=Number of ops for journal transactions}, 4
2020-12-03 07:21:04,638 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=TransactionsAvgTime, description=Average time for journal transactions}, 5.25
2020-12-03 07:21:04,638 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=SyncsNumOps, description=Number of ops for journal syncs}, 4
2020-12-03 07:21:04,639 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=SyncsAvgTime, description=Average time for journal syncs}, 0.25
2020-12-03 07:21:04,639 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=TransactionsBatchedInSync, description=Journal transactions batched in sync}, 0
2020-12-03 07:21:04,639 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=StorageBlockReportNumOps, description=Number of ops for number of blockReports from individual storages}, 8
2020-12-03 07:21:04,640 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=StorageBlockReportAvgTime, description=Average time for number of blockReports from individual storages}, 0.5
2020-12-03 07:21:04,640 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=CacheReportNumOps, description=Number of ops for cache report}, 0
2020-12-03 07:21:04,640 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=CacheReportAvgTime, description=Average time for cache report}, 0.0
2020-12-03 07:21:04,640 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GenerateEDEKTimeNumOps, description=Number of ops for generate EDEK time}, 0
2020-12-03 07:21:04,641 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GenerateEDEKTimeAvgTime, description=Average time for generate EDEK time}, 0.0
2020-12-03 07:21:04,641 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=WarmUpEDEKTimeNumOps, description=Number of ops for warm-up EDEK time}, 0
2020-12-03 07:21:04,641 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=WarmUpEDEKTimeAvgTime, description=Average time for warm-up EDEK time}, 0.0
2020-12-03 07:21:04,642 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=ResourceCheckTimeNumOps, description=Number of ops for resource check time}, 2
2020-12-03 07:21:04,642 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=ResourceCheckTimeAvgTime, description=Average time for resource check time}, 0.5
2020-12-03 07:21:04,642 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=SafeModeTime, description=Duration in SafeMode at startup in msec}, 0
2020-12-03 07:21:04,643 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=FsImageLoadTime, description=Time loading FS Image at startup in msec}, 434
2020-12-03 07:21:04,643 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=EditLogTailTimeNumOps, description=Number of ops for time tailing edit logs in msec}, 0
2020-12-03 07:21:04,643 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailTimeAvgTime, description=Average time for time tailing edit logs in msec}, 0.0
2020-12-03 07:21:04,644 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=EditLogFetchTimeNumOps, description=Number of ops for editLogFetchTime}, 0
2020-12-03 07:21:04,644 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogFetchTimeAvgTime, description=Average time for editLogFetchTime}, 0.0
2020-12-03 07:21:04,645 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=NumEditLogLoadedNumOps, description=Number of ops for number of edits loaded}, 0
2020-12-03 07:21:04,645 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=NumEditLogLoadedAvgCount, description=Average count for number of edits loaded}, 0.0
2020-12-03 07:21:04,646 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=EditLogTailIntervalNumOps, description=Number of ops for time between edit log tailing in msec}, 0
2020-12-03 07:21:04,646 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=EditLogTailIntervalAvgTime, description=Average time for time between edit log tailing in msec}, 0.0
2020-12-03 07:21:04,646 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetEditNumOps, description=Number of ops for getImageServlet getEdit}, 0
2020-12-03 07:21:04,647 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetEditAvgTime, description=Average time for getImageServlet getEdit}, 0.0
2020-12-03 07:21:04,647 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetImageNumOps, description=Number of ops for getImageServlet getImage}, 0
2020-12-03 07:21:04,647 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetImageAvgTime, description=Average time for getImageServlet getImage}, 0.0
2020-12-03 07:21:04,648 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=PutImageNumOps, description=Number of ops for getImageServlet putImage}, 0
2020-12-03 07:21:04,648 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=PutImageAvgTime, description=Average time for getImageServlet putImage}, 0.0
2020-12-03 07:21:04,648 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=TotalFileOps, description=Number of file system operations}, 0
2020-12-03 07:21:06,679 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - parent: 
2020-12-03 07:21:06,680 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - add: MetricsTag{info=MsInfo{name=Context, description=Metrics context}, value=ugi}
2020-12-03 07:21:06,680 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=LoginSuccessNumOps, description=Number of ops for rate of successful kerberos logins and latency (milliseconds)}, 1
2020-12-03 07:21:06,680 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=LoginSuccessAvgTime, description=Average time for rate of successful kerberos logins and latency (milliseconds)}, 3.0
2020-12-03 07:21:06,680 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=LoginFailureNumOps, description=Number of ops for rate of failed kerberos logins and latency (milliseconds)}, 0
2020-12-03 07:21:06,681 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=LoginFailureAvgTime, description=Average time for rate of failed kerberos logins and latency (milliseconds)}, 0.0
2020-12-03 07:21:06,681 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addCounter: MetricsInfoImpl{name=GetGroupsNumOps, description=Number of ops for getGroups}, 1
2020-12-03 07:21:06,681 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroupsAvgTime, description=Average time for getGroups}, 1.0
2020-12-03 07:21:06,681 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=RenewalFailuresTotal, description=Renewal failures since startup}, 0
2020-12-03 07:21:06,681 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=RenewalFailures, description=Renewal failures since last successful login}, 0
2020-12-03 07:21:06,682 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1sNumOps, description=Number of ops for get groups with 1s interval}, 0
2020-12-03 07:21:06,687 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1s50thPercentileLatency, description=50 percentile latency with 1 second interval for get groups}, 0
2020-12-03 07:21:06,687 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1s75thPercentileLatency, description=75 percentile latency with 1 second interval for get groups}, 0
2020-12-03 07:21:06,687 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1s90thPercentileLatency, description=90 percentile latency with 1 second interval for get groups}, 0
2020-12-03 07:21:06,687 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1s95thPercentileLatency, description=95 percentile latency with 1 second interval for get groups}, 0
2020-12-03 07:21:06,688 [Listener at localhost/38400] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - addGauge: MetricsInfoImpl{name=GetGroups1s99thPercentileLatency, description=99 percentile latency with 1 second interval for get groups}, 0
2020-12-03 07:21:06,691 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:06,692 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:21:06,693 [Listener at localhost/38400] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:06,693 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21680803] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:06,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4e14a717-4079-4694-a34a-4793fba8a545) exiting.
2020-12-03 07:21:06,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dd1437e5-d0a4-4bdd-a9ed-46eb0c450933) exiting.
2020-12-03 07:21:06,726 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c8bdd5b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:06,731 [Listener at localhost/38400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@29d2d081{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:06,731 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5949eba8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:06,733 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c074c0c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:06,737 [Listener at localhost/38400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38400
2020-12-03 07:21:06,741 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:06,742 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:06,744 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:06,744 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 903fc7c6-e04b-4768-ba43-5570b640bc62) service to localhost/127.0.0.1:35464
2020-12-03 07:21:06,744 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 903fc7c6-e04b-4768-ba43-5570b640bc62)
2020-12-03 07:21:06,744 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:06,745 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,745 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,748 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:06,748 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:06,749 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:06,749 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:06,756 [Listener at localhost/38400] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:06,757 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:06,757 [Listener at localhost/38400] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:06,757 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@c41709a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:06,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-87b65d91-a106-4e48-90b9-53e935df9a69) exiting.
2020-12-03 07:21:06,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-4a9b22fb-710f-468e-8fdf-3b8e7d1e7f95) exiting.
2020-12-03 07:21:06,784 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@324dcd31{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:06,785 [Listener at localhost/38400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@503d56b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:06,785 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cc0bcf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:06,785 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ec2bf82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:06,787 [Listener at localhost/38400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37850
2020-12-03 07:21:06,790 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:06,791 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:06,795 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:06,796 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 823f7691-933f-4f8a-bc4a-dd695e1e0315) service to localhost/127.0.0.1:35464
2020-12-03 07:21:06,796 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid 823f7691-933f-4f8a-bc4a-dd695e1e0315)
2020-12-03 07:21:06,796 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:06,797 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,797 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,801 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:06,801 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:06,802 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:06,802 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:06,804 [Listener at localhost/38400] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:06,804 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:06,804 [Listener at localhost/38400] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:06,804 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2db2cd5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:06,806 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c49982f5-7fe1-4ecf-b289-8fd44349e746) exiting.
2020-12-03 07:21:06,806 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-91d34a39-871b-4ff3-9ac0-53f709647c75) exiting.
2020-12-03 07:21:06,873 [Finalizer] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - finalize: 
2020-12-03 07:21:06,888 [Finalizer] DEBUG test.MetricsAsserts (MetricsAsserts.java:answer(75)) - finalize: 
2020-12-03 07:21:06,905 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@473b3b7a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:06,906 [Listener at localhost/38400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1734f68{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:06,907 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4362d7df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:06,907 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48e64352{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:06,908 [Listener at localhost/38400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38022
2020-12-03 07:21:06,910 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:06,910 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:06,912 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:06,912 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid bf383aa6-aaa6-4e01-8789-0502814535f0) service to localhost/127.0.0.1:35464
2020-12-03 07:21:06,912 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid bf383aa6-aaa6-4e01-8789-0502814535f0)
2020-12-03 07:21:06,912 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:06,913 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,913 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:06,917 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:06,918 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:06,918 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:06,919 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:06,921 [Listener at localhost/38400] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:06,921 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:06,921 [Listener at localhost/38400] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:06,921 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68d6972f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:06,924 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f64cae25-1447-4c9a-9973-6094603523bb) exiting.
2020-12-03 07:21:06,924 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9d3a0f8-c5cd-4b5f-ac9d-c2344c63d01c) exiting.
2020-12-03 07:21:06,940 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d08f3f5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:06,941 [Listener at localhost/38400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@119f1f2a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:06,941 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c7a975a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:06,941 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@235f4c10{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:06,942 [Listener at localhost/38400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40567
2020-12-03 07:21:06,944 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:06,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:06,945 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:06,946 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd) service to localhost/127.0.0.1:35464
2020-12-03 07:21:07,046 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2049721092-172.17.0.10-1606980058179 (Datanode Uuid b93552fd-39b5-4d3c-a6cf-1b821fdcf8bd)
2020-12-03 07:21:07,047 [BP-2049721092-172.17.0.10-1606980058179 heartbeating to localhost/127.0.0.1:35464] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2049721092-172.17.0.10-1606980058179
2020-12-03 07:21:07,047 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,049 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049721092-172.17.0.10-1606980058179] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,056 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:07,056 [Listener at localhost/38400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:07,058 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:07,058 [Listener at localhost/38400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:07,061 [Listener at localhost/38400] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:07,061 [Listener at localhost/38400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:07,061 [Listener at localhost/38400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:07,061 [Listener at localhost/38400] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 4
2020-12-03 07:21:07,062 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6ca0256d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:07,065 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@28d6290] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:07,067 [Listener at localhost/38400] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 5 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 6 2 
2020-12-03 07:21:07,068 [Listener at localhost/38400] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:21:07,069 [Listener at localhost/38400] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:21:07,069 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:07,070 [CacheReplicationMonitor(1635716611)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:07,072 [Listener at localhost/38400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35464
2020-12-03 07:21:07,074 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,074 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,075 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:07,075 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:07,127 [Listener at localhost/38400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:07,127 [Listener at localhost/38400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:07,128 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e403b4a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:07,130 [Listener at localhost/38400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e6f3f28{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:07,130 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33f676f6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:07,130 [Listener at localhost/38400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3cce57c7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:07,132 [Listener at localhost/38400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:21:07,139 [Listener at localhost/38400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:21:07,140 [Listener at localhost/38400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
