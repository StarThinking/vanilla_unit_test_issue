2020-12-03 07:20:00,594 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:20:00,910 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:00,926 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:00,928 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:00,929 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:00,955 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:00,955 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:00,956 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:00,957 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:01,020 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:01,028 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:01,029 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:01,029 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:01,037 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:01,038 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:01
2020-12-03 07:20:01,041 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:01,042 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:01,044 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:01,045 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:01,067 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:01,068 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:01,075 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:01,076 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:01,076 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:01,076 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:01,077 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:01,077 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:01,078 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:01,078 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:01,078 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:01,078 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:01,079 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:01,117 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:01,117 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:01,117 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:01,118 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:01,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:01,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:01,137 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:01,138 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:01,145 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:20:01,145 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:01,145 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:01,146 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:01,152 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:01,155 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:01,160 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:01,161 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:01,161 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:01,161 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:01,174 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:01,175 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:01,175 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:01,180 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:01,180 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:01,184 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:01,184 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:01,185 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:01,185 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:01,221 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:01,338 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name has been successfully formatted.
2020-12-03 07:20:01,376 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:01,507 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:01,572 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:01,575 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:01,700 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:02,085 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:02,086 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:02,119 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:02,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cebbb30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:02,205 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:02,213 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:02,231 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3334ms
2020-12-03 07:20:02,375 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:02,380 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:02,380 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:02,392 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:02,395 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:02,395 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:02,396 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:02,435 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:02,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:02,445 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42140
2020-12-03 07:20:02,447 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:02,516 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d2de489{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:02,518 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12591ac8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:02,562 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d43661b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:02,571 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2660a7da{HTTP/1.1,[http/1.1]}{localhost:42140}
2020-12-03 07:20:02,572 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3676ms
2020-12-03 07:20:02,573 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:20:02,573 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:20:02,582 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:02,583 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:02,583 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:02,583 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:02,583 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:02,584 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:02,584 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:02,584 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:02,585 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:02,586 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:02,586 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:02,586 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:02,587 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:02
2020-12-03 07:20:02,587 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:02,587 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,588 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:02,588 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:02,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:02,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:02,594 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:02,594 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:02,595 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:02,595 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:02,595 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:02,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:02,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:02,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:02,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:02,596 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:02,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:02,597 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:02,597 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:02,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:02,601 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:20:02,601 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:02,601 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:02,602 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:02,602 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:02,603 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:02,603 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:02,603 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,604 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:02,604 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:02,605 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:02,606 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:02,606 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:02,606 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:02,606 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:02,607 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:02,607 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,607 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:02,607 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:02,712 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:02,717 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current
2020-12-03 07:20:02,718 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:02,719 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:02,766 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:02,773 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:02,774 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/fsimage_0000000000000000000
2020-12-03 07:20:02,779 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:02,780 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:03,687 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:03,688 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 1078 msecs
2020-12-03 07:20:03,907 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:03,959 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:03,976 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,301 [Listener at localhost/33098] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33098 to access this namenode/service.
2020-12-03 07:20:04,306 [Listener at localhost/33098] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:04,329 [Listener at localhost/33098] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:04,360 [Listener at localhost/33098] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:04,361 [Listener at localhost/33098] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:04,361 [Listener at localhost/33098] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:04,361 [Listener at localhost/33098] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:04,362 [Listener at localhost/33098] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-12-03 07:20:04,367 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-12-03 07:20:04,368 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-12-03 07:20:04,369 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:04,370 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:04,370 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:04,370 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:04,370 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:04,370 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-12-03 07:20:04,413 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,413 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,420 [Listener at localhost/33098] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33098
2020-12-03 07:20:04,424 [Listener at localhost/33098] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:04,424 [Listener at localhost/33098] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:04,436 [Listener at localhost/33098] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:04,444 [CacheReplicationMonitor(1169040953)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:04,451 [Listener at localhost/33098] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:04,543 [Listener at localhost/33098] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:04,567 [Listener at localhost/33098] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:04,594 [Listener at localhost/33098] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,599 [Listener at localhost/33098] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,602 [Listener at localhost/33098] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,607 [Listener at localhost/33098] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,608 [Listener at localhost/33098] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,613 [Listener at localhost/33098] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,621 [Listener at localhost/33098] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34173
2020-12-03 07:20:04,623 [Listener at localhost/33098] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,623 [Listener at localhost/33098] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,648 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,650 [Listener at localhost/33098] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,651 [Listener at localhost/33098] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,651 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,654 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,655 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,656 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,656 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,662 [Listener at localhost/33098] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44256
2020-12-03 07:20:04,662 [Listener at localhost/33098] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,664 [Listener at localhost/33098] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,665 [Listener at localhost/33098] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,673 [Listener at localhost/33098] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fcbe147{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,676 [Listener at localhost/33098] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:44256}
2020-12-03 07:20:04,677 [Listener at localhost/33098] INFO  server.Server (Server.java:doStart(419)) - Started @5780ms
2020-12-03 07:20:05,088 [Listener at localhost/33098] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44126
2020-12-03 07:20:05,091 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b78e55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,093 [Listener at localhost/33098] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,093 [Listener at localhost/33098] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,375 [Listener at localhost/33098] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,384 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,400 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33311
2020-12-03 07:20:05,421 [Listener at localhost/33311] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,423 [Listener at localhost/33311] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,437 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,443 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,443 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,448 [Listener at localhost/33311] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:05,450 [Listener at localhost/33311] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:05,450 [Listener at localhost/33311] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:05,452 [Listener at localhost/33311] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:05,453 [Listener at localhost/33311] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,454 [Listener at localhost/33311] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:05,454 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:05,455 [Listener at localhost/33311] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,455 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:05,456 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46556
2020-12-03 07:20:05,457 [Listener at localhost/33311] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:05,457 [Listener at localhost/33311] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:05,459 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,461 [Listener at localhost/33311] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:05,461 [Listener at localhost/33311] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:05,462 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,465 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:05,466 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:05,466 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:05,467 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:05,468 [Listener at localhost/33311] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34541
2020-12-03 07:20:05,468 [Listener at localhost/33311] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:05,471 [Listener at localhost/33311] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@408b35bf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:05,471 [Listener at localhost/33311] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15bcf458{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:05,483 [Listener at localhost/33311] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@285f09de{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:05,484 [Listener at localhost/33311] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73393584{HTTP/1.1,[http/1.1]}{localhost:34541}
2020-12-03 07:20:05,485 [Listener at localhost/33311] INFO  server.Server (Server.java:doStart(419)) - Started @6589ms
2020-12-03 07:20:05,548 [Listener at localhost/33311] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46543
2020-12-03 07:20:05,549 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,549 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1827a871] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,549 [Listener at localhost/33311] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,551 [Listener at localhost/33311] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,551 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,557 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39214
2020-12-03 07:20:05,565 [Listener at localhost/39214] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,565 [Listener at localhost/39214] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,566 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,567 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,567 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,579 [Listener at localhost/39214] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:05,582 [Listener at localhost/39214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:05,583 [Listener at localhost/39214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:05,585 [Listener at localhost/39214] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:05,586 [Listener at localhost/39214] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,587 [Listener at localhost/39214] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:05,590 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:05,590 [Listener at localhost/39214] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,590 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:05,595 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38017
2020-12-03 07:20:05,596 [Listener at localhost/39214] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:05,596 [Listener at localhost/39214] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:05,598 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,601 [Listener at localhost/39214] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:05,602 [Listener at localhost/39214] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:05,603 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,606 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:05,607 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:05,607 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:05,607 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:05,608 [Listener at localhost/39214] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46593
2020-12-03 07:20:05,608 [Listener at localhost/39214] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:05,612 [Listener at localhost/39214] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:05,612 [Listener at localhost/39214] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:05,621 [Listener at localhost/39214] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5528a42c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:05,622 [Listener at localhost/39214] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:46593}
2020-12-03 07:20:05,622 [Listener at localhost/39214] INFO  server.Server (Server.java:doStart(419)) - Started @6726ms
2020-12-03 07:20:05,650 [Listener at localhost/39214] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34917
2020-12-03 07:20:05,651 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,651 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,651 [Listener at localhost/39214] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,652 [Listener at localhost/39214] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,653 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,658 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39316
2020-12-03 07:20:05,666 [Listener at localhost/39316] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,667 [Listener at localhost/39316] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,668 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,670 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,670 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,673 [Listener at localhost/39316] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:05,675 [Listener at localhost/39316] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:05,676 [Listener at localhost/39316] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:05,679 [Listener at localhost/39316] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:05,680 [Listener at localhost/39316] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,680 [Listener at localhost/39316] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:05,681 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:05,681 [Listener at localhost/39316] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,682 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:05,683 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38594
2020-12-03 07:20:05,683 [Listener at localhost/39316] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:05,684 [Listener at localhost/39316] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:05,685 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,687 [Listener at localhost/39316] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:05,688 [Listener at localhost/39316] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:05,689 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,692 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:05,693 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:05,693 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:05,693 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:05,694 [Listener at localhost/39316] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41916
2020-12-03 07:20:05,694 [Listener at localhost/39316] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:05,697 [Listener at localhost/39316] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27f9e982{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:05,698 [Listener at localhost/39316] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37d3d232{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:05,714 [Listener at localhost/39316] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d8f2f3a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:05,715 [Listener at localhost/39316] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2024293c{HTTP/1.1,[http/1.1]}{localhost:41916}
2020-12-03 07:20:05,716 [Listener at localhost/39316] INFO  server.Server (Server.java:doStart(419)) - Started @6820ms
2020-12-03 07:20:05,786 [Listener at localhost/39316] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44297
2020-12-03 07:20:05,787 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,787 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c074c0c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,787 [Listener at localhost/39316] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,788 [Listener at localhost/39316] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,788 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,792 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34739
2020-12-03 07:20:05,798 [Listener at localhost/34739] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,799 [Listener at localhost/34739] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,800 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,803 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,803 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,807 [Listener at localhost/34739] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:05,809 [Listener at localhost/34739] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:05,810 [Listener at localhost/34739] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:05,812 [Listener at localhost/34739] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:05,813 [Listener at localhost/34739] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,813 [Listener at localhost/34739] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:05,814 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:05,814 [Listener at localhost/34739] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,815 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:05,816 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37412
2020-12-03 07:20:05,816 [Listener at localhost/34739] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:05,817 [Listener at localhost/34739] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:05,818 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,821 [Listener at localhost/34739] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:05,823 [Listener at localhost/34739] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:05,824 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,828 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:05,831 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:05,831 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:05,831 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:05,832 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,832 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,832 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,832 [Listener at localhost/34739] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46608
2020-12-03 07:20:05,833 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,833 [Listener at localhost/34739] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:05,835 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:05,837 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:05,837 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:05,838 [Listener at localhost/34739] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62c5bbdc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:05,835 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:05,841 [Listener at localhost/34739] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bc53649{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:05,851 [Listener at localhost/34739] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3abd581e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:05,852 [Listener at localhost/34739] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d4d8fcf{HTTP/1.1,[http/1.1]}{localhost:46608}
2020-12-03 07:20:05,854 [Listener at localhost/34739] INFO  server.Server (Server.java:doStart(419)) - Started @6957ms
2020-12-03 07:20:05,871 [Listener at localhost/34739] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45729
2020-12-03 07:20:05,872 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,872 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f0628de] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,873 [Listener at localhost/34739] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,873 [Listener at localhost/34739] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,874 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,879 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38270
2020-12-03 07:20:05,886 [Listener at localhost/38270] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,886 [Listener at localhost/38270] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,887 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,888 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,889 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,898 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:05,898 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:05,898 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:05,898 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:05,899 [Listener at localhost/38270] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:05,899 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:05,899 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:05,899 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:05,899 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:05,901 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,902 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:05,902 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:05,902 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e52750fc-8712-4097-9015-944b7016457b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:05,902 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f70488d-39ce-4760-b3d9-a1b077305b19 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:05,903 [Listener at localhost/38270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:05,904 [Listener at localhost/38270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:05,905 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-65a75d84-3884-416a-83cc-f8b08b3cba00 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:05,906 [Listener at localhost/38270] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:05,907 [Listener at localhost/38270] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,908 [Listener at localhost/38270] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:05,908 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:05,908 [Listener at localhost/38270] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:05,909 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:05,910 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37543
2020-12-03 07:20:05,910 [Listener at localhost/38270] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:05,910 [Listener at localhost/38270] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:05,912 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,914 [Listener at localhost/38270] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:05,914 [Listener at localhost/38270] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:05,915 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:05,917 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:05,918 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:05,919 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:05,919 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:05,920 [Listener at localhost/38270] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45358
2020-12-03 07:20:05,921 [Listener at localhost/38270] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:05,923 [Listener at localhost/38270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@619bd14c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:05,924 [Listener at localhost/38270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a23a01d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:05,931 [Listener at localhost/38270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22ee2d0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:05,933 [Listener at localhost/38270] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bfc3126{HTTP/1.1,[http/1.1]}{localhost:45358}
2020-12-03 07:20:05,933 [Listener at localhost/38270] INFO  server.Server (Server.java:doStart(419)) - Started @7037ms
2020-12-03 07:20:05,942 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:05,943 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:05,943 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:05,953 [Listener at localhost/38270] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37058
2020-12-03 07:20:05,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@53bc1328] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:05,954 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:05,954 [Listener at localhost/38270] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:05,955 [Listener at localhost/38270] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:05,961 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:05,966 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35028
2020-12-03 07:20:05,971 [Listener at localhost/35028] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:05,971 [Listener at localhost/35028] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:05,972 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:05,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:05,974 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:05,977 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:05,997 [Listener at localhost/35028] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:05,999 [Listener at localhost/35028] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:06,003 [Listener at localhost/35028] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:06,004 [Listener at localhost/35028] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:06,007 [Listener at localhost/35028] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,007 [Listener at localhost/35028] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:06,007 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:06,008 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:06,008 [Listener at localhost/35028] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,009 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:06,010 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34880
2020-12-03 07:20:06,010 [Listener at localhost/35028] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:06,010 [Listener at localhost/35028] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:06,012 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,014 [Listener at localhost/35028] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:06,015 [Listener at localhost/35028] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:06,015 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,018 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:06,019 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:06,019 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:06,019 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:06,021 [Listener at localhost/35028] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42817
2020-12-03 07:20:06,021 [Listener at localhost/35028] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:06,023 [Listener at localhost/35028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e8e8651{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:06,024 [Listener at localhost/35028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@271f18d3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:06,034 [Listener at localhost/35028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b65e559{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:06,035 [Listener at localhost/35028] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@bae47a0{HTTP/1.1,[http/1.1]}{localhost:42817}
2020-12-03 07:20:06,036 [Listener at localhost/35028] INFO  server.Server (Server.java:doStart(419)) - Started @7140ms
2020-12-03 07:20:06,059 [Listener at localhost/35028] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33851
2020-12-03 07:20:06,060 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:06,060 [Listener at localhost/35028] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:06,061 [Listener at localhost/35028] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:06,061 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@85ec632] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:06,064 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:06,067 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41841
2020-12-03 07:20:06,072 [Listener at localhost/41841] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:06,073 [Listener at localhost/41841] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:06,074 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:06,078 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:06,078 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:06,082 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:06,082 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:06,084 [Listener at localhost/41841] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:06,086 [Listener at localhost/41841] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:06,087 [Listener at localhost/41841] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:06,088 [Listener at localhost/41841] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:06,089 [Listener at localhost/41841] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,090 [Listener at localhost/41841] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:06,090 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:06,090 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,091 [Listener at localhost/41841] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,090 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,090 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,091 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:06,091 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,091 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,091 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,092 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:06,093 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f2abdf7a-7257-4635-8ee2-18dbb331e383 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:06,092 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fb58d30a-f7d7-4e26-afee-3f36329431e6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:06,093 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37771
2020-12-03 07:20:06,094 [Listener at localhost/41841] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:06,094 [Listener at localhost/41841] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:06,095 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,097 [Listener at localhost/41841] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:06,097 [Listener at localhost/41841] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:06,097 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,100 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:06,101 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:06,101 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:06,101 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:06,102 [Listener at localhost/41841] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42816
2020-12-03 07:20:06,103 [Listener at localhost/41841] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:06,105 [Listener at localhost/41841] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c65121{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:06,106 [Listener at localhost/41841] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57dc9128{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:06,114 [Listener at localhost/41841] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@126be319{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:06,115 [Listener at localhost/41841] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c44052e{HTTP/1.1,[http/1.1]}{localhost:42816}
2020-12-03 07:20:06,116 [Listener at localhost/41841] INFO  server.Server (Server.java:doStart(419)) - Started @7220ms
2020-12-03 07:20:06,151 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,151 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,151 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,151 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,151 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,151 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,152 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7e31da9a-b648-400c-8c71-42d17a340159 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:06,152 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2e30838d-7764-49bf-b5c7-a52b506c028a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:06,152 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:06,178 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,178 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,181 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ec340079-da43-481c-a95e-abcc97e4118b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:06,181 [Listener at localhost/41841] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43104
2020-12-03 07:20:06,182 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:06,182 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@530a8454] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:06,182 [Listener at localhost/41841] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:06,183 [Listener at localhost/41841] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:06,204 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:06,210 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43703
2020-12-03 07:20:06,217 [Listener at localhost/43703] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:06,218 [Listener at localhost/43703] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:06,219 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:06,221 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:06,221 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:06,229 [Listener at localhost/43703] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:06,229 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:06,230 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:06,231 [Listener at localhost/43703] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:06,231 [Listener at localhost/43703] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:06,233 [Listener at localhost/43703] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:06,234 [Listener at localhost/43703] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,234 [Listener at localhost/43703] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:06,235 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:06,235 [Listener at localhost/43703] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:06,235 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:06,236 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35773
2020-12-03 07:20:06,237 [Listener at localhost/43703] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:06,237 [Listener at localhost/43703] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:06,238 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,240 [Listener at localhost/43703] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:06,241 [Listener at localhost/43703] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:06,241 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:06,244 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:06,244 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:06,245 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:06,245 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:06,246 [Listener at localhost/43703] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38617
2020-12-03 07:20:06,246 [Listener at localhost/43703] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:06,252 [Listener at localhost/43703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6650813a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:06,253 [Listener at localhost/43703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50cf5a23{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:06,275 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,276 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,277 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,277 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,279 [Listener at localhost/43703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5bb3d42d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:06,281 [Listener at localhost/43703] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5bf61e67{HTTP/1.1,[http/1.1]}{localhost:38617}
2020-12-03 07:20:06,282 [Listener at localhost/43703] INFO  server.Server (Server.java:doStart(419)) - Started @7386ms
2020-12-03 07:20:06,288 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,289 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,289 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,289 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,300 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,301 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,302 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:06,309 [Listener at localhost/43703] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33930
2020-12-03 07:20:06,310 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:06,310 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b273a59] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:06,310 [Listener at localhost/43703] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:06,311 [Listener at localhost/43703] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:06,312 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:06,316 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39349
2020-12-03 07:20:06,322 [Listener at localhost/39349] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:06,323 [Listener at localhost/39349] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:06,323 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098 starting to offer service
2020-12-03 07:20:06,327 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:06,327 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:06,351 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33098
2020-12-03 07:20:06,356 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:06,370 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,370 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,370 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,370 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,374 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,374 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,375 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,375 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,413 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,413 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,414 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:06,427 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,427 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,427 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,428 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,475 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,475 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,475 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,476 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,476 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1d82fb96-4cde-4273-a6e6-7e34143f1695 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:20:06,476 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:06,485 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,486 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,486 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,486 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,487 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,487 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,488 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,488 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,627 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,628 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,628 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,628 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,630 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,632 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,632 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,632 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,643 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,643 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,646 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-578bf417-795b-4e90-be0b-440362874bc0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:06,654 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,654 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,654 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,654 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,660 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,660 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,660 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,661 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,696 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:06,698 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:06,708 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,708 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,708 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,708 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,804 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 980@fb494546b379
2020-12-03 07:20:06,804 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:06,804 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:06,804 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1422713663. Formatting...
2020-12-03 07:20:06,805 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-af81443f-431f-4f34-9f17-1833c481c1ff for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:20:06,849 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:06,859 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,859 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,860 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,860 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,860 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,861 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,861 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,861 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,863 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:06,873 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:06,873 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:06,898 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7bdcb99b-2669-49d1-afd1-dc64cb1dab30
2020-12-03 07:20:06,899 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 616457bc-d176-436d-bb41-d2849860b9d8
2020-12-03 07:20:06,910 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,910 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:06,910 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:06,910 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:06,978 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:06,979 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:06,980 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,002 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f95bd9c1-4095-403f-92ec-d83341a43aa4
2020-12-03 07:20:07,002 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2757df4b-cdad-4ac8-86e5-272ebf780937
2020-12-03 07:20:07,013 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,013 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,013 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:07,013 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:07,049 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:07,052 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9a3c9f46-217b-4c98-bf9c-976813f1b7b9
2020-12-03 07:20:07,058 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,058 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,058 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:07,058 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:07,062 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8
2020-12-03 07:20:07,062 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:07,064 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0
2020-12-03 07:20:07,064 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:07,066 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ec340079-da43-481c-a95e-abcc97e4118b
2020-12-03 07:20:07,067 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:07,062 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e52750fc-8712-4097-9015-944b7016457b
2020-12-03 07:20:07,068 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:07,068 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fb58d30a-f7d7-4e26-afee-3f36329431e6
2020-12-03 07:20:07,068 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:07,062 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6f70488d-39ce-4760-b3d9-a1b077305b19
2020-12-03 07:20:07,070 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:07,063 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-65a75d84-3884-416a-83cc-f8b08b3cba00
2020-12-03 07:20:07,070 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:07,071 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f2abdf7a-7257-4635-8ee2-18dbb331e383
2020-12-03 07:20:07,071 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:07,078 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7e31da9a-b648-400c-8c71-42d17a340159
2020-12-03 07:20:07,078 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:07,085 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,086 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,085 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,086 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,087 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,088 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:07,088 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,088 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2e30838d-7764-49bf-b5c7-a52b506c028a
2020-12-03 07:20:07,088 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:07,089 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,094 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:07,096 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:07,097 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:07,098 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:07,100 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:07,105 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:07,105 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:07,107 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:07,108 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:07,108 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:07,108 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:07,109 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:07,109 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:07,110 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:07,110 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:07,110 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:07,110 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:07,110 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:07,111 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:07,110 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:07,112 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,111 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,110 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,112 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:07,114 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,114 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:07,114 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:07,114 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:07,114 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:07,115 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:07,115 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:07,115 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:07,115 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:07,128 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,129 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:07,129 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:07,192 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,198 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:07,199 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,246 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,246 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,246 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-877205389-172.17.0.11-1606980001210 is not formatted. Formatting ...
2020-12-03 07:20:07,246 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-877205389-172.17.0.11-1606980001210 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-877205389-172.17.0.11-1606980001210/current
2020-12-03 07:20:07,247 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 132ms
2020-12-03 07:20:07,249 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 134ms
2020-12-03 07:20:07,249 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 133ms
2020-12-03 07:20:07,251 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 136ms
2020-12-03 07:20:07,251 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 136ms
2020-12-03 07:20:07,251 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 138ms
2020-12-03 07:20:07,252 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 123ms
2020-12-03 07:20:07,252 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 123ms
2020-12-03 07:20:07,254 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 125ms
2020-12-03 07:20:07,255 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a650887a-9b41-4140-9ae1-784510c83ff1
2020-12-03 07:20:07,255 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:07,255 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:07,255 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:07,255 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:07,259 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,260 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:20:07,261 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 146ms
2020-12-03 07:20:07,261 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e
2020-12-03 07:20:07,261 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:07,255 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,263 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 8ms
2020-12-03 07:20:07,263 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 149ms
2020-12-03 07:20:07,263 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 150ms
2020-12-03 07:20:07,255 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,255 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:07,261 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 148ms
2020-12-03 07:20:07,264 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 9ms
2020-12-03 07:20:07,261 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 146ms
2020-12-03 07:20:07,264 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 10ms
2020-12-03 07:20:07,264 [Thread-284] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,265 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:07,264 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:07,265 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:20:07,265 [Thread-287] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,265 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,265 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:07,265 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:07,264 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 151ms
2020-12-03 07:20:07,267 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,267 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:20:07,265 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,268 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:20:07,268 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:07,265 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:20:07,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:07,265 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd
2020-12-03 07:20:07,265 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 11ms
2020-12-03 07:20:07,270 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:07,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:07,270 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:07,270 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:07,269 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 5ms
2020-12-03 07:20:07,269 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,268 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:20:07,268 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:07,271 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 7ms
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:07,271 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-65a75d84-3884-416a-83cc-f8b08b3cba00): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,271 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,271 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 2ms
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e52750fc-8712-4097-9015-944b7016457b): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f2abdf7a-7257-4635-8ee2-18dbb331e383): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-fb58d30a-f7d7-4e26-afee-3f36329431e6): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2e30838d-7764-49bf-b5c7-a52b506c028a): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ec340079-da43-481c-a95e-abcc97e4118b): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,272 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:07,274 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 7ms
2020-12-03 07:20:07,275 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:07,275 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:07,275 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6f70488d-39ce-4760-b3d9-a1b077305b19): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,275 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:07,275 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7e31da9a-b648-400c-8c71-42d17a340159): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,276 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:07,276 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:07,276 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:07,280 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,281 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:07,281 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:07,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-65a75d84-3884-416a-83cc-f8b08b3cba00): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:20:07,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e52750fc-8712-4097-9015-944b7016457b): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:20:07,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6f70488d-39ce-4760-b3d9-a1b077305b19): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:20:07,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-fb58d30a-f7d7-4e26-afee-3f36329431e6): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:07,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:20:07,303 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f2abdf7a-7257-4635-8ee2-18dbb331e383): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:07,303 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2e30838d-7764-49bf-b5c7-a52b506c028a): no suitable block pools found to scan.  Waiting 1814399967 ms.
2020-12-03 07:20:07,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7e31da9a-b648-400c-8c71-42d17a340159): no suitable block pools found to scan.  Waiting 1814399971 ms.
2020-12-03 07:20:07,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ec340079-da43-481c-a95e-abcc97e4118b): no suitable block pools found to scan.  Waiting 1814399967 ms.
2020-12-03 07:20:07,307 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:20:07,308 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,310 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:07,310 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,313 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9dc8304b-2a07-4b7b-9490-b4a0b87f3371
2020-12-03 07:20:07,318 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:30 AM with interval of 21600000ms
2020-12-03 07:20:07,318 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:15 PM with interval of 21600000ms
2020-12-03 07:20:07,318 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:50 AM with interval of 21600000ms
2020-12-03 07:20:07,318 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:48 AM with interval of 21600000ms
2020-12-03 07:20:07,318 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31
2020-12-03 07:20:07,320 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:45 AM with interval of 21600000ms
2020-12-03 07:20:07,323 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:07,325 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d
2020-12-03 07:20:07,325 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:07,326 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,328 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:07,331 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:07,331 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:07,332 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:07,332 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 51ms
2020-12-03 07:20:07,333 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,334 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:07,334 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:07,334 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 616457bc-d176-436d-bb41-d2849860b9d8) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,334 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 7bdcb99b-2669-49d1-afd1-dc64cb1dab30) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,334 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 2757df4b-cdad-4ac8-86e5-272ebf780937) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,334 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9a3c9f46-217b-4c98-bf9c-976813f1b7b9) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,334 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid f95bd9c1-4095-403f-92ec-d83341a43aa4) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,337 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 56ms
2020-12-03 07:20:07,337 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 56ms
2020-12-03 07:20:07,338 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:07,338 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:07,338 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,339 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,339 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:07,339 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:20:07,339 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 1ms
2020-12-03 07:20:07,340 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:07,340 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:42 AM with interval of 21600000ms
2020-12-03 07:20:07,340 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,343 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid a650887a-9b41-4140-9ae1-784510c83ff1) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:07,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:07,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:07,363 [IPC Server handler 1 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38594, datanodeUuid=f95bd9c1-4095-403f-92ec-d83341a43aa4, infoPort=44297, infoSecurePort=0, ipcPort=34739, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage f95bd9c1-4095-403f-92ec-d83341a43aa4
2020-12-03 07:20:07,365 [IPC Server handler 1 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38594
2020-12-03 07:20:07,365 [IPC Server handler 1 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f95bd9c1-4095-403f-92ec-d83341a43aa4 (127.0.0.1:38594).
2020-12-03 07:20:07,367 [IPC Server handler 3 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34173, datanodeUuid=7bdcb99b-2669-49d1-afd1-dc64cb1dab30, infoPort=44126, infoSecurePort=0, ipcPort=33311, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage 7bdcb99b-2669-49d1-afd1-dc64cb1dab30
2020-12-03 07:20:07,368 [IPC Server handler 3 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34173
2020-12-03 07:20:07,368 [IPC Server handler 3 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7bdcb99b-2669-49d1-afd1-dc64cb1dab30 (127.0.0.1:34173).
2020-12-03 07:20:07,368 [IPC Server handler 4 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37412, datanodeUuid=9a3c9f46-217b-4c98-bf9c-976813f1b7b9, infoPort=45729, infoSecurePort=0, ipcPort=38270, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage 9a3c9f46-217b-4c98-bf9c-976813f1b7b9
2020-12-03 07:20:07,368 [IPC Server handler 4 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37412
2020-12-03 07:20:07,368 [IPC Server handler 4 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9a3c9f46-217b-4c98-bf9c-976813f1b7b9 (127.0.0.1:37412).
2020-12-03 07:20:07,369 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37543, datanodeUuid=a650887a-9b41-4140-9ae1-784510c83ff1, infoPort=37058, infoSecurePort=0, ipcPort=35028, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage a650887a-9b41-4140-9ae1-784510c83ff1
2020-12-03 07:20:07,369 [IPC Server handler 0 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37543
2020-12-03 07:20:07,369 [IPC Server handler 0 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a650887a-9b41-4140-9ae1-784510c83ff1 (127.0.0.1:37543).
2020-12-03 07:20:07,369 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38017, datanodeUuid=616457bc-d176-436d-bb41-d2849860b9d8, infoPort=34917, infoSecurePort=0, ipcPort=39316, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage 616457bc-d176-436d-bb41-d2849860b9d8
2020-12-03 07:20:07,370 [IPC Server handler 5 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38017
2020-12-03 07:20:07,370 [IPC Server handler 5 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 616457bc-d176-436d-bb41-d2849860b9d8 (127.0.0.1:38017).
2020-12-03 07:20:07,370 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 36ms
2020-12-03 07:20:07,370 [IPC Server handler 6 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46556, datanodeUuid=2757df4b-cdad-4ac8-86e5-272ebf780937, infoPort=46543, infoSecurePort=0, ipcPort=39214, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage 2757df4b-cdad-4ac8-86e5-272ebf780937
2020-12-03 07:20:07,371 [IPC Server handler 6 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46556
2020-12-03 07:20:07,371 [IPC Server handler 6 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2757df4b-cdad-4ac8-86e5-272ebf780937 (127.0.0.1:46556).
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9a3c9f46-217b-4c98-bf9c-976813f1b7b9) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,371 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 38ms
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 616457bc-d176-436d-bb41-d2849860b9d8) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,372 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 38ms
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 7bdcb99b-2669-49d1-afd1-dc64cb1dab30) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,372 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,373 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:07,373 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,373 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:07,373 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,376 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 3ms
2020-12-03 07:20:07,377 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 4ms
2020-12-03 07:20:07,377 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 2757df4b-cdad-4ac8-86e5-272ebf780937) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,377 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid a650887a-9b41-4140-9ae1-784510c83ff1) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,377 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 4ms
2020-12-03 07:20:07,377 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid f95bd9c1-4095-403f-92ec-d83341a43aa4) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,378 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,377 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,378 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:07,378 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,378 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:07,381 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:40 PM with interval of 21600000ms
2020-12-03 07:20:07,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,382 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,384 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9dc8304b-2a07-4b7b-9490-b4a0b87f3371) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,384 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:20:07,384 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:20:07,386 [IPC Server handler 8 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34880, datanodeUuid=9dc8304b-2a07-4b7b-9490-b4a0b87f3371, infoPort=33851, infoSecurePort=0, ipcPort=41841, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage 9dc8304b-2a07-4b7b-9490-b4a0b87f3371
2020-12-03 07:20:07,386 [IPC Server handler 8 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34880
2020-12-03 07:20:07,386 [IPC Server handler 8 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9dc8304b-2a07-4b7b-9490-b4a0b87f3371 (127.0.0.1:34880).
2020-12-03 07:20:07,387 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9dc8304b-2a07-4b7b-9490-b4a0b87f3371) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,387 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,402 [IPC Server handler 9 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f70488d-39ce-4760-b3d9-a1b077305b19 for DN 127.0.0.1:38594
2020-12-03 07:20:07,404 [IPC Server handler 9 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7e31da9a-b648-400c-8c71-42d17a340159 for DN 127.0.0.1:38594
2020-12-03 07:20:07,405 [IPC Server handler 7 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31 for DN 127.0.0.1:34880
2020-12-03 07:20:07,407 [IPC Server handler 7 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d for DN 127.0.0.1:34880
2020-12-03 07:20:07,408 [IPC Server handler 2 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8 for DN 127.0.0.1:37412
2020-12-03 07:20:07,408 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1422713663;bpid=BP-877205389-172.17.0.11-1606980001210;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1422713663;c=1606980001210;bpid=BP-877205389-172.17.0.11-1606980001210;dnuuid=null
2020-12-03 07:20:07,408 [IPC Server handler 2 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec340079-da43-481c-a95e-abcc97e4118b for DN 127.0.0.1:37412
2020-12-03 07:20:07,409 [IPC Server handler 6 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e52750fc-8712-4097-9015-944b7016457b for DN 127.0.0.1:34173
2020-12-03 07:20:07,409 [IPC Server handler 6 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f2abdf7a-7257-4635-8ee2-18dbb331e383 for DN 127.0.0.1:34173
2020-12-03 07:20:07,409 [IPC Server handler 3 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e for DN 127.0.0.1:37543
2020-12-03 07:20:07,410 [IPC Server handler 3 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd for DN 127.0.0.1:37543
2020-12-03 07:20:07,410 [IPC Server handler 5 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0 for DN 127.0.0.1:38017
2020-12-03 07:20:07,410 [IPC Server handler 5 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fb58d30a-f7d7-4e26-afee-3f36329431e6 for DN 127.0.0.1:38017
2020-12-03 07:20:07,411 [IPC Server handler 4 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-65a75d84-3884-416a-83cc-f8b08b3cba00 for DN 127.0.0.1:46556
2020-12-03 07:20:07,411 [IPC Server handler 4 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2e30838d-7764-49bf-b5c7-a52b506c028a for DN 127.0.0.1:46556
2020-12-03 07:20:07,415 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,425 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:07,425 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,444 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID cc8e4c36-62ec-479a-ae72-d04343254319
2020-12-03 07:20:07,451 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5
2020-12-03 07:20:07,452 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:07,453 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x429f6dc29f292118: Processing first storage report for DS-ec340079-da43-481c-a95e-abcc97e4118b from datanode 9a3c9f46-217b-4c98-bf9c-976813f1b7b9
2020-12-03 07:20:07,457 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-578bf417-795b-4e90-be0b-440362874bc0
2020-12-03 07:20:07,457 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:07,459 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x429f6dc29f292118: from storage DS-ec340079-da43-481c-a95e-abcc97e4118b node DatanodeRegistration(127.0.0.1:37412, datanodeUuid=9a3c9f46-217b-4c98-bf9c-976813f1b7b9, infoPort=45729, infoSecurePort=0, ipcPort=38270, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 6 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,459 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x433c8cc9b1040c7a: Processing first storage report for DS-f2abdf7a-7257-4635-8ee2-18dbb331e383 from datanode 7bdcb99b-2669-49d1-afd1-dc64cb1dab30
2020-12-03 07:20:07,459 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,459 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x433c8cc9b1040c7a: from storage DS-f2abdf7a-7257-4635-8ee2-18dbb331e383 node DatanodeRegistration(127.0.0.1:34173, datanodeUuid=7bdcb99b-2669-49d1-afd1-dc64cb1dab30, infoPort=44126, infoSecurePort=0, ipcPort=33311, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b192898d66481ec: Processing first storage report for DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e from datanode a650887a-9b41-4140-9ae1-784510c83ff1
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b192898d66481ec: from storage DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e node DatanodeRegistration(127.0.0.1:37543, datanodeUuid=a650887a-9b41-4140-9ae1-784510c83ff1, infoPort=37058, infoSecurePort=0, ipcPort=35028, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6f34de684d658937: Processing first storage report for DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d from datanode 9dc8304b-2a07-4b7b-9490-b4a0b87f3371
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6f34de684d658937: from storage DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d node DatanodeRegistration(127.0.0.1:34880, datanodeUuid=9dc8304b-2a07-4b7b-9490-b4a0b87f3371, infoPort=33851, infoSecurePort=0, ipcPort=41841, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe0f46bd315fedf2e: Processing first storage report for DS-fb58d30a-f7d7-4e26-afee-3f36329431e6 from datanode 616457bc-d176-436d-bb41-d2849860b9d8
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe0f46bd315fedf2e: from storage DS-fb58d30a-f7d7-4e26-afee-3f36329431e6 node DatanodeRegistration(127.0.0.1:38017, datanodeUuid=616457bc-d176-436d-bb41-d2849860b9d8, infoPort=34917, infoSecurePort=0, ipcPort=39316, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4f5ab2f24650969: Processing first storage report for DS-7e31da9a-b648-400c-8c71-42d17a340159 from datanode f95bd9c1-4095-403f-92ec-d83341a43aa4
2020-12-03 07:20:07,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4f5ab2f24650969: from storage DS-7e31da9a-b648-400c-8c71-42d17a340159 node DatanodeRegistration(127.0.0.1:38594, datanodeUuid=f95bd9c1-4095-403f-92ec-d83341a43aa4, infoPort=44297, infoSecurePort=0, ipcPort=34739, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,461 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x429f6dc29f292118: Processing first storage report for DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8 from datanode 9a3c9f46-217b-4c98-bf9c-976813f1b7b9
2020-12-03 07:20:07,461 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x429f6dc29f292118: from storage DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8 node DatanodeRegistration(127.0.0.1:37412, datanodeUuid=9a3c9f46-217b-4c98-bf9c-976813f1b7b9, infoPort=45729, infoSecurePort=0, ipcPort=38270, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,461 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x433c8cc9b1040c7a: Processing first storage report for DS-e52750fc-8712-4097-9015-944b7016457b from datanode 7bdcb99b-2669-49d1-afd1-dc64cb1dab30
2020-12-03 07:20:07,461 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,461 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x433c8cc9b1040c7a: from storage DS-e52750fc-8712-4097-9015-944b7016457b node DatanodeRegistration(127.0.0.1:34173, datanodeUuid=7bdcb99b-2669-49d1-afd1-dc64cb1dab30, infoPort=44126, infoSecurePort=0, ipcPort=33311, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,461 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b192898d66481ec: Processing first storage report for DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd from datanode a650887a-9b41-4140-9ae1-784510c83ff1
2020-12-03 07:20:07,462 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b192898d66481ec: from storage DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd node DatanodeRegistration(127.0.0.1:37543, datanodeUuid=a650887a-9b41-4140-9ae1-784510c83ff1, infoPort=37058, infoSecurePort=0, ipcPort=35028, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,462 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,462 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6f34de684d658937: Processing first storage report for DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31 from datanode 9dc8304b-2a07-4b7b-9490-b4a0b87f3371
2020-12-03 07:20:07,462 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,462 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6f34de684d658937: from storage DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31 node DatanodeRegistration(127.0.0.1:34880, datanodeUuid=9dc8304b-2a07-4b7b-9490-b4a0b87f3371, infoPort=33851, infoSecurePort=0, ipcPort=41841, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,462 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,463 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe0f46bd315fedf2e: Processing first storage report for DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0 from datanode 616457bc-d176-436d-bb41-d2849860b9d8
2020-12-03 07:20:07,463 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,463 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe0f46bd315fedf2e: from storage DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0 node DatanodeRegistration(127.0.0.1:38017, datanodeUuid=616457bc-d176-436d-bb41-d2849860b9d8, infoPort=34917, infoSecurePort=0, ipcPort=39316, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,464 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:07,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4f5ab2f24650969: Processing first storage report for DS-6f70488d-39ce-4760-b3d9-a1b077305b19 from datanode f95bd9c1-4095-403f-92ec-d83341a43aa4
2020-12-03 07:20:07,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4f5ab2f24650969: from storage DS-6f70488d-39ce-4760-b3d9-a1b077305b19 node DatanodeRegistration(127.0.0.1:38594, datanodeUuid=f95bd9c1-4095-403f-92ec-d83341a43aa4, infoPort=44297, infoSecurePort=0, ipcPort=34739, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,465 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6f34de684d658937,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4f5ab2f24650969,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe0f46bd315fedf2e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x433c8cc9b1040c7a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x429f6dc29f292118,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b192898d66481ec,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,519 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,524 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 58ms
2020-12-03 07:20:07,527 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 63ms
2020-12-03 07:20:07,536 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 73ms
2020-12-03 07:20:07,537 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:07,537 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:07,537 [Thread-335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,537 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,537 [Thread-336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,538 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:20:07,538 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:20:07,539 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 2ms
2020-12-03 07:20:07,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,540 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:13 AM with interval of 21600000ms
2020-12-03 07:20:07,540 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-578bf417-795b-4e90-be0b-440362874bc0): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,541 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:07,546 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b1e39e00-460e-4c8e-b201-d285caec8622
2020-12-03 07:20:07,546 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid cc8e4c36-62ec-479a-ae72-d04343254319) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,547 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:07,547 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:07,548 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-578bf417-795b-4e90-be0b-440362874bc0): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:20:07,551 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37771, datanodeUuid=cc8e4c36-62ec-479a-ae72-d04343254319, infoPort=43104, infoSecurePort=0, ipcPort=43703, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage cc8e4c36-62ec-479a-ae72-d04343254319
2020-12-03 07:20:07,551 [IPC Server handler 5 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37771
2020-12-03 07:20:07,551 [IPC Server handler 5 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cc8e4c36-62ec-479a-ae72-d04343254319 (127.0.0.1:37771).
2020-12-03 07:20:07,552 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1d82fb96-4cde-4273-a6e6-7e34143f1695
2020-12-03 07:20:07,553 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:07,554 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid cc8e4c36-62ec-479a-ae72-d04343254319) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,554 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,556 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-af81443f-431f-4f34-9f17-1833c481c1ff
2020-12-03 07:20:07,558 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:07,559 [IPC Server handler 1 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5 for DN 127.0.0.1:37771
2020-12-03 07:20:07,559 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,560 [IPC Server handler 1 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-578bf417-795b-4e90-be0b-440362874bc0 for DN 127.0.0.1:37771
2020-12-03 07:20:07,561 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:07,563 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:07,563 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x49d21eb38cbf4a4: Processing first storage report for DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5 from datanode cc8e4c36-62ec-479a-ae72-d04343254319
2020-12-03 07:20:07,563 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:07,563 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x49d21eb38cbf4a4: from storage DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5 node DatanodeRegistration(127.0.0.1:37771, datanodeUuid=cc8e4c36-62ec-479a-ae72-d04343254319, infoPort=43104, infoSecurePort=0, ipcPort=43703, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,564 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:07,565 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x49d21eb38cbf4a4: Processing first storage report for DS-578bf417-795b-4e90-be0b-440362874bc0 from datanode cc8e4c36-62ec-479a-ae72-d04343254319
2020-12-03 07:20:07,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x49d21eb38cbf4a4: from storage DS-578bf417-795b-4e90-be0b-440362874bc0 node DatanodeRegistration(127.0.0.1:37771, datanodeUuid=cc8e4c36-62ec-479a-ae72-d04343254319, infoPort=43104, infoSecurePort=0, ipcPort=43703, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,565 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:07,566 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:07,566 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x49d21eb38cbf4a4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,566 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,599 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 33ms
2020-12-03 07:20:07,599 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-877205389-172.17.0.11-1606980001210 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 33ms
2020-12-03 07:20:07,600 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-877205389-172.17.0.11-1606980001210: 35ms
2020-12-03 07:20:07,600 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:07,600 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:07,601 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,601 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-877205389-172.17.0.11-1606980001210/current/replicas doesn't exist 
2020-12-03 07:20:07,604 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 3ms
2020-12-03 07:20:07,604 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 3ms
2020-12-03 07:20:07,604 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-877205389-172.17.0.11-1606980001210: 4ms
2020-12-03 07:20:07,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:07,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-1d82fb96-4cde-4273-a6e6-7e34143f1695): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,605 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:45 AM with interval of 21600000ms
2020-12-03 07:20:07,606 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid b1e39e00-460e-4c8e-b201-d285caec8622) service to localhost/127.0.0.1:33098 beginning handshake with NN
2020-12-03 07:20:07,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-1d82fb96-4cde-4273-a6e6-7e34143f1695): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:07,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-877205389-172.17.0.11-1606980001210 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:07,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-af81443f-431f-4f34-9f17-1833c481c1ff): finished scanning block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,612 [IPC Server handler 4 on default port 33098] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35773, datanodeUuid=b1e39e00-460e-4c8e-b201-d285caec8622, infoPort=33930, infoSecurePort=0, ipcPort=39349, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210) storage b1e39e00-460e-4c8e-b201-d285caec8622
2020-12-03 07:20:07,613 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-af81443f-431f-4f34-9f17-1833c481c1ff): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-12-03 07:20:07,616 [IPC Server handler 4 on default port 33098] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35773
2020-12-03 07:20:07,616 [IPC Server handler 4 on default port 33098] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b1e39e00-460e-4c8e-b201-d285caec8622 (127.0.0.1:35773).
2020-12-03 07:20:07,618 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid b1e39e00-460e-4c8e-b201-d285caec8622) service to localhost/127.0.0.1:33098 successfully registered with NN
2020-12-03 07:20:07,618 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33098 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:07,623 [IPC Server handler 9 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1d82fb96-4cde-4273-a6e6-7e34143f1695 for DN 127.0.0.1:35773
2020-12-03 07:20:07,623 [IPC Server handler 9 on default port 33098] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af81443f-431f-4f34-9f17-1833c481c1ff for DN 127.0.0.1:35773
2020-12-03 07:20:07,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8e4c369211b2f9ed: Processing first storage report for DS-1d82fb96-4cde-4273-a6e6-7e34143f1695 from datanode b1e39e00-460e-4c8e-b201-d285caec8622
2020-12-03 07:20:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8e4c369211b2f9ed: from storage DS-1d82fb96-4cde-4273-a6e6-7e34143f1695 node DatanodeRegistration(127.0.0.1:35773, datanodeUuid=b1e39e00-460e-4c8e-b201-d285caec8622, infoPort=33930, infoSecurePort=0, ipcPort=39349, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8e4c369211b2f9ed: Processing first storage report for DS-af81443f-431f-4f34-9f17-1833c481c1ff from datanode b1e39e00-460e-4c8e-b201-d285caec8622
2020-12-03 07:20:07,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8e4c369211b2f9ed: from storage DS-af81443f-431f-4f34-9f17-1833c481c1ff node DatanodeRegistration(127.0.0.1:35773, datanodeUuid=b1e39e00-460e-4c8e-b201-d285caec8622, infoPort=33930, infoSecurePort=0, ipcPort=39349, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:07,628 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8e4c369211b2f9ed,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:07,628 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:07,649 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,653 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:07,661 [Listener at localhost/39349] INFO  namenode.OfflineEditsViewerHelper (OfflineEditsViewerHelper.java:runOperations(129)) - Creating edits by performing fs operations
2020-12-03 07:20:07,761 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_create	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:07,808 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_create is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:07,822 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/file_create	dst=null	perm=null	proto=rpc
2020-12-03 07:20:07,829 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_create is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:07,832 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/update_blocks	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:07,854 [IPC Server handler 7 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:35773 for /update_blocks
2020-12-03 07:20:07,872 [Thread-354] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:07,952 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:36828 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001 src: /127.0.0.1:36828 dest: /127.0.0.1:35773
2020-12-03 07:20:08,024 [IPC Server handler 9 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /update_blocks for DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,040 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/update_blocks	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,067 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36828, dest: /127.0.0.1:35773, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: b1e39e00-460e-4c8e-b201-d285caec8622, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001, duration(ns): 71695340
2020-12-03 07:20:08,068 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,071 [IPC Server handler 3 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /update_blocks is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,079 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/file_create	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,095 [IPC Server handler 5 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/file_create	dst=/file_moved	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,106 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/file_moved	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,117 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/directory_mkdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:08,127 [IPC Server handler 4 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/directory_mkdir	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,134 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=disallowSnapshot	src=/directory_mkdir	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,136 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/directory_mkdir	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,153 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSnapshot	src=/directory_mkdir	dst=/directory_mkdir/.snapshot/snapshot1	perm=null	proto=rpc
2020-12-03 07:20:08,159 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=renameSnapshot	src=/directory_mkdir/.snapshot/snapshot1	dst=/directory_mkdir/.snapshot/snapshot2	perm=null	proto=rpc
2020-12-03 07:20:08,167 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=deleteSnapshot	src=/directory_mkdir/.snapshot/snapshot2	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,170 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_create	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,176 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_create is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,183 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/file_create	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,193 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/file_create	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-12-03 07:20:08,201 [IPC Server handler 4 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/file_create	dst=null	perm=newOwner:supergroup:rwxrwxrwx	proto=rpc
2020-12-03 07:20:08,208 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setTimes	src=/file_create	dst=null	perm=newOwner:supergroup:rwxrwxrwx	proto=rpc
2020-12-03 07:20:08,213 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setQuota	src=/directory_mkdir	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,219 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/directory_mkdir	dst=null	perm=null	proto=rpc
2020-12-03 07:20:08,226 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[NONE])	src=/file_create	dst=/file_moved	perm=newOwner:supergroup:rwxrwxrwx	proto=rpc
2020-12-03 07:20:08,230 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:08,233 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_concat_target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,241 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46556 for /file_concat_target
2020-12-03 07:20:08,243 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,248 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:60312 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002 src: /127.0.0.1:60312 dest: /127.0.0.1:46556
2020-12-03 07:20:08,264 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60312, dest: /127.0.0.1:46556, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 2757df4b-cdad-4ac8-86e5-272ebf780937, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002, duration(ns): 13170009
2020-12-03 07:20:08,266 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,273 [IPC Server handler 7 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:34880 for /file_concat_target
2020-12-03 07:20:08,275 [DataStreamer for file /file_concat_target] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,277 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38074 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003 src: /127.0.0.1:38074 dest: /127.0.0.1:34880
2020-12-03 07:20:08,288 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38074, dest: /127.0.0.1:34880, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 9dc8304b-2a07-4b7b-9490-b4a0b87f3371, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003, duration(ns): 7097375
2020-12-03 07:20:08,288 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,291 [IPC Server handler 4 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:46556 for /file_concat_target
2020-12-03 07:20:08,293 [DataStreamer for file /file_concat_target] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,294 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:60342 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004 src: /127.0.0.1:60342 dest: /127.0.0.1:46556
2020-12-03 07:20:08,312 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60342, dest: /127.0.0.1:46556, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 2757df4b-cdad-4ac8-86e5-272ebf780937, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004, duration(ns): 14054531
2020-12-03 07:20:08,312 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,315 [IPC Server handler 2 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_concat_target is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,317 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:08,320 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_concat_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,325 [IPC Server handler 6 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:35773 for /file_concat_0
2020-12-03 07:20:08,327 [Thread-369] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,329 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:37020 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005 src: /127.0.0.1:37020 dest: /127.0.0.1:35773
2020-12-03 07:20:08,408 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37020, dest: /127.0.0.1:35773, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: b1e39e00-460e-4c8e-b201-d285caec8622, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005, duration(ns): 75472819
2020-12-03 07:20:08,409 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,413 [IPC Server handler 1 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:35773 for /file_concat_0
2020-12-03 07:20:08,416 [DataStreamer for file /file_concat_0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,418 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:37060 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006 src: /127.0.0.1:37060 dest: /127.0.0.1:35773
2020-12-03 07:20:08,427 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37060, dest: /127.0.0.1:35773, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: b1e39e00-460e-4c8e-b201-d285caec8622, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006, duration(ns): 6608166
2020-12-03 07:20:08,428 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,430 [IPC Server handler 9 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:37412 for /file_concat_0
2020-12-03 07:20:08,431 [DataStreamer for file /file_concat_0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,434 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:46052 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007 src: /127.0.0.1:46052 dest: /127.0.0.1:37412
2020-12-03 07:20:08,442 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46052, dest: /127.0.0.1:37412, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 9a3c9f46-217b-4c98-bf9c-976813f1b7b9, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007, duration(ns): 5946252
2020-12-03 07:20:08,443 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,445 [IPC Server handler 8 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_concat_0 is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,449 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:08,454 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_concat_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,459 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:46556 for /file_concat_1
2020-12-03 07:20:08,461 [Thread-379] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,466 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:60432 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008 src: /127.0.0.1:60432 dest: /127.0.0.1:46556
2020-12-03 07:20:08,474 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60432, dest: /127.0.0.1:46556, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 2757df4b-cdad-4ac8-86e5-272ebf780937, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008, duration(ns): 5858705
2020-12-03 07:20:08,474 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,477 [IPC Server handler 6 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:34880 for /file_concat_1
2020-12-03 07:20:08,479 [DataStreamer for file /file_concat_1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38192 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009 src: /127.0.0.1:38192 dest: /127.0.0.1:34880
2020-12-03 07:20:08,497 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38192, dest: /127.0.0.1:34880, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 9dc8304b-2a07-4b7b-9490-b4a0b87f3371, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009, duration(ns): 5689325
2020-12-03 07:20:08,497 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,500 [IPC Server handler 7 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:34880 for /file_concat_1
2020-12-03 07:20:08,502 [DataStreamer for file /file_concat_1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,506 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38206 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010 src: /127.0.0.1:38206 dest: /127.0.0.1:34880
2020-12-03 07:20:08,516 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38206, dest: /127.0.0.1:34880, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 9dc8304b-2a07-4b7b-9490-b4a0b87f3371, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010, duration(ns): 7858523
2020-12-03 07:20:08,517 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,519 [IPC Server handler 4 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_concat_1 is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,526 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=concat	src=[/file_concat_0, /file_concat_1]	dst=/file_concat_target	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,528 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:08,531 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file_create	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,535 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:46556 for /file_create
2020-12-03 07:20:08,536 [Thread-389] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,538 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:60484 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011 src: /127.0.0.1:60484 dest: /127.0.0.1:46556
2020-12-03 07:20:08,546 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60484, dest: /127.0.0.1:46556, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 2757df4b-cdad-4ac8-86e5-272ebf780937, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011, duration(ns): 4725410
2020-12-03 07:20:08,546 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,548 [IPC Server handler 5 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:37543 for /file_create
2020-12-03 07:20:08,550 [DataStreamer for file /file_create] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,551 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:40962 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012 src: /127.0.0.1:40962 dest: /127.0.0.1:37543
2020-12-03 07:20:08,559 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40962, dest: /127.0.0.1:37543, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: a650887a-9b41-4140-9ae1-784510c83ff1, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012, duration(ns): 4723839
2020-12-03 07:20:08,560 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:08,561 [IPC Server handler 1 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file_create is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:08,572 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/file_create	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,583 [IPC Server handler 4 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSymlink	src=/file_symlink	dst=/file_concat_target	perm=null	proto=rpc
2020-12-03 07:20:08,589 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/hard-lease-recovery-test	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:08,596 [IPC Server handler 2 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34880, 127.0.0.1:37771, 127.0.0.1:38017 for /hard-lease-recovery-test
2020-12-03 07:20:08,599 [Thread-396] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,602 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38271 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 src: /127.0.0.1:38271 dest: /127.0.0.1:34880
2020-12-03 07:20:08,604 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38271 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,608 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:45730 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 src: /127.0.0.1:45730 dest: /127.0.0.1:37771
2020-12-03 07:20:08,609 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:45730 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:08,611 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:49426 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 src: /127.0.0.1:49426 dest: /127.0.0.1:38017
2020-12-03 07:20:08,626 [IPC Server handler 3 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /hard-lease-recovery-test for DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:10,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2df9bc6d937747b1: Processing first storage report for DS-65a75d84-3884-416a-83cc-f8b08b3cba00 from datanode 2757df4b-cdad-4ac8-86e5-272ebf780937
2020-12-03 07:20:10,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2df9bc6d937747b1: from storage DS-65a75d84-3884-416a-83cc-f8b08b3cba00 node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=2757df4b-cdad-4ac8-86e5-272ebf780937, infoPort=46543, infoSecurePort=0, ipcPort=39214, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 2, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:10,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2df9bc6d937747b1: Processing first storage report for DS-2e30838d-7764-49bf-b5c7-a52b506c028a from datanode 2757df4b-cdad-4ac8-86e5-272ebf780937
2020-12-03 07:20:10,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2df9bc6d937747b1: from storage DS-2e30838d-7764-49bf-b5c7-a52b506c028a node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=2757df4b-cdad-4ac8-86e5-272ebf780937, infoPort=46543, infoSecurePort=0, ipcPort=39214, storageInfo=lv=-57;cid=testClusterID;nsid=1422713663;c=1606980001210), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:10,416 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2df9bc6d937747b1,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 2 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:10,416 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:10,426 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2020-12-03 07:20:10,429 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-877205389-172.17.0.11-1606980001210 blk_1073741836_1012 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210/current/finalized/subdir0/subdir0/blk_1073741836
2020-12-03 07:20:10,622 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 1
  getBytesOnDisk()  = 1
  getVisibleLength()= 1
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-12-03 07:20:10,624 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-877205389-172.17.0.11-1606980001210 blk_1073741825_1001 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-03 07:20:10,628 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] INFO  namenode.LeaseManager (LeaseManager.java:checkLeases(558)) - [Lease.  Holder: DFSClient_NONMAPREDUCE_-27027137_1, pending creates: 1] has expired hard limit
2020-12-03 07:20:10,630 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] INFO  namenode.FSNamesystem (FSNamesystem.java:internalReleaseLease(3398)) - Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-27027137_1, pending creates: 1], src=/hard-lease-recovery-test
2020-12-03 07:20:10,635 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] WARN  hdfs.StateChange (FSNamesystem.java:internalReleaseLease(3524)) - DIR* NameSystem.internalReleaseLease: File /hard-lease-recovery-test has not been closed. Lease recovery is in progress. RecoveryId = 1014 for block blk_1073741837_1013
2020-12-03 07:20:12,637 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] INFO  namenode.LeaseManager (LeaseManager.java:checkLeases(558)) - [Lease.  Holder: HDFS_NameNode-2020-12-03 07:20:10,630+0000, pending creates: 1] has expired hard limit
2020-12-03 07:20:12,638 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] INFO  namenode.FSNamesystem (FSNamesystem.java:internalReleaseLease(3398)) - Recovering [Lease.  Holder: HDFS_NameNode-2020-12-03 07:20:10,630+0000, pending creates: 1], src=/hard-lease-recovery-test
2020-12-03 07:20:12,638 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@4e28bdd1] INFO  blockmanagement.BlockManager (PendingRecoveryBlocks.java:add(80)) - Block recovery attempt for blk_1073741837_1013 rejected, as the previous attempt times out in 87 seconds.
2020-12-03 07:20:13,568 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  datanode.DataNode (BlockRecoveryWorker.java:logRecoverBlock(549)) - BlockRecoveryWorker: NameNode at localhost/127.0.0.1:33098 calls recoverBlock(BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, targets=[DatanodeInfoWithStorage[127.0.0.1:34880,null,null], DatanodeInfoWithStorage[127.0.0.1:37771,null,null], DatanodeInfoWithStorage[127.0.0.1:38017,null,null]], newGenerationStamp=1014, newBlock=null, isStriped=false)
2020-12-03 07:20:13,604 [IPC Server handler 0 on default port 41841] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,606 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38271 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:34880 remote=/127.0.0.1:38271]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,609 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37771, 127.0.0.1:38017]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37771, 127.0.0.1:38017]: Thread is interrupted.
2020-12-03 07:20:13,609 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37771, 127.0.0.1:38017]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37771, 127.0.0.1:38017] terminating
2020-12-03 07:20:13,609 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38271 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 received exception java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:34880 remote=/127.0.0.1:38271]. 60000 millis timeout left.
2020-12-03 07:20:13,613 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:38271 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34880:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:38271 dst: /127.0.0.1:34880
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:34880 remote=/127.0.0.1:38271]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,616 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:45730 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,616 [ResponseProcessor for block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013] WARN  hdfs.DataStreamer (DataStreamer.java:run(1196)) - Exception for BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
	at org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1086)
2020-12-03 07:20:13,617 [IPC Server handler 0 on default port 41841] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,617 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38017]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38017]: Thread is interrupted.
2020-12-03 07:20:13,618 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38017]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38017] terminating
2020-12-03 07:20:13,618 [DataStreamer for file /hard-lease-recovery-test block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013] WARN  hdfs.DataStreamer (DataStreamer.java:handleBadDatanode(1571)) - Error Recovery for BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 in pipeline [DatanodeInfoWithStorage[127.0.0.1:34880,DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-fb58d30a-f7d7-4e26-afee-3f36329431e6,DISK]]: datanode 0(DatanodeInfoWithStorage[127.0.0.1:34880,DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d,DISK]) is bad.
2020-12-03 07:20:13,619 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:45730 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:13,619 [IPC Server handler 0 on default port 41841] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from RBW to RUR
2020-12-03 07:20:13,620 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:49426 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,620 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:45730 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37771:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:45730 dst: /127.0.0.1:37771
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,621 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:20:13,621 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:13,621 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:49426 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:13,622 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:49426 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38017:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:49426 dst: /127.0.0.1:38017
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:13,625 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,625 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,625 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from RBW to RUR
2020-12-03 07:20:13,626 [IPC Server handler 4 on default port 33098] INFO  ipc.Server (Server.java:logException(2969)) - IPC Server handler 4 on default port 33098, call Call#137 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getAdditionalDatanode from 127.0.0.1:47352: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: Client (=DFSClient_NONMAPREDUCE_-27027137_1) is not the lease owner (=HDFS_NameNode-2020-12-03 07:20:12,637+0000: /hard-lease-recovery-test (inode 16395) Holder DFSClient_NONMAPREDUCE_-27027137_1 does not have any open files.
2020-12-03 07:20:13,648 [IPC Server handler 0 on default port 39316] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,649 [IPC Server handler 0 on default port 39316] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,649 [IPC Server handler 0 on default port 39316] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from RBW to RUR
2020-12-03 07:20:13,650 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 (length=11), isTruncateRecovery=false, syncList=[block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:34880,null,null], block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:37771,null,null], block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:38017,null,null]]
2020-12-03 07:20:13,651 [DataStreamer for file /hard-lease-recovery-test block BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): Client (=DFSClient_NONMAPREDUCE_-27027137_1) is not the lease owner (=HDFS_NameNode-2020-12-03 07:20:12,637+0000: /hard-lease-recovery-test (inode 16395) Holder DFSClient_NONMAPREDUCE_-27027137_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2920)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalDatanode(FSNamesystem.java:2833)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getAdditionalDatanode(NameNodeRpcServer.java:927)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolServerSideTranslatorPB.java:598)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy26.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolTranslatorPB.java:541)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy27.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1362)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)
2020-12-03 07:20:13,651 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(293)) - BlockRecoveryWorker: block=BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013 (length=11), bestState=RBW, newBlock=BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1014 (length=11), participatingList=[block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:34880,null,null], block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:37771,null,null], block:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW] node:DatanodeInfoWithStorage[127.0.0.1:38017,null,null]]
2020-12-03 07:20:13,655 [IPC Server handler 1 on default port 41841] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, recoveryId=1014, length=11, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  recoveryId=1014
  original=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,662 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@47434755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013[numBytes=11,originalReplicaState=RBW], recoveryId=1014, length=11, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  recoveryId=1014
  original=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,665 [IPC Server handler 1 on default port 39316] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, recoveryId=1014, length=11, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  recoveryId=1014
  original=ReplicaBeingWritten, blk_1073741837_1013, RBW
  getNumBytes()     = 11
  getBytesOnDisk()  = 11
  getVisibleLength()= 11
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210/current/rbw/blk_1073741837
  bytesAcked=11
  bytesOnDisk=11
2020-12-03 07:20:13,672 [IPC Server handler 1 on default port 33098] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3655)) - commitBlockSynchronization(oldBlock=BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, newgenerationstamp=1014, newlength=11, newtargets=[127.0.0.1:34880, 127.0.0.1:37771, 127.0.0.1:38017], closeFile=true, deleteBlock=false)
2020-12-03 07:20:13,675 [IPC Server handler 1 on default port 33098] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3805)) - commitBlockSynchronization(oldBlock=BP-877205389-172.17.0.11-1606980001210:blk_1073741837_1013, file=/hard-lease-recovery-test, newgenerationstamp=1014, newlength=11, newtargets=[127.0.0.1:34880, 127.0.0.1:37771, 127.0.0.1:38017]) successful
2020-12-03 07:20:14,655 [IPC Server handler 8 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:addCachePool(813)) - addCachePool of {poolName:pool1, ownerName:null, groupName:null, mode:null, limit:null, defaultReplication:null, maxRelativeExpiryMs:null} successful.
2020-12-03 07:20:14,657 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addCachePool	src={poolName:pool1, ownerName:root, groupName:root, mode:0755, limit:9223372036854775807, defaultReplication:1, maxRelativeExpiryMs:2305843009213693951}	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,663 [IPC Server handler 3 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:modifyCachePool(883)) - modifyCachePool of pool1 successful; set limit to 99
2020-12-03 07:20:14,664 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyCachePool	src={poolName: pool1}	dst={poolName:pool1, ownerName:null, groupName:null, mode:null, limit:99, defaultReplication:null, maxRelativeExpiryMs:null}	perm=null	proto=rpc
2020-12-03 07:20:14,681 [IPC Server handler 7 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:addDirective(574)) - addDirective of {path: /path, replication: 1, pool: pool1} successful.
2020-12-03 07:20:14,683 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addCacheDirective	src={id: 1, path: /path, replication: 1, pool: pool1, expiration: 73071277-01-29T03:08:28+0000}	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,691 [IPC Server handler 0 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:modifyDirective(676)) - modifyDirective of 1 successfully applied {id: 1, replication: 2}.
2020-12-03 07:20:14,691 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyCacheDirective	src={id: 1}	dst={id: 1, replication: 2}	perm=null	proto=rpc
2020-12-03 07:20:14,697 [IPC Server handler 9 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:removeDirective(715)) - removeDirective of 1 successful.
2020-12-03 07:20:14,697 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeCacheDirective	src={id: 1}	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,703 [IPC Server handler 5 on default port 33098] INFO  namenode.CacheManager (CacheManager.java:removeCachePool(918)) - removeCachePool of pool1 successful.
2020-12-03 07:20:14,704 [IPC Server handler 5 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeCachePool	src={poolName: pool1}	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,727 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/file_concat_target	dst=null	perm=root:supergroup:rw-rw----	proto=rpc
2020-12-03 07:20:14,741 [IPC Server handler 4 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/file_concat_target	dst=null	perm=root:supergroup:rw-rw----	proto=rpc
2020-12-03 07:20:14,744 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/file_concat_target	dst=null	perm=root:supergroup:rw-rw----	proto=rpc
2020-12-03 07:20:14,748 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/file_concat_target	dst=null	perm=root:supergroup:rw-rw----	proto=rpc
2020-12-03 07:20:14,764 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-3-2-8k]	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,778 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-6-10-4k]	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,781 [IPC Server handler 7 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-8k
2020-12-03 07:20:14,782 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-8k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,786 [IPC Server handler 0 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-6-10-4k
2020-12-03 07:20:14,786 [IPC Server handler 0 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-10-4k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,789 [IPC Server handler 9 on default port 33098] INFO  namenode.FSNamesystem (FSNamesystem.java:disableErasureCodingPolicy(7690)) - Disable the erasure coding policy RS-3-2-8k
2020-12-03 07:20:14,789 [IPC Server handler 9 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:disablePolicy(395)) - Disable the erasure coding policy RS-3-2-8k
2020-12-03 07:20:14,789 [IPC Server handler 9 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=disableErasureCodingPolicy	src=RS-3-2-8k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,793 [IPC Server handler 5 on default port 33098] INFO  namenode.FSNamesystem (FSNamesystem.java:disableErasureCodingPolicy(7690)) - Disable the erasure coding policy RS-6-10-4k
2020-12-03 07:20:14,793 [IPC Server handler 5 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:disablePolicy(395)) - Disable the erasure coding policy RS-6-10-4k
2020-12-03 07:20:14,793 [IPC Server handler 5 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=disableErasureCodingPolicy	src=RS-6-10-4k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,797 [IPC Server handler 6 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:removePolicy(359)) - Remove erasure coding policy RS-3-2-8k
2020-12-03 07:20:14,798 [IPC Server handler 6 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeErasureCodingPolicy	src=RS-3-2-8k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,806 [IPC Server handler 4 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:removePolicy(359)) - Remove erasure coding policy RS-6-10-4k
2020-12-03 07:20:14,807 [IPC Server handler 4 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeErasureCodingPolicy	src=RS-6-10-4k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,809 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:14,810 [IPC Server handler 3 on default port 33098] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:20:14,811 [IPC Server handler 3 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,812 [IPC Server handler 2 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:14,817 [IPC Server handler 1 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:14,824 [IPC Server handler 7 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/replicated	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:14,828 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741838_1015, replicas=127.0.0.1:38017, 127.0.0.1:37543, 127.0.0.1:38594 for /ec/replicated
2020-12-03 07:20:14,829 [Thread-410] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:52600 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015 src: /127.0.0.1:52600 dest: /127.0.0.1:38017
2020-12-03 07:20:14,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:52600 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,834 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:44182 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015 src: /127.0.0.1:44182 dest: /127.0.0.1:37543
2020-12-03 07:20:14,835 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:44182 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,837 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:57428 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015 src: /127.0.0.1:57428 dest: /127.0.0.1:38594
2020-12-03 07:20:14,853 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57428, dest: /127.0.0.1:38594, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: f95bd9c1-4095-403f-92ec-d83341a43aa4, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, duration(ns): 13142647
2020-12-03 07:20:14,853 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:14,856 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38594]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44182, dest: /127.0.0.1:37543, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: a650887a-9b41-4140-9ae1-784510c83ff1, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, duration(ns): 15882121
2020-12-03 07:20:14,856 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38594]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38594] terminating
2020-12-03 07:20:14,858 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37543, 127.0.0.1:38594]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52600, dest: /127.0.0.1:38017, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: 616457bc-d176-436d-bb41-d2849860b9d8, blockid: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, duration(ns): 16596254
2020-12-03 07:20:14,859 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37543, 127.0.0.1:38594]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_1073741838_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37543, 127.0.0.1:38594] terminating
2020-12-03 07:20:14,863 [IPC Server handler 4 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /ec/replicated is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:14,866 [IPC Server handler 8 on default port 33098] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/RS-3-2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:14,890 [IPC Server handler 3 on default port 33098] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1016, replicas=127.0.0.1:37543, 127.0.0.1:46556, 127.0.0.1:37771, 127.0.0.1:35773, 127.0.0.1:38594 for /ec/RS-3-2
2020-12-03 07:20:14,901 [Thread-421] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,901 [Thread-422] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,901 [Thread-418] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:14,902 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:40430 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016 src: /127.0.0.1:40430 dest: /127.0.0.1:35773
2020-12-03 07:20:14,903 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:57490 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016 src: /127.0.0.1:57490 dest: /127.0.0.1:38594
2020-12-03 07:20:14,911 [DataXceiver for client DFSClient_NONMAPREDUCE_-27027137_1 at /127.0.0.1:44244 [Receiving block BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016 src: /127.0.0.1:44244 dest: /127.0.0.1:37543
2020-12-03 07:20:14,927 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44244, dest: /127.0.0.1:37543, bytes: 6, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: a650887a-9b41-4140-9ae1-784510c83ff1, blockid: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016, duration(ns): 11638092
2020-12-03 07:20:14,927 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775792_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:14,938 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40430, dest: /127.0.0.1:35773, bytes: 6, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: b1e39e00-460e-4c8e-b201-d285caec8622, blockid: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016, duration(ns): 31899923
2020-12-03 07:20:14,938 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775789_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:14,941 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57490, dest: /127.0.0.1:38594, bytes: 6, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27027137_1, offset: 0, srvID: f95bd9c1-4095-403f-92ec-d83341a43aa4, blockid: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016, duration(ns): 34748652
2020-12-03 07:20:14,941 [PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-877205389-172.17.0.11-1606980001210:blk_-9223372036854775788_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:14,945 [IPC Server handler 0 on default port 33098] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /ec/RS-3-2 is closed by DFSClient_NONMAPREDUCE_-27027137_1
2020-12-03 07:20:14,947 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:20:14,947 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 120
2020-12-03 07:20:14,947 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 121 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 15 Number of syncs: 107 SyncTimes(ms): 11 
2020-12-03 07:20:14,949 [Listener at localhost/39349] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121
2020-12-03 07:20:14,949 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 122
2020-12-03 07:20:14,984 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:testGenerated(105)) - Generated edits=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121
2020-12-03 07:20:14,985 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:runOev(200)) - Running oev [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121] [/tmp/junit437526837032643078/editsParsed.xml]
input  [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121]
output [/tmp/junit437526837032643078/editsParsed.xml]
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<EDITS>
  <EDITS_VERSION>-65</EDITS_VERSION>
  <RECORD>
    <OPCODE>OP_START_LOG_SEGMENT</OPCODE>
    <DATA>
      <TXID>1</TXID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_MASTER_KEY</OPCODE>
    <DATA>
      <TXID>2</TXID>
      <DELEGATION_KEY>
        <KEY_ID>1</KEY_ID>
        <EXPIRY_DATE>1607671204363</EXPIRY_DATE>
        <KEY>86d3143302822a41</KEY>
      </DELEGATION_KEY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_MASTER_KEY</OPCODE>
    <DATA>
      <TXID>3</TXID>
      <DELEGATION_KEY>
        <KEY_ID>2</KEY_ID>
        <EXPIRY_DATE>1607671204368</EXPIRY_DATE>
        <KEY>a6f24ea33a6beb59</KEY>
      </DELEGATION_KEY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>4</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16386</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007727</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>43</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>5</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007808</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_APPEND</OPCODE>
    <DATA>
      <TXID>6</TXID>
      <PATH>/file_create</PATH>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <NEWBLOCK>false</NEWBLOCK>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>45</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>7</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007829</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>8</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16387</INODEID>
      <PATH>/update_blocks</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980007831</MTIME>
      <ATIME>1606980007831</ATIME>
      <BLOCKSIZE>4096</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>47</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>9</TXID>
      <BLOCK_ID>1073741825</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>10</TXID>
      <GENSTAMPV2>1001</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>11</TXID>
      <PATH>/update_blocks</PATH>
      <BLOCK>
        <BLOCK_ID>1073741825</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1001</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>12</TXID>
      <PATH>/update_blocks</PATH>
      <BLOCK>
        <BLOCK_ID>1073741825</BLOCK_ID>
        <NUM_BYTES>1</NUM_BYTES>
        <GENSTAMP>1001</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>13</TXID>
      <PATH>/update_blocks</PATH>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>14</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/update_blocks</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008071</MTIME>
      <ATIME>1606980007831</ATIME>
      <BLOCKSIZE>4096</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_STORAGE_POLICY</OPCODE>
    <DATA>
      <TXID>15</TXID>
      <PATH>/file_create</PATH>
      <POLICYID>7</POLICYID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME_OLD</OPCODE>
    <DATA>
      <TXID>16</TXID>
      <LENGTH>0</LENGTH>
      <SRC>/file_create</SRC>
      <DST>/file_moved</DST>
      <TIMESTAMP>1606980008089</TIMESTAMP>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>55</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DELETE</OPCODE>
    <DATA>
      <TXID>17</TXID>
      <LENGTH>0</LENGTH>
      <PATH>/file_moved</PATH>
      <TIMESTAMP>1606980008103</TIMESTAMP>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>57</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MKDIR</OPCODE>
    <DATA>
      <TXID>18</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16388</INODEID>
      <PATH>/directory_mkdir</PATH>
      <TIMESTAMP>1606980008115</TIMESTAMP>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>493</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>19</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>20</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>21</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CREATE_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>22</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTNAME>snapshot1</SNAPSHOTNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>62</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>23</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTOLDNAME>snapshot1</SNAPSHOTOLDNAME>
      <SNAPSHOTNEWNAME>snapshot2</SNAPSHOTNEWNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>63</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DELETE_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>24</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTNAME>snapshot2</SNAPSHOTNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>64</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>25</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16389</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008170</MTIME>
      <ATIME>1606980008170</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>65</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>26</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008176</MTIME>
      <ATIME>1606980008170</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_REPLICATION</OPCODE>
    <DATA>
      <TXID>27</TXID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_PERMISSIONS</OPCODE>
    <DATA>
      <TXID>28</TXID>
      <SRC>/file_create</SRC>
      <MODE>511</MODE>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_OWNER</OPCODE>
    <DATA>
      <TXID>29</TXID>
      <SRC>/file_create</SRC>
      <USERNAME>newOwner</USERNAME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_TIMES</OPCODE>
    <DATA>
      <TXID>30</TXID>
      <LENGTH>0</LENGTH>
      <PATH>/file_create</PATH>
      <MTIME>1285195527000</MTIME>
      <ATIME>1285195527000</ATIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_QUOTA</OPCODE>
    <DATA>
      <TXID>31</TXID>
      <SRC>/directory_mkdir</SRC>
      <NSQUOTA>1000</NSQUOTA>
      <DSQUOTA>-1</DSQUOTA>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_QUOTA_BY_STORAGETYPE</OPCODE>
    <DATA>
      <TXID>32</TXID>
      <SRC>/directory_mkdir</SRC>
      <STORAGETYPE>1</STORAGETYPE>
      <DSQUOTA>888</DSQUOTA>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME</OPCODE>
    <DATA>
      <TXID>33</TXID>
      <LENGTH>0</LENGTH>
      <SRC>/file_create</SRC>
      <DST>/file_moved</DST>
      <TIMESTAMP>1606980008224</TIMESTAMP>
      <OPTIONS>NONE</OPTIONS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>73</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>34</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16390</INODEID>
      <PATH>/file_concat_target</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008232</MTIME>
      <ATIME>1606980008232</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>75</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>35</TXID>
      <BLOCK_ID>1073741826</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>36</TXID>
      <GENSTAMPV2>1002</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>37</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>38</TXID>
      <BLOCK_ID>1073741827</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>39</TXID>
      <GENSTAMPV2>1003</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>40</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>41</TXID>
      <BLOCK_ID>1073741828</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>42</TXID>
      <GENSTAMPV2>1004</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>43</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741828</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1004</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>44</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_target</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008315</MTIME>
      <ATIME>1606980008232</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741828</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1004</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>45</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16391</INODEID>
      <PATH>/file_concat_0</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008320</MTIME>
      <ATIME>1606980008320</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>84</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>46</TXID>
      <BLOCK_ID>1073741829</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>47</TXID>
      <GENSTAMPV2>1005</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>48</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>49</TXID>
      <BLOCK_ID>1073741830</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>50</TXID>
      <GENSTAMPV2>1006</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>51</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>52</TXID>
      <BLOCK_ID>1073741831</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>53</TXID>
      <GENSTAMPV2>1007</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>54</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741831</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1007</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>55</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_0</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008445</MTIME>
      <ATIME>1606980008320</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741831</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1007</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>56</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16392</INODEID>
      <PATH>/file_concat_1</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008453</MTIME>
      <ATIME>1606980008453</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>93</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>57</TXID>
      <BLOCK_ID>1073741832</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>58</TXID>
      <GENSTAMPV2>1008</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>59</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>60</TXID>
      <BLOCK_ID>1073741833</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>61</TXID>
      <GENSTAMPV2>1009</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>62</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>63</TXID>
      <BLOCK_ID>1073741834</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>64</TXID>
      <GENSTAMPV2>1010</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>65</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741834</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1010</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>66</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_1</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008518</MTIME>
      <ATIME>1606980008453</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741834</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1010</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CONCAT_DELETE</OPCODE>
    <DATA>
      <TXID>67</TXID>
      <LENGTH>0</LENGTH>
      <TRG>/file_concat_target</TRG>
      <TIMESTAMP>1606980008525</TIMESTAMP>
      <SOURCES>
        <SOURCE1>/file_concat_0</SOURCE1>
        <SOURCE2>/file_concat_1</SOURCE2>
      </SOURCES>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>101</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>68</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16393</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008530</MTIME>
      <ATIME>1606980008530</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>103</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>69</TXID>
      <BLOCK_ID>1073741835</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>70</TXID>
      <GENSTAMPV2>1011</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>71</TXID>
      <PATH>/file_create</PATH>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>72</TXID>
      <BLOCK_ID>1073741836</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>73</TXID>
      <GENSTAMPV2>1012</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>74</TXID>
      <PATH>/file_create</PATH>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741836</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1012</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>75</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008561</MTIME>
      <ATIME>1606980008530</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741836</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1012</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_TRUNCATE</OPCODE>
    <DATA>
      <TXID>76</TXID>
      <SRC>/file_create</SRC>
      <CLIENTNAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENTNAME>
      <CLIENTMACHINE>127.0.0.1</CLIENTMACHINE>
      <NEWLENGTH>512</NEWLENGTH>
      <TIMESTAMP>1606980008566</TIMESTAMP>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SYMLINK</OPCODE>
    <DATA>
      <TXID>77</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16394</INODEID>
      <PATH>/file_symlink</PATH>
      <VALUE>/file_concat_target</VALUE>
      <MTIME>1606980008582</MTIME>
      <ATIME>1606980008582</ATIME>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>511</MODE>
      </PERMISSION_STATUS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>110</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>78</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16395</INODEID>
      <PATH>/hard-lease-recovery-test</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008588</MTIME>
      <ATIME>1606980008588</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>111</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>79</TXID>
      <BLOCK_ID>1073741837</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>80</TXID>
      <GENSTAMPV2>1013</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>81</TXID>
      <PATH>/hard-lease-recovery-test</PATH>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1013</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>82</TXID>
      <PATH>/hard-lease-recovery-test</PATH>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>11</NUM_BYTES>
        <GENSTAMP>1013</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>83</TXID>
      <GENSTAMPV2>1014</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REASSIGN_LEASE</OPCODE>
    <DATA>
      <TXID>84</TXID>
      <LEASEHOLDER>DFSClient_NONMAPREDUCE_-27027137_1</LEASEHOLDER>
      <PATH>/hard-lease-recovery-test</PATH>
      <NEWHOLDER>HDFS_NameNode-2020-12-03 07:20:10,630+0000</NEWHOLDER>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REASSIGN_LEASE</OPCODE>
    <DATA>
      <TXID>85</TXID>
      <LEASEHOLDER>HDFS_NameNode-2020-12-03 07:20:10,630+0000</LEASEHOLDER>
      <PATH>/hard-lease-recovery-test</PATH>
      <NEWHOLDER>HDFS_NameNode-2020-12-03 07:20:12,637+0000</NEWHOLDER>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>86</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/hard-lease-recovery-test</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980013674</MTIME>
      <ATIME>1606980008588</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>11</NUM_BYTES>
        <GENSTAMP>1014</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>87</TXID>
      <POOLNAME>pool1</POOLNAME>
      <OWNERNAME>root</OWNERNAME>
      <GROUPNAME>root</GROUPNAME>
      <MODE>493</MODE>
      <LIMIT>9223372036854775807</LIMIT>
      <MAXRELATIVEEXPIRY>2305843009213693951</MAXRELATIVEEXPIRY>
      <DEFAULTREPLICATION>1</DEFAULTREPLICATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>146</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MODIFY_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>88</TXID>
      <POOLNAME>pool1</POOLNAME>
      <LIMIT>99</LIMIT>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>147</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>89</TXID>
      <ID>1</ID>
      <PATH>/path</PATH>
      <REPLICATION>1</REPLICATION>
      <POOL>pool1</POOL>
      <EXPIRATION>2305844616193708630</EXPIRATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>148</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MODIFY_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>90</TXID>
      <ID>1</ID>
      <REPLICATION>2</REPLICATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>149</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>91</TXID>
      <ID>1</ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>150</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>92</TXID>
      <POOLNAME>pool1</POOLNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>151</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_ACL</OPCODE>
    <DATA>
      <TXID>93</TXID>
      <SRC>/file_concat_target</SRC>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>USER</TYPE>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>USER</TYPE>
        <NAME>user</NAME>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>GROUP</TYPE>
        <PERM>-w-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>MASK</TYPE>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>OTHER</TYPE>
        <PERM>---</PERM>
      </ENTRY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>94</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a1</NAME>
        <VALUE>0x313233</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>153</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>95</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a2</NAME>
        <VALUE>0x373839</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>154</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_XATTR</OPCODE>
    <DATA>
      <TXID>96</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a2</NAME>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>155</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>97</TXID>
      <CODEC>rs</CODEC>
      <DATAUNITS>3</DATAUNITS>
      <PARITYUNITS>2</PARITYUNITS>
      <CELLSIZE>8192</CELLSIZE>
      <EXTRAOPTIONS>0</EXTRAOPTIONS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>156</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>98</TXID>
      <CODEC>rs</CODEC>
      <DATAUNITS>6</DATAUNITS>
      <PARITYUNITS>10</PARITYUNITS>
      <CELLSIZE>4096</CELLSIZE>
      <EXTRAOPTIONS>1</EXTRAOPTIONS>
      <EXTRAOPTION>
        <KEY>dummyKey</KEY>
        <VALUE>dummyValue</VALUE>
      </EXTRAOPTION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>157</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>99</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>158</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>100</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>159</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>101</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>160</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>102</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>161</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>103</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>162</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>104</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>163</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MKDIR</OPCODE>
    <DATA>
      <TXID>105</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16396</INODEID>
      <PATH>/ec</PATH>
      <TIMESTAMP>1606980014809</TIMESTAMP>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>493</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>106</TXID>
      <POLICYNAME>RS-3-2-1024k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>165</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>107</TXID>
      <POLICYNAME>RS-6-3-1024k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>166</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>108</TXID>
      <SRC>/ec</SRC>
      <XATTR>
        <NAMESPACE>SYSTEM</NAMESPACE>
        <NAME>hdfs.erasurecoding.policy</NAME>
        <VALUE>0x0000000c52532d362d332d313032346b</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>167</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>109</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16397</INODEID>
      <PATH>/ec/replicated</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980014823</MTIME>
      <ATIME>1606980014823</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>168</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>110</TXID>
      <BLOCK_ID>1073741838</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>111</TXID>
      <GENSTAMPV2>1015</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>112</TXID>
      <PATH>/ec/replicated</PATH>
      <BLOCK>
        <BLOCK_ID>1073741838</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1015</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>113</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/ec/replicated</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980014863</MTIME>
      <ATIME>1606980014823</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741838</BLOCK_ID>
        <NUM_BYTES>10</NUM_BYTES>
        <GENSTAMP>1015</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>114</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16398</INODEID>
      <PATH>/ec/RS-3-2</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980014865</MTIME>
      <ATIME>1606980014865</ATIME>
      <BLOCKSIZE>1048576</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>2</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>174</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>115</TXID>
      <BLOCK_ID>-9223372036854775792</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>116</TXID>
      <GENSTAMPV2>1016</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>117</TXID>
      <PATH>/ec/RS-3-2</PATH>
      <BLOCK>
        <BLOCK_ID>-9223372036854775792</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1016</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>118</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/ec/RS-3-2</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980014944</MTIME>
      <ATIME>1606980014865</ATIME>
      <BLOCKSIZE>1048576</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>-9223372036854775792</BLOCK_ID>
        <NUM_BYTES>6</NUM_BYTES>
        <GENSTAMP>1016</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ROLLING_UPGRADE_START</OPCODE>
    <DATA>
      <TXID>119</TXID>
      <STARTTIME>1606980014946</STARTTIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ROLLING_UPGRADE_FINALIZE</OPCODE>
    <DATA>
      <TXID>120</TXID>
      <FINALIZETIME>1606980014946</FINALIZETIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_END_LOG_SEGMENT</OPCODE>
    <DATA>
      <TXID>121</TXID>
    </DATA>
  </RECORD>
</EDITS>
2020-12-03 07:20:15,333 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:runOev(200)) - Running oev [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121] [/tmp/junit437526837032643078/editsRecoveredParsed.XML]
input  [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121]
output [/tmp/junit437526837032643078/editsRecoveredParsed.XML]
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<EDITS>
  <EDITS_VERSION>-65</EDITS_VERSION>
  <RECORD>
    <OPCODE>OP_START_LOG_SEGMENT</OPCODE>
    <DATA>
      <TXID>1</TXID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_MASTER_KEY</OPCODE>
    <DATA>
      <TXID>2</TXID>
      <DELEGATION_KEY>
        <KEY_ID>1</KEY_ID>
        <EXPIRY_DATE>1607671204363</EXPIRY_DATE>
        <KEY>86d3143302822a41</KEY>
      </DELEGATION_KEY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_MASTER_KEY</OPCODE>
    <DATA>
      <TXID>3</TXID>
      <DELEGATION_KEY>
        <KEY_ID>2</KEY_ID>
        <EXPIRY_DATE>1607671204368</EXPIRY_DATE>
        <KEY>a6f24ea33a6beb59</KEY>
      </DELEGATION_KEY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>4</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16386</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007727</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>43</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>5</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007808</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_APPEND</OPCODE>
    <DATA>
      <TXID>6</TXID>
      <PATH>/file_create</PATH>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <NEWBLOCK>false</NEWBLOCK>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>45</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>7</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980007829</MTIME>
      <ATIME>1606980007727</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>8</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16387</INODEID>
      <PATH>/update_blocks</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980007831</MTIME>
      <ATIME>1606980007831</ATIME>
      <BLOCKSIZE>4096</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>47</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>9</TXID>
      <BLOCK_ID>1073741825</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>10</TXID>
      <GENSTAMPV2>1001</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>11</TXID>
      <PATH>/update_blocks</PATH>
      <BLOCK>
        <BLOCK_ID>1073741825</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1001</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>12</TXID>
      <PATH>/update_blocks</PATH>
      <BLOCK>
        <BLOCK_ID>1073741825</BLOCK_ID>
        <NUM_BYTES>1</NUM_BYTES>
        <GENSTAMP>1001</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>13</TXID>
      <PATH>/update_blocks</PATH>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>14</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/update_blocks</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008071</MTIME>
      <ATIME>1606980007831</ATIME>
      <BLOCKSIZE>4096</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_STORAGE_POLICY</OPCODE>
    <DATA>
      <TXID>15</TXID>
      <PATH>/file_create</PATH>
      <POLICYID>7</POLICYID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME_OLD</OPCODE>
    <DATA>
      <TXID>16</TXID>
      <LENGTH>0</LENGTH>
      <SRC>/file_create</SRC>
      <DST>/file_moved</DST>
      <TIMESTAMP>1606980008089</TIMESTAMP>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>55</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DELETE</OPCODE>
    <DATA>
      <TXID>17</TXID>
      <LENGTH>0</LENGTH>
      <PATH>/file_moved</PATH>
      <TIMESTAMP>1606980008103</TIMESTAMP>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>57</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MKDIR</OPCODE>
    <DATA>
      <TXID>18</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16388</INODEID>
      <PATH>/directory_mkdir</PATH>
      <TIMESTAMP>1606980008115</TIMESTAMP>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>493</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>19</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>20</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOW_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>21</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CREATE_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>22</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTNAME>snapshot1</SNAPSHOTNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>62</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>23</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTOLDNAME>snapshot1</SNAPSHOTOLDNAME>
      <SNAPSHOTNEWNAME>snapshot2</SNAPSHOTNEWNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>63</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DELETE_SNAPSHOT</OPCODE>
    <DATA>
      <TXID>24</TXID>
      <SNAPSHOTROOT>/directory_mkdir</SNAPSHOTROOT>
      <SNAPSHOTNAME>snapshot2</SNAPSHOTNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>64</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>25</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16389</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008170</MTIME>
      <ATIME>1606980008170</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>65</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>26</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008176</MTIME>
      <ATIME>1606980008170</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_REPLICATION</OPCODE>
    <DATA>
      <TXID>27</TXID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_PERMISSIONS</OPCODE>
    <DATA>
      <TXID>28</TXID>
      <SRC>/file_create</SRC>
      <MODE>511</MODE>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_OWNER</OPCODE>
    <DATA>
      <TXID>29</TXID>
      <SRC>/file_create</SRC>
      <USERNAME>newOwner</USERNAME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_TIMES</OPCODE>
    <DATA>
      <TXID>30</TXID>
      <LENGTH>0</LENGTH>
      <PATH>/file_create</PATH>
      <MTIME>1285195527000</MTIME>
      <ATIME>1285195527000</ATIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_QUOTA</OPCODE>
    <DATA>
      <TXID>31</TXID>
      <SRC>/directory_mkdir</SRC>
      <NSQUOTA>1000</NSQUOTA>
      <DSQUOTA>-1</DSQUOTA>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_QUOTA_BY_STORAGETYPE</OPCODE>
    <DATA>
      <TXID>32</TXID>
      <SRC>/directory_mkdir</SRC>
      <STORAGETYPE>1</STORAGETYPE>
      <DSQUOTA>888</DSQUOTA>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_RENAME</OPCODE>
    <DATA>
      <TXID>33</TXID>
      <LENGTH>0</LENGTH>
      <SRC>/file_create</SRC>
      <DST>/file_moved</DST>
      <TIMESTAMP>1606980008224</TIMESTAMP>
      <OPTIONS>NONE</OPTIONS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>73</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>34</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16390</INODEID>
      <PATH>/file_concat_target</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008232</MTIME>
      <ATIME>1606980008232</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>75</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>35</TXID>
      <BLOCK_ID>1073741826</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>36</TXID>
      <GENSTAMPV2>1002</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>37</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>38</TXID>
      <BLOCK_ID>1073741827</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>39</TXID>
      <GENSTAMPV2>1003</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>40</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>41</TXID>
      <BLOCK_ID>1073741828</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>42</TXID>
      <GENSTAMPV2>1004</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>43</TXID>
      <PATH>/file_concat_target</PATH>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741828</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1004</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>44</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_target</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008315</MTIME>
      <ATIME>1606980008232</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741826</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1002</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741827</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1003</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741828</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1004</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>45</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16391</INODEID>
      <PATH>/file_concat_0</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008320</MTIME>
      <ATIME>1606980008320</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>84</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>46</TXID>
      <BLOCK_ID>1073741829</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>47</TXID>
      <GENSTAMPV2>1005</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>48</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>49</TXID>
      <BLOCK_ID>1073741830</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>50</TXID>
      <GENSTAMPV2>1006</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>51</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>52</TXID>
      <BLOCK_ID>1073741831</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>53</TXID>
      <GENSTAMPV2>1007</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>54</TXID>
      <PATH>/file_concat_0</PATH>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741831</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1007</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>55</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_0</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008445</MTIME>
      <ATIME>1606980008320</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741829</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1005</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741830</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1006</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741831</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1007</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>56</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16392</INODEID>
      <PATH>/file_concat_1</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008453</MTIME>
      <ATIME>1606980008453</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>93</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>57</TXID>
      <BLOCK_ID>1073741832</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>58</TXID>
      <GENSTAMPV2>1008</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>59</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>60</TXID>
      <BLOCK_ID>1073741833</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>61</TXID>
      <GENSTAMPV2>1009</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>62</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>63</TXID>
      <BLOCK_ID>1073741834</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>64</TXID>
      <GENSTAMPV2>1010</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>65</TXID>
      <PATH>/file_concat_1</PATH>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741834</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1010</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>66</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_concat_1</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008518</MTIME>
      <ATIME>1606980008453</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741832</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1008</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741833</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1009</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741834</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1010</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CONCAT_DELETE</OPCODE>
    <DATA>
      <TXID>67</TXID>
      <LENGTH>0</LENGTH>
      <TRG>/file_concat_target</TRG>
      <TIMESTAMP>1606980008525</TIMESTAMP>
      <SOURCES>
        <SOURCE1>/file_concat_0</SOURCE1>
        <SOURCE2>/file_concat_1</SOURCE2>
      </SOURCES>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>101</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>68</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16393</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008530</MTIME>
      <ATIME>1606980008530</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>103</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>69</TXID>
      <BLOCK_ID>1073741835</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>70</TXID>
      <GENSTAMPV2>1011</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>71</TXID>
      <PATH>/file_create</PATH>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>72</TXID>
      <BLOCK_ID>1073741836</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>73</TXID>
      <GENSTAMPV2>1012</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>74</TXID>
      <PATH>/file_create</PATH>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741836</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1012</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>75</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/file_create</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980008561</MTIME>
      <ATIME>1606980008530</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741835</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1011</GENSTAMP>
      </BLOCK>
      <BLOCK>
        <BLOCK_ID>1073741836</BLOCK_ID>
        <NUM_BYTES>512</NUM_BYTES>
        <GENSTAMP>1012</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_TRUNCATE</OPCODE>
    <DATA>
      <TXID>76</TXID>
      <SRC>/file_create</SRC>
      <CLIENTNAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENTNAME>
      <CLIENTMACHINE>127.0.0.1</CLIENTMACHINE>
      <NEWLENGTH>512</NEWLENGTH>
      <TIMESTAMP>1606980008566</TIMESTAMP>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SYMLINK</OPCODE>
    <DATA>
      <TXID>77</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16394</INODEID>
      <PATH>/file_symlink</PATH>
      <VALUE>/file_concat_target</VALUE>
      <MTIME>1606980008582</MTIME>
      <ATIME>1606980008582</ATIME>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>511</MODE>
      </PERMISSION_STATUS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>110</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>78</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16395</INODEID>
      <PATH>/hard-lease-recovery-test</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980008588</MTIME>
      <ATIME>1606980008588</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>111</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>79</TXID>
      <BLOCK_ID>1073741837</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>80</TXID>
      <GENSTAMPV2>1013</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>81</TXID>
      <PATH>/hard-lease-recovery-test</PATH>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1013</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_UPDATE_BLOCKS</OPCODE>
    <DATA>
      <TXID>82</TXID>
      <PATH>/hard-lease-recovery-test</PATH>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>11</NUM_BYTES>
        <GENSTAMP>1013</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>83</TXID>
      <GENSTAMPV2>1014</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REASSIGN_LEASE</OPCODE>
    <DATA>
      <TXID>84</TXID>
      <LEASEHOLDER>DFSClient_NONMAPREDUCE_-27027137_1</LEASEHOLDER>
      <PATH>/hard-lease-recovery-test</PATH>
      <NEWHOLDER>HDFS_NameNode-2020-12-03 07:20:10,630+0000</NEWHOLDER>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REASSIGN_LEASE</OPCODE>
    <DATA>
      <TXID>85</TXID>
      <LEASEHOLDER>HDFS_NameNode-2020-12-03 07:20:10,630+0000</LEASEHOLDER>
      <PATH>/hard-lease-recovery-test</PATH>
      <NEWHOLDER>HDFS_NameNode-2020-12-03 07:20:12,637+0000</NEWHOLDER>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>86</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/hard-lease-recovery-test</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980013674</MTIME>
      <ATIME>1606980008588</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741837</BLOCK_ID>
        <NUM_BYTES>11</NUM_BYTES>
        <GENSTAMP>1014</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>87</TXID>
      <POOLNAME>pool1</POOLNAME>
      <OWNERNAME>root</OWNERNAME>
      <GROUPNAME>root</GROUPNAME>
      <MODE>493</MODE>
      <LIMIT>9223372036854775807</LIMIT>
      <MAXRELATIVEEXPIRY>2305843009213693951</MAXRELATIVEEXPIRY>
      <DEFAULTREPLICATION>1</DEFAULTREPLICATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>146</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MODIFY_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>88</TXID>
      <POOLNAME>pool1</POOLNAME>
      <LIMIT>99</LIMIT>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>147</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>89</TXID>
      <ID>1</ID>
      <PATH>/path</PATH>
      <REPLICATION>1</REPLICATION>
      <POOL>pool1</POOL>
      <EXPIRATION>2305844616193708630</EXPIRATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>148</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MODIFY_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>90</TXID>
      <ID>1</ID>
      <REPLICATION>2</REPLICATION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>149</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_CACHE_DIRECTIVE</OPCODE>
    <DATA>
      <TXID>91</TXID>
      <ID>1</ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>150</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_CACHE_POOL</OPCODE>
    <DATA>
      <TXID>92</TXID>
      <POOLNAME>pool1</POOLNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>151</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_ACL</OPCODE>
    <DATA>
      <TXID>93</TXID>
      <SRC>/file_concat_target</SRC>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>USER</TYPE>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>USER</TYPE>
        <NAME>user</NAME>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>GROUP</TYPE>
        <PERM>-w-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>MASK</TYPE>
        <PERM>rw-</PERM>
      </ENTRY>
      <ENTRY>
        <SCOPE>ACCESS</SCOPE>
        <TYPE>OTHER</TYPE>
        <PERM>---</PERM>
      </ENTRY>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>94</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a1</NAME>
        <VALUE>0x313233</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>153</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>95</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a2</NAME>
        <VALUE>0x373839</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>154</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_XATTR</OPCODE>
    <DATA>
      <TXID>96</TXID>
      <SRC>/file_concat_target</SRC>
      <XATTR>
        <NAMESPACE>USER</NAMESPACE>
        <NAME>a2</NAME>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>155</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>97</TXID>
      <CODEC>rs</CODEC>
      <DATAUNITS>3</DATAUNITS>
      <PARITYUNITS>2</PARITYUNITS>
      <CELLSIZE>8192</CELLSIZE>
      <EXTRAOPTIONS>0</EXTRAOPTIONS>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>156</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>98</TXID>
      <CODEC>rs</CODEC>
      <DATAUNITS>6</DATAUNITS>
      <PARITYUNITS>10</PARITYUNITS>
      <CELLSIZE>4096</CELLSIZE>
      <EXTRAOPTIONS>1</EXTRAOPTIONS>
      <EXTRAOPTION>
        <KEY>dummyKey</KEY>
        <VALUE>dummyValue</VALUE>
      </EXTRAOPTION>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>157</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>99</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>158</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>100</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>159</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>101</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>160</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_DISABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>102</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>161</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>103</TXID>
      <POLICYNAME>RS-3-2-8k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>162</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_REMOVE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>104</TXID>
      <POLICYNAME>RS-6-10-4k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>163</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_MKDIR</OPCODE>
    <DATA>
      <TXID>105</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16396</INODEID>
      <PATH>/ec</PATH>
      <TIMESTAMP>1606980014809</TIMESTAMP>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>493</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>106</TXID>
      <POLICYNAME>RS-3-2-1024k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>165</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ENABLE_ERASURE_CODING_POLICY</OPCODE>
    <DATA>
      <TXID>107</TXID>
      <POLICYNAME>RS-6-3-1024k</POLICYNAME>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>166</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_XATTR</OPCODE>
    <DATA>
      <TXID>108</TXID>
      <SRC>/ec</SRC>
      <XATTR>
        <NAMESPACE>SYSTEM</NAMESPACE>
        <NAME>hdfs.erasurecoding.policy</NAME>
        <VALUE>0x0000000c52532d362d332d313032346b</VALUE>
      </XATTR>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>167</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>109</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16397</INODEID>
      <PATH>/ec/replicated</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980014823</MTIME>
      <ATIME>1606980014823</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>0</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>168</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>110</TXID>
      <BLOCK_ID>1073741838</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>111</TXID>
      <GENSTAMPV2>1015</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>112</TXID>
      <PATH>/ec/replicated</PATH>
      <BLOCK>
        <BLOCK_ID>1073741838</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1015</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>113</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/ec/replicated</PATH>
      <REPLICATION>3</REPLICATION>
      <MTIME>1606980014863</MTIME>
      <ATIME>1606980014823</ATIME>
      <BLOCKSIZE>512</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>1073741838</BLOCK_ID>
        <NUM_BYTES>10</NUM_BYTES>
        <GENSTAMP>1015</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD</OPCODE>
    <DATA>
      <TXID>114</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>16398</INODEID>
      <PATH>/ec/RS-3-2</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980014865</MTIME>
      <ATIME>1606980014865</ATIME>
      <BLOCKSIZE>1048576</BLOCKSIZE>
      <CLIENT_NAME>DFSClient_NONMAPREDUCE_-27027137_1</CLIENT_NAME>
      <CLIENT_MACHINE>127.0.0.1</CLIENT_MACHINE>
      <OVERWRITE>true</OVERWRITE>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
      <ERASURE_CODING_POLICY_ID>2</ERASURE_CODING_POLICY_ID>
      <RPC_CLIENTID>3029c106-b28c-4e86-906b-db97759bfb03</RPC_CLIENTID>
      <RPC_CALLID>174</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ALLOCATE_BLOCK_ID</OPCODE>
    <DATA>
      <TXID>115</TXID>
      <BLOCK_ID>-9223372036854775792</BLOCK_ID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_SET_GENSTAMP_V2</OPCODE>
    <DATA>
      <TXID>116</TXID>
      <GENSTAMPV2>1016</GENSTAMPV2>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ADD_BLOCK</OPCODE>
    <DATA>
      <TXID>117</TXID>
      <PATH>/ec/RS-3-2</PATH>
      <BLOCK>
        <BLOCK_ID>-9223372036854775792</BLOCK_ID>
        <NUM_BYTES>0</NUM_BYTES>
        <GENSTAMP>1016</GENSTAMP>
      </BLOCK>
      <RPC_CLIENTID/>
      <RPC_CALLID>-2</RPC_CALLID>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_CLOSE</OPCODE>
    <DATA>
      <TXID>118</TXID>
      <LENGTH>0</LENGTH>
      <INODEID>0</INODEID>
      <PATH>/ec/RS-3-2</PATH>
      <REPLICATION>1</REPLICATION>
      <MTIME>1606980014944</MTIME>
      <ATIME>1606980014865</ATIME>
      <BLOCKSIZE>1048576</BLOCKSIZE>
      <CLIENT_NAME/>
      <CLIENT_MACHINE/>
      <OVERWRITE>false</OVERWRITE>
      <BLOCK>
        <BLOCK_ID>-9223372036854775792</BLOCK_ID>
        <NUM_BYTES>6</NUM_BYTES>
        <GENSTAMP>1016</GENSTAMP>
      </BLOCK>
      <PERMISSION_STATUS>
        <USERNAME>root</USERNAME>
        <GROUPNAME>supergroup</GROUPNAME>
        <MODE>420</MODE>
      </PERMISSION_STATUS>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ROLLING_UPGRADE_START</OPCODE>
    <DATA>
      <TXID>119</TXID>
      <STARTTIME>1606980014946</STARTTIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_ROLLING_UPGRADE_FINALIZE</OPCODE>
    <DATA>
      <TXID>120</TXID>
      <FINALIZETIME>1606980014946</FINALIZETIME>
    </DATA>
  </RECORD>
  <RECORD>
    <OPCODE>OP_END_LOG_SEGMENT</OPCODE>
    <DATA>
      <TXID>121</TXID>
    </DATA>
  </RECORD>
</EDITS>
2020-12-03 07:20:15,344 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:runOev(200)) - Running oev [/tmp/junit437526837032643078/editsParsed.xml] [/tmp/junit437526837032643078/editsParsed]
input  [/tmp/junit437526837032643078/editsParsed.xml]
output [/tmp/junit437526837032643078/editsParsed]
2020-12-03 07:20:15,437 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:runOev(200)) - Running oev [/tmp/junit437526837032643078/editsRecoveredParsed.XML] [/tmp/junit437526837032643078/editsParsed]
input  [/tmp/junit437526837032643078/editsRecoveredParsed.XML]
output [/tmp/junit437526837032643078/editsParsed]
2020-12-03 07:20:15,483 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:hasAllOpCodes(224)) - Statistics for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121
    VERSION                             : -65
    OP_ADD                         (  0): 10
    OP_RENAME_OLD                  (  1): 1
    OP_DELETE                      (  2): 1
    OP_MKDIR                       (  3): 2
    OP_SET_REPLICATION             (  4): 1
    OP_DATANODE_ADD                (  5): 0
    OP_DATANODE_REMOVE             (  6): 0
    OP_SET_PERMISSIONS             (  7): 1
    OP_SET_OWNER                   (  8): 1
    OP_CLOSE                       (  9): 11
    OP_SET_GENSTAMP_V1             ( 10): 0
    OP_SET_NS_QUOTA                ( 11): 0
    OP_CLEAR_NS_QUOTA              ( 12): 0
    OP_TIMES                       ( 13): 1
    OP_SET_QUOTA                   ( 14): 1
    OP_RENAME                      ( 15): 1
    OP_CONCAT_DELETE               ( 16): 1
    OP_SYMLINK                     ( 17): 1
    OP_GET_DELEGATION_TOKEN        ( 18): 0
    OP_RENEW_DELEGATION_TOKEN      ( 19): 0
    OP_CANCEL_DELEGATION_TOKEN     ( 20): 0
    OP_UPDATE_MASTER_KEY           ( 21): 2
    OP_REASSIGN_LEASE              ( 22): 2
    OP_END_LOG_SEGMENT             ( 23): 1
    OP_START_LOG_SEGMENT           ( 24): 1
    OP_UPDATE_BLOCKS               ( 25): 3
    OP_CREATE_SNAPSHOT             ( 26): 1
    OP_DELETE_SNAPSHOT             ( 27): 1
    OP_RENAME_SNAPSHOT             ( 28): 1
    OP_ALLOW_SNAPSHOT              ( 29): 2
    OP_DISALLOW_SNAPSHOT           ( 30): 1
    OP_SET_GENSTAMP_V2             ( 31): 16
    OP_ALLOCATE_BLOCK_ID           ( 32): 15
    OP_ADD_BLOCK                   ( 33): 15
    OP_ADD_CACHE_DIRECTIVE         ( 34): 1
    OP_REMOVE_CACHE_DIRECTIVE      ( 35): 1
    OP_ADD_CACHE_POOL              ( 36): 1
    OP_MODIFY_CACHE_POOL           ( 37): 1
    OP_REMOVE_CACHE_POOL           ( 38): 1
    OP_MODIFY_CACHE_DIRECTIVE      ( 39): 1
    OP_SET_ACL                     ( 40): 1
    OP_ROLLING_UPGRADE_START       ( 41): 1
    OP_ROLLING_UPGRADE_FINALIZE    ( 42): 1
    OP_SET_XATTR                   ( 43): 3
    OP_REMOVE_XATTR                ( 44): 1
    OP_SET_STORAGE_POLICY          ( 45): 1
    OP_TRUNCATE                    ( 46): 1
    OP_APPEND                      ( 47): 1
    OP_SET_QUOTA_BY_STORAGETYPE    ( 48): 1
    OP_ADD_ERASURE_CODING_POLICY   ( 49): 2
    OP_ENABLE_ERASURE_CODING_POLIC ( 50): 4
    OP_DISABLE_ERASURE_CODING_POLI ( 51): 2
    OP_REMOVE_ERASURE_CODING_POLIC ( 52): 2
    OP_INVALID                     ( -1): 0

2020-12-03 07:20:15,483 [Listener at localhost/39349] INFO  offlineEditsViewer.TestOfflineEditsViewer (TestOfflineEditsViewer.java:testGenerated(123)) - Comparing generated file /tmp/junit437526837032643078/editsParsed with reference file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000001-0000000000000000121
2020-12-03 07:20:15,487 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:15,488 [Listener at localhost/39349] ERROR hdfs.DFSClient (DFSClient.java:closeAllFilesBeingWritten(617)) - Failed to close file: /hard-lease-recovery-test with inode: 16395
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): Client (=DFSClient_NONMAPREDUCE_-27027137_1) is not the lease owner (=HDFS_NameNode-2020-12-03 07:20:12,637+0000: /hard-lease-recovery-test (inode 16395) Holder DFSClient_NONMAPREDUCE_-27027137_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2920)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalDatanode(FSNamesystem.java:2833)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getAdditionalDatanode(NameNodeRpcServer.java:927)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolServerSideTranslatorPB.java:598)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy26.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolTranslatorPB.java:541)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy27.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1362)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)
2020-12-03 07:20:15,489 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:20:15,492 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,492 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5a6d5a8f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,494 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-1d82fb96-4cde-4273-a6e6-7e34143f1695) exiting.
2020-12-03 07:20:15,494 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-af81443f-431f-4f34-9f17-1833c481c1ff) exiting.
2020-12-03 07:20:15,524 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5bb3d42d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:15,529 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5bf61e67{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:15,530 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50cf5a23{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:15,530 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6650813a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:15,533 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39349
2020-12-03 07:20:15,542 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:15,543 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:15,543 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid b1e39e00-460e-4c8e-b201-d285caec8622) service to localhost/127.0.0.1:33098
2020-12-03 07:20:15,543 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid b1e39e00-460e-4c8e-b201-d285caec8622)
2020-12-03 07:20:15,544 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:15,545 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,545 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:15,546 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,562 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:15,563 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:15,565 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:15,565 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:15,575 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:15,575 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:15,576 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60b85ba1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,576 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,578 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-37e269f7-e7c7-44d7-8db9-f11fe39b24a5) exiting.
2020-12-03 07:20:15,580 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-578bf417-795b-4e90-be0b-440362874bc0) exiting.
2020-12-03 07:20:15,686 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@126be319{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:15,688 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c44052e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:15,688 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57dc9128{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:15,688 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c65121{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:15,701 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43703
2020-12-03 07:20:15,722 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:15,733 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:15,734 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:15,736 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid cc8e4c36-62ec-479a-ae72-d04343254319) service to localhost/127.0.0.1:33098
2020-12-03 07:20:15,736 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid cc8e4c36-62ec-479a-ae72-d04343254319)
2020-12-03 07:20:15,736 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:15,737 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,737 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,755 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:15,755 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:15,757 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:15,757 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:15,762 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:15,762 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:15,762 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,763 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@61a5b4ae] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,765 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-33632ca0-fe6b-45e9-b5b8-44e8b85e911d) exiting.
2020-12-03 07:20:15,766 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-807930b3-4aec-47a8-bc9d-0a1b2e7d7a31) exiting.
2020-12-03 07:20:15,797 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b65e559{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:15,797 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@bae47a0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:15,798 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@271f18d3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:15,798 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e8e8651{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:15,799 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41841
2020-12-03 07:20:15,802 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:15,805 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:15,805 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9dc8304b-2a07-4b7b-9490-b4a0b87f3371) service to localhost/127.0.0.1:33098
2020-12-03 07:20:15,805 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9dc8304b-2a07-4b7b-9490-b4a0b87f3371)
2020-12-03 07:20:15,806 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:15,806 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:15,807 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,814 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,815 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:15,816 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:15,817 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:15,817 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:15,827 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:15,827 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:15,828 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,828 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@79f227a9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,834 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1f4afaa5-f8c9-4b2b-8bd3-4fd9353838cd) exiting.
2020-12-03 07:20:15,835 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-33781b5c-5591-4a46-8e6d-7dfaa2b21c1e) exiting.
2020-12-03 07:20:15,862 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22ee2d0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:15,863 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bfc3126{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:15,863 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a23a01d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:15,863 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@619bd14c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:15,865 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35028
2020-12-03 07:20:15,867 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:15,871 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:15,871 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:15,872 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid a650887a-9b41-4140-9ae1-784510c83ff1) service to localhost/127.0.0.1:33098
2020-12-03 07:20:15,872 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid a650887a-9b41-4140-9ae1-784510c83ff1)
2020-12-03 07:20:15,872 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:15,873 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,890 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:15,891 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:15,877 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,904 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:15,906 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:15,917 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:15,918 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:15,919 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51c929ae] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,919 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,922 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-12f2c4ba-e5cd-4b66-a2cb-4ff7a31a16d8) exiting.
2020-12-03 07:20:15,922 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ec340079-da43-481c-a95e-abcc97e4118b) exiting.
2020-12-03 07:20:15,945 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3abd581e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:15,946 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d4d8fcf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:15,946 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bc53649{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:15,947 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62c5bbdc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:15,948 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38270
2020-12-03 07:20:15,953 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:15,962 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:15,962 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:15,962 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9a3c9f46-217b-4c98-bf9c-976813f1b7b9) service to localhost/127.0.0.1:33098
2020-12-03 07:20:15,962 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 9a3c9f46-217b-4c98-bf9c-976813f1b7b9)
2020-12-03 07:20:15,962 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:15,964 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,970 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:15,974 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:15,974 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:15,977 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:15,978 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:15,985 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:15,985 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:15,985 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:15,985 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72bca894] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:15,989 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7e31da9a-b648-400c-8c71-42d17a340159) exiting.
2020-12-03 07:20:15,989 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6f70488d-39ce-4760-b3d9-a1b077305b19) exiting.
2020-12-03 07:20:16,012 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d8f2f3a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:16,013 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2024293c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:16,013 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37d3d232{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:16,014 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27f9e982{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:16,015 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34739
2020-12-03 07:20:16,021 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:16,021 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:16,022 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:16,022 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid f95bd9c1-4095-403f-92ec-d83341a43aa4) service to localhost/127.0.0.1:33098
2020-12-03 07:20:16,022 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid f95bd9c1-4095-403f-92ec-d83341a43aa4)
2020-12-03 07:20:16,022 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:16,028 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,042 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,043 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:16,043 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:16,048 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:16,049 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:16,059 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:16,059 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:16,060 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1734f68] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:16,060 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:16,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0d1771e0-6db7-4d6e-85dc-25ee851bfca0) exiting.
2020-12-03 07:20:16,067 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-fb58d30a-f7d7-4e26-afee-3f36329431e6) exiting.
2020-12-03 07:20:16,091 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5528a42c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:16,092 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:16,092 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:16,093 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:16,095 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39316
2020-12-03 07:20:16,096 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:16,106 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:16,107 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:16,107 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 616457bc-d176-436d-bb41-d2849860b9d8) service to localhost/127.0.0.1:33098
2020-12-03 07:20:16,107 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 616457bc-d176-436d-bb41-d2849860b9d8)
2020-12-03 07:20:16,107 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:16,108 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,109 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,128 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:16,128 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:16,133 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:16,133 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:16,142 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:16,143 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:16,143 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:16,143 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@62da83ed] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:16,148 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-2e30838d-7764-49bf-b5c7-a52b506c028a) exiting.
2020-12-03 07:20:16,148 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-65a75d84-3884-416a-83cc-f8b08b3cba00) exiting.
2020-12-03 07:20:16,177 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@285f09de{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:16,178 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73393584{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:16,179 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15bcf458{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:16,181 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@408b35bf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:16,188 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39214
2020-12-03 07:20:16,190 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:16,191 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:16,204 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:16,204 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 2757df4b-cdad-4ac8-86e5-272ebf780937) service to localhost/127.0.0.1:33098
2020-12-03 07:20:16,204 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 2757df4b-cdad-4ac8-86e5-272ebf780937)
2020-12-03 07:20:16,205 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:16,212 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,216 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,231 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:16,232 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:16,239 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:16,239 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:16,246 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:16,246 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:16,248 [Listener at localhost/39349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:16,248 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7a48e6e2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:16,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e52750fc-8712-4097-9015-944b7016457b) exiting.
2020-12-03 07:20:16,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f2abdf7a-7257-4635-8ee2-18dbb331e383) exiting.
2020-12-03 07:20:16,294 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fcbe147{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:16,296 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:16,296 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:16,297 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:16,303 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33311
2020-12-03 07:20:16,304 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:16,315 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:16,315 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:16,316 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 7bdcb99b-2669-49d1-afd1-dc64cb1dab30) service to localhost/127.0.0.1:33098
2020-12-03 07:20:16,316 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-877205389-172.17.0.11-1606980001210 (Datanode Uuid 7bdcb99b-2669-49d1-afd1-dc64cb1dab30)
2020-12-03 07:20:16,316 [BP-877205389-172.17.0.11-1606980001210 heartbeating to localhost/127.0.0.1:33098] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-877205389-172.17.0.11-1606980001210
2020-12-03 07:20:16,316 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,317 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-877205389-172.17.0.11-1606980001210] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:16,335 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:16,335 [Listener at localhost/39349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:16,343 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:16,343 [Listener at localhost/39349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:16,355 [Listener at localhost/39349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:16,356 [Listener at localhost/39349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:16,356 [Listener at localhost/39349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:16,356 [Thread[Thread-30,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-12-03 07:20:16,357 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 122, 122
2020-12-03 07:20:16,364 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@f0e995e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:16,364 [Listener at localhost/39349] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:20:16,365 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@24d4d7c9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:16,371 [Listener at localhost/39349] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_inprogress_0000000000000000122 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/xWDEkkWLx4/TestOfflineEditsViewer/dfs/name/current/edits_0000000000000000122-0000000000000000123
2020-12-03 07:20:16,376 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:16,377 [CacheReplicationMonitor(1169040953)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:16,406 [Listener at localhost/39349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33098
2020-12-03 07:20:16,419 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:16,428 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:16,429 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:16,432 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:16,485 [Listener at localhost/39349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:16,485 [Listener at localhost/39349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:16,487 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d43661b{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:16,491 [Listener at localhost/39349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2660a7da{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:16,491 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12591ac8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:16,492 [Listener at localhost/39349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d2de489{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:16,497 [Listener at localhost/39349] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:16,544 [Listener at localhost/39349] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:16,545 [Listener at localhost/39349] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
