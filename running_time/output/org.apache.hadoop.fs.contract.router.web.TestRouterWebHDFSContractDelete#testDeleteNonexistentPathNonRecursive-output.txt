2020-12-03 07:22:53,077 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:22:53,129 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:22:53,130 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:22:54,030 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:54,048 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:54,050 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:54,050 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:54,059 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:54,059 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:54,060 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:54,065 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:54,065 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:54,137 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:54,150 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:54,153 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:54,154 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:54,179 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:54,181 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:54
2020-12-03 07:22:54,185 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:54,186 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,189 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:54,190 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:54,216 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:54,217 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:54,229 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:54,230 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:54,230 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:54,231 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:54,232 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:54,233 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:54,233 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:54,233 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:54,233 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:54,234 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:54,234 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:54,300 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:54,300 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,300 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,301 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,324 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:54,324 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,325 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:54,325 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:54,332 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:54,332 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:54,332 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:54,336 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:54,346 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:54,354 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:54,360 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:54,361 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,361 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:54,361 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:54,377 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:54,378 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:54,378 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:54,388 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:54,388 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:54,393 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:54,393 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,394 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:54,394 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:54,465 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:22:54,665 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:54,848 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:55,036 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:22:55,072 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:55,072 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:55,214 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:55,214 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:55,382 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:55,514 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:22:55,558 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:22:55,569 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:55,839 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:22:55,931 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:22:55,931 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:55,939 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:55,940 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:22:55,983 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72ade7e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:55,999 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:56,020 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4418ms
2020-12-03 07:22:56,184 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,188 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:56,201 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,203 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:56,203 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,204 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,234 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:56,234 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:56,244 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44248
2020-12-03 07:22:56,246 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,294 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60129b9a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:56,295 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@492691d7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:56,625 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@512535ff{/,file:///tmp/jetty-localhost-44248-hdfs-_-any-186402822027361817.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:56,634 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4be9529d{HTTP/1.1,[http/1.1]}{localhost:44248}
2020-12-03 07:22:56,636 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5034ms
2020-12-03 07:22:56,647 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:56,648 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:56,648 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:56,648 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:56,649 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:56,649 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:56,649 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:56,650 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:56,650 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:56,651 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,652 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:56,652 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:56,653 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:56,653 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:56
2020-12-03 07:22:56,653 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:56,654 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,654 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:56,654 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:56,659 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:56,660 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:56,660 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:56,661 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:56,661 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:56,661 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:56,662 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:56,662 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:56,662 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:56,662 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:56,662 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:56,663 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:56,663 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:56,665 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:56,665 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,665 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:56,666 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:56,668 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:56,668 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:56,669 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:56,669 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:56,669 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:56,670 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:56,670 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:56,670 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,671 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:56,671 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:56,675 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:56,676 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:56,676 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:56,676 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:56,677 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:56,677 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:56,677 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,678 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:56,678 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:56,722 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:56,756 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:56,757 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:22:56,761 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:56,762 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:56,799 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:56,810 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:56,810 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:56,818 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:56,819 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:56,819 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 138 msecs
2020-12-03 07:22:57,039 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:57,081 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,096 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,359 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:57,381 [Listener at 0.0.0.0/33986] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:57,395 [Listener at 0.0.0.0/33986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:57,396 [Listener at 0.0.0.0/33986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:57,396 [Listener at 0.0.0.0/33986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:57,438 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,438 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,443 [Listener at 0.0.0.0/33986] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33986
2020-12-03 07:22:57,446 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:57,449 [Listener at 0.0.0.0/33986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:57,449 [Listener at 0.0.0.0/33986] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:57,449 [Listener at 0.0.0.0/33986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:57,450 [Listener at 0.0.0.0/33986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:57,454 [Listener at 0.0.0.0/33986] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:57,455 [Listener at 0.0.0.0/33986] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:57,455 [Listener at 0.0.0.0/33986] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:57,456 [Listener at 0.0.0.0/33986] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:22:57,466 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29ad44e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,466 [Listener at 0.0.0.0/33986] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:57,469 [Listener at 0.0.0.0/33986] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,469 [Listener at 0.0.0.0/33986] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:57,472 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,473 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:57,473 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,473 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,476 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:57,477 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:57,478 [Listener at 0.0.0.0/33986] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44990
2020-12-03 07:22:57,478 [Listener at 0.0.0.0/33986] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,481 [Listener at 0.0.0.0/33986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@649f2009{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:57,481 [Listener at 0.0.0.0/33986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69adf72c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:57,670 [Listener at 0.0.0.0/33986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e11bc55{/,file:///tmp/jetty-localhost-44990-hdfs-_-any-675202225525764133.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:57,672 [Listener at 0.0.0.0/33986] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7544a1e4{HTTP/1.1,[http/1.1]}{localhost:44990}
2020-12-03 07:22:57,673 [Listener at 0.0.0.0/33986] INFO  server.Server (Server.java:doStart(419)) - Started @6071ms
2020-12-03 07:22:57,683 [Listener at 0.0.0.0/33986] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:57,683 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:57,683 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:57,683 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:57,684 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:57,684 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:57,684 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:57,684 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:57,685 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:57,685 [Listener at 0.0.0.0/33986] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,686 [Listener at 0.0.0.0/33986] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:57,686 [Listener at 0.0.0.0/33986] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:57,686 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:57,687 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:57
2020-12-03 07:22:57,687 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:57,687 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,687 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:57,687 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:57,699 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:57,700 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:57,700 [Listener at 0.0.0.0/33986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:57,700 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:57,701 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:57,702 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:57,702 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:57,702 [Listener at 0.0.0.0/33986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:57,702 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:57,703 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,703 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:57,703 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:57,710 [Listener at 0.0.0.0/33986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:57,710 [Listener at 0.0.0.0/33986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:57,710 [Listener at 0.0.0.0/33986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:57,710 [Listener at 0.0.0.0/33986] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:57,711 [Listener at 0.0.0.0/33986] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:57,711 [Listener at 0.0.0.0/33986] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:57,711 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:57,712 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,712 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:57,713 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:57,715 [Listener at 0.0.0.0/33986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:57,715 [Listener at 0.0.0.0/33986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:57,715 [Listener at 0.0.0.0/33986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:57,716 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:57,716 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:57,716 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:57,716 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,717 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:57,717 [Listener at 0.0.0.0/33986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:57,803 [Listener at 0.0.0.0/33986] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:57,904 [Listener at 0.0.0.0/33986] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:57,905 [Listener at 0.0.0.0/33986] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:22:57,909 [Listener at 0.0.0.0/33986] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:57,910 [Listener at 0.0.0.0/33986] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:57,912 [Listener at 0.0.0.0/33986] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:57,915 [Listener at 0.0.0.0/33986] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:57,915 [Listener at 0.0.0.0/33986] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:22:57,916 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:57,916 [Listener at 0.0.0.0/33986] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:57,916 [Listener at 0.0.0.0/33986] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 198 msecs
2020-12-03 07:22:57,917 [Listener at 0.0.0.0/33986] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:57,918 [Listener at 0.0.0.0/33986] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,920 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,937 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:57,991 [Listener at 0.0.0.0/38067] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:57,994 [Listener at 0.0.0.0/38067] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:57,995 [Listener at 0.0.0.0/38067] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:57,995 [Listener at 0.0.0.0/38067] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:58,004 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:58,004 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:58,008 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38067
2020-12-03 07:22:58,008 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:58,009 [Listener at 0.0.0.0/38067] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:58,009 [Listener at 0.0.0.0/38067] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:58,009 [Listener at 0.0.0.0/38067] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:58,009 [Listener at 0.0.0.0/38067] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:22:58,017 [Listener at 0.0.0.0/38067] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:58,018 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:58,018 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:58,019 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:58,019 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:58,019 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:58,019 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:58,020 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:58,020 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:58,020 [Listener at 0.0.0.0/38067] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,021 [Listener at 0.0.0.0/38067] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:58,021 [Listener at 0.0.0.0/38067] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:58,022 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:58,022 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:58
2020-12-03 07:22:58,022 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:58,022 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:58,023 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:58,023 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:58,035 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:58,035 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:58,036 [Listener at 0.0.0.0/38067] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:58,036 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:58,036 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:58,037 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:58,038 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:58,038 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:58,038 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:58,039 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:58,039 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:58,045 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:58,045 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:58,045 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:58,045 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:58,046 [Listener at 0.0.0.0/38067] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:58,046 [Listener at 0.0.0.0/38067] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:58,046 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:58,046 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:58,046 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:58,047 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:58,049 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:58,050 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:58,050 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:58,050 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:58,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:22:58,253 [Listener at 0.0.0.0/38067] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:22:58,455 [Listener at 0.0.0.0/38067] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:22:58,695 [Listener at 0.0.0.0/38067] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:22:58,706 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:58,708 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:58,713 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 395 bytes saved in 0 seconds .
2020-12-03 07:22:58,714 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 395 bytes saved in 0 seconds .
2020-12-03 07:22:58,820 [Listener at 0.0.0.0/38067] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:58,823 [Listener at 0.0.0.0/38067] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:22:58,827 [Listener at 0.0.0.0/38067] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:22:58,831 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:58,832 [Listener at 0.0.0.0/38067] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:58,832 [Listener at 0.0.0.0/38067] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:58,832 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:58,839 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a551a63] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:58,839 [Listener at 0.0.0.0/38067] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:58,841 [Listener at 0.0.0.0/38067] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:58,841 [Listener at 0.0.0.0/38067] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:58,844 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:58,844 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:58,845 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:58,845 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:58,847 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:58,847 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:58,847 [Listener at 0.0.0.0/38067] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33765
2020-12-03 07:22:58,847 [Listener at 0.0.0.0/38067] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:58,850 [Listener at 0.0.0.0/38067] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29539e36{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:58,851 [Listener at 0.0.0.0/38067] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f5c79a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:59,046 [Listener at 0.0.0.0/38067] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30c0ccff{/,file:///tmp/jetty-localhost-33765-hdfs-_-any-8263826758494609032.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:59,048 [Listener at 0.0.0.0/38067] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@581d969c{HTTP/1.1,[http/1.1]}{localhost:33765}
2020-12-03 07:22:59,048 [Listener at 0.0.0.0/38067] INFO  server.Server (Server.java:doStart(419)) - Started @7447ms
2020-12-03 07:22:59,052 [Listener at 0.0.0.0/38067] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:59,053 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:59,054 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:59,054 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:59,054 [Listener at 0.0.0.0/38067] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,055 [Listener at 0.0.0.0/38067] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:59,055 [Listener at 0.0.0.0/38067] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:59,055 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:59,056 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:59
2020-12-03 07:22:59,056 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:59,056 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,056 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:59,057 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:59,068 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:59,069 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:59,069 [Listener at 0.0.0.0/38067] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:59,070 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:59,071 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:59,071 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:59,071 [Listener at 0.0.0.0/38067] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:59,071 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:59,071 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,072 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:59,072 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:59,078 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:59,078 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:59,078 [Listener at 0.0.0.0/38067] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:59,078 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:59,078 [Listener at 0.0.0.0/38067] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:59,079 [Listener at 0.0.0.0/38067] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:59,079 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:59,079 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,079 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:59,079 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:59,081 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:59,081 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:59,081 [Listener at 0.0.0.0/38067] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:59,082 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:59,082 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:59,082 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:59,082 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,082 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:59,083 [Listener at 0.0.0.0/38067] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:59,182 [Listener at 0.0.0.0/38067] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:59,323 [Listener at 0.0.0.0/38067] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:59,324 [Listener at 0.0.0.0/38067] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:22:59,328 [Listener at 0.0.0.0/38067] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:59,328 [Listener at 0.0.0.0/38067] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:59,332 [Listener at 0.0.0.0/38067] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:59,333 [Listener at 0.0.0.0/38067] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:59,333 [Listener at 0.0.0.0/38067] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:22:59,334 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:59,334 [Listener at 0.0.0.0/38067] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:59,334 [Listener at 0.0.0.0/38067] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 250 msecs
2020-12-03 07:22:59,334 [Listener at 0.0.0.0/38067] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:59,335 [Listener at 0.0.0.0/38067] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,336 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,342 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:59,361 [Listener at 0.0.0.0/37541] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:59,362 [Listener at 0.0.0.0/37541] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:59,363 [Listener at 0.0.0.0/37541] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:59,363 [Listener at 0.0.0.0/37541] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:59,369 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,369 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,372 [Listener at 0.0.0.0/37541] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37541
2020-12-03 07:22:59,372 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:59,372 [Listener at 0.0.0.0/37541] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:59,372 [Listener at 0.0.0.0/37541] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:59,373 [Listener at 0.0.0.0/37541] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:59,373 [Listener at 0.0.0.0/37541] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:59,376 [Listener at 0.0.0.0/37541] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:59,376 [Listener at 0.0.0.0/37541] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:59,377 [Listener at 0.0.0.0/37541] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:59,377 [Listener at 0.0.0.0/37541] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:59,384 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cfd1875] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,384 [Listener at 0.0.0.0/37541] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:59,386 [Listener at 0.0.0.0/37541] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,387 [Listener at 0.0.0.0/37541] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:59,389 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,390 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:59,391 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,391 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,393 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:59,393 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:59,393 [Listener at 0.0.0.0/37541] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45508
2020-12-03 07:22:59,393 [Listener at 0.0.0.0/37541] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,397 [Listener at 0.0.0.0/37541] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68ed96ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:59,398 [Listener at 0.0.0.0/37541] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3228d990{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:59,583 [Listener at 0.0.0.0/37541] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33c2bd{/,file:///tmp/jetty-localhost-45508-hdfs-_-any-1917454018001481611.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:59,584 [Listener at 0.0.0.0/37541] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1dfd5f51{HTTP/1.1,[http/1.1]}{localhost:45508}
2020-12-03 07:22:59,584 [Listener at 0.0.0.0/37541] INFO  server.Server (Server.java:doStart(419)) - Started @7982ms
2020-12-03 07:22:59,587 [Listener at 0.0.0.0/37541] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:59,595 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:59,595 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:59,596 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:59,596 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:59,596 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:59,597 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:59,597 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:59,598 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:59,598 [Listener at 0.0.0.0/37541] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,599 [Listener at 0.0.0.0/37541] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:59,599 [Listener at 0.0.0.0/37541] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:59,600 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:59,600 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:59
2020-12-03 07:22:59,601 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:59,601 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,601 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:59,601 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:59,614 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:59,614 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:59,614 [Listener at 0.0.0.0/37541] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:59,615 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:59,616 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:59,616 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:59,616 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:59,616 [Listener at 0.0.0.0/37541] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:59,616 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:59,617 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,617 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:59,617 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:59,623 [Listener at 0.0.0.0/37541] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:59,624 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:59,625 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,625 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:59,625 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:59,627 [Listener at 0.0.0.0/37541] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:59,627 [Listener at 0.0.0.0/37541] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:59,627 [Listener at 0.0.0.0/37541] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:59,627 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:59,628 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:59,628 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:59,628 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:59,628 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:59,628 [Listener at 0.0.0.0/37541] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:59,690 [Listener at 0.0.0.0/37541] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:59,830 [Listener at 0.0.0.0/37541] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:22:59,831 [Listener at 0.0.0.0/37541] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:22:59,835 [Listener at 0.0.0.0/37541] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:59,835 [Listener at 0.0.0.0/37541] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:59,837 [Listener at 0.0.0.0/37541] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:59,838 [Listener at 0.0.0.0/37541] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:59,838 [Listener at 0.0.0.0/37541] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:22:59,839 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:59,839 [Listener at 0.0.0.0/37541] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:59,839 [Listener at 0.0.0.0/37541] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 209 msecs
2020-12-03 07:22:59,839 [Listener at 0.0.0.0/37541] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:59,840 [Listener at 0.0.0.0/37541] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:00,000 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:00,016 [Listener at 0.0.0.0/44894] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:00,043 [Listener at 0.0.0.0/44894] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:00,045 [Listener at 0.0.0.0/44894] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:00,045 [Listener at 0.0.0.0/44894] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:00,045 [Listener at 0.0.0.0/44894] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:00,052 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:00,052 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:00,055 [Listener at 0.0.0.0/44894] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44894
2020-12-03 07:23:00,056 [Listener at 0.0.0.0/44894] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:00,056 [Listener at 0.0.0.0/44894] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:00,056 [Listener at 0.0.0.0/44894] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:00,056 [Listener at 0.0.0.0/44894] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:00,057 [Listener at 0.0.0.0/44894] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:00,070 [Listener at 0.0.0.0/44894] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:00,103 [Listener at 0.0.0.0/44894] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:00,120 [Listener at 0.0.0.0/44894] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:00,136 [Listener at 0.0.0.0/44894] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:00,143 [Listener at 0.0.0.0/44894] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:00,148 [Listener at 0.0.0.0/44894] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:00,154 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:00,156 [Listener at 0.0.0.0/44894] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:00,162 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:00,172 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35706
2020-12-03 07:23:00,176 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:00,176 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:00,201 [Listener at 0.0.0.0/44894] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:00,201 [Listener at 0.0.0.0/44894] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:00,204 [Listener at 0.0.0.0/44894] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:00,204 [Listener at 0.0.0.0/44894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:00,204 [Listener at 0.0.0.0/44894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:00,205 [Listener at 0.0.0.0/44894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:00,217 [Listener at 0.0.0.0/44894] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37590
2020-12-03 07:23:00,218 [Listener at 0.0.0.0/44894] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:00,221 [Listener at 0.0.0.0/44894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73e132e0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:00,221 [Listener at 0.0.0.0/44894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:00,551 [Listener at 0.0.0.0/44894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6c2f1700{/,file:///tmp/jetty-localhost-37590-datanode-_-any-2169925567670884961.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:00,553 [Listener at 0.0.0.0/44894] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@350b3a17{HTTP/1.1,[http/1.1]}{localhost:37590}
2020-12-03 07:23:00,554 [Listener at 0.0.0.0/44894] INFO  server.Server (Server.java:doStart(419)) - Started @8952ms
2020-12-03 07:23:01,084 [Listener at 0.0.0.0/44894] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43400
2020-12-03 07:23:01,085 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f12e153] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:01,087 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:01,087 [Listener at 0.0.0.0/44894] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:01,112 [Listener at 0.0.0.0/44894] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:01,113 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:01,124 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42839
2020-12-03 07:23:01,148 [Listener at localhost/42839] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:01,151 [Listener at localhost/42839] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:01,165 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33986 starting to offer service
2020-12-03 07:23:01,167 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38067 starting to offer service
2020-12-03 07:23:01,167 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37541 starting to offer service
2020-12-03 07:23:01,173 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44894 starting to offer service
2020-12-03 07:23:01,180 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:01,181 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:01,185 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:01,186 [Listener at localhost/42839] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:01,187 [Listener at localhost/42839] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:01,193 [Listener at localhost/42839] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:01,194 [Listener at localhost/42839] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,194 [Listener at localhost/42839] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:01,195 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:01,195 [Listener at localhost/42839] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,196 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:01,202 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42030
2020-12-03 07:23:01,203 [Listener at localhost/42839] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:01,203 [Listener at localhost/42839] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:01,207 [Listener at localhost/42839] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:01,214 [Listener at localhost/42839] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:01,217 [Listener at localhost/42839] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:01,219 [Listener at localhost/42839] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:01,219 [Listener at localhost/42839] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:01,219 [Listener at localhost/42839] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:01,220 [Listener at localhost/42839] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34465
2020-12-03 07:23:01,220 [Listener at localhost/42839] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:01,233 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:01,237 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:01,470 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cbb84b1{/,file:///tmp/jetty-localhost-34465-datanode-_-any-4863147897311979727.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:01,472 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:34465}
2020-12-03 07:23:01,472 [Listener at localhost/42839] INFO  server.Server (Server.java:doStart(419)) - Started @9870ms
2020-12-03 07:23:01,590 [Listener at localhost/42839] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37293
2020-12-03 07:23:01,591 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5183d589] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:01,591 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:01,591 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:01,592 [Thread-158] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:01,592 [Listener at localhost/42839] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:01,593 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:01,597 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40286
2020-12-03 07:23:01,602 [Listener at localhost/40286] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:01,602 [Listener at localhost/40286] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:01,603 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33986 starting to offer service
2020-12-03 07:23:01,604 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38067 starting to offer service
2020-12-03 07:23:01,604 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37541 starting to offer service
2020-12-03 07:23:01,605 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44894 starting to offer service
2020-12-03 07:23:01,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:01,607 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:01,615 [Thread-185] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:01,619 [Listener at localhost/40286] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:01,621 [Listener at localhost/40286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:01,621 [Thread-158] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:01,621 [Listener at localhost/40286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:01,622 [Thread-158] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:01,623 [Listener at localhost/40286] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:01,624 [Thread-158] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:23:01,625 [Listener at localhost/40286] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,625 [Listener at localhost/40286] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:01,626 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:01,626 [Listener at localhost/40286] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,626 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:01,627 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44110
2020-12-03 07:23:01,627 [Listener at localhost/40286] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:01,627 [Listener at localhost/40286] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:01,631 [Listener at localhost/40286] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:01,631 [Listener at localhost/40286] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:01,633 [Listener at localhost/40286] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:01,634 [Listener at localhost/40286] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:01,634 [Listener at localhost/40286] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:01,634 [Listener at localhost/40286] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:01,635 [Listener at localhost/40286] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33429
2020-12-03 07:23:01,635 [Listener at localhost/40286] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:01,637 [Listener at localhost/40286] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:01,637 [Listener at localhost/40286] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:01,655 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:01,655 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 318819230. Formatting...
2020-12-03 07:23:01,656 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:23:01,800 [Thread-158] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:01,800 [Thread-158] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:01,801 [Thread-158] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:23:01,812 [Listener at localhost/40286] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69cac930{/,file:///tmp/jetty-localhost-33429-datanode-_-any-8538479720204071279.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:01,813 [Listener at localhost/40286] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:33429}
2020-12-03 07:23:01,814 [Listener at localhost/40286] INFO  server.Server (Server.java:doStart(419)) - Started @10212ms
2020-12-03 07:23:01,842 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:01,843 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 318819230. Formatting...
2020-12-03 07:23:01,843 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-37937d60-da85-4710-a676-a9dd1f3a21cf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:23:01,852 [Listener at localhost/40286] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43776
2020-12-03 07:23:01,852 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:01,852 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ad6fa53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:01,853 [Listener at localhost/40286] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:01,853 [Listener at localhost/40286] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:01,854 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:01,858 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45511
2020-12-03 07:23:01,863 [Listener at localhost/45511] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:01,864 [Listener at localhost/45511] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:01,865 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33986 starting to offer service
2020-12-03 07:23:01,866 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38067 starting to offer service
2020-12-03 07:23:01,866 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37541 starting to offer service
2020-12-03 07:23:01,867 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44894 starting to offer service
2020-12-03 07:23:01,868 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:01,869 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:01,875 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:01,876 [Listener at localhost/45511] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:01,877 [Listener at localhost/45511] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:01,878 [Listener at localhost/45511] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:01,879 [Listener at localhost/45511] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:01,880 [Listener at localhost/45511] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,880 [Listener at localhost/45511] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:01,881 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:01,881 [Listener at localhost/45511] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,882 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:01,882 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37512
2020-12-03 07:23:01,882 [Listener at localhost/45511] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:01,883 [Listener at localhost/45511] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:01,885 [Listener at localhost/45511] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:01,886 [Listener at localhost/45511] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:01,888 [Listener at localhost/45511] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:01,888 [Listener at localhost/45511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:01,889 [Listener at localhost/45511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:01,889 [Listener at localhost/45511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:01,890 [Listener at localhost/45511] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35605
2020-12-03 07:23:01,890 [Listener at localhost/45511] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:01,892 [Listener at localhost/45511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f9b5552{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:01,893 [Listener at localhost/45511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d2d99fc{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:01,933 [Thread-212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:01,934 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:01,934 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:23:01,950 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:01,951 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:01,951 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:01,951 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:01,972 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:01,972 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:01,972 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:01,972 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,075 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,075 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,076 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,076 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,076 [Listener at localhost/45511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5486887b{/,file:///tmp/jetty-localhost-35605-datanode-_-any-5415235991065185369.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:02,078 [Listener at localhost/45511] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5226e402{HTTP/1.1,[http/1.1]}{localhost:35605}
2020-12-03 07:23:02,078 [Listener at localhost/45511] INFO  server.Server (Server.java:doStart(419)) - Started @10476ms
2020-12-03 07:23:02,121 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,122 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,122 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,122 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,124 [Thread-212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:02,125 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:02,126 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-939a6047-89b2-442b-9fb8-2090ffa647b2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:23:02,133 [Listener at localhost/45511] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33475
2020-12-03 07:23:02,133 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:02,133 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@189b5fb1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:02,133 [Listener at localhost/45511] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:02,134 [Listener at localhost/45511] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:02,135 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:02,138 [Listener at localhost/37367] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37367
2020-12-03 07:23:02,144 [Listener at localhost/37367] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:02,145 [Listener at localhost/37367] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:02,146 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33986 starting to offer service
2020-12-03 07:23:02,146 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38067 starting to offer service
2020-12-03 07:23:02,148 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37541 starting to offer service
2020-12-03 07:23:02,148 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44894 starting to offer service
2020-12-03 07:23:02,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:02,152 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:02,160 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,182 [Thread-157] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,182 [Thread-158] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1176993;bpid=BP-153778976-172.17.0.11-1606980178053;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1176993;c=1606980178053;bpid=BP-153778976-172.17.0.11-1606980178053;dnuuid=null
2020-12-03 07:23:02,183 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:23:02,183 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:23:02,199 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,200 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,200 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,200 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,214 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:02,215 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:02,215 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:23:02,261 [Thread-185] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=318819230;bpid=BP-1997458851-172.17.0.11-1606980174443;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=318819230;c=1606980174443;bpid=BP-1997458851-172.17.0.11-1606980174443;dnuuid=null
2020-12-03 07:23:02,262 [Thread-187] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,262 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:23:02,262 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:23:02,283 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,284 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,284 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,285 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,292 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,292 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,292 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,292 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,349 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,350 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,350 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,350 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,423 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,424 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,424 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,424 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,437 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7833@82ba21544e84
2020-12-03 07:23:02,438 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1176993. Formatting...
2020-12-03 07:23:02,439 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:23:02,450 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,451 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,451 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,451 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,473 [Thread-157] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=318819230;bpid=BP-1997458851-172.17.0.11-1606980174443;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=318819230;c=1606980174443;bpid=BP-1997458851-172.17.0.11-1606980174443;dnuuid=null
2020-12-03 07:23:02,551 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1176993;bpid=BP-153778976-172.17.0.11-1606980178053;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1176993;c=1606980178053;bpid=BP-153778976-172.17.0.11-1606980178053;dnuuid=null
2020-12-03 07:23:02,582 [Thread-187] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1176993;bpid=BP-153778976-172.17.0.11-1606980178053;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1176993;c=1606980178053;bpid=BP-153778976-172.17.0.11-1606980178053;dnuuid=null
2020-12-03 07:23:02,593 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,593 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,593 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,593 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,624 [Thread-157] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:02,715 [IPC Server handler 3 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,723 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,723 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,733 [Thread-212] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:02,734 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,735 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:23:02,735 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:23:02,750 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,751 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,751 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,751 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,758 [Thread-185] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:02,761 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb
2020-12-03 07:23:02,762 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b874ad0a-3825-43ef-9ab5-3cbe67256437
2020-12-03 07:23:02,762 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:02,762 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:02,764 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-37937d60-da85-4710-a676-a9dd1f3a21cf
2020-12-03 07:23:02,765 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:02,766 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46
2020-12-03 07:23:02,767 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:02,772 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:02,772 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:02,773 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,773 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,773 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-153778976-172.17.0.11-1606980178053 is not formatted. Formatting ...
2020-12-03 07:23:02,774 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-153778976-172.17.0.11-1606980178053 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-153778976-172.17.0.11-1606980178053/current
2020-12-03 07:23:02,780 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,781 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,782 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:02,782 [Thread-158] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,783 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:02,783 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:02,794 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,794 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:02,795 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,797 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,797 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:02,797 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,798 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:02,798 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,798 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,799 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,799 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,799 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,799 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:02,799 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:02,827 [IPC Server handler 4 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,828 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,828 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,835 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 51ms
2020-12-03 07:23:02,835 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 35ms
2020-12-03 07:23:02,835 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 36ms
2020-12-03 07:23:02,836 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-153778976-172.17.0.11-1606980178053: 37ms
2020-12-03 07:23:02,836 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 52ms
2020-12-03 07:23:02,836 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-153778976-172.17.0.11-1606980178053: 53ms
2020-12-03 07:23:02,838 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:02,838 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:02,838 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:02,838 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:02,838 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:02,838 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:02,838 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:02,838 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:02,839 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:02,839 [Thread-268] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:02,840 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:02,840 [Thread-270] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:02,848 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 8ms
2020-12-03 07:23:02,852 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 13ms
2020-12-03 07:23:02,856 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 19ms
2020-12-03 07:23:02,857 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-153778976-172.17.0.11-1606980178053: 19ms
2020-12-03 07:23:02,859 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 20ms
2020-12-03 07:23:02,861 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-153778976-172.17.0.11-1606980178053: 24ms
2020-12-03 07:23:02,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,867 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:02,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:02,866 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,868 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,868 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-37937d60-da85-4710-a676-a9dd1f3a21cf): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,868 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b874ad0a-3825-43ef-9ab5-3cbe67256437): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,868 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:02,882 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 44ms
2020-12-03 07:23:02,883 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 44ms
2020-12-03 07:23:02,883 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 45ms
2020-12-03 07:23:02,883 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1997458851-172.17.0.11-1606980174443: 46ms
2020-12-03 07:23:02,885 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:02,885 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:02,886 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:02,886 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:02,886 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:23:02,886 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:02,886 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443: 2ms
2020-12-03 07:23:02,886 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 48ms
2020-12-03 07:23:02,898 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1997458851-172.17.0.11-1606980174443: 60ms
2020-12-03 07:23:02,899 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:02,899 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:02,899 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:02,899 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:02,899 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:02,900 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:23:02,900 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:23:02,900 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:23:02,900 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b874ad0a-3825-43ef-9ab5-3cbe67256437): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,899 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:23:02,901 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443: 2ms
2020-12-03 07:23:02,901 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:02,900 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:02,901 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,901 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b874ad0a-3825-43ef-9ab5-3cbe67256437): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-37937d60-da85-4710-a676-a9dd1f3a21cf): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:23:02,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-37937d60-da85-4710-a676-a9dd1f3a21cf): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:23:02,903 [Thread-187] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:17 AM with interval of 21600000ms
2020-12-03 07:23:02,903 [Thread-158] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:09 PM with interval of 21600000ms
2020-12-03 07:23:02,905 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1176993;bpid=BP-153778976-172.17.0.11-1606980178053;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1176993;c=1606980178053;bpid=BP-153778976-172.17.0.11-1606980178053;dnuuid=null
2020-12-03 07:23:02,905 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,906 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:23:02,907 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:23:02,913 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,914 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,914 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,914 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,927 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:44894 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:37541 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:38067 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:37541 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:33986 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:44894 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:33986 beginning handshake with NN
2020-12-03 07:23:02,927 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:38067 beginning handshake with NN
2020-12-03 07:23:02,936 [IPC Server handler 6 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,937 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,938 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,938 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,938 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:02,939 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:02,939 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:02,953 [IPC Server handler 5 on default port 33986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:02,953 [IPC Server handler 3 on default port 37541] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:02,956 [IPC Server handler 5 on default port 33986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35706
2020-12-03 07:23:02,956 [IPC Server handler 5 on default port 33986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c10005ce-6ce1-4776-81ef-52aea79b68b8 (127.0.0.1:35706).
2020-12-03 07:23:02,958 [IPC Server handler 7 on default port 38067] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:02,961 [IPC Server handler 3 on default port 37541] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35706
2020-12-03 07:23:02,961 [IPC Server handler 3 on default port 37541] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c10005ce-6ce1-4776-81ef-52aea79b68b8 (127.0.0.1:35706).
2020-12-03 07:23:02,963 [IPC Server handler 7 on default port 38067] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35706
2020-12-03 07:23:02,963 [IPC Server handler 7 on default port 38067] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c10005ce-6ce1-4776-81ef-52aea79b68b8 (127.0.0.1:35706).
2020-12-03 07:23:02,963 [IPC Server handler 3 on default port 44894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:02,979 [IPC Server handler 2 on default port 37541] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:02,979 [IPC Server handler 2 on default port 37541] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42030
2020-12-03 07:23:02,980 [IPC Server handler 7 on default port 33986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:02,982 [IPC Server handler 7 on default port 33986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42030
2020-12-03 07:23:02,983 [IPC Server handler 3 on default port 44894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35706
2020-12-03 07:23:02,983 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:37541 successfully registered with NN
2020-12-03 07:23:02,984 [IPC Server handler 7 on default port 33986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7fefaf99-cdee-44a9-a2f1-4109e900669b (127.0.0.1:42030).
2020-12-03 07:23:02,984 [IPC Server handler 4 on default port 38067] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:02,984 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:38067 successfully registered with NN
2020-12-03 07:23:02,984 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38067 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,985 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:33986 successfully registered with NN
2020-12-03 07:23:02,985 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,984 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:33986 successfully registered with NN
2020-12-03 07:23:02,984 [IPC Server handler 3 on default port 44894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c10005ce-6ce1-4776-81ef-52aea79b68b8 (127.0.0.1:35706).
2020-12-03 07:23:02,988 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,984 [IPC Server handler 4 on default port 38067] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42030
2020-12-03 07:23:02,984 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37541 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,984 [IPC Server handler 2 on default port 37541] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7fefaf99-cdee-44a9-a2f1-4109e900669b (127.0.0.1:42030).
2020-12-03 07:23:02,992 [IPC Server handler 4 on default port 38067] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7fefaf99-cdee-44a9-a2f1-4109e900669b (127.0.0.1:42030).
2020-12-03 07:23:02,994 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:38067 successfully registered with NN
2020-12-03 07:23:02,994 [IPC Server handler 4 on default port 44894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:02,994 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38067 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,995 [IPC Server handler 4 on default port 44894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42030
2020-12-03 07:23:02,995 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:44894 successfully registered with NN
2020-12-03 07:23:02,994 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:37541 successfully registered with NN
2020-12-03 07:23:02,997 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37541 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,997 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,996 [IPC Server handler 4 on default port 44894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7fefaf99-cdee-44a9-a2f1-4109e900669b (127.0.0.1:42030).
2020-12-03 07:23:02,999 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:44894 successfully registered with NN
2020-12-03 07:23:02,999 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,015 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=318819230;bpid=BP-1997458851-172.17.0.11-1606980174443;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=318819230;c=1606980174443;bpid=BP-1997458851-172.17.0.11-1606980174443;dnuuid=51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,028 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b
2020-12-03 07:23:03,029 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:03,031 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-939a6047-89b2-442b-9fb8-2090ffa647b2
2020-12-03 07:23:03,035 [IPC Server handler 7 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 for DN 127.0.0.1:42030
2020-12-03 07:23:03,034 [IPC Server handler 7 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 for DN 127.0.0.1:42030
2020-12-03 07:23:03,034 [IPC Server handler 0 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb for DN 127.0.0.1:35706
2020-12-03 07:23:03,035 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:03,036 [IPC Server handler 7 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37937d60-da85-4710-a676-a9dd1f3a21cf for DN 127.0.0.1:42030
2020-12-03 07:23:03,037 [IPC Server handler 6 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 for DN 127.0.0.1:42030
2020-12-03 07:23:03,037 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:03,037 [IPC Server handler 6 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37937d60-da85-4710-a676-a9dd1f3a21cf for DN 127.0.0.1:42030
2020-12-03 07:23:03,038 [IPC Server handler 7 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37937d60-da85-4710-a676-a9dd1f3a21cf for DN 127.0.0.1:42030
2020-12-03 07:23:03,038 [IPC Server handler 0 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 for DN 127.0.0.1:35706
2020-12-03 07:23:03,040 [IPC Server handler 5 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb for DN 127.0.0.1:35706
2020-12-03 07:23:03,040 [IPC Server handler 9 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb for DN 127.0.0.1:35706
2020-12-03 07:23:03,043 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,039 [IPC Server handler 5 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb for DN 127.0.0.1:35706
2020-12-03 07:23:03,043 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,041 [IPC Server handler 9 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 for DN 127.0.0.1:42030
2020-12-03 07:23:03,050 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,050 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:03,050 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,050 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:03,050 [IPC Server handler 5 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 for DN 127.0.0.1:35706
2020-12-03 07:23:03,050 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:03,050 [IPC Server handler 5 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 for DN 127.0.0.1:35706
2020-12-03 07:23:03,053 [IPC Server handler 9 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 for DN 127.0.0.1:35706
2020-12-03 07:23:03,053 [IPC Server handler 9 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37937d60-da85-4710-a676-a9dd1f3a21cf for DN 127.0.0.1:42030
2020-12-03 07:23:03,053 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,055 [IPC Server handler 8 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,055 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,059 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:03,060 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:03,062 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,062 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,062 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1997458851-172.17.0.11-1606980174443 is not formatted. Formatting ...
2020-12-03 07:23:03,063 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1997458851-172.17.0.11-1606980174443 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1997458851-172.17.0.11-1606980174443/current
2020-12-03 07:23:03,079 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:03,080 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:03,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb7f26026803344cb: Processing first storage report for DS-37937d60-da85-4710-a676-a9dd1f3a21cf from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x18b2ed6c72681dce: Processing first storage report for DS-37937d60-da85-4710-a676-a9dd1f3a21cf from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,132 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 72ms
2020-12-03 07:23:03,133 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x687aa1e76c4a0bcd: Processing first storage report for DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,138 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x687aa1e76c4a0bcd: from storage DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,138 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb107212fdd985f9e: Processing first storage report for DS-37937d60-da85-4710-a676-a9dd1f3a21cf from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x52c1653ba5d62082: Processing first storage report for DS-37937d60-da85-4710-a676-a9dd1f3a21cf from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb107212fdd985f9e: from storage DS-37937d60-da85-4710-a676-a9dd1f3a21cf node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x52c1653ba5d62082: from storage DS-37937d60-da85-4710-a676-a9dd1f3a21cf node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe2ef49871363a95: Processing first storage report for DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x687aa1e76c4a0bcd: Processing first storage report for DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe2ef49871363a95: from storage DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x687aa1e76c4a0bcd: from storage DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb107212fdd985f9e: Processing first storage report for DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb107212fdd985f9e: from storage DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfe2ef49871363a95: Processing first storage report for DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfe2ef49871363a95: from storage DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,141 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x52c1653ba5d62082: Processing first storage report for DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,141 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x52c1653ba5d62082: from storage DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,142 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb7f26026803344cb: from storage DS-37937d60-da85-4710-a676-a9dd1f3a21cf node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 8 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,142 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 83ms
2020-12-03 07:23:03,142 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x18b2ed6c72681dce: from storage DS-37937d60-da85-4710-a676-a9dd1f3a21cf node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x59be42f8626da580: Processing first storage report for DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,142 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbe91030a4b0b5ae4: Processing first storage report for DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbe91030a4b0b5ae4: from storage DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb7f26026803344cb: Processing first storage report for DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb7f26026803344cb: from storage DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbe91030a4b0b5ae4: Processing first storage report for DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbe91030a4b0b5ae4: from storage DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,143 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x59be42f8626da580: from storage DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46 node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x18b2ed6c72681dce: Processing first storage report for DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 from datanode 7fefaf99-cdee-44a9-a2f1-4109e900669b
2020-12-03 07:23:03,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x18b2ed6c72681dce: from storage DS-b874ad0a-3825-43ef-9ab5-3cbe67256437 node DatanodeRegistration(127.0.0.1:42030, datanodeUuid=7fefaf99-cdee-44a9-a2f1-4109e900669b, infoPort=37293, infoSecurePort=0, ipcPort=40286, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,145 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x59be42f8626da580: Processing first storage report for DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb from datanode c10005ce-6ce1-4776-81ef-52aea79b68b8
2020-12-03 07:23:03,145 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x59be42f8626da580: from storage DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb node DatanodeRegistration(127.0.0.1:35706, datanodeUuid=c10005ce-6ce1-4776-81ef-52aea79b68b8, infoPort=43400, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,143 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-153778976-172.17.0.11-1606980178053: 90ms
2020-12-03 07:23:03,155 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:03,156 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:03,155 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:03,156 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:03,156 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:03,160 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:03,160 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=318819230;bpid=BP-1997458851-172.17.0.11-1606980174443;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=318819230;c=1606980174443;bpid=BP-1997458851-172.17.0.11-1606980174443;dnuuid=null
2020-12-03 07:23:03,162 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:23:03,162 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 6ms
2020-12-03 07:23:03,165 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-153778976-172.17.0.11-1606980178053: 17ms
2020-12-03 07:23:03,165 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,166 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,166 [Thread-212] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:10 AM with interval of 21600000ms
2020-12-03 07:23:03,166 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:03,166 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:03,168 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-939a6047-89b2-442b-9fb8-2090ffa647b2): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,169 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-939a6047-89b2-442b-9fb8-2090ffa647b2): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:23:03,169 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:37541 beginning handshake with NN
2020-12-03 07:23:03,171 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:44894 beginning handshake with NN
2020-12-03 07:23:03,171 [IPC Server handler 8 on default port 37541] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,171 [IPC Server handler 8 on default port 37541] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44110
2020-12-03 07:23:03,172 [IPC Server handler 8 on default port 37541] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 51f49252-0d16-481e-8402-27dd316ee7d5 (127.0.0.1:44110).
2020-12-03 07:23:03,173 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:37541 successfully registered with NN
2020-12-03 07:23:03,173 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37541 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,173 [IPC Server handler 2 on default port 44894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,179 [IPC Server handler 2 on default port 44894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44110
2020-12-03 07:23:03,180 [IPC Server handler 2 on default port 44894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 51f49252-0d16-481e-8402-27dd316ee7d5 (127.0.0.1:44110).
2020-12-03 07:23:03,181 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:44894 successfully registered with NN
2020-12-03 07:23:03,181 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,190 [IPC Server handler 0 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b for DN 127.0.0.1:44110
2020-12-03 07:23:03,190 [IPC Server handler 0 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-939a6047-89b2-442b-9fb8-2090ffa647b2 for DN 127.0.0.1:44110
2020-12-03 07:23:03,190 [IPC Server handler 3 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,194 [IPC Server handler 3 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b for DN 127.0.0.1:44110
2020-12-03 07:23:03,194 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbe91030a4b0b5ae4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 100 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,194 [IPC Server handler 3 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-939a6047-89b2-442b-9fb8-2090ffa647b2 for DN 127.0.0.1:44110
2020-12-03 07:23:03,195 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb7f26026803344cb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 102 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,196 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x18b2ed6c72681dce,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 103 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,197 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x52c1653ba5d62082,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 103 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,197 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x687aa1e76c4a0bcd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 103 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,196 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x59be42f8626da580,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 105 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,199 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:03,200 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:03,200 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb107212fdd985f9e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 106 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,199 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfe2ef49871363a95,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 106 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,208 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 49ms
2020-12-03 07:23:03,210 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 54ms
2020-12-03 07:23:03,211 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1997458851-172.17.0.11-1606980174443: 60ms
2020-12-03 07:23:03,212 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:03,212 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:03,212 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:03,212 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:03,213 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:03,213 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x62f7f4b0d5e74228: Processing first storage report for DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x62f7f4b0d5e74228: from storage DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3c73ab39e8ca9e45: Processing first storage report for DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x62f7f4b0d5e74228: Processing first storage report for DS-939a6047-89b2-442b-9fb8-2090ffa647b2 from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3c73ab39e8ca9e45: from storage DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x62f7f4b0d5e74228: from storage DS-939a6047-89b2-442b-9fb8-2090ffa647b2 node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,214 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3c73ab39e8ca9e45: Processing first storage report for DS-939a6047-89b2-442b-9fb8-2090ffa647b2 from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,215 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3c73ab39e8ca9e45: from storage DS-939a6047-89b2-442b-9fb8-2090ffa647b2 node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,216 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443: 4ms
2020-12-03 07:23:03,216 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x62f7f4b0d5e74228,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 20 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,218 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:33986 beginning handshake with NN
2020-12-03 07:23:03,218 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:38067 beginning handshake with NN
2020-12-03 07:23:03,218 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:03,216 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3c73ab39e8ca9e45,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 17 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,221 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,222 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b): no suitable block pools found to scan.  Waiting 1814399943 ms.
2020-12-03 07:23:03,222 [IPC Server handler 4 on default port 33986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,222 [IPC Server handler 4 on default port 38067] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,223 [IPC Server handler 4 on default port 33986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44110
2020-12-03 07:23:03,223 [IPC Server handler 4 on default port 38067] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44110
2020-12-03 07:23:03,223 [IPC Server handler 4 on default port 38067] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 51f49252-0d16-481e-8402-27dd316ee7d5 (127.0.0.1:44110).
2020-12-03 07:23:03,223 [IPC Server handler 4 on default port 33986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 51f49252-0d16-481e-8402-27dd316ee7d5 (127.0.0.1:44110).
2020-12-03 07:23:03,223 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:03,224 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-939a6047-89b2-442b-9fb8-2090ffa647b2): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,225 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-939a6047-89b2-442b-9fb8-2090ffa647b2): no suitable block pools found to scan.  Waiting 1814399940 ms.
2020-12-03 07:23:03,226 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:33986 successfully registered with NN
2020-12-03 07:23:03,227 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,226 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:38067 successfully registered with NN
2020-12-03 07:23:03,228 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38067 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,230 [IPC Server handler 6 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b for DN 127.0.0.1:44110
2020-12-03 07:23:03,230 [IPC Server handler 6 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-939a6047-89b2-442b-9fb8-2090ffa647b2 for DN 127.0.0.1:44110
2020-12-03 07:23:03,231 [IPC Server handler 5 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b for DN 127.0.0.1:44110
2020-12-03 07:23:03,231 [IPC Server handler 5 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-939a6047-89b2-442b-9fb8-2090ffa647b2 for DN 127.0.0.1:44110
2020-12-03 07:23:03,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe5823751565bbc83: Processing first storage report for DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6b5e21603a0712ed: Processing first storage report for DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe5823751565bbc83: from storage DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6b5e21603a0712ed: from storage DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6b5e21603a0712ed: Processing first storage report for DS-939a6047-89b2-442b-9fb8-2090ffa647b2 from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,235 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6b5e21603a0712ed: from storage DS-939a6047-89b2-442b-9fb8-2090ffa647b2 node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,235 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe5823751565bbc83: Processing first storage report for DS-939a6047-89b2-442b-9fb8-2090ffa647b2 from datanode 51f49252-0d16-481e-8402-27dd316ee7d5
2020-12-03 07:23:03,235 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe5823751565bbc83: from storage DS-939a6047-89b2-442b-9fb8-2090ffa647b2 node DatanodeRegistration(127.0.0.1:44110, datanodeUuid=51f49252-0d16-481e-8402-27dd316ee7d5, infoPort=43776, infoSecurePort=0, ipcPort=45511, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,236 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe5823751565bbc83,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,236 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6b5e21603a0712ed,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,303 [IPC Server handler 7 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,303 [Thread-236] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,305 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:03,305 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:03,308 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1
2020-12-03 07:23:03,308 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:03,312 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e
2020-12-03 07:23:03,312 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:03,313 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:03,316 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,316 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:03,317 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:03,317 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:03,317 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:03,317 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:03,317 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:03,318 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,344 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 28ms
2020-12-03 07:23:03,352 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-153778976-172.17.0.11-1606980178053 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 36ms
2020-12-03 07:23:03,353 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-153778976-172.17.0.11-1606980178053: 37ms
2020-12-03 07:23:03,353 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:03,354 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:03,354 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:03,354 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:03,355 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:23:03,354 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:03,354 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-153778976-172.17.0.11-1606980178053/current/replicas doesn't exist 
2020-12-03 07:23:03,356 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:03,356 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-153778976-172.17.0.11-1606980178053: 3ms
2020-12-03 07:23:03,357 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:03,357 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-153778976-172.17.0.11-1606980178053 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:03,358 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,358 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1): finished scanning block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:03,359 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:03,358 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:16 AM with interval of 21600000ms
2020-12-03 07:23:03,359 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:03,360 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:44894 beginning handshake with NN
2020-12-03 07:23:03,361 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:37541 beginning handshake with NN
2020-12-03 07:23:03,363 [IPC Server handler 9 on default port 44894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,363 [IPC Server handler 4 on default port 37541] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053) storage b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,363 [IPC Server handler 9 on default port 44894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37512
2020-12-03 07:23:03,363 [IPC Server handler 4 on default port 37541] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37512
2020-12-03 07:23:03,363 [IPC Server handler 4 on default port 37541] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b578e957-80bd-41c3-95d2-2bebf54d4ae6 (127.0.0.1:37512).
2020-12-03 07:23:03,363 [IPC Server handler 9 on default port 44894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b578e957-80bd-41c3-95d2-2bebf54d4ae6 (127.0.0.1:37512).
2020-12-03 07:23:03,366 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:44894 successfully registered with NN
2020-12-03 07:23:03,366 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,380 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:37541 successfully registered with NN
2020-12-03 07:23:03,380 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37541 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,387 [IPC Server handler 6 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 for DN 127.0.0.1:37512
2020-12-03 07:23:03,389 [IPC Server handler 6 on default port 44894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e for DN 127.0.0.1:37512
2020-12-03 07:23:03,391 [IPC Server handler 3 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 for DN 127.0.0.1:37512
2020-12-03 07:23:03,391 [IPC Server handler 3 on default port 37541] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e for DN 127.0.0.1:37512
2020-12-03 07:23:03,403 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 48ms
2020-12-03 07:23:03,410 [IPC Server handler 8 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,412 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1997458851-172.17.0.11-1606980174443 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 57ms
2020-12-03 07:23:03,412 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1997458851-172.17.0.11-1606980174443: 60ms
2020-12-03 07:23:03,413 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:03,413 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:03,414 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:03,414 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:03,414 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:03,414 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1997458851-172.17.0.11-1606980174443/current/replicas doesn't exist 
2020-12-03 07:23:03,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd5828016b885f179: Processing first storage report for DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,415 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:23:03,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd5828016b885f179: from storage DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,415 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:03,415 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd5828016b885f179: Processing first storage report for DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,416 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd5828016b885f179: from storage DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,417 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1997458851-172.17.0.11-1606980174443: 5ms
2020-12-03 07:23:03,418 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd5828016b885f179,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 21 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:03,422 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:38067 beginning handshake with NN
2020-12-03 07:23:03,422 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1997458851-172.17.0.11-1606980174443 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:03,422 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,422 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:33986 beginning handshake with NN
2020-12-03 07:23:03,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcc4ff821db9079df: Processing first storage report for DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e): finished scanning block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:03,432 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcc4ff821db9079df: from storage DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: true, processing time: 11 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,432 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcc4ff821db9079df: Processing first storage report for DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,433 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcc4ff821db9079df: from storage DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=1176993;c=1606980178053), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,433 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e): no suitable block pools found to scan.  Waiting 1814399924 ms.
2020-12-03 07:23:03,433 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1): no suitable block pools found to scan.  Waiting 1814399924 ms.
2020-12-03 07:23:03,433 [IPC Server handler 0 on default port 33986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,434 [IPC Server handler 2 on default port 38067] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443) storage b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,435 [IPC Server handler 0 on default port 33986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37512
2020-12-03 07:23:03,435 [IPC Server handler 0 on default port 33986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b578e957-80bd-41c3-95d2-2bebf54d4ae6 (127.0.0.1:37512).
2020-12-03 07:23:03,437 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:33986 successfully registered with NN
2020-12-03 07:23:03,437 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,434 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcc4ff821db9079df,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 21 msec to generate and 21 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,435 [IPC Server handler 2 on default port 38067] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37512
2020-12-03 07:23:03,439 [IPC Server handler 2 on default port 38067] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b578e957-80bd-41c3-95d2-2bebf54d4ae6 (127.0.0.1:37512).
2020-12-03 07:23:03,441 [IPC Server handler 9 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 for DN 127.0.0.1:37512
2020-12-03 07:23:03,443 [IPC Server handler 9 on default port 33986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e for DN 127.0.0.1:37512
2020-12-03 07:23:03,444 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:38067 successfully registered with NN
2020-12-03 07:23:03,444 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38067 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:03,448 [IPC Server handler 1 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 for DN 127.0.0.1:37512
2020-12-03 07:23:03,449 [IPC Server handler 1 on default port 38067] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e for DN 127.0.0.1:37512
2020-12-03 07:23:03,451 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x737154562f9152c3: Processing first storage report for DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,451 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb3f677eaeb29b209: Processing first storage report for DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,451 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb3f677eaeb29b209: from storage DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,451 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x737154562f9152c3: from storage DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1 node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,452 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb3f677eaeb29b209: Processing first storage report for DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,452 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb3f677eaeb29b209: from storage DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,452 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x737154562f9152c3: Processing first storage report for DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e from datanode b578e957-80bd-41c3-95d2-2bebf54d4ae6
2020-12-03 07:23:03,452 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x737154562f9152c3: from storage DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e node DatanodeRegistration(127.0.0.1:37512, datanodeUuid=b578e957-80bd-41c3-95d2-2bebf54d4ae6, infoPort=33475, infoSecurePort=0, ipcPort=37367, storageInfo=lv=-57;cid=testClusterID;nsid=318819230;c=1606980174443), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,453 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb3f677eaeb29b209,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,454 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x737154562f9152c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:03,515 [IPC Server handler 2 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,529 [IPC Server handler 9 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,538 [IPC Server handler 5 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,544 [IPC Server handler 5 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,546 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:03,556 [IPC Server handler 1 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,560 [IPC Server handler 6 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,565 [IPC Server handler 7 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,572 [IPC Server handler 7 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:03,575 [Listener at localhost/37367] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:03,623 [Listener at localhost/37367] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:03,624 [Listener at localhost/37367] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,626 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,638 [Listener at 0.0.0.0/41583] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:03,639 [Listener at 0.0.0.0/41583] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:03,639 [Listener at 0.0.0.0/41583] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:03,661 [Listener at 0.0.0.0/41583] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:03,662 [Listener at 0.0.0.0/41583] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,667 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,676 [Listener at 0.0.0.0/37224] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:03,679 [Listener at 0.0.0.0/37224] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:03,680 [Listener at 0.0.0.0/37224] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:03,680 [Listener at 0.0.0.0/37224] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:03,680 [Listener at 0.0.0.0/37224] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:03,681 [Listener at 0.0.0.0/37224] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:03,696 [Listener at 0.0.0.0/37224] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:23:03,696 [Listener at 0.0.0.0/37224] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:03,701 [Listener at 0.0.0.0/37224] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:23:03,707 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,708 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,708 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,708 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33765
2020-12-03 07:23:03,709 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,709 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,709 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,709 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:44248
2020-12-03 07:23:03,710 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,710 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,710 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,710 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45508
2020-12-03 07:23:03,711 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,711 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,711 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,711 [Listener at 0.0.0.0/37224] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44990
2020-12-03 07:23:03,728 [Listener at 0.0.0.0/37224] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:03,729 [Listener at 0.0.0.0/37224] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,730 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,749 [Listener at 0.0.0.0/40866] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:03,749 [Listener at 0.0.0.0/40866] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:03,749 [Listener at 0.0.0.0/40866] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:03,751 [Listener at 0.0.0.0/40866] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:03,752 [Listener at 0.0.0.0/40866] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,752 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,756 [Listener at 0.0.0.0/40467] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:03,757 [Listener at 0.0.0.0/40467] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:03,757 [Listener at 0.0.0.0/40467] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:03,757 [Listener at 0.0.0.0/40467] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:03,758 [Listener at 0.0.0.0/40467] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:03,758 [Listener at 0.0.0.0/40467] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:03,773 [Listener at 0.0.0.0/40467] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:23:03,773 [Listener at 0.0.0.0/40467] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:03,775 [Listener at 0.0.0.0/40467] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:23:03,776 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,776 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,776 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,776 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33765
2020-12-03 07:23:03,777 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,777 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,778 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,778 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:44248
2020-12-03 07:23:03,779 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,779 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,779 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,779 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45508
2020-12-03 07:23:03,780 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,780 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,780 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,781 [Listener at 0.0.0.0/40467] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44990
2020-12-03 07:23:03,801 [Listener at 0.0.0.0/40467] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:03,803 [Listener at 0.0.0.0/40467] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,804 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,809 [Listener at 0.0.0.0/32848] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:03,809 [Listener at 0.0.0.0/32848] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:03,810 [Listener at 0.0.0.0/32848] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:03,811 [Listener at 0.0.0.0/32848] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:03,812 [Listener at 0.0.0.0/32848] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,813 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,817 [Listener at 0.0.0.0/42303] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:03,817 [Listener at 0.0.0.0/42303] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:03,817 [Listener at 0.0.0.0/42303] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:03,817 [Listener at 0.0.0.0/42303] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:03,818 [Listener at 0.0.0.0/42303] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:03,818 [Listener at 0.0.0.0/42303] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:03,819 [Listener at 0.0.0.0/42303] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:23:03,819 [Listener at 0.0.0.0/42303] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:03,820 [Listener at 0.0.0.0/42303] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:23:03,821 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,821 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,821 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,822 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33765
2020-12-03 07:23:03,822 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,822 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,822 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,822 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:44248
2020-12-03 07:23:03,823 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,823 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,823 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,823 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45508
2020-12-03 07:23:03,824 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,824 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,824 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,824 [Listener at 0.0.0.0/42303] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44990
2020-12-03 07:23:03,839 [Listener at 0.0.0.0/42303] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:03,840 [Listener at 0.0.0.0/42303] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,841 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,846 [Listener at 0.0.0.0/40179] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:03,846 [Listener at 0.0.0.0/40179] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:03,846 [Listener at 0.0.0.0/40179] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:03,847 [Listener at 0.0.0.0/40179] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:03,849 [Listener at 0.0.0.0/40179] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,849 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,855 [Listener at 0.0.0.0/34945] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:03,855 [Listener at 0.0.0.0/34945] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:03,855 [Listener at 0.0.0.0/34945] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:03,855 [Listener at 0.0.0.0/34945] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:03,856 [Listener at 0.0.0.0/34945] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:03,856 [Listener at 0.0.0.0/34945] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:03,857 [Listener at 0.0.0.0/34945] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:23:03,857 [Listener at 0.0.0.0/34945] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:03,858 [Listener at 0.0.0.0/34945] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:23:03,860 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,860 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,860 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:37541
2020-12-03 07:23:03,861 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33765
2020-12-03 07:23:03,861 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,861 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,861 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44894
2020-12-03 07:23:03,861 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45508
2020-12-03 07:23:03,862 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,862 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,862 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33986
2020-12-03 07:23:03,862 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:44248
2020-12-03 07:23:03,863 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,863 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,863 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:38067
2020-12-03 07:23:03,863 [Listener at 0.0.0.0/34945] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44990
2020-12-03 07:23:03,869 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:41583: State Store unavailable
2020-12-03 07:23:03,869 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b917fb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:03,869 [Listener at 0.0.0.0/34945] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:03,873 [Listener at 0.0.0.0/34945] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete.createCluster(TestRouterWebHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:03,878 [Listener at 0.0.0.0/34945] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:03,878 [Listener at 0.0.0.0/34945] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:03,879 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:03,880 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:03,880 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:03,881 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:03,882 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,883 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:03,883 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:03,882 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:03,884 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:03,897 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:03,898 [Listener at 0.0.0.0/34945] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:41583
2020-12-03 07:23:03,899 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,900 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:03,902 [Listener at 0.0.0.0/34945] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:03,902 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,904 [Listener at 0.0.0.0/34945] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:03,905 [Listener at 0.0.0.0/34945] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:03,906 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,909 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:03,909 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:03,909 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:03,909 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:03,913 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:03,914 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:03,915 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37084
2020-12-03 07:23:03,915 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:03,917 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69fa8e76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:03,918 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31f20c9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:03,925 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71cb3139{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:03,927 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1639f93a{HTTP/1.1,[http/1.1]}{0.0.0.0:37084}
2020-12-03 07:23:03,928 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(419)) - Started @12326ms
2020-12-03 07:23:03,928 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:03,928 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:03,929 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:03,929 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:03,929 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:03,931 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:41583: State Store unavailable
2020-12-03 07:23:03,934 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:23:03,935 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:23:03,937 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:23:03,937 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:23:03,943 [Listener at 0.0.0.0/34945] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:23:03,943 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40866: State Store unavailable
2020-12-03 07:23:03,943 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2eaef76d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:03,943 [Listener at 0.0.0.0/34945] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:03,944 [Listener at 0.0.0.0/34945] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete.createCluster(TestRouterWebHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:03,944 [Listener at 0.0.0.0/34945] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:03,945 [Listener at 0.0.0.0/34945] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:03,945 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:03,945 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:03,946 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:03,947 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:03,953 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:03,952 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,952 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:03,985 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:03,986 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:03,986 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:03,989 [Listener at 0.0.0.0/34945] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:40866
2020-12-03 07:23:03,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,993 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:03,996 [Listener at 0.0.0.0/34945] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:03,996 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,999 [Listener at 0.0.0.0/34945] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:04,000 [Listener at 0.0.0.0/34945] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:04,001 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,004 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:04,004 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:04,005 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:04,005 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:04,007 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:04,007 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:04,008 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44342
2020-12-03 07:23:04,008 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:04,012 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1da4b6b3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:04,013 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e1f584d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:04,025 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@46d567cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:04,026 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@363a3d15{HTTP/1.1,[http/1.1]}{0.0.0.0:44342}
2020-12-03 07:23:04,026 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(419)) - Started @12424ms
2020-12-03 07:23:04,027 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:04,027 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:04,028 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:04,032 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:04,032 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:04,034 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40866: State Store unavailable
2020-12-03 07:23:04,034 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:23:04,035 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:23:04,035 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:23:04,036 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:23:04,036 [Listener at 0.0.0.0/34945] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:23:04,037 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:32848: State Store unavailable
2020-12-03 07:23:04,037 [Listener at 0.0.0.0/34945] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:04,037 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4efc25fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:04,037 [Listener at 0.0.0.0/34945] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete.createCluster(TestRouterWebHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:04,038 [Listener at 0.0.0.0/34945] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:04,038 [Listener at 0.0.0.0/34945] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:04,038 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:04,039 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:04,039 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:04,040 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:04,040 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:04,040 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,043 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:04,046 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:04,046 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:04,046 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:04,048 [Listener at 0.0.0.0/34945] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:32848
2020-12-03 07:23:04,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:04,048 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,052 [Listener at 0.0.0.0/34945] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:04,052 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,054 [Listener at 0.0.0.0/34945] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:04,055 [Listener at 0.0.0.0/34945] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:04,055 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,057 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:04,057 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:04,058 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:04,058 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:04,061 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:04,061 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:04,061 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45593
2020-12-03 07:23:04,061 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:04,066 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5176d279{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:04,066 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d74bac4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:04,076 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4c59e45e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:04,083 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58ec7116{HTTP/1.1,[http/1.1]}{0.0.0.0:45593}
2020-12-03 07:23:04,085 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(419)) - Started @12483ms
2020-12-03 07:23:04,085 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:04,086 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:04,089 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:04,089 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:04,090 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:04,091 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:32848: State Store unavailable
2020-12-03 07:23:04,092 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:23:04,092 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:23:04,092 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:23:04,092 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:23:04,093 [Listener at 0.0.0.0/34945] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:23:04,094 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40179: State Store unavailable
2020-12-03 07:23:04,094 [Listener at 0.0.0.0/34945] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:04,094 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36fcf6c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:04,094 [Listener at 0.0.0.0/34945] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete.createCluster(TestRouterWebHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:04,095 [Listener at 0.0.0.0/34945] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:04,096 [Listener at 0.0.0.0/34945] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:04,096 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:04,097 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:04,098 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:04,101 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:04,102 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:04,102 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:04,103 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:04,107 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:04,107 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,108 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:04,117 [Listener at 0.0.0.0/34945] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:40179
2020-12-03 07:23:04,118 [IPC Server handler 3 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,118 [IPC Server handler 9 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,118 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:04,118 [IPC Server handler 4 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,118 [IPC Server handler 6 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,118 [IPC Server handler 5 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,118 [IPC Server handler 7 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,172 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,175 [Listener at 0.0.0.0/34945] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:04,176 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,176 [IPC Server handler 1 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,176 [IPC Server handler 4 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,176 [IPC Server handler 0 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,177 [IPC Server handler 8 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,177 [IPC Server handler 2 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,178 [Listener at 0.0.0.0/34945] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:04,179 [Listener at 0.0.0.0/34945] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:04,179 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,181 [IPC Server handler 0 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,182 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:04,183 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:04,183 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:04,183 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:04,185 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:04,186 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:04,186 [Listener at 0.0.0.0/34945] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35419
2020-12-03 07:23:04,186 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:04,214 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68217d41{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:04,251 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e5d4f6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:04,328 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39e43310{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:04,338 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@eb507b9{HTTP/1.1,[http/1.1]}{0.0.0.0:35419}
2020-12-03 07:23:04,338 [Listener at 0.0.0.0/34945] INFO  server.Server (Server.java:doStart(419)) - Started @12736ms
2020-12-03 07:23:04,338 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:04,339 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:04,339 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:04,350 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:04,351 [Listener at 0.0.0.0/34945] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:04,366 [IPC Server handler 2 on default port 37541] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,370 [IPC Server handler 8 on default port 44894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,384 [IPC Server handler 3 on default port 38067] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,384 [IPC Server handler 3 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:04,384 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40179: State Store unavailable
2020-12-03 07:23:04,385 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:23:04,385 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:23:04,385 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:23:04,386 [Listener at 0.0.0.0/34945] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:23:04,400 [Listener at 0.0.0.0/34945] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:23:04,426 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:04,427 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:04,430 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:04,432 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:23:04,433 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:04,433 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:04,433 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:04,438 [Listener at 0.0.0.0/34945] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:04,486 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:04,486 [Listener at 0.0.0.0/34945] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:04,488 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:04,489 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:04,562 [Listener at 0.0.0.0/34945] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:04,587 [Listener at 0.0.0.0/34945] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 24 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:04,618 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:04,618 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:04,618 [CacheReplicationMonitor(761227445)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:04,618 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:04,619 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:04,619 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:04,619 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:04,619 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:04,619 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:04,619 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 132 msec
2020-12-03 07:23:04,624 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:23:04,625 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:23:04,625 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:23:04,625 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:04,628 [Listener at 0.0.0.0/34945] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:04,643 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:04,644 [Listener at 0.0.0.0/34945] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:04,646 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:04,647 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:04,691 [Listener at 0.0.0.0/34945] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:04,692 [Listener at 0.0.0.0/34945] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:04,696 [CacheReplicationMonitor(858120908)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:04,698 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:04,699 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:04,699 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:04,699 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:04,699 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:04,699 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 52 msec
2020-12-03 07:23:05,747 [Thread-474] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:44342 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6ad23db3
Dec 03, 2020 7:23:05 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:23:06,060 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:37541 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,061 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:37541 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,061 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:37541
2020-12-03 07:23:06,061 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:37541
2020-12-03 07:23:06,063 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:33986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,063 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:33986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,063 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:33986
2020-12-03 07:23:06,063 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:33986
2020-12-03 07:23:06,179 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:37541 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,179 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:37541
2020-12-03 07:23:06,235 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:33986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,235 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:33986
2020-12-03 07:23:06,384 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:37541 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,384 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:37541
2020-12-03 07:23:06,443 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:33986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:06,443 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:33986
Dec 03, 2020 7:23:06 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Dec 03, 2020 7:23:06 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 03, 2020 7:23:06 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:23:07 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:07,887 [IPC Server handler 4 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:08,020 [IPC Server handler 5 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonexistentPathNonRecursive	dst=null	perm=null	proto=rpc
2020-12-03 07:23:08,055 [IPC Server handler 7 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteNonexistentPathNonRecursive	dst=null	perm=null	proto=rpc
2020-12-03 07:23:08,075 [IPC Server handler 8 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:08,127 [IPC Server handler 0 on default port 33986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:08,132 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:08,132 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:08,133 [Listener at 0.0.0.0/34945] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:08,135 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@59942b48] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:08,136 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-3b037ae1-e318-439d-b21b-dbb52d0bde8e) exiting.
2020-12-03 07:23:08,139 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-d7ed7bea-2d08-407f-b6f2-4ed84e0957d1) exiting.
2020-12-03 07:23:08,168 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5486887b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:08,172 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5226e402{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,172 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d2d99fc{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,172 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f9b5552{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,183 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37367
2020-12-03 07:23:08,197 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,199 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,201 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,201 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:38067
2020-12-03 07:23:08,201 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,201 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,201 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,212 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:37541
2020-12-03 07:23:08,212 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:33986
2020-12-03 07:23:08,212 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6) service to localhost/127.0.0.1:44894
2020-12-03 07:23:08,212 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6)
2020-12-03 07:23:08,212 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid b578e957-80bd-41c3-95d2-2bebf54d4ae6)
2020-12-03 07:23:08,212 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:08,214 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,214 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,214 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:08,221 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:08,221 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,221 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:08,221 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,224 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:08,224 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:08,232 [Listener at 0.0.0.0/34945] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:08,232 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:08,233 [Listener at 0.0.0.0/34945] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:08,233 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34b9fc7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:08,235 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0f43a0f9-5ac0-48e9-8d38-6a835c62d89b) exiting.
2020-12-03 07:23:08,235 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-939a6047-89b2-442b-9fb8-2090ffa647b2) exiting.
2020-12-03 07:23:08,289 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69cac930{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:08,290 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,290 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,290 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,291 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45511
2020-12-03 07:23:08,292 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,293 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,294 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,294 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,294 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:33986
2020-12-03 07:23:08,294 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,294 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:37541
2020-12-03 07:23:08,294 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:38067
2020-12-03 07:23:08,294 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5)
2020-12-03 07:23:08,295 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:08,295 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,295 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,296 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,296 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5) service to localhost/127.0.0.1:44894
2020-12-03 07:23:08,296 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 51f49252-0d16-481e-8402-27dd316ee7d5)
2020-12-03 07:23:08,296 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:08,297 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,297 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,310 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:08,310 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:08,311 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:08,312 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:08,314 [Listener at 0.0.0.0/34945] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:08,314 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:08,315 [Listener at 0.0.0.0/34945] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:08,315 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72458efc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:08,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-b874ad0a-3825-43ef-9ab5-3cbe67256437) exiting.
2020-12-03 07:23:08,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-37937d60-da85-4710-a676-a9dd1f3a21cf) exiting.
2020-12-03 07:23:08,356 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cbb84b1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:08,358 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,363 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,363 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,365 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40286
2020-12-03 07:23:08,369 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,379 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,379 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,380 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,380 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:33986
2020-12-03 07:23:08,380 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:38067
2020-12-03 07:23:08,380 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b)
2020-12-03 07:23:08,380 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:08,381 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,381 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,381 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,381 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:37541
2020-12-03 07:23:08,381 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,381 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b) service to localhost/127.0.0.1:44894
2020-12-03 07:23:08,381 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid 7fefaf99-cdee-44a9-a2f1-4109e900669b)
2020-12-03 07:23:08,392 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:08,393 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,393 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,404 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:08,404 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:08,406 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:08,406 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:08,409 [Listener at 0.0.0.0/34945] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:08,410 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:08,411 [Listener at 0.0.0.0/34945] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:08,411 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@50cf5a23] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:08,414 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-31f49327-4df8-4bf4-8376-9b3a8e7890fb) exiting.
2020-12-03 07:23:08,414 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-4f73b3b9-75c2-4b4c-97ea-fec74c7a0d46) exiting.
2020-12-03 07:23:08,437 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6c2f1700{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:08,438 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@350b3a17{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,439 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,439 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73e132e0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,448 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42839
2020-12-03 07:23:08,452 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,452 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,453 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,453 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,453 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,460 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:37541] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:37541
2020-12-03 07:23:08,460 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:38067] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:38067
2020-12-03 07:23:08,460 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:33986
2020-12-03 07:23:08,460 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:08,461 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8) service to localhost/127.0.0.1:44894
2020-12-03 07:23:08,461 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1997458851-172.17.0.11-1606980174443 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8)
2020-12-03 07:23:08,461 [BP-1997458851-172.17.0.11-1606980174443 heartbeating to localhost/127.0.0.1:33986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1997458851-172.17.0.11-1606980174443
2020-12-03 07:23:08,462 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,462 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1997458851-172.17.0.11-1606980174443] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,466 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-153778976-172.17.0.11-1606980178053 (Datanode Uuid c10005ce-6ce1-4776-81ef-52aea79b68b8)
2020-12-03 07:23:08,472 [BP-153778976-172.17.0.11-1606980178053 heartbeating to localhost/127.0.0.1:44894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-153778976-172.17.0.11-1606980178053
2020-12-03 07:23:08,473 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,473 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-153778976-172.17.0.11-1606980178053] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:08,483 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:08,484 [Listener at 0.0.0.0/34945] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:08,486 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:08,486 [Listener at 0.0.0.0/34945] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:08,490 [Listener at 0.0.0.0/34945] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:08,491 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:08,491 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,495 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 3
2020-12-03 07:23:08,506 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@67d86804] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:08,510 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7afb1741] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:08,510 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 12 15 3 
2020-12-03 07:23:08,515 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:08,516 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:08,517 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:08,517 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:08,518 [CacheReplicationMonitor(761227445)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:08,518 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33986
2020-12-03 07:23:08,518 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,527 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:08,527 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:08,590 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,591 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,593 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@512535ff{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:08,598 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4be9529d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,598 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@492691d7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,599 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60129b9a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,614 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:08,615 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,615 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:08,616 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38067
2020-12-03 07:23:08,621 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,622 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:08,628 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:08,629 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,648 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,677 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,699 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e11bc55{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:08,705 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7544a1e4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,706 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69adf72c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,707 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@649f2009{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,712 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:08,712 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,712 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6fa69af7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:08,712 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4b1a43d8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:08,713 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:23:08,725 [Listener at 0.0.0.0/34945] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 15 7 2 
2020-12-03 07:23:08,727 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:08,728 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:08,728 [Listener at 0.0.0.0/34945] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:08,729 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:08,729 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37541
2020-12-03 07:23:08,736 [CacheReplicationMonitor(858120908)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:08,737 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,737 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,745 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:08,744 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:08,759 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,760 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,762 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30c0ccff{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:08,769 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@581d969c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,769 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f5c79a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,770 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29539e36{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,777 [Listener at 0.0.0.0/34945] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:08,777 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,777 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:08,778 [Listener at 0.0.0.0/34945] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44894
2020-12-03 07:23:08,785 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:08,790 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:08,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:08,794 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:08,804 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:08,828 [Listener at 0.0.0.0/34945] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:08,835 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33c2bd{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:08,841 [Listener at 0.0.0.0/34945] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1dfd5f51{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:08,841 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3228d990{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:08,842 [Listener at 0.0.0.0/34945] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68ed96ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:08,864 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:41583: State Store unavailable
2020-12-03 07:23:08,887 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:08,895 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:08,895 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:08,908 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:08,908 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:08,915 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:08,915 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:08,922 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:08,922 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:08,927 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:08,927 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:08,954 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:08,961 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71cb3139{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:08,989 [Thread-482] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1639f93a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:08,996 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31f20c9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:09,001 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69fa8e76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:09,023 [Thread-482] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37224
2020-12-03 07:23:09,031 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:09,048 [Thread-482] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41583
2020-12-03 07:23:09,049 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40866: State Store unavailable
2020-12-03 07:23:09,049 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:09,052 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:09,075 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:09,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:09,093 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:09,093 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:32848: State Store unavailable
2020-12-03 07:23:09,094 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:09,104 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:09,104 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:09,112 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:09,385 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40179: State Store unavailable
2020-12-03 07:23:09,866 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40866: State Store unavailable
2020-12-03 07:23:09,878 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:09,879 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:09,892 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:09,892 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:09,914 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:09,914 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:09,928 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:09,928 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:09,930 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:09,930 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:09,946 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@46d567cb{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:09,948 [Thread-487] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@363a3d15{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:09,952 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e1f584d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:09,956 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1da4b6b3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:09,960 [Thread-487] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40467
2020-12-03 07:23:09,966 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:09,966 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:09,991 [Thread-487] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40866
2020-12-03 07:23:09,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:09,996 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:09,997 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:23:10,010 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:23:10,015 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:23:10,026 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:10,027 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:10,030 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:10,031 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:10,307 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33986: End of File Exception between local host is: "82ba21544e84/172.17.0.11"; destination host is: "localhost":33986; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:23:10,307 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33986
2020-12-03 07:23:10,308 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:44894: End of File Exception between local host is: "82ba21544e84/172.17.0.11"; destination host is: "localhost":44894; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:23:10,311 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:44894
2020-12-03 07:23:10,312 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:44894: End of File Exception between local host is: "82ba21544e84/172.17.0.11"; destination host is: "localhost":44894; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:23:10,312 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:44894
2020-12-03 07:23:10,313 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:37541: End of File Exception between local host is: "82ba21544e84/172.17.0.11"; destination host is: "localhost":37541; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:23:10,313 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:37541
2020-12-03 07:23:10,331 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:38067: End of File Exception between local host is: "82ba21544e84/172.17.0.11"; destination host is: "localhost":38067; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:23:10,331 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:38067
2020-12-03 07:23:10,859 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:32848: State Store unavailable
2020-12-03 07:23:10,860 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:10,861 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:10,862 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:10,862 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:10,862 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:10,862 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:10,863 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:10,863 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:10,865 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:10,865 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:10,867 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:37541: DestHost:destPort localhost:37541 , LocalHost:localPort 82ba21544e84/172.17.0.11:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:10,868 [Thread-491] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4c59e45e{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:10,868 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:37541
2020-12-03 07:23:10,870 [Thread-491] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58ec7116{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:10,870 [Thread-491] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d74bac4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:10,871 [Thread-491] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5176d279{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:10,874 [Thread-491] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42303
2020-12-03 07:23:10,875 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:10,876 [Thread-491] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32848
2020-12-03 07:23:10,876 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:10,877 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:10,880 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:10,881 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:10,882 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:10,883 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:10,883 [Thread-491] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:11,304 [NamenodeHeartbeatService ns0 nn1-0] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:38067. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:11,306 [NamenodeHeartbeatService ns0 nn0-0] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:33986. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:11,860 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 82ba21544e84:40179: State Store unavailable
2020-12-03 07:23:11,861 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:11,861 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:11,862 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:11,862 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:11,862 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:11,863 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:38067: DestHost:destPort localhost:38067 , LocalHost:localPort 82ba21544e84/172.17.0.11:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:11,863 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33986: DestHost:destPort localhost:33986 , LocalHost:localPort 82ba21544e84/172.17.0.11:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:11,863 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33986
2020-12-03 07:23:11,863 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:38067
2020-12-03 07:23:11,864 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:11,864 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:11,865 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:11,865 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:11,865 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:11,867 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39e43310{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:11,868 [Thread-492] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@eb507b9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:11,868 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e5d4f6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:11,869 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68217d41{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:11,870 [Thread-492] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34945
2020-12-03 07:23:11,870 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:11,871 [Thread-492] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40179
2020-12-03 07:23:11,870 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:11,872 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:11,872 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:11,873 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:11,873 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:11,874 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:11,874 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
