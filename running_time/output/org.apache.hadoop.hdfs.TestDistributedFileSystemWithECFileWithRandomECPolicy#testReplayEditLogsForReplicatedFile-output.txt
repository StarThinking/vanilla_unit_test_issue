2020-12-03 07:20:36,904 [main] INFO  hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy (TestDistributedFileSystemWithECFileWithRandomECPolicy.java:<init>(40)) - run TestDistributedFileSystemWithECFile with RS-10-4-1024k.
2020-12-03 07:20:37,185 [Thread-0] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=14
Formatting using clusterid: testClusterID
2020-12-03 07:20:38,090 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:38,104 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:38,106 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:38,107 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:38,119 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:38,119 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:38,119 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:38,120 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:38,176 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:38,182 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:38,182 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:38,183 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:38,189 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:38,190 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:38
2020-12-03 07:20:38,195 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:38,196 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:38,198 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:38,199 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:38,222 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:38,223 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:38,230 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:38,230 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:38,231 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:38,231 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:38,232 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:38,233 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:38,233 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:38,234 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:38,234 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:38,234 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:38,235 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:38,285 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:38,285 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:38,286 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:38,286 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:38,313 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:38,313 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:38,314 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:38,314 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:38,320 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:38,321 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:38,321 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:38,322 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:38,328 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:38,331 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:38,336 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:38,336 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:38,337 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:38,337 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:38,346 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:38,346 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:38,346 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:38,352 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:38,353 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:38,356 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:38,356 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:38,356 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:38,357 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:38,404 [Thread-0] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:38,485 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:38,536 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:38,577 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:38,579 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:38,755 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:38,755 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:38,842 [Thread-0] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:38,846 [Thread-0] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:39,001 [Thread-0] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:39,423 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:39,424 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:39,475 [Thread-0] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:39,527 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e8825d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:39,542 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:39,547 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:39,562 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3507ms
2020-12-03 07:20:39,700 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:39,705 [Thread-0] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:39,706 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:39,722 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:39,726 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:39,726 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:39,727 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:39,761 [Thread-0] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:39,762 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:39,773 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39982
2020-12-03 07:20:39,776 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:39,850 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67026b22{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:39,852 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4dffa621{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:39,899 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c305066{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:39,912 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@660be5fc{HTTP/1.1,[http/1.1]}{localhost:39982}
2020-12-03 07:20:39,913 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @3858ms
2020-12-03 07:20:39,934 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:39,934 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:39,935 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:39,935 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:39,935 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:39,935 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:39,936 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:39,936 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:39,937 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:39,937 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:39,937 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:39,938 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:39,938 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:39
2020-12-03 07:20:39,939 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:39,939 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:39,939 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:39,939 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:39,949 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:39,950 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:39,951 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:39,951 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:39,952 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:39,952 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:39,952 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:39,952 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:39,953 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:39,953 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:39,953 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:39,954 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:39,954 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:39,955 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:39,955 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:39,955 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:39,956 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:39,969 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:39,970 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:39,970 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:39,970 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:39,971 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:39,971 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:39,971 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:39,971 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:39,972 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:39,972 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:39,976 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:39,976 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:39,977 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:39,977 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:39,977 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:39,978 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:39,978 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:39,978 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:39,979 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:40,026 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:40,060 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:40,064 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:40,065 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:40,066 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:40,066 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:40,103 [Thread-0] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:40,113 [Thread-0] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:40,113 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:40,120 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:40,121 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:40,246 [Thread-0] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:40,247 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 265 msecs
2020-12-03 07:20:40,467 [Thread-0] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:40,510 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:40,525 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:40,855 [Listener at localhost/43742] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43742 to access this namenode/service.
2020-12-03 07:20:40,860 [Listener at localhost/43742] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:40,879 [Listener at localhost/43742] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:40,892 [Listener at localhost/43742] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:40,893 [Listener at localhost/43742] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:40,893 [Listener at localhost/43742] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:40,894 [Listener at localhost/43742] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:40,899 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:40,899 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:40,899 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:40,899 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:40,900 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:40,900 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:20:40,938 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:40,938 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:40,945 [Listener at localhost/43742] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43742
2020-12-03 07:20:40,950 [Listener at localhost/43742] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:40,951 [Listener at localhost/43742] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:40,960 [Listener at localhost/43742] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:40,966 [CacheReplicationMonitor(1301918523)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:40,977 [Listener at localhost/43742] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:41,077 [Listener at localhost/43742] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:41,098 [Listener at localhost/43742] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:41,128 [Listener at localhost/43742] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:41,137 [Listener at localhost/43742] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:41,141 [Listener at localhost/43742] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:41,147 [Listener at localhost/43742] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:41,149 [Listener at localhost/43742] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:41,155 [Listener at localhost/43742] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:41,165 [Listener at localhost/43742] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35702
2020-12-03 07:20:41,168 [Listener at localhost/43742] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:41,169 [Listener at localhost/43742] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:41,195 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:41,197 [Listener at localhost/43742] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:41,197 [Listener at localhost/43742] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:41,198 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:41,200 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:41,201 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:41,201 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:41,202 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:41,205 [Listener at localhost/43742] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41744
2020-12-03 07:20:41,206 [Listener at localhost/43742] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:41,207 [Listener at localhost/43742] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ad60e61{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:41,208 [Listener at localhost/43742] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51d8eddf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:41,215 [Listener at localhost/43742] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55dd8950{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:41,217 [Listener at localhost/43742] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@82b089e{HTTP/1.1,[http/1.1]}{localhost:41744}
2020-12-03 07:20:41,218 [Listener at localhost/43742] INFO  server.Server (Server.java:doStart(419)) - Started @5163ms
2020-12-03 07:20:41,537 [Listener at localhost/43742] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42120
2020-12-03 07:20:41,537 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e8eeb47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:41,539 [Listener at localhost/43742] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:41,539 [Listener at localhost/43742] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:41,825 [Listener at localhost/43742] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:41,827 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:41,845 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40851
2020-12-03 07:20:41,866 [Listener at localhost/40851] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:41,868 [Listener at localhost/40851] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:41,883 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:41,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:41,891 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:41,900 [Listener at localhost/40851] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:41,902 [Listener at localhost/40851] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:41,903 [Listener at localhost/40851] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:41,918 [Listener at localhost/40851] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:41,919 [Listener at localhost/40851] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:41,919 [Listener at localhost/40851] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:41,920 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:41,920 [Listener at localhost/40851] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:41,921 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:41,922 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37039
2020-12-03 07:20:41,922 [Listener at localhost/40851] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:41,922 [Listener at localhost/40851] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:41,924 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:41,927 [Listener at localhost/40851] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:41,927 [Listener at localhost/40851] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:41,928 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:41,930 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:41,931 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:41,931 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:41,932 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:41,933 [Listener at localhost/40851] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33326
2020-12-03 07:20:41,933 [Listener at localhost/40851] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:41,935 [Listener at localhost/40851] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40956612{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:41,936 [Listener at localhost/40851] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b850d00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:41,979 [Listener at localhost/40851] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a9a46d8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:41,980 [Listener at localhost/40851] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54f20b5f{HTTP/1.1,[http/1.1]}{localhost:33326}
2020-12-03 07:20:41,981 [Listener at localhost/40851] INFO  server.Server (Server.java:doStart(419)) - Started @5926ms
2020-12-03 07:20:42,142 [Listener at localhost/40851] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33497
2020-12-03 07:20:42,150 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,150 [Listener at localhost/40851] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,151 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e0fa37c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,152 [Listener at localhost/40851] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,154 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,176 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33034
2020-12-03 07:20:42,183 [Listener at localhost/33034] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,189 [Listener at localhost/33034] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,190 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,201 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,212 [Listener at localhost/33034] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:42,215 [Listener at localhost/33034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:42,215 [Listener at localhost/33034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:42,218 [Listener at localhost/33034] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,218 [Listener at localhost/33034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,219 [Listener at localhost/33034] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,219 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,219 [Listener at localhost/33034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,220 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,221 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45689
2020-12-03 07:20:42,221 [Listener at localhost/33034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,221 [Listener at localhost/33034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,223 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,225 [Listener at localhost/33034] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,227 [Listener at localhost/33034] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,227 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,246 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,266 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,269 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,269 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,271 [Listener at localhost/33034] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45833
2020-12-03 07:20:42,272 [Listener at localhost/33034] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,276 [Listener at localhost/33034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@128bdb05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,279 [Listener at localhost/33034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29a009cf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,286 [Listener at localhost/33034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d9b2e59{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,288 [Listener at localhost/33034] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f22dd3b{HTTP/1.1,[http/1.1]}{localhost:45833}
2020-12-03 07:20:42,289 [Listener at localhost/33034] INFO  server.Server (Server.java:doStart(419)) - Started @6234ms
2020-12-03 07:20:42,308 [Listener at localhost/33034] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34326
2020-12-03 07:20:42,308 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,308 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42a20c17] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,308 [Listener at localhost/33034] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,309 [Listener at localhost/33034] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,310 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,315 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38200
2020-12-03 07:20:42,326 [Listener at localhost/38200] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,326 [Listener at localhost/38200] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,327 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,333 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,333 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,353 [Listener at localhost/38200] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:42,355 [Listener at localhost/38200] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:42,356 [Listener at localhost/38200] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:42,359 [Listener at localhost/38200] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,361 [Listener at localhost/38200] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,364 [Listener at localhost/38200] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,364 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,364 [Listener at localhost/38200] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,365 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,366 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46225
2020-12-03 07:20:42,366 [Listener at localhost/38200] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,366 [Listener at localhost/38200] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,370 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,372 [Listener at localhost/38200] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,373 [Listener at localhost/38200] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,373 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,376 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,378 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,378 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,378 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,379 [Listener at localhost/38200] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33725
2020-12-03 07:20:42,380 [Listener at localhost/38200] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,384 [Listener at localhost/38200] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fc393e1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,385 [Listener at localhost/38200] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fa32594{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,395 [Listener at localhost/38200] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b8a810{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,396 [Listener at localhost/38200] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d6530b5{HTTP/1.1,[http/1.1]}{localhost:33725}
2020-12-03 07:20:42,397 [Listener at localhost/38200] INFO  server.Server (Server.java:doStart(419)) - Started @6342ms
2020-12-03 07:20:42,509 [Listener at localhost/38200] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39098
2020-12-03 07:20:42,510 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73f93107] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,510 [Listener at localhost/38200] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,511 [Listener at localhost/38200] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,512 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,517 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41354
2020-12-03 07:20:42,524 [Listener at localhost/41354] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,525 [Listener at localhost/41354] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,526 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,531 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,536 [Listener at localhost/41354] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:42,538 [Listener at localhost/41354] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:42,539 [Listener at localhost/41354] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:42,541 [Listener at localhost/41354] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,541 [Listener at localhost/41354] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,542 [Listener at localhost/41354] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,544 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,544 [Listener at localhost/41354] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,545 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,546 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38087
2020-12-03 07:20:42,546 [Listener at localhost/41354] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,546 [Listener at localhost/41354] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,548 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,551 [Listener at localhost/41354] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,552 [Listener at localhost/41354] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,552 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,552 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,553 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,553 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,556 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,557 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,557 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,557 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,557 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,558 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,559 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,559 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,559 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,560 [Listener at localhost/41354] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33139
2020-12-03 07:20:42,561 [Listener at localhost/41354] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,564 [Listener at localhost/41354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@de5dae3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,565 [Listener at localhost/41354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6360d154{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,571 [Listener at localhost/41354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44246bbe{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,572 [Listener at localhost/41354] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@466b494f{HTTP/1.1,[http/1.1]}{localhost:33139}
2020-12-03 07:20:42,573 [Listener at localhost/41354] INFO  server.Server (Server.java:doStart(419)) - Started @6519ms
2020-12-03 07:20:42,589 [Listener at localhost/41354] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42907
2020-12-03 07:20:42,591 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,591 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64bb78b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,591 [Listener at localhost/41354] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,592 [Listener at localhost/41354] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,593 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,597 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41390
2020-12-03 07:20:42,601 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,601 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,601 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,603 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,615 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0c93847c-8e34-43eb-8021-0fd84554c690 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:42,601 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,617 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,617 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-60c044a7-3204-45ca-a351-a573aa6ea615 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:42,604 [Listener at localhost/41390] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,603 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,622 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-12411823-7732-4561-91e7-6fe103839f26 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:42,603 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,623 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-adfa01be-3413-4228-81c8-bf207c9149ee for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:42,622 [Listener at localhost/41390] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,625 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,638 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,638 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,652 [Listener at localhost/41390] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:42,654 [Listener at localhost/41390] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:42,654 [Listener at localhost/41390] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:42,669 [Listener at localhost/41390] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,669 [Listener at localhost/41390] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,669 [Listener at localhost/41390] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,670 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,670 [Listener at localhost/41390] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,671 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,671 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37433
2020-12-03 07:20:42,672 [Listener at localhost/41390] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,672 [Listener at localhost/41390] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,737 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,739 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,740 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,742 [Listener at localhost/41390] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,743 [Listener at localhost/41390] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,743 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,745 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,746 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,747 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,747 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,748 [Listener at localhost/41390] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42579
2020-12-03 07:20:42,748 [Listener at localhost/41390] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,750 [Listener at localhost/41390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8548075{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,751 [Listener at localhost/41390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a833c6d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,760 [Listener at localhost/41390] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@578beada{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,762 [Listener at localhost/41390] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6acad585{HTTP/1.1,[http/1.1]}{localhost:42579}
2020-12-03 07:20:42,762 [Listener at localhost/41390] INFO  server.Server (Server.java:doStart(419)) - Started @6708ms
2020-12-03 07:20:42,774 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,774 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,775 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2460861a-d19c-405c-a815-b8d4a4882cad for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:42,779 [Listener at localhost/41390] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37891
2020-12-03 07:20:42,779 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dc066d9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,779 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,780 [Listener at localhost/41390] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,780 [Listener at localhost/41390] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,781 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,785 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45466
2020-12-03 07:20:42,789 [Listener at localhost/45466] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,790 [Listener at localhost/45466] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,791 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,793 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,800 [Listener at localhost/45466] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:42,802 [Listener at localhost/45466] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:42,803 [Listener at localhost/45466] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:42,804 [Listener at localhost/45466] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,806 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,806 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,807 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,807 [Listener at localhost/45466] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,807 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,807 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,822 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,822 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,822 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-564a2870-26e3-40b4-984d-67f7a5a0d798 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:42,822 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:42,823 [Listener at localhost/45466] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,821 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,823 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,823 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,821 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,823 [Listener at localhost/45466] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,824 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,823 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-99210ad9-1119-45fb-b961-07366c288cd3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:42,824 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0af8b64e-afba-4f98-8651-e61bc7cda735 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:42,825 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42392
2020-12-03 07:20:42,825 [Listener at localhost/45466] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,825 [Listener at localhost/45466] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,827 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,828 [Listener at localhost/45466] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,829 [Listener at localhost/45466] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,829 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,831 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,832 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,832 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,833 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,833 [Listener at localhost/45466] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43877
2020-12-03 07:20:42,834 [Listener at localhost/45466] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,835 [Listener at localhost/45466] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@587a26d1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,836 [Listener at localhost/45466] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43a0a6f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,851 [Listener at localhost/45466] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3735f996{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,852 [Listener at localhost/45466] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@214b538d{HTTP/1.1,[http/1.1]}{localhost:43877}
2020-12-03 07:20:42,853 [Listener at localhost/45466] INFO  server.Server (Server.java:doStart(419)) - Started @6798ms
2020-12-03 07:20:42,876 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:42,877 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:42,877 [Listener at localhost/45466] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40563
2020-12-03 07:20:42,877 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d53db321-0c3d-4d08-84ea-41e40537cd31 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:42,877 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f67c5aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:42,877 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:42,878 [Listener at localhost/45466] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:42,878 [Listener at localhost/45466] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:42,879 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:42,884 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36193
2020-12-03 07:20:42,890 [Listener at localhost/36193] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:42,890 [Listener at localhost/36193] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:42,891 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:42,894 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:42,894 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:42,919 [Listener at localhost/36193] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:42,925 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:42,927 [Listener at localhost/36193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:42,928 [Listener at localhost/36193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:42,930 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:42,931 [Listener at localhost/36193] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:42,931 [Listener at localhost/36193] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,932 [Listener at localhost/36193] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:42,932 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:42,932 [Listener at localhost/36193] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:42,933 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:42,934 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42029
2020-12-03 07:20:42,934 [Listener at localhost/36193] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:42,934 [Listener at localhost/36193] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:42,937 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,938 [Listener at localhost/36193] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:42,939 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:42,939 [Listener at localhost/36193] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:42,939 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:42,939 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:42,942 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:42,942 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:42,947 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:42,948 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:42,948 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:42,949 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:42,950 [Listener at localhost/36193] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38100
2020-12-03 07:20:42,951 [Listener at localhost/36193] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:42,953 [Listener at localhost/36193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@666b16ba{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:42,955 [Listener at localhost/36193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3542cfea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:42,969 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:42,970 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:42,970 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:42,970 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:42,972 [Listener at localhost/36193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2b7322dc{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:42,973 [Listener at localhost/36193] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@396d5941{HTTP/1.1,[http/1.1]}{localhost:38100}
2020-12-03 07:20:42,974 [Listener at localhost/36193] INFO  server.Server (Server.java:doStart(419)) - Started @6919ms
2020-12-03 07:20:43,014 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,014 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,015 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9a63d75c-72da-4dc3-9085-1d68c845f80e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:43,045 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,046 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,046 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-93571342-50b7-4feb-a300-0b796a6c2b84 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:43,066 [Listener at localhost/36193] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41374
2020-12-03 07:20:43,068 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,068 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,069 [Listener at localhost/36193] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,069 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,069 [Listener at localhost/36193] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,068 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,069 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,070 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,069 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d4ea5d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,070 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,071 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,071 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,071 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,087 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44949
2020-12-03 07:20:43,095 [Listener at localhost/44949] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,096 [Listener at localhost/44949] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,096 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,102 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,106 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,106 [Listener at localhost/44949] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:43,108 [Listener at localhost/44949] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:43,109 [Listener at localhost/44949] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:43,110 [Listener at localhost/44949] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,111 [Listener at localhost/44949] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,111 [Listener at localhost/44949] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,112 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,112 [Listener at localhost/44949] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,112 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,113 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35616
2020-12-03 07:20:43,114 [Listener at localhost/44949] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,114 [Listener at localhost/44949] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,115 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,117 [Listener at localhost/44949] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,118 [Listener at localhost/44949] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,118 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,115 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,120 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,121 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,121 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,122 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,123 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,123 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,123 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,123 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d0ec2253-f82f-4911-b608-2ae12a422ebe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:43,124 [Listener at localhost/44949] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46413
2020-12-03 07:20:43,124 [Listener at localhost/44949] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,128 [Listener at localhost/44949] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65f5c7f2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,129 [Listener at localhost/44949] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3de07f87{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,186 [Listener at localhost/44949] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@19fa8f8c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,188 [Listener at localhost/44949] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@8d06c0f{HTTP/1.1,[http/1.1]}{localhost:46413}
2020-12-03 07:20:43,206 [Listener at localhost/44949] INFO  server.Server (Server.java:doStart(419)) - Started @7134ms
2020-12-03 07:20:43,213 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,214 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,216 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,218 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,218 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,219 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,217 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:43,269 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,275 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,278 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,279 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:43,280 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,280 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,280 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,287 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,287 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,290 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,296 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,296 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,296 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,299 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,299 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,301 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,301 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,302 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,302 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,305 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,312 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,312 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,312 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,332 [Listener at localhost/44949] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39136
2020-12-03 07:20:43,333 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,333 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e5001b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,333 [Listener at localhost/44949] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,338 [Listener at localhost/44949] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,339 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,347 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40775
2020-12-03 07:20:43,357 [Listener at localhost/40775] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,359 [Listener at localhost/40775] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,361 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,398 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,400 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,406 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,405 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,411 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,402 [Listener at localhost/40775] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:43,411 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,411 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,414 [Listener at localhost/40775] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:43,415 [Listener at localhost/40775] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:43,416 [Listener at localhost/40775] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,417 [Listener at localhost/40775] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,417 [Listener at localhost/40775] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,418 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,418 [Listener at localhost/40775] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,418 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,419 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39275
2020-12-03 07:20:43,419 [Listener at localhost/40775] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,419 [Listener at localhost/40775] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,420 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,422 [Listener at localhost/40775] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,423 [Listener at localhost/40775] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,423 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,423 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,424 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,424 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,424 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,425 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,425 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,426 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,426 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,430 [Listener at localhost/40775] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37484
2020-12-03 07:20:43,431 [Listener at localhost/40775] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,449 [Listener at localhost/40775] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6fc5a79f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,457 [Listener at localhost/40775] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21b577d9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,470 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,471 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,471 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d55537a9-9314-487a-b0ec-d6b4a3198b88 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:43,478 [Listener at localhost/40775] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@261dbd6d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,478 [Listener at localhost/40775] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3fe08823{HTTP/1.1,[http/1.1]}{localhost:37484}
2020-12-03 07:20:43,493 [Listener at localhost/40775] INFO  server.Server (Server.java:doStart(419)) - Started @7438ms
2020-12-03 07:20:43,500 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,500 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,500 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,502 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,502 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:20:43,502 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,503 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,503 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,509 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,509 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,509 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,509 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,514 [Listener at localhost/40775] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40533
2020-12-03 07:20:43,515 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5be0f78c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,515 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,515 [Listener at localhost/40775] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,516 [Listener at localhost/40775] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,516 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,521 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45700
2020-12-03 07:20:43,527 [Listener at localhost/45700] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,527 [Listener at localhost/45700] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,528 [Thread-260] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,530 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,533 [Thread-260] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,541 [Listener at localhost/45700] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:20:43,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,542 [Thread-260] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,543 [Listener at localhost/45700] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:20:43,544 [Listener at localhost/45700] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:20:43,545 [Listener at localhost/45700] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,545 [Listener at localhost/45700] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,545 [Listener at localhost/45700] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,546 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,546 [Listener at localhost/45700] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,546 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,555 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34357
2020-12-03 07:20:43,555 [Listener at localhost/45700] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,555 [Listener at localhost/45700] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,556 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,558 [Listener at localhost/45700] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,558 [Listener at localhost/45700] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,558 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,560 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,561 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,561 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,561 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,562 [Listener at localhost/45700] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46783
2020-12-03 07:20:43,562 [Listener at localhost/45700] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,563 [Listener at localhost/45700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@344001ba{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,564 [Listener at localhost/45700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3462d9bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,575 [Listener at localhost/45700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5fd04f93{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,576 [Listener at localhost/45700] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@569dc84c{HTTP/1.1,[http/1.1]}{localhost:46783}
2020-12-03 07:20:43,576 [Listener at localhost/45700] INFO  server.Server (Server.java:doStart(419)) - Started @7522ms
2020-12-03 07:20:43,602 [Listener at localhost/45700] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44899
2020-12-03 07:20:43,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75685b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,603 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,603 [Listener at localhost/45700] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,604 [Listener at localhost/45700] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,604 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,609 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45995
2020-12-03 07:20:43,616 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f87e3368-f0ec-4a0e-b68b-67e021ee5858
2020-12-03 07:20:43,617 [Listener at localhost/45995] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,617 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9ffb508b-a1fc-4440-913c-788ca9bd6d31
2020-12-03 07:20:43,617 [Listener at localhost/45995] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,617 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7359969d-12ff-4604-b1dd-72e4f6d19ed1
2020-12-03 07:20:43,617 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,618 [Thread-282] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,618 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,626 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,628 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e03ad099-8ae8-440d-bf93-1919d0e4c949 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:20:43,629 [Listener at localhost/45995] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 11 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24
2020-12-03 07:20:43,629 [Thread-282] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,631 [Thread-282] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,632 [Listener at localhost/45995] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23
2020-12-03 07:20:43,633 [Listener at localhost/45995] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24
2020-12-03 07:20:43,637 [Listener at localhost/45995] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,638 [Listener at localhost/45995] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,638 [Listener at localhost/45995] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,638 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,638 [Listener at localhost/45995] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,639 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,640 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38420
2020-12-03 07:20:43,640 [Listener at localhost/45995] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,640 [Listener at localhost/45995] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,641 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,647 [Listener at localhost/45995] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,647 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,648 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,648 [Listener at localhost/45995] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,648 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,648 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,648 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,654 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,655 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,655 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,655 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,656 [Listener at localhost/45995] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38666
2020-12-03 07:20:43,656 [Listener at localhost/45995] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,658 [Listener at localhost/45995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ef94491{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,658 [Listener at localhost/45995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21c8e86{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,665 [Listener at localhost/45995] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3fd5ff1c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,666 [Listener at localhost/45995] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26a471d{HTTP/1.1,[http/1.1]}{localhost:38666}
2020-12-03 07:20:43,667 [Listener at localhost/45995] INFO  server.Server (Server.java:doStart(419)) - Started @7612ms
2020-12-03 07:20:43,694 [Listener at localhost/45995] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33539
2020-12-03 07:20:43,695 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,695 [Listener at localhost/45995] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,696 [Listener at localhost/45995] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,697 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b72c63c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,697 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,709 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,709 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,709 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:43,709 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:43,710 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46765
2020-12-03 07:20:43,721 [Listener at localhost/46765] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,722 [Listener at localhost/46765] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,722 [Thread-304] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,728 [Thread-304] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,732 [Thread-304] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,732 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,732 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,737 [Listener at localhost/46765] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 12 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26
2020-12-03 07:20:43,738 [Listener at localhost/46765] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25
2020-12-03 07:20:43,739 [Listener at localhost/46765] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26
2020-12-03 07:20:43,740 [Listener at localhost/46765] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,742 [Listener at localhost/46765] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,742 [Listener at localhost/46765] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,742 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,743 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4f10650e-50f8-4175-8f23-c134bf995968
2020-12-03 07:20:43,743 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,743 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,743 [Listener at localhost/46765] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,744 [Thread-282] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,744 [Thread-282] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,744 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,745 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36480
2020-12-03 07:20:43,746 [Listener at localhost/46765] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,746 [Listener at localhost/46765] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,749 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,750 [Thread-282] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3380f552-e47a-4033-ab27-3be3ff9125ea for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-12-03 07:20:43,757 [Listener at localhost/46765] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,758 [Listener at localhost/46765] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,758 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,761 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,762 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,762 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,762 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,763 [Listener at localhost/46765] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40556
2020-12-03 07:20:43,764 [Listener at localhost/46765] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,766 [Listener at localhost/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c33d741{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,766 [Listener at localhost/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51701891{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,773 [Listener at localhost/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@45011f4c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,776 [Listener at localhost/46765] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bc33152{HTTP/1.1,[http/1.1]}{localhost:40556}
2020-12-03 07:20:43,776 [Listener at localhost/46765] INFO  server.Server (Server.java:doStart(419)) - Started @7722ms
2020-12-03 07:20:43,806 [Listener at localhost/46765] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39302
2020-12-03 07:20:43,807 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,807 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f2e19aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,807 [Listener at localhost/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,808 [Listener at localhost/46765] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,810 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:43,815 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:32913
2020-12-03 07:20:43,826 [Listener at localhost/32913] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:43,826 [Listener at localhost/32913] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:43,827 [Thread-326] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:43,832 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:43,835 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:43,835 [Thread-326] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:43,839 [Thread-326] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:43,843 [Thread-304] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,843 [Thread-304] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,844 [Thread-304] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23 
2020-12-03 07:20:43,844 [Listener at localhost/32913] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 13 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28
2020-12-03 07:20:43,846 [Listener at localhost/32913] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27
2020-12-03 07:20:43,846 [Listener at localhost/32913] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28
2020-12-03 07:20:43,848 [Listener at localhost/32913] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:43,849 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-adfa01be-3413-4228-81c8-bf207c9149ee
2020-12-03 07:20:43,851 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0c93847c-8e34-43eb-8021-0fd84554c690
2020-12-03 07:20:43,852 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:43,852 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:43,854 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-12411823-7732-4561-91e7-6fe103839f26
2020-12-03 07:20:43,874 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:43,887 [Listener at localhost/32913] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,888 [Listener at localhost/32913] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:43,888 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:43,888 [Listener at localhost/32913] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:43,889 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:43,890 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44274
2020-12-03 07:20:43,890 [Listener at localhost/32913] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:43,890 [Listener at localhost/32913] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:43,892 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,894 [Listener at localhost/32913] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:43,895 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-60c044a7-3204-45ca-a351-a573aa6ea615
2020-12-03 07:20:43,896 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:43,896 [Listener at localhost/32913] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:43,898 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:43,899 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2460861a-d19c-405c-a815-b8d4a4882cad
2020-12-03 07:20:43,899 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:43,896 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0af8b64e-afba-4f98-8651-e61bc7cda735
2020-12-03 07:20:43,900 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:43,900 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:43,901 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-564a2870-26e3-40b4-984d-67f7a5a0d798
2020-12-03 07:20:43,901 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:43,905 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-99210ad9-1119-45fb-b961-07366c288cd3
2020-12-03 07:20:43,906 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:43,906 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:43,907 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:43,909 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:43,909 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:43,909 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:43,910 [Listener at localhost/32913] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41438
2020-12-03 07:20:43,910 [Listener at localhost/32913] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:43,912 [Thread-326] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,912 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:43,912 [Listener at localhost/32913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77452206{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:43,913 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:43,913 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,913 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:43,913 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:43,913 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f56f340a-e0ea-4edb-a9bd-499891b439f4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:20:43,914 [Listener at localhost/32913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d012249{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:43,913 [Thread-326] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:43,914 [Thread-326] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25 
2020-12-03 07:20:43,918 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:43,917 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:43,919 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:43,931 [Listener at localhost/32913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43029ddb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:43,937 [Listener at localhost/32913] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@667feb57{HTTP/1.1,[http/1.1]}{localhost:41438}
2020-12-03 07:20:43,938 [Listener at localhost/32913] INFO  server.Server (Server.java:doStart(419)) - Started @7884ms
2020-12-03 07:20:43,950 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:43,952 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:43,950 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:43,950 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:43,954 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:43,954 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:43,954 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:43,954 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:43,961 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:43,962 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,962 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,962 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:43,962 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:43,962 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:43,963 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,964 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:43,964 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:43,964 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:43,965 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:43,965 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:43,967 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:43,969 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:43,972 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:43,973 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:43,973 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:43,981 [Listener at localhost/32913] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40190
2020-12-03 07:20:43,982 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1968f9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:43,982 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:43,983 [Listener at localhost/32913] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:43,984 [Listener at localhost/32913] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:43,985 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:44,003 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,004 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,004 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,004 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,006 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40180
2020-12-03 07:20:44,015 [Listener at localhost/40180] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:44,015 [Listener at localhost/40180] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:44,016 [Thread-364] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742 starting to offer service
2020-12-03 07:20:44,020 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:44,020 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:44,034 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ecfa2f1c-1975-41e8-b946-b05fd9e94841
2020-12-03 07:20:44,034 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,034 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,051 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1d42abd3-ac8d-4471-90b2-9b417baa6db1
2020-12-03 07:20:44,051 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:20:44,070 [Thread-364] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43742
2020-12-03 07:20:44,071 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d53db321-0c3d-4d08-84ea-41e40537cd31
2020-12-03 07:20:44,072 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:44,080 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43
2020-12-03 07:20:44,080 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:44,082 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-93571342-50b7-4feb-a300-0b796a6c2b84
2020-12-03 07:20:44,082 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:44,082 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d0ec2253-f82f-4911-b608-2ae12a422ebe
2020-12-03 07:20:44,082 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:44,082 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:44,083 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:44,099 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 135ms
2020-12-03 07:20:44,100 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:44,100 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:44,101 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:44,101 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:44,101 [Thread-364] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:44,101 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,102 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:44,102 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:44,105 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:44,106 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:44,106 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:44,106 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:44,108 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 135ms
2020-12-03 07:20:44,113 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 142ms
2020-12-03 07:20:44,116 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 151ms
2020-12-03 07:20:44,119 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,120 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 155ms
2020-12-03 07:20:44,120 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:44,121 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:44,123 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 159ms
2020-12-03 07:20:44,127 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:44,127 [Thread-392] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,129 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 2ms
2020-12-03 07:20:44,223 [Thread-304] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,223 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,223 [Thread-282] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,223 [Thread-282] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,224 [Thread-282] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-12-03 07:20:44,223 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b2b4aee8-f14a-4214-9204-d7d6e6b80c6a
2020-12-03 07:20:44,223 [Thread-364] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,223 [Thread-304] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,224 [Thread-364] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,224 [Thread-304] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24 
2020-12-03 07:20:44,244 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 279ms
2020-12-03 07:20:44,244 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 282ms
2020-12-03 07:20:44,260 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:44,260 [Thread-391] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,263 [Thread-364] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e2a42c5d-7440-4deb-ba1b-27e69712399e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27 
2020-12-03 07:20:44,264 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 4ms
2020-12-03 07:20:44,264 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 139ms
2020-12-03 07:20:44,265 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:44,265 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,267 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:20:44,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:44,267 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9a63d75c-72da-4dc3-9085-1d68c845f80e
2020-12-03 07:20:44,275 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:44,297 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-60c044a7-3204-45ca-a351-a573aa6ea615): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,299 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 197ms
2020-12-03 07:20:44,275 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:44,300 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2460861a-d19c-405c-a815-b8d4a4882cad): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,302 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e
2020-12-03 07:20:44,302 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:44,303 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:44,284 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,280 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 306ms
2020-12-03 07:20:44,276 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 305ms
2020-12-03 07:20:44,320 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,276 [Thread-398] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:44,320 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,321 [Thread-398] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,321 [Thread-398] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:20:44,321 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 76ms
2020-12-03 07:20:44,321 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,322 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:44,321 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 349ms
2020-12-03 07:20:44,333 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:44,333 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 362ms
2020-12-03 07:20:44,332 [Thread-326] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,334 [Thread-326] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,334 [Thread-326] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-02779bd4-5a16-47bf-b763-6bf98ed80273 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26 
2020-12-03 07:20:44,322 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:44,335 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:44,334 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:44,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-99210ad9-1119-45fb-b961-07366c288cd3): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0c93847c-8e34-43eb-8021-0fd84554c690): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,345 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 224ms
2020-12-03 07:20:44,346 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 226ms
2020-12-03 07:20:44,345 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:44,347 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:44,358 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:44,351 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:44,351 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:44,351 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 232ms
2020-12-03 07:20:44,347 [Thread-405] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,359 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,359 [Thread-408] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,359 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,360 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 12ms
2020-12-03 07:20:44,358 [Thread-407] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,359 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 257ms
2020-12-03 07:20:44,361 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:44,362 [Thread-411] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:44,362 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 4ms
2020-12-03 07:20:44,362 [Thread-409] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,361 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 260ms
2020-12-03 07:20:44,362 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:44,362 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:20:44,363 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:44,364 [Thread-410] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:44,364 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 5ms
2020-12-03 07:20:44,364 [Thread-410] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,364 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 31ms
2020-12-03 07:20:44,365 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:44,365 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:44,374 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:44,371 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:44,371 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0af8b64e-afba-4f98-8651-e61bc7cda735): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,371 [Thread-410] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 7ms
2020-12-03 07:20:44,385 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 26ms
2020-12-03 07:20:44,386 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:44,386 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:44,371 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 37ms
2020-12-03 07:20:44,386 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d0ec2253-f82f-4911-b608-2ae12a422ebe): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,383 [Thread-414] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,387 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 4ms
2020-12-03 07:20:44,383 [Thread-413] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:44,403 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-adfa01be-3413-4228-81c8-bf207c9149ee): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,403 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 26ms
2020-12-03 07:20:44,393 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:44,386 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-d53db321-0c3d-4d08-84ea-41e40537cd31): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,413 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-12411823-7732-4561-91e7-6fe103839f26): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,408 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 45ms
2020-12-03 07:20:44,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:44,403 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-564a2870-26e3-40b4-984d-67f7a5a0d798): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-93571342-50b7-4feb-a300-0b796a6c2b84): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,415 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:44,416 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:44,417 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2460861a-d19c-405c-a815-b8d4a4882cad): no suitable block pools found to scan.  Waiting 1814399850 ms.
2020-12-03 07:20:44,418 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-60c044a7-3204-45ca-a351-a573aa6ea615): no suitable block pools found to scan.  Waiting 1814399849 ms.
2020-12-03 07:20:44,418 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d0ec2253-f82f-4911-b608-2ae12a422ebe): no suitable block pools found to scan.  Waiting 1814399967 ms.
2020-12-03 07:20:44,418 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-99210ad9-1119-45fb-b961-07366c288cd3): no suitable block pools found to scan.  Waiting 1814399904 ms.
2020-12-03 07:20:44,418 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,418 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-12411823-7732-4561-91e7-6fe103839f26): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:44,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0af8b64e-afba-4f98-8651-e61bc7cda735): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:20:44,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0c93847c-8e34-43eb-8021-0fd84554c690): no suitable block pools found to scan.  Waiting 1814399902 ms.
2020-12-03 07:20:44,422 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-d53db321-0c3d-4d08-84ea-41e40537cd31): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:20:44,422 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-564a2870-26e3-40b4-984d-67f7a5a0d798): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:20:44,423 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-93571342-50b7-4feb-a300-0b796a6c2b84): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-12-03 07:20:44,425 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-adfa01be-3413-4228-81c8-bf207c9149ee): no suitable block pools found to scan.  Waiting 1814399940 ms.
2020-12-03 07:20:44,425 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 62ms
2020-12-03 07:20:44,432 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:58 PM with interval of 21600000ms
2020-12-03 07:20:44,434 [Thread-411] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 72ms
2020-12-03 07:20:44,436 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 77ms
2020-12-03 07:20:44,439 [Thread-426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:44,439 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:44,439 [Thread-426] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,439 [Thread-427] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,439 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,439 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:20:44,439 [Thread-426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-12-03 07:20:44,432 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:00 AM with interval of 21600000ms
2020-12-03 07:20:44,432 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:10 AM with interval of 21600000ms
2020-12-03 07:20:44,432 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:01 AM with interval of 21600000ms
2020-12-03 07:20:44,432 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:23 AM with interval of 21600000ms
2020-12-03 07:20:44,457 [Thread-304] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,458 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,458 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,461 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 25ms
2020-12-03 07:20:44,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:44,432 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:21 AM with interval of 21600000ms
2020-12-03 07:20:44,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9a63d75c-72da-4dc3-9085-1d68c845f80e): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:44,464 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,465 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7359969d-12ff-4604-b1dd-72e4f6d19ed1) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,463 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:55 AM with interval of 21600000ms
2020-12-03 07:20:44,466 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 1d42abd3-ac8d-4471-90b2-9b417baa6db1) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,465 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:44,464 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9a63d75c-72da-4dc3-9085-1d68c845f80e): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:44,469 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 4f10650e-50f8-4175-8f23-c134bf995968) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,469 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid ecfa2f1c-1975-41e8-b946-b05fd9e94841) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,469 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9ffb508b-a1fc-4440-913c-788ca9bd6d31) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,472 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid f87e3368-f0ec-4a0e-b68b-67e021ee5858) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,472 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid b2b4aee8-f14a-4214-9204-d7d6e6b80c6a) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,480 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9b9d7152-8d8f-4103-b81f-c86be6562af0
2020-12-03 07:20:44,482 [IPC Server handler 2 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37433, datanodeUuid=ecfa2f1c-1975-41e8-b946-b05fd9e94841, infoPort=37891, infoSecurePort=0, ipcPort=45466, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage ecfa2f1c-1975-41e8-b946-b05fd9e94841
2020-12-03 07:20:44,484 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93
2020-12-03 07:20:44,486 [IPC Server handler 2 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37433
2020-12-03 07:20:44,486 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:44,486 [IPC Server handler 2 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ecfa2f1c-1975-41e8-b946-b05fd9e94841 (127.0.0.1:37433).
2020-12-03 07:20:44,488 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d55537a9-9314-487a-b0ec-d6b4a3198b88
2020-12-03 07:20:44,488 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:44,489 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:44,490 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:44,490 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:44,490 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:44,491 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:44,491 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,491 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:44,491 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:44,492 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,493 [Thread-282] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,493 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,493 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,510 [IPC Server handler 0 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45689, datanodeUuid=9ffb508b-a1fc-4440-913c-788ca9bd6d31, infoPort=34326, infoSecurePort=0, ipcPort=38200, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 9ffb508b-a1fc-4440-913c-788ca9bd6d31
2020-12-03 07:20:44,511 [IPC Server handler 0 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45689
2020-12-03 07:20:44,511 [IPC Server handler 0 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9ffb508b-a1fc-4440-913c-788ca9bd6d31 (127.0.0.1:45689).
2020-12-03 07:20:44,512 [IPC Server handler 3 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46225, datanodeUuid=f87e3368-f0ec-4a0e-b68b-67e021ee5858, infoPort=39098, infoSecurePort=0, ipcPort=41354, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage f87e3368-f0ec-4a0e-b68b-67e021ee5858
2020-12-03 07:20:44,512 [IPC Server handler 3 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46225
2020-12-03 07:20:44,512 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f87e3368-f0ec-4a0e-b68b-67e021ee5858 (127.0.0.1:46225).
2020-12-03 07:20:44,513 [IPC Server handler 6 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37039, datanodeUuid=7359969d-12ff-4604-b1dd-72e4f6d19ed1, infoPort=33497, infoSecurePort=0, ipcPort=33034, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 7359969d-12ff-4604-b1dd-72e4f6d19ed1
2020-12-03 07:20:44,513 [IPC Server handler 6 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37039
2020-12-03 07:20:44,513 [IPC Server handler 6 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7359969d-12ff-4604-b1dd-72e4f6d19ed1 (127.0.0.1:37039).
2020-12-03 07:20:44,513 [IPC Server handler 9 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38087, datanodeUuid=1d42abd3-ac8d-4471-90b2-9b417baa6db1, infoPort=42907, infoSecurePort=0, ipcPort=41390, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 1d42abd3-ac8d-4471-90b2-9b417baa6db1
2020-12-03 07:20:44,514 [IPC Server handler 9 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38087
2020-12-03 07:20:44,514 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,514 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1d42abd3-ac8d-4471-90b2-9b417baa6db1 (127.0.0.1:38087).
2020-12-03 07:20:44,514 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,515 [IPC Server handler 4 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35702, datanodeUuid=4f10650e-50f8-4175-8f23-c134bf995968, infoPort=42120, infoSecurePort=0, ipcPort=40851, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 4f10650e-50f8-4175-8f23-c134bf995968
2020-12-03 07:20:44,515 [IPC Server handler 4 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35702
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid f87e3368-f0ec-4a0e-b68b-67e021ee5858) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7359969d-12ff-4604-b1dd-72e4f6d19ed1) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,515 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid ecfa2f1c-1975-41e8-b946-b05fd9e94841) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,515 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 1d42abd3-ac8d-4471-90b2-9b417baa6db1) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,515 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4f10650e-50f8-4175-8f23-c134bf995968 (127.0.0.1:35702).
2020-12-03 07:20:44,516 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,516 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,517 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 4f10650e-50f8-4175-8f23-c134bf995968) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,515 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,516 [IPC Server handler 8 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42392, datanodeUuid=b2b4aee8-f14a-4214-9204-d7d6e6b80c6a, infoPort=40563, infoSecurePort=0, ipcPort=36193, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage b2b4aee8-f14a-4214-9204-d7d6e6b80c6a
2020-12-03 07:20:44,516 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9ffb508b-a1fc-4440-913c-788ca9bd6d31) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,528 [IPC Server handler 8 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42392
2020-12-03 07:20:44,528 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,551 [IPC Server handler 8 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b2b4aee8-f14a-4214-9204-d7d6e6b80c6a (127.0.0.1:42392).
2020-12-03 07:20:44,551 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,556 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid b2b4aee8-f14a-4214-9204-d7d6e6b80c6a) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,557 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,581 [Thread-439] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 90ms
2020-12-03 07:20:44,586 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,586 [Thread-326] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,587 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,587 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,589 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 98ms
2020-12-03 07:20:44,589 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 98ms
2020-12-03 07:20:44,589 [Thread-364] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:44,590 [Thread-442] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:44,590 [Thread-364] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28 is not formatted for namespace 2101009238. Formatting...
2020-12-03 07:20:44,590 [Thread-442] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,590 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:44,590 [Thread-443] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,590 [Thread-442] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:44,600 [Thread-364] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28 
2020-12-03 07:20:44,603 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 13ms
2020-12-03 07:20:44,604 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 14ms
2020-12-03 07:20:44,605 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:20 AM with interval of 21600000ms
2020-12-03 07:20:44,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:44,607 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b9d7152-8d8f-4103-b81f-c86be6562af0) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:44,607 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:44,607 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,607 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d55537a9-9314-487a-b0ec-d6b4a3198b88): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-12-03 07:20:44,615 [IPC Server handler 7 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42029, datanodeUuid=9b9d7152-8d8f-4103-b81f-c86be6562af0, infoPort=41374, infoSecurePort=0, ipcPort=44949, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 9b9d7152-8d8f-4103-b81f-c86be6562af0
2020-12-03 07:20:44,616 [IPC Server handler 7 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42029
2020-12-03 07:20:44,616 [IPC Server handler 7 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9b9d7152-8d8f-4103-b81f-c86be6562af0 (127.0.0.1:42029).
2020-12-03 07:20:44,616 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d55537a9-9314-487a-b0ec-d6b4a3198b88): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-12-03 07:20:44,617 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b9d7152-8d8f-4103-b81f-c86be6562af0) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:44,617 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:44,620 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,621 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,621 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,621 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,641 [IPC Server handler 1 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c93847c-8e34-43eb-8021-0fd84554c690 for DN 127.0.0.1:45689
2020-12-03 07:20:44,642 [IPC Server handler 1 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-99210ad9-1119-45fb-b961-07366c288cd3 for DN 127.0.0.1:45689
2020-12-03 07:20:44,650 [IPC Server handler 5 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43 for DN 127.0.0.1:38087
2020-12-03 07:20:44,653 [IPC Server handler 5 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93571342-50b7-4feb-a300-0b796a6c2b84 for DN 127.0.0.1:38087
2020-12-03 07:20:44,654 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d53db321-0c3d-4d08-84ea-41e40537cd31 for DN 127.0.0.1:37433
2020-12-03 07:20:44,654 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d0ec2253-f82f-4911-b608-2ae12a422ebe for DN 127.0.0.1:37433
2020-12-03 07:20:44,655 [IPC Server handler 6 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-12411823-7732-4561-91e7-6fe103839f26 for DN 127.0.0.1:37039
2020-12-03 07:20:44,655 [IPC Server handler 6 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-564a2870-26e3-40b4-984d-67f7a5a0d798 for DN 127.0.0.1:37039
2020-12-03 07:20:44,658 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93 for DN 127.0.0.1:42029
2020-12-03 07:20:44,658 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d55537a9-9314-487a-b0ec-d6b4a3198b88 for DN 127.0.0.1:42029
2020-12-03 07:20:44,661 [IPC Server handler 0 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a63d75c-72da-4dc3-9085-1d68c845f80e for DN 127.0.0.1:42392
2020-12-03 07:20:44,661 [IPC Server handler 0 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e for DN 127.0.0.1:42392
2020-12-03 07:20:44,662 [IPC Server handler 2 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-60c044a7-3204-45ca-a351-a573aa6ea615 for DN 127.0.0.1:46225
2020-12-03 07:20:44,663 [IPC Server handler 2 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2460861a-d19c-405c-a815-b8d4a4882cad for DN 127.0.0.1:46225
2020-12-03 07:20:44,663 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-adfa01be-3413-4228-81c8-bf207c9149ee for DN 127.0.0.1:35702
2020-12-03 07:20:44,663 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0af8b64e-afba-4f98-8651-e61bc7cda735 for DN 127.0.0.1:35702
2020-12-03 07:20:44,668 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,668 [Thread-304] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,668 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,668 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,700 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,716 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xec7bd8013f3cbe51: Processing first storage report for DS-d53db321-0c3d-4d08-84ea-41e40537cd31 from datanode ecfa2f1c-1975-41e8-b946-b05fd9e94841
2020-12-03 07:20:44,717 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,717 [Thread-282] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,717 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,717 [Thread-282] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,719 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xec7bd8013f3cbe51: from storage DS-d53db321-0c3d-4d08-84ea-41e40537cd31 node DatanodeRegistration(127.0.0.1:37433, datanodeUuid=ecfa2f1c-1975-41e8-b946-b05fd9e94841, infoPort=37891, infoSecurePort=0, ipcPort=45466, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,720 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6263ede939a00d67: Processing first storage report for DS-12411823-7732-4561-91e7-6fe103839f26 from datanode 7359969d-12ff-4604-b1dd-72e4f6d19ed1
2020-12-03 07:20:44,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6263ede939a00d67: from storage DS-12411823-7732-4561-91e7-6fe103839f26 node DatanodeRegistration(127.0.0.1:37039, datanodeUuid=7359969d-12ff-4604-b1dd-72e4f6d19ed1, infoPort=33497, infoSecurePort=0, ipcPort=33034, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcd55b8c22aa9825d: Processing first storage report for DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43 from datanode 1d42abd3-ac8d-4471-90b2-9b417baa6db1
2020-12-03 07:20:44,721 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcd55b8c22aa9825d: from storage DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43 node DatanodeRegistration(127.0.0.1:38087, datanodeUuid=1d42abd3-ac8d-4471-90b2-9b417baa6db1, infoPort=42907, infoSecurePort=0, ipcPort=41390, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb4d0b3a40a1b0660: Processing first storage report for DS-99210ad9-1119-45fb-b961-07366c288cd3 from datanode 9ffb508b-a1fc-4440-913c-788ca9bd6d31
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4d0b3a40a1b0660: from storage DS-99210ad9-1119-45fb-b961-07366c288cd3 node DatanodeRegistration(127.0.0.1:45689, datanodeUuid=9ffb508b-a1fc-4440-913c-788ca9bd6d31, infoPort=34326, infoSecurePort=0, ipcPort=38200, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x48865910c8a3a665: Processing first storage report for DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e from datanode b2b4aee8-f14a-4214-9204-d7d6e6b80c6a
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x48865910c8a3a665: from storage DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e node DatanodeRegistration(127.0.0.1:42392, datanodeUuid=b2b4aee8-f14a-4214-9204-d7d6e6b80c6a, infoPort=40563, infoSecurePort=0, ipcPort=36193, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3f3aeed3dbdcf50a: Processing first storage report for DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93 from datanode 9b9d7152-8d8f-4103-b81f-c86be6562af0
2020-12-03 07:20:44,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3f3aeed3dbdcf50a: from storage DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93 node DatanodeRegistration(127.0.0.1:42029, datanodeUuid=9b9d7152-8d8f-4103-b81f-c86be6562af0, infoPort=41374, infoSecurePort=0, ipcPort=44949, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xec7bd8013f3cbe51: Processing first storage report for DS-d0ec2253-f82f-4911-b608-2ae12a422ebe from datanode ecfa2f1c-1975-41e8-b946-b05fd9e94841
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xec7bd8013f3cbe51: from storage DS-d0ec2253-f82f-4911-b608-2ae12a422ebe node DatanodeRegistration(127.0.0.1:37433, datanodeUuid=ecfa2f1c-1975-41e8-b946-b05fd9e94841, infoPort=37891, infoSecurePort=0, ipcPort=45466, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcd55b8c22aa9825d: Processing first storage report for DS-93571342-50b7-4feb-a300-0b796a6c2b84 from datanode 1d42abd3-ac8d-4471-90b2-9b417baa6db1
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcd55b8c22aa9825d: from storage DS-93571342-50b7-4feb-a300-0b796a6c2b84 node DatanodeRegistration(127.0.0.1:38087, datanodeUuid=1d42abd3-ac8d-4471-90b2-9b417baa6db1, infoPort=42907, infoSecurePort=0, ipcPort=41390, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6263ede939a00d67: Processing first storage report for DS-564a2870-26e3-40b4-984d-67f7a5a0d798 from datanode 7359969d-12ff-4604-b1dd-72e4f6d19ed1
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6263ede939a00d67: from storage DS-564a2870-26e3-40b4-984d-67f7a5a0d798 node DatanodeRegistration(127.0.0.1:37039, datanodeUuid=7359969d-12ff-4604-b1dd-72e4f6d19ed1, infoPort=33497, infoSecurePort=0, ipcPort=33034, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb4d0b3a40a1b0660: Processing first storage report for DS-0c93847c-8e34-43eb-8021-0fd84554c690 from datanode 9ffb508b-a1fc-4440-913c-788ca9bd6d31
2020-12-03 07:20:44,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb4d0b3a40a1b0660: from storage DS-0c93847c-8e34-43eb-8021-0fd84554c690 node DatanodeRegistration(127.0.0.1:45689, datanodeUuid=9ffb508b-a1fc-4440-913c-788ca9bd6d31, infoPort=34326, infoSecurePort=0, ipcPort=38200, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x48865910c8a3a665: Processing first storage report for DS-9a63d75c-72da-4dc3-9085-1d68c845f80e from datanode b2b4aee8-f14a-4214-9204-d7d6e6b80c6a
2020-12-03 07:20:44,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x48865910c8a3a665: from storage DS-9a63d75c-72da-4dc3-9085-1d68c845f80e node DatanodeRegistration(127.0.0.1:42392, datanodeUuid=b2b4aee8-f14a-4214-9204-d7d6e6b80c6a, infoPort=40563, infoSecurePort=0, ipcPort=36193, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3f3aeed3dbdcf50a: Processing first storage report for DS-d55537a9-9314-487a-b0ec-d6b4a3198b88 from datanode 9b9d7152-8d8f-4103-b81f-c86be6562af0
2020-12-03 07:20:44,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3f3aeed3dbdcf50a: from storage DS-d55537a9-9314-487a-b0ec-d6b4a3198b88 node DatanodeRegistration(127.0.0.1:42029, datanodeUuid=9b9d7152-8d8f-4103-b81f-c86be6562af0, infoPort=41374, infoSecurePort=0, ipcPort=44949, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:44,757 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,757 [Thread-326] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,758 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,758 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,769 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3f3aeed3dbdcf50a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,769 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,769 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcd55b8c22aa9825d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,769 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xec7bd8013f3cbe51,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,769 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb4d0b3a40a1b0660,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,781 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,781 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,778 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6263ede939a00d67,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 87 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,778 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x48865910c8a3a665,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 85 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:44,782 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,782 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,782 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,803 [Thread-260] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,814 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,815 [Thread-364] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,815 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:44,815 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:44,853 [Thread-304] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,912 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7d6e587c-4450-4b71-be8b-89ab99e4e737
2020-12-03 07:20:44,914 [Thread-282] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,915 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9
2020-12-03 07:20:44,915 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:44,919 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f56f340a-e0ea-4edb-a9bd-499891b439f4
2020-12-03 07:20:44,921 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:44,922 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:44,923 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:44,924 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:44,924 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:44,924 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:44,926 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:44,926 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:44,926 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:44,970 [Thread-326] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:44,984 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 58ms
2020-12-03 07:20:44,998 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 72ms
2020-12-03 07:20:44,998 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 72ms
2020-12-03 07:20:44,999 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:44,999 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:44,999 [Thread-454] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:44,999 [Thread-453] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,000 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:20:45,000 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:20:45,011 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 13ms
2020-12-03 07:20:45,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:45,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:45,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f56f340a-e0ea-4edb-a9bd-499891b439f4): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,013 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:02 PM with interval of 21600000ms
2020-12-03 07:20:45,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f56f340a-e0ea-4edb-a9bd-499891b439f4): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:45,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:45,013 [Thread-260] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 623cba50-c688-4156-9da8-5678fe706968
2020-12-03 07:20:45,017 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7d6e587c-4450-4b71-be8b-89ab99e4e737) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,020 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e03ad099-8ae8-440d-bf93-1919d0e4c949
2020-12-03 07:20:45,020 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:20:45,022 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4
2020-12-03 07:20:45,022 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:20:45,022 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:45,024 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:45,024 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:45,030 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:45,030 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:45,032 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,032 [IPC Server handler 5 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35616, datanodeUuid=7d6e587c-4450-4b71-be8b-89ab99e4e737, infoPort=39136, infoSecurePort=0, ipcPort=40775, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 7d6e587c-4450-4b71-be8b-89ab99e4e737
2020-12-03 07:20:45,032 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:20:45,032 [IPC Server handler 5 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35616
2020-12-03 07:20:45,033 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:20:45,033 [IPC Server handler 5 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7d6e587c-4450-4b71-be8b-89ab99e4e737 (127.0.0.1:35616).
2020-12-03 07:20:45,034 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7d6e587c-4450-4b71-be8b-89ab99e4e737) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,034 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,034 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,036 [Thread-364] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28/current/BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,037 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28 and block pool id BP-1131314314-172.17.0.3-1606980038383 is not formatted. Formatting ...
2020-12-03 07:20:45,037 [Thread-364] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1131314314-172.17.0.3-1606980038383 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28/current/BP-1131314314-172.17.0.3-1606980038383/current
2020-12-03 07:20:45,040 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9 for DN 127.0.0.1:35616
2020-12-03 07:20:45,040 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f56f340a-e0ea-4edb-a9bd-499891b439f4 for DN 127.0.0.1:35616
2020-12-03 07:20:45,072 [Thread-304] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33
2020-12-03 07:20:45,078 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb1f7fe516cb90c59: Processing first storage report for DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9 from datanode 7d6e587c-4450-4b71-be8b-89ab99e4e737
2020-12-03 07:20:45,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb1f7fe516cb90c59: from storage DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9 node DatanodeRegistration(127.0.0.1:35616, datanodeUuid=7d6e587c-4450-4b71-be8b-89ab99e4e737, infoPort=39136, infoSecurePort=0, ipcPort=40775, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb1f7fe516cb90c59: Processing first storage report for DS-f56f340a-e0ea-4edb-a9bd-499891b439f4 from datanode 7d6e587c-4450-4b71-be8b-89ab99e4e737
2020-12-03 07:20:45,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb1f7fe516cb90c59: from storage DS-f56f340a-e0ea-4edb-a9bd-499891b439f4 node DatanodeRegistration(127.0.0.1:35616, datanodeUuid=7d6e587c-4450-4b71-be8b-89ab99e4e737, infoPort=39136, infoSecurePort=0, ipcPort=40775, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,080 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb1f7fe516cb90c59,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 29 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,080 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,082 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87
2020-12-03 07:20:45,084 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23, StorageType: DISK
2020-12-03 07:20:45,086 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c
2020-12-03 07:20:45,086 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24, StorageType: DISK
2020-12-03 07:20:45,087 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:45,090 [Thread-304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23
2020-12-03 07:20:45,091 [Thread-304] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23
2020-12-03 07:20:45,091 [Thread-304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24
2020-12-03 07:20:45,091 [Thread-304] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24
2020-12-03 07:20:45,094 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,095 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23...
2020-12-03 07:20:45,095 [Thread-467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24...
2020-12-03 07:20:45,097 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 65ms
2020-12-03 07:20:45,098 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 65ms
2020-12-03 07:20:45,098 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 66ms
2020-12-03 07:20:45,099 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:20:45,099 [Thread-469] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:20:45,099 [Thread-468] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,099 [Thread-469] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,099 [Thread-468] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 0ms
2020-12-03 07:20:45,100 [Thread-469] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:20:45,100 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 2ms
2020-12-03 07:20:45,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:45,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:45,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,101 [Thread-260] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:26 PM with interval of 21600000ms
2020-12-03 07:20:45,101 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:45,101 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e03ad099-8ae8-440d-bf93-1919d0e4c949): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,102 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e03ad099-8ae8-440d-bf93-1919d0e4c949): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:45,108 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 623cba50-c688-4156-9da8-5678fe706968) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,122 [Thread-282] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3
2020-12-03 07:20:45,129 [IPC Server handler 6 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39275, datanodeUuid=623cba50-c688-4156-9da8-5678fe706968, infoPort=40533, infoSecurePort=0, ipcPort=45700, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 623cba50-c688-4156-9da8-5678fe706968
2020-12-03 07:20:45,130 [IPC Server handler 6 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39275
2020-12-03 07:20:45,130 [IPC Server handler 6 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 623cba50-c688-4156-9da8-5678fe706968 (127.0.0.1:39275).
2020-12-03 07:20:45,133 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3380f552-e47a-4033-ab27-3be3ff9125ea
2020-12-03 07:20:45,133 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:20:45,135 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818
2020-12-03 07:20:45,135 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:20:45,135 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:45,151 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 623cba50-c688-4156-9da8-5678fe706968) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,151 [Thread-326] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2fcd4088-6b0b-4f36-a983-125bd709aa78
2020-12-03 07:20:45,151 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,157 [Thread-282] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:20:45,164 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23: 69ms
2020-12-03 07:20:45,167 [Thread-282] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:20:45,168 [Thread-282] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:20:45,168 [Thread-467] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24: 73ms
2020-12-03 07:20:45,168 [Thread-282] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:20:45,168 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 73ms
2020-12-03 07:20:45,169 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23...
2020-12-03 07:20:45,169 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,169 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24...
2020-12-03 07:20:45,169 [Thread-479] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,170 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24: 1ms
2020-12-03 07:20:45,170 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23: 1ms
2020-12-03 07:20:45,171 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe
2020-12-03 07:20:45,175 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25, StorageType: DISK
2020-12-03 07:20:45,177 [Thread-282] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,177 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 8ms
2020-12-03 07:20:45,177 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:20:45,191 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23
2020-12-03 07:20:45,191 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e03ad099-8ae8-440d-bf93-1919d0e4c949 for DN 127.0.0.1:39275
2020-12-03 07:20:45,191 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24
2020-12-03 07:20:45,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24, DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,193 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-02779bd4-5a16-47bf-b763-6bf98ed80273
2020-12-03 07:20:45,193 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26, StorageType: DISK
2020-12-03 07:20:45,193 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:45,194 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24, DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:45,195 [Thread-326] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25
2020-12-03 07:20:45,177 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:20:45,191 [Thread-364] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2101009238;bpid=BP-1131314314-172.17.0.3-1606980038383;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2101009238;c=1606980038383;bpid=BP-1131314314-172.17.0.3-1606980038383;dnuuid=null
2020-12-03 07:20:45,192 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4 for DN 127.0.0.1:39275
2020-12-03 07:20:45,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23, DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,192 [Thread-304] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:17 AM with interval of 21600000ms
2020-12-03 07:20:45,198 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23, DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:20:45,205 [Thread-326] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25
2020-12-03 07:20:45,205 [Thread-326] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26
2020-12-03 07:20:45,205 [Thread-326] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26
2020-12-03 07:20:45,205 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,205 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,205 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf0ee82784aee1b4f: Processing first storage report for DS-e03ad099-8ae8-440d-bf93-1919d0e4c949 from datanode 623cba50-c688-4156-9da8-5678fe706968
2020-12-03 07:20:45,206 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25...
2020-12-03 07:20:45,206 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26...
2020-12-03 07:20:45,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf0ee82784aee1b4f: from storage DS-e03ad099-8ae8-440d-bf93-1919d0e4c949 node DatanodeRegistration(127.0.0.1:39275, datanodeUuid=623cba50-c688-4156-9da8-5678fe706968, infoPort=40533, infoSecurePort=0, ipcPort=45700, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,207 [IPC Server handler 7 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38420, datanodeUuid=9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33, infoPort=33539, infoSecurePort=0, ipcPort=46765, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33
2020-12-03 07:20:45,208 [IPC Server handler 7 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38420
2020-12-03 07:20:45,208 [IPC Server handler 7 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33 (127.0.0.1:38420).
2020-12-03 07:20:45,209 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf0ee82784aee1b4f: Processing first storage report for DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4 from datanode 623cba50-c688-4156-9da8-5678fe706968
2020-12-03 07:20:45,209 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf0ee82784aee1b4f: from storage DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4 node DatanodeRegistration(127.0.0.1:39275, datanodeUuid=623cba50-c688-4156-9da8-5678fe706968, infoPort=40533, infoSecurePort=0, ipcPort=45700, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,211 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,211 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf0ee82784aee1b4f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,211 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,211 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,216 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87 for DN 127.0.0.1:38420
2020-12-03 07:20:45,217 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c for DN 127.0.0.1:38420
2020-12-03 07:20:45,219 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9f51a2cbeab91470: Processing first storage report for DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87 from datanode 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33
2020-12-03 07:20:45,219 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9f51a2cbeab91470: from storage DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87 node DatanodeRegistration(127.0.0.1:38420, datanodeUuid=9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33, infoPort=33539, infoSecurePort=0, ipcPort=46765, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,220 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9f51a2cbeab91470: Processing first storage report for DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c from datanode 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33
2020-12-03 07:20:45,220 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9f51a2cbeab91470: from storage DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c node DatanodeRegistration(127.0.0.1:38420, datanodeUuid=9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33, infoPort=33539, infoSecurePort=0, ipcPort=46765, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,221 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9f51a2cbeab91470,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,221 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,269 [Thread-364] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3b19a149-e853-4c6d-bf74-7ee9a5fa257e
2020-12-03 07:20:45,282 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26: 76ms
2020-12-03 07:20:45,283 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 92ms
2020-12-03 07:20:45,284 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 89ms
2020-12-03 07:20:45,284 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 107ms
2020-12-03 07:20:45,287 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a42c5d-7440-4deb-ba1b-27e69712399e
2020-12-03 07:20:45,295 [Thread-497] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:20:45,295 [Thread-497] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,294 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:20:45,295 [Thread-364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27, StorageType: DISK
2020-12-03 07:20:45,296 [Thread-496] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,296 [Thread-497] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 1ms
2020-12-03 07:20:45,296 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 1ms
2020-12-03 07:20:45,300 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 6ms
2020-12-03 07:20:45,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:20:45,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,302 [Thread-282] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:03 PM with interval of 21600000ms
2020-12-03 07:20:45,302 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55
2020-12-03 07:20:45,302 [Thread-364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28, StorageType: DISK
2020-12-03 07:20:45,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:45,302 [Thread-364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:45,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:20:45,304 [Thread-364] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27
2020-12-03 07:20:45,305 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-3380f552-e47a-4033-ab27-3be3ff9125ea): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,306 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-3380f552-e47a-4033-ab27-3be3ff9125ea): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:20:45,316 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25: 110ms
2020-12-03 07:20:45,316 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 111ms
2020-12-03 07:20:45,318 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,319 [Thread-364] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27
2020-12-03 07:20:45,319 [Thread-364] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28
2020-12-03 07:20:45,319 [Thread-364] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28
2020-12-03 07:20:45,321 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25...
2020-12-03 07:20:45,323 [IPC Server handler 5 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34357, datanodeUuid=157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3, infoPort=44899, infoSecurePort=0, ipcPort=45995, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3
2020-12-03 07:20:45,330 [IPC Server handler 5 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34357
2020-12-03 07:20:45,331 [IPC Server handler 5 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3 (127.0.0.1:34357).
2020-12-03 07:20:45,322 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26...
2020-12-03 07:20:45,331 [Thread-503] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,332 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26: 1ms
2020-12-03 07:20:45,322 [Thread-364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,330 [Thread-502] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,350 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25: 20ms
2020-12-03 07:20:45,350 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 32ms
2020-12-03 07:20:45,350 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26
2020-12-03 07:20:45,350 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25
2020-12-03 07:20:45,351 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26, DS-02779bd4-5a16-47bf-b763-6bf98ed80273): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,351 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25, DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,352 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25, DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:45,352 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26, DS-02779bd4-5a16-47bf-b763-6bf98ed80273): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:45,353 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,353 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,357 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27...
2020-12-03 07:20:45,357 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28...
2020-12-03 07:20:45,357 [Thread-326] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:34 AM with interval of 21600000ms
2020-12-03 07:20:45,359 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 2fcd4088-6b0b-4f36-a983-125bd709aa78) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,365 [IPC Server handler 0 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3380f552-e47a-4033-ab27-3be3ff9125ea for DN 127.0.0.1:34357
2020-12-03 07:20:45,365 [IPC Server handler 0 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818 for DN 127.0.0.1:34357
2020-12-03 07:20:45,366 [IPC Server handler 9 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36480, datanodeUuid=2fcd4088-6b0b-4f36-a983-125bd709aa78, infoPort=39302, infoSecurePort=0, ipcPort=32913, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 2fcd4088-6b0b-4f36-a983-125bd709aa78
2020-12-03 07:20:45,367 [IPC Server handler 9 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36480
2020-12-03 07:20:45,367 [IPC Server handler 9 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2fcd4088-6b0b-4f36-a983-125bd709aa78 (127.0.0.1:36480).
2020-12-03 07:20:45,368 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 2fcd4088-6b0b-4f36-a983-125bd709aa78) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,368 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,368 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xae8f49980e5a2285: Processing first storage report for DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818 from datanode 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3
2020-12-03 07:20:45,368 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xae8f49980e5a2285: from storage DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818 node DatanodeRegistration(127.0.0.1:34357, datanodeUuid=157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3, infoPort=44899, infoSecurePort=0, ipcPort=45995, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xae8f49980e5a2285: Processing first storage report for DS-3380f552-e47a-4033-ab27-3be3ff9125ea from datanode 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3
2020-12-03 07:20:45,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xae8f49980e5a2285: from storage DS-3380f552-e47a-4033-ab27-3be3ff9125ea node DatanodeRegistration(127.0.0.1:34357, datanodeUuid=157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3, infoPort=44899, infoSecurePort=0, ipcPort=45995, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,398 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe for DN 127.0.0.1:36480
2020-12-03 07:20:45,399 [IPC Server handler 3 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02779bd4-5a16-47bf-b763-6bf98ed80273 for DN 127.0.0.1:36480
2020-12-03 07:20:45,410 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xae8f49980e5a2285,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,420 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a580a4336db6e04: Processing first storage report for DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe from datanode 2fcd4088-6b0b-4f36-a983-125bd709aa78
2020-12-03 07:20:45,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a580a4336db6e04: from storage DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe node DatanodeRegistration(127.0.0.1:36480, datanodeUuid=2fcd4088-6b0b-4f36-a983-125bd709aa78, infoPort=39302, infoSecurePort=0, ipcPort=32913, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a580a4336db6e04: Processing first storage report for DS-02779bd4-5a16-47bf-b763-6bf98ed80273 from datanode 2fcd4088-6b0b-4f36-a983-125bd709aa78
2020-12-03 07:20:45,422 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28: 65ms
2020-12-03 07:20:45,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a580a4336db6e04: from storage DS-02779bd4-5a16-47bf-b763-6bf98ed80273 node DatanodeRegistration(127.0.0.1:36480, datanodeUuid=2fcd4088-6b0b-4f36-a983-125bd709aa78, infoPort=39302, infoSecurePort=0, ipcPort=32913, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,430 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6a580a4336db6e04,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,430 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,431 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1131314314-172.17.0.3-1606980038383 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27: 74ms
2020-12-03 07:20:45,431 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1131314314-172.17.0.3-1606980038383: 82ms
2020-12-03 07:20:45,431 [Thread-511] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27...
2020-12-03 07:20:45,431 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28...
2020-12-03 07:20:45,431 [Thread-511] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,432 [Thread-512] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28/current/BP-1131314314-172.17.0.3-1606980038383/current/replicas doesn't exist 
2020-12-03 07:20:45,432 [Thread-511] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27: 1ms
2020-12-03 07:20:45,432 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28: 1ms
2020-12-03 07:20:45,432 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1131314314-172.17.0.3-1606980038383: 1ms
2020-12-03 07:20:45,433 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28
2020-12-03 07:20:45,433 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28, DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,433 [Thread-364] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:12 AM with interval of 21600000ms
2020-12-03 07:20:45,440 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1131314314-172.17.0.3-1606980038383 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27
2020-12-03 07:20:45,440 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28, DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:20:45,440 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 3b19a149-e853-4c6d-bf74-7ee9a5fa257e) service to localhost/127.0.0.1:43742 beginning handshake with NN
2020-12-03 07:20:45,440 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27, DS-e2a42c5d-7440-4deb-ba1b-27e69712399e): finished scanning block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,441 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27, DS-e2a42c5d-7440-4deb-ba1b-27e69712399e): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:20:45,442 [IPC Server handler 2 on default port 43742] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44274, datanodeUuid=3b19a149-e853-4c6d-bf74-7ee9a5fa257e, infoPort=40190, infoSecurePort=0, ipcPort=40180, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383) storage 3b19a149-e853-4c6d-bf74-7ee9a5fa257e
2020-12-03 07:20:45,443 [IPC Server handler 2 on default port 43742] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44274
2020-12-03 07:20:45,443 [IPC Server handler 2 on default port 43742] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3b19a149-e853-4c6d-bf74-7ee9a5fa257e (127.0.0.1:44274).
2020-12-03 07:20:45,444 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 3b19a149-e853-4c6d-bf74-7ee9a5fa257e) service to localhost/127.0.0.1:43742 successfully registered with NN
2020-12-03 07:20:45,444 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43742 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:45,450 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a42c5d-7440-4deb-ba1b-27e69712399e for DN 127.0.0.1:44274
2020-12-03 07:20:45,450 [IPC Server handler 4 on default port 43742] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55 for DN 127.0.0.1:44274
2020-12-03 07:20:45,454 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaf5f195f4857d1ad: Processing first storage report for DS-e2a42c5d-7440-4deb-ba1b-27e69712399e from datanode 3b19a149-e853-4c6d-bf74-7ee9a5fa257e
2020-12-03 07:20:45,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf5f195f4857d1ad: from storage DS-e2a42c5d-7440-4deb-ba1b-27e69712399e node DatanodeRegistration(127.0.0.1:44274, datanodeUuid=3b19a149-e853-4c6d-bf74-7ee9a5fa257e, infoPort=40190, infoSecurePort=0, ipcPort=40180, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaf5f195f4857d1ad: Processing first storage report for DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55 from datanode 3b19a149-e853-4c6d-bf74-7ee9a5fa257e
2020-12-03 07:20:45,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf5f195f4857d1ad: from storage DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55 node DatanodeRegistration(127.0.0.1:44274, datanodeUuid=3b19a149-e853-4c6d-bf74-7ee9a5fa257e, infoPort=40190, infoSecurePort=0, ipcPort=40180, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:45,457 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaf5f195f4857d1ad,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:45,457 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,476 [IPC Server handler 1 on default port 43742] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:45,499 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:44274
2020-12-03 07:20:45,499 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:45,603 [IPC Server handler 5 on default port 43742] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:45,609 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:45,638 [IPC Server handler 0 on default port 43742] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:20:45,639 [IPC Server handler 0 on default port 43742] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:45,669 [IPC Server handler 9 on default port 43742] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:45,688 [IPC Server handler 3 on default port 43742] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:45,692 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:45,692 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 13
2020-12-03 07:20:45,693 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:45,701 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55f8d1c6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:45,701 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28, DS-4fe8cdf5-f6c6-4df9-83a4-67b85e8d5d55) exiting.
2020-12-03 07:20:45,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27, DS-e2a42c5d-7440-4deb-ba1b-27e69712399e) exiting.
2020-12-03 07:20:45,783 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43029ddb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:45,789 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@667feb57{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:45,792 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d012249{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:45,794 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77452206{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:45,803 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40180
2020-12-03 07:20:45,810 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:45,811 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:45,814 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:45,814 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 3b19a149-e853-4c6d-bf74-7ee9a5fa257e) service to localhost/127.0.0.1:43742
2020-12-03 07:20:45,815 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 3b19a149-e853-4c6d-bf74-7ee9a5fa257e)
2020-12-03 07:20:45,815 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,816 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data27/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:45,816 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data28/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:45,830 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:45,831 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:45,832 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:45,833 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:45,844 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:45,844 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 12
2020-12-03 07:20:45,844 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:45,844 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21440fb0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:45,849 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26, DS-02779bd4-5a16-47bf-b763-6bf98ed80273) exiting.
2020-12-03 07:20:45,849 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25, DS-03be78aa-b0ae-408c-92aa-7fca6d54ddbe) exiting.
2020-12-03 07:20:45,879 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@45011f4c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:45,880 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1bc33152{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:45,885 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51701891{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:45,901 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c33d741{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:45,919 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32913
2020-12-03 07:20:45,957 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:45,957 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:45,969 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:45,972 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 2fcd4088-6b0b-4f36-a983-125bd709aa78) service to localhost/127.0.0.1:43742
2020-12-03 07:20:45,972 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 2fcd4088-6b0b-4f36-a983-125bd709aa78)
2020-12-03 07:20:45,972 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:45,973 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data25/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:45,973 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data26/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,021 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:46,021 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:46,024 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:46,024 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:46,031 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:46,031 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 11
2020-12-03 07:20:46,031 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:46,034 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@36df5858] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:46,041 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24, DS-3c41d82b-f67a-4a28-a3ff-b12e17bc368c) exiting.
2020-12-03 07:20:46,041 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23, DS-5ac8c05a-964d-4767-8ce1-c2d53a6cee87) exiting.
2020-12-03 07:20:46,170 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3fd5ff1c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:46,171 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26a471d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:46,180 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21c8e86{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:46,185 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ef94491{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:46,212 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46765
2020-12-03 07:20:46,217 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:46,220 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:46,222 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:46,223 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33) service to localhost/127.0.0.1:43742
2020-12-03 07:20:46,223 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b92c77e-3f2f-4daf-a21c-ca1ccc06ff33)
2020-12-03 07:20:46,223 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:46,224 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data23/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,224 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data24/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,234 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:46,235 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:46,237 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:46,237 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:46,242 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:46,243 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:20:46,243 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:46,243 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6c19a053] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:46,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-3380f552-e47a-4033-ab27-3be3ff9125ea) exiting.
2020-12-03 07:20:46,249 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-d2065dfe-7cb5-47a0-85e3-7e53e697b818) exiting.
2020-12-03 07:20:46,306 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5fd04f93{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:46,315 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@569dc84c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:46,321 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3462d9bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:46,325 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@344001ba{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:46,340 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45995
2020-12-03 07:20:46,347 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:46,359 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:46,359 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:46,359 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3) service to localhost/127.0.0.1:43742
2020-12-03 07:20:46,360 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 157cd7cf-8e1f-4d9b-a913-5e5e246aa0e3)
2020-12-03 07:20:46,360 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:46,365 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,365 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,383 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:46,383 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:46,387 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:46,387 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:46,394 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:46,394 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:20:46,395 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:46,395 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7ab66621] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:46,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-69dbd3be-7ce4-4150-ad07-8185d5dedfe4) exiting.
2020-12-03 07:20:46,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e03ad099-8ae8-440d-bf93-1919d0e4c949) exiting.
2020-12-03 07:20:46,465 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@261dbd6d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:46,471 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3fe08823{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:46,477 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21b577d9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:46,482 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6fc5a79f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:46,501 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45700
2020-12-03 07:20:46,512 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:46,512 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:46,520 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:46,520 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 623cba50-c688-4156-9da8-5678fe706968) service to localhost/127.0.0.1:43742
2020-12-03 07:20:46,520 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 623cba50-c688-4156-9da8-5678fe706968)
2020-12-03 07:20:46,520 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:46,523 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,523 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,571 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:46,571 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:46,576 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:46,576 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:46,608 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:46,608 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:20:46,608 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:46,608 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4323728c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:46,633 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f56f340a-e0ea-4edb-a9bd-499891b439f4) exiting.
2020-12-03 07:20:46,640 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-e50e898b-fd15-4aa0-aee1-4bcf12b058c9) exiting.
2020-12-03 07:20:46,704 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@19fa8f8c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:46,705 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@8d06c0f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:46,711 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3de07f87{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:46,718 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65f5c7f2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:46,728 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40775
2020-12-03 07:20:46,732 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:46,732 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:46,732 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:46,738 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7d6e587c-4450-4b71-be8b-89ab99e4e737) service to localhost/127.0.0.1:43742
2020-12-03 07:20:46,738 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7d6e587c-4450-4b71-be8b-89ab99e4e737)
2020-12-03 07:20:46,738 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:46,739 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,739 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:46,762 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:46,762 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:46,766 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:46,767 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:46,791 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:46,791 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:46,791 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:46,791 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12ebb8e5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:46,808 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d55537a9-9314-487a-b0ec-d6b4a3198b88) exiting.
2020-12-03 07:20:46,809 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-ea5d21a0-97a2-4b06-bab2-b5731f8aca93) exiting.
2020-12-03 07:20:46,882 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2b7322dc{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:46,883 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@396d5941{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:46,910 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3542cfea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:46,910 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@666b16ba{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:46,926 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44949
2020-12-03 07:20:46,933 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:46,945 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:46,945 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:46,945 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b9d7152-8d8f-4103-b81f-c86be6562af0) service to localhost/127.0.0.1:43742
2020-12-03 07:20:46,946 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9b9d7152-8d8f-4103-b81f-c86be6562af0)
2020-12-03 07:20:46,946 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:46,946 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,114 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,136 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:47,137 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:47,140 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:47,140 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:47,141 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:47,141 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:47,142 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:47,142 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@283a64d4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:47,146 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f47c8e7c-976b-4b30-bc57-9ef708aa867e) exiting.
2020-12-03 07:20:47,146 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9a63d75c-72da-4dc3-9085-1d68c845f80e) exiting.
2020-12-03 07:20:47,378 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3735f996{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:47,379 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@214b538d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:47,380 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43a0a6f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:47,380 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@587a26d1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:47,404 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36193
2020-12-03 07:20:47,418 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:47,430 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:47,430 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:47,431 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid b2b4aee8-f14a-4214-9204-d7d6e6b80c6a) service to localhost/127.0.0.1:43742
2020-12-03 07:20:47,431 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid b2b4aee8-f14a-4214-9204-d7d6e6b80c6a)
2020-12-03 07:20:47,431 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:47,432 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,435 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,469 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:47,470 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:47,476 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:47,476 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:47,478 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:47,478 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:47,479 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:47,479 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@44e443aa] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:47,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d0ec2253-f82f-4911-b608-2ae12a422ebe) exiting.
2020-12-03 07:20:47,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-d53db321-0c3d-4d08-84ea-41e40537cd31) exiting.
2020-12-03 07:20:47,516 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid ecfa2f1c-1975-41e8-b946-b05fd9e94841) service to localhost/127.0.0.1:43742
2020-12-03 07:20:47,517 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid ecfa2f1c-1975-41e8-b946-b05fd9e94841)
2020-12-03 07:20:47,517 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:47,520 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,520 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,589 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@578beada{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:47,613 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6acad585{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:47,614 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a833c6d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:47,614 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8548075{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:47,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xef98f7fee5d4d52f: Processing first storage report for DS-60c044a7-3204-45ca-a351-a573aa6ea615 from datanode f87e3368-f0ec-4a0e-b68b-67e021ee5858
2020-12-03 07:20:47,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xef98f7fee5d4d52f: from storage DS-60c044a7-3204-45ca-a351-a573aa6ea615 node DatanodeRegistration(127.0.0.1:46225, datanodeUuid=f87e3368-f0ec-4a0e-b68b-67e021ee5858, infoPort=39098, infoSecurePort=0, ipcPort=41354, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:47,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xef98f7fee5d4d52f: Processing first storage report for DS-2460861a-d19c-405c-a815-b8d4a4882cad from datanode f87e3368-f0ec-4a0e-b68b-67e021ee5858
2020-12-03 07:20:47,637 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xef98f7fee5d4d52f: from storage DS-2460861a-d19c-405c-a815-b8d4a4882cad node DatanodeRegistration(127.0.0.1:46225, datanodeUuid=f87e3368-f0ec-4a0e-b68b-67e021ee5858, infoPort=39098, infoSecurePort=0, ipcPort=41354, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:47,638 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xef98f7fee5d4d52f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 69 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:47,638 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:47,641 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x55243edcfb34fd91: Processing first storage report for DS-adfa01be-3413-4228-81c8-bf207c9149ee from datanode 4f10650e-50f8-4175-8f23-c134bf995968
2020-12-03 07:20:47,642 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x55243edcfb34fd91: from storage DS-adfa01be-3413-4228-81c8-bf207c9149ee node DatanodeRegistration(127.0.0.1:35702, datanodeUuid=4f10650e-50f8-4175-8f23-c134bf995968, infoPort=42120, infoSecurePort=0, ipcPort=40851, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:47,642 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x55243edcfb34fd91: Processing first storage report for DS-0af8b64e-afba-4f98-8651-e61bc7cda735 from datanode 4f10650e-50f8-4175-8f23-c134bf995968
2020-12-03 07:20:47,642 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x55243edcfb34fd91: from storage DS-0af8b64e-afba-4f98-8651-e61bc7cda735 node DatanodeRegistration(127.0.0.1:35702, datanodeUuid=4f10650e-50f8-4175-8f23-c134bf995968, infoPort=42120, infoSecurePort=0, ipcPort=40851, storageInfo=lv=-57;cid=testClusterID;nsid=2101009238;c=1606980038383), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:47,643 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x55243edcfb34fd91,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:47,643 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:47,672 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45466
2020-12-03 07:20:47,679 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:47,698 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:47,744 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:47,746 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:47,753 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:47,753 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:47,754 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:47,754 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:47,762 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:47,769 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-93571342-50b7-4feb-a300-0b796a6c2b84) exiting.
2020-12-03 07:20:47,772 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-bd1252fb-a5ae-4d20-b9b6-83abccfc5d43) exiting.
2020-12-03 07:20:47,798 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b982fc1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:47,845 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44246bbe{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:47,847 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@466b494f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:47,848 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6360d154{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:47,848 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@de5dae3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:47,868 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41390
2020-12-03 07:20:47,881 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:47,881 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:47,907 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:47,907 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 1d42abd3-ac8d-4471-90b2-9b417baa6db1) service to localhost/127.0.0.1:43742
2020-12-03 07:20:47,907 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 1d42abd3-ac8d-4471-90b2-9b417baa6db1)
2020-12-03 07:20:47,907 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:47,908 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:47,941 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,177 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:48,178 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:48,211 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:48,211 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:48,212 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:48,212 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:48,212 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:48,213 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@63ef095d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:48,219 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-60c044a7-3204-45ca-a351-a573aa6ea615) exiting.
2020-12-03 07:20:48,219 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-2460861a-d19c-405c-a815-b8d4a4882cad) exiting.
2020-12-03 07:20:48,277 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b8a810{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:48,283 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d6530b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:48,285 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fa32594{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:48,286 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fc393e1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:48,299 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41354
2020-12-03 07:20:48,305 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:48,310 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:48,310 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:48,310 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid f87e3368-f0ec-4a0e-b68b-67e021ee5858) service to localhost/127.0.0.1:43742
2020-12-03 07:20:48,310 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid f87e3368-f0ec-4a0e-b68b-67e021ee5858)
2020-12-03 07:20:48,310 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:48,312 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,319 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:48,319 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:48,325 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:48,326 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:48,327 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:48,327 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:48,327 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:48,327 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@137676] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:48,332 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-0c93847c-8e34-43eb-8021-0fd84554c690) exiting.
2020-12-03 07:20:48,334 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-99210ad9-1119-45fb-b961-07366c288cd3) exiting.
2020-12-03 07:20:48,418 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,425 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d9b2e59{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:48,450 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f22dd3b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:48,450 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29a009cf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:48,450 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@128bdb05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:48,464 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38200
2020-12-03 07:20:48,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:48,477 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:48,477 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:48,477 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9ffb508b-a1fc-4440-913c-788ca9bd6d31) service to localhost/127.0.0.1:43742
2020-12-03 07:20:48,502 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 9ffb508b-a1fc-4440-913c-788ca9bd6d31)
2020-12-03 07:20:48,502 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:48,521 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,522 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,538 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:48,538 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:48,543 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:48,544 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:48,544 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:48,545 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:48,545 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:48,546 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77f42921] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:48,552 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-12411823-7732-4561-91e7-6fe103839f26) exiting.
2020-12-03 07:20:48,553 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-564a2870-26e3-40b4-984d-67f7a5a0d798) exiting.
2020-12-03 07:20:48,589 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a9a46d8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:48,592 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54f20b5f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:48,594 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b850d00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:48,595 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40956612{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:48,630 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33034
2020-12-03 07:20:48,645 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:48,681 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:48,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:48,682 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7359969d-12ff-4604-b1dd-72e4f6d19ed1) service to localhost/127.0.0.1:43742
2020-12-03 07:20:48,682 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 7359969d-12ff-4604-b1dd-72e4f6d19ed1)
2020-12-03 07:20:48,682 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:48,683 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,683 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,688 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:48,688 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:48,693 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:48,694 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:48,694 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:48,695 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:48,695 [Thread-516] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:48,695 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3b53d546] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:48,700 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-adfa01be-3413-4228-81c8-bf207c9149ee) exiting.
2020-12-03 07:20:48,700 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0af8b64e-afba-4f98-8651-e61bc7cda735) exiting.
2020-12-03 07:20:48,734 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55dd8950{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:48,736 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@82b089e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:48,737 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51d8eddf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:48,738 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ad60e61{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:48,750 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40851
2020-12-03 07:20:48,761 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:48,761 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:48,761 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:48,761 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 4f10650e-50f8-4175-8f23-c134bf995968) service to localhost/127.0.0.1:43742
2020-12-03 07:20:48,762 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1131314314-172.17.0.3-1606980038383 (Datanode Uuid 4f10650e-50f8-4175-8f23-c134bf995968)
2020-12-03 07:20:48,767 [BP-1131314314-172.17.0.3-1606980038383 heartbeating to localhost/127.0.0.1:43742] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1131314314-172.17.0.3-1606980038383
2020-12-03 07:20:48,768 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,768 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1131314314-172.17.0.3-1606980038383] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:48,775 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:48,775 [Thread-516] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:48,783 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:48,783 [Thread-516] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:48,784 [Thread-516] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:48,784 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:48,784 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:48,785 [Thread-516] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 4
2020-12-03 07:20:48,785 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2379102] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:48,786 [Thread-516] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 5 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 2 1 
2020-12-03 07:20:48,787 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@68fac845] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:48,790 [Thread-516] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:20:48,791 [Thread-516] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:20:48,792 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:48,793 [CacheReplicationMonitor(1301918523)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:48,972 [Thread-516] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43742
2020-12-03 07:20:48,987 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:48,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:48,988 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:48,988 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:49,046 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:49,046 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:49,050 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c305066{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:49,053 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@660be5fc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:49,054 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4dffa621{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:49,054 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67026b22{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:49,060 [Thread-516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:49,094 [Thread-516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:49,095 [Thread-516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:20:49,123 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=9
2020-12-03 07:20:49,123 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:20:49,123 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:20:49,129 [Thread-516] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:49,129 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:49,130 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:49,130 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:49,130 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:49,130 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:49,130 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:49,131 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:49,131 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:49,131 [Thread-516] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,132 [Thread-516] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:49,132 [Thread-516] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:49,132 [Thread-516] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:49,133 [Thread-516] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:49
2020-12-03 07:20:49,133 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:49,133 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,134 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:49,134 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:49,146 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:49,146 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:49,147 [Thread-516] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:49,147 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:49,147 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:49,147 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:49,147 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:49,147 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:49,148 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:49,148 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:49,148 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:49,148 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:49,148 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:49,149 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:49,149 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,149 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:49,150 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:49,369 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:49,370 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:49,370 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:49,370 [Thread-516] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:49,372 [Thread-516] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:49,372 [Thread-516] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:49,373 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:49,373 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,373 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:49,373 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:49,375 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:49,375 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:49,375 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:49,375 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:49,376 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:49,376 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:49,376 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,376 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:49,376 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:49,384 [Thread-516] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:49,460 [Thread-516] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:49,511 [Thread-516] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:49,562 [Thread-516] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:20:49,582 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:49,582 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:49,599 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 430 bytes saved in 0 seconds .
2020-12-03 07:20:49,602 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 430 bytes saved in 0 seconds .
2020-12-03 07:20:49,691 [Thread-516] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:49,694 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3
2020-12-03 07:20:49,715 [Thread-516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4
2020-12-03 07:20:49,720 [Thread-516] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:49,727 [Thread-516] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:49,729 [Thread-516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:49,729 [Thread-516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:49,730 [Thread-516] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:43742
2020-12-03 07:20:49,731 [Thread-516] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use minidfs-ns to access this namenode/service.
2020-12-03 07:20:49,770 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a912db6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:49,770 [Thread-516] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:49,771 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:49,773 [Thread-516] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:49,774 [Thread-516] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:49,774 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:49,776 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:49,777 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:49,777 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:49,777 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:49,779 [Thread-516] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:49,779 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:49,779 [Thread-516] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35434
2020-12-03 07:20:49,779 [Thread-516] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:49,783 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8299c43{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:49,784 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58fe55cc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:49,792 [Thread-516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@64979a6e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:49,793 [Thread-516] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f7fabcc{HTTP/1.1,[http/1.1]}{localhost:35434}
2020-12-03 07:20:49,796 [Thread-516] INFO  server.Server (Server.java:doStart(419)) - Started @13742ms
2020-12-03 07:20:49,800 [Thread-516] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:49,800 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:49,800 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:49,800 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:49,801 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:49,801 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:49,801 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:49,801 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:49,802 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:49,802 [Thread-516] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,803 [Thread-516] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:49,803 [Thread-516] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:49,803 [Thread-516] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:49,804 [Thread-516] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:49
2020-12-03 07:20:49,804 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:49,804 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,804 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:49,804 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:49,811 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:49,811 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:49,811 [Thread-516] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:49,812 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:49,813 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:49,813 [Thread-516] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:49,813 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:49,813 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,813 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:49,814 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:49,818 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:49,818 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:49,819 [Thread-516] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:49,819 [Thread-516] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:49,819 [Thread-516] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:49,819 [Thread-516] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:49,819 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:49,819 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,820 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:49,820 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:49,820 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:49,821 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:49,821 [Thread-516] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:49,821 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:49,821 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:49,821 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:49,821 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,821 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:49,822 [Thread-516] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:49,849 [Thread-516] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:49,876 [Thread-516] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:49,877 [Thread-516] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:20:49,879 [Thread-516] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:49,879 [Thread-516] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:49,888 [Thread-516] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:49,890 [Thread-516] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:49,890 [Thread-516] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:49,891 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:20:49,891 [Thread-516] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:49,891 [Thread-516] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 68 msecs
2020-12-03 07:20:49,892 [Thread-516] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:49,894 [Thread-516] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:49,902 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:49,931 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:50,047 [Listener at localhost/34660] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:50,052 [Listener at localhost/34660] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:50,052 [Listener at localhost/34660] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:50,053 [Listener at localhost/34660] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:50,059 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,059 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,077 [Listener at localhost/34660] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34660
2020-12-03 07:20:50,081 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:50,084 [Listener at localhost/34660] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:50,084 [Listener at localhost/34660] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:50,084 [Listener at localhost/34660] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:50,084 [Listener at localhost/34660] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:50,109 [Listener at localhost/34660] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:50,109 [Listener at localhost/34660] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:50,110 [Listener at localhost/34660] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:43742
2020-12-03 07:20:50,110 [Listener at localhost/34660] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use minidfs-ns to access this namenode/service.
2020-12-03 07:20:50,142 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3818e52f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,142 [Listener at localhost/34660] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:50,142 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,146 [Listener at localhost/34660] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,147 [Listener at localhost/34660] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:50,147 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,150 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,150 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:50,151 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,151 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,153 [Listener at localhost/34660] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:50,153 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:50,154 [Listener at localhost/34660] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41393
2020-12-03 07:20:50,154 [Listener at localhost/34660] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,156 [Listener at localhost/34660] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1549620b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:50,157 [Listener at localhost/34660] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f643de8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:50,164 [Listener at localhost/34660] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a23c548{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:50,165 [Listener at localhost/34660] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@95d300e{HTTP/1.1,[http/1.1]}{localhost:41393}
2020-12-03 07:20:50,165 [Listener at localhost/34660] INFO  server.Server (Server.java:doStart(419)) - Started @14111ms
2020-12-03 07:20:50,170 [Listener at localhost/34660] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:50,170 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:50,170 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:50,171 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:50,172 [Listener at localhost/34660] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,172 [Listener at localhost/34660] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:50,172 [Listener at localhost/34660] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:50,173 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:50,173 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:50
2020-12-03 07:20:50,173 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:50,173 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,173 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:50,174 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:50,179 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:50,179 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:50,180 [Listener at localhost/34660] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:50,180 [Listener at localhost/34660] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:50,180 [Listener at localhost/34660] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:50,180 [Listener at localhost/34660] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:50,181 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:50,183 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:50,184 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:50,184 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:50,184 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:50,184 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:50,184 [Listener at localhost/34660] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:50,185 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:50,185 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,186 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:50,186 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:50,188 [Listener at localhost/34660] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:50,188 [Listener at localhost/34660] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:50,188 [Listener at localhost/34660] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:50,189 [Listener at localhost/34660] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:50,189 [Listener at localhost/34660] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:50,189 [Listener at localhost/34660] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:50,189 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:50,190 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,190 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:50,190 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:50,191 [Listener at localhost/34660] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:50,191 [Listener at localhost/34660] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:50,191 [Listener at localhost/34660] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:50,191 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:50,191 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:50,192 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:50,192 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:50,192 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:50,192 [Listener at localhost/34660] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:50,241 [Listener at localhost/34660] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:50,295 [Listener at localhost/34660] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:50,296 [Listener at localhost/34660] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:20:50,299 [Listener at localhost/34660] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:50,300 [Listener at localhost/34660] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:50,302 [Listener at localhost/34660] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:50,315 [Listener at localhost/34660] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:50,315 [Listener at localhost/34660] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:20:50,321 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:20:50,322 [Listener at localhost/34660] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:50,322 [Listener at localhost/34660] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 129 msecs
2020-12-03 07:20:50,322 [Listener at localhost/34660] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:50,324 [Listener at localhost/34660] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,324 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,367 [Listener at localhost/40767] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:50,424 [Listener at localhost/40767] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:50,431 [Listener at localhost/40767] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:50,431 [Listener at localhost/40767] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:50,432 [Listener at localhost/40767] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:50,451 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,453 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,463 [Listener at localhost/40767] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40767
2020-12-03 07:20:50,463 [Listener at localhost/40767] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:50,463 [Listener at localhost/40767] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:50,463 [Listener at localhost/40767] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:50,464 [Listener at localhost/40767] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:50,464 [Listener at localhost/40767] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:50,578 [Listener at localhost/40767] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:50,579 [Listener at localhost/40767] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:50,580 [Listener at localhost/40767] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:50,581 [Listener at localhost/40767] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,581 [Listener at localhost/40767] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,581 [Listener at localhost/40767] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,585 [Listener at localhost/40767] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,585 [Listener at localhost/40767] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,585 [Listener at localhost/40767] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,586 [Listener at localhost/40767] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46404
2020-12-03 07:20:50,586 [Listener at localhost/40767] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,586 [Listener at localhost/40767] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,587 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,589 [Listener at localhost/40767] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,591 [Listener at localhost/40767] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,591 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,607 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,608 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,608 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,608 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,615 [Listener at localhost/40767] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43615
2020-12-03 07:20:50,615 [Listener at localhost/40767] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,619 [Listener at localhost/40767] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7eaa5e40{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:50,620 [Listener at localhost/40767] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a09052d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:50,632 [Listener at localhost/40767] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6372bf60{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,633 [Listener at localhost/40767] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1684c1d7{HTTP/1.1,[http/1.1]}{localhost:43615}
2020-12-03 07:20:50,634 [Listener at localhost/40767] INFO  server.Server (Server.java:doStart(419)) - Started @14579ms
2020-12-03 07:20:50,679 [Listener at localhost/40767] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32972
2020-12-03 07:20:50,685 [Listener at localhost/40767] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,685 [Listener at localhost/40767] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,685 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@14c78eef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,686 [Listener at localhost/40767] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,686 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,691 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39192
2020-12-03 07:20:50,699 [Listener at localhost/39192] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:50,700 [Listener at localhost/39192] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:50,701 [Thread-605] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:50,701 [Thread-606] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:50,706 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,707 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,731 [Listener at localhost/39192] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:50,750 [Thread-605] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:50,754 [Listener at localhost/39192] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:50,754 [Listener at localhost/39192] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:50,758 [Listener at localhost/39192] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,764 [Listener at localhost/39192] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,764 [Listener at localhost/39192] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,765 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,766 [Listener at localhost/39192] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,766 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,767 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43541
2020-12-03 07:20:50,767 [Listener at localhost/39192] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,767 [Listener at localhost/39192] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,771 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,773 [Listener at localhost/39192] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,775 [Listener at localhost/39192] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,775 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,778 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,778 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,779 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,779 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,780 [Listener at localhost/39192] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39791
2020-12-03 07:20:50,780 [Listener at localhost/39192] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,782 [Listener at localhost/39192] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d5e2194{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:50,783 [Listener at localhost/39192] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@545e2c83{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:50,789 [Listener at localhost/39192] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54afdbbc{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,791 [Listener at localhost/39192] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1cba6856{HTTP/1.1,[http/1.1]}{localhost:39791}
2020-12-03 07:20:50,791 [Listener at localhost/39192] INFO  server.Server (Server.java:doStart(419)) - Started @14737ms
2020-12-03 07:20:50,805 [Thread-605] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:50,806 [Thread-605] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:50,807 [Thread-605] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:50,810 [Listener at localhost/39192] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38023
2020-12-03 07:20:50,810 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,811 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d36dc74] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,811 [Listener at localhost/39192] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,811 [Listener at localhost/39192] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,812 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,819 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40358
2020-12-03 07:20:50,824 [Listener at localhost/40358] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:50,825 [Listener at localhost/40358] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:50,826 [Thread-630] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:50,826 [Thread-631] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:50,832 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,832 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,837 [Thread-630] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:50,837 [Listener at localhost/40358] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:50,838 [Listener at localhost/40358] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:50,838 [Listener at localhost/40358] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:50,839 [Listener at localhost/40358] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,840 [Listener at localhost/40358] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,840 [Listener at localhost/40358] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,840 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,841 [Listener at localhost/40358] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,841 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,841 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35665
2020-12-03 07:20:50,842 [Listener at localhost/40358] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,842 [Listener at localhost/40358] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,842 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,844 [Listener at localhost/40358] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,845 [Listener at localhost/40358] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,845 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,847 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,847 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,847 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,848 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,848 [Listener at localhost/40358] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38570
2020-12-03 07:20:50,848 [Listener at localhost/40358] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,852 [Listener at localhost/40358] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ca4fea9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:50,852 [Listener at localhost/40358] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22824406{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:50,858 [Listener at localhost/40358] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c964831{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,860 [Listener at localhost/40358] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1ca332ca{HTTP/1.1,[http/1.1]}{localhost:38570}
2020-12-03 07:20:50,860 [Listener at localhost/40358] INFO  server.Server (Server.java:doStart(419)) - Started @14806ms
2020-12-03 07:20:50,876 [Listener at localhost/40358] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39170
2020-12-03 07:20:50,877 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,877 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@79bfd1dd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,877 [Listener at localhost/40358] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,878 [Listener at localhost/40358] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,878 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,889 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39270
2020-12-03 07:20:50,894 [Thread-630] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:50,894 [Listener at localhost/39270] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:50,894 [Thread-630] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:50,894 [Listener at localhost/39270] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:50,895 [Thread-630] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:50,895 [Thread-653] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:50,895 [Thread-654] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:50,897 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,901 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,910 [Thread-654] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:50,910 [Listener at localhost/39270] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:50,911 [Listener at localhost/39270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:50,913 [Listener at localhost/39270] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:50,921 [Listener at localhost/39270] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,923 [Listener at localhost/39270] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,923 [Listener at localhost/39270] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,923 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,923 [Listener at localhost/39270] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,924 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,925 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34311
2020-12-03 07:20:50,925 [Listener at localhost/39270] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,925 [Listener at localhost/39270] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,926 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,933 [Listener at localhost/39270] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,934 [Listener at localhost/39270] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,934 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:50,935 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,936 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,936 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,936 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,937 [Listener at localhost/39270] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42069
2020-12-03 07:20:50,937 [Listener at localhost/39270] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,939 [Listener at localhost/39270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69a4b8bf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:50,939 [Listener at localhost/39270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@46492430{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:50,945 [Listener at localhost/39270] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@597f87ba{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,946 [Listener at localhost/39270] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@95bc572{HTTP/1.1,[http/1.1]}{localhost:42069}
2020-12-03 07:20:50,946 [Listener at localhost/39270] INFO  server.Server (Server.java:doStart(419)) - Started @14891ms
2020-12-03 07:20:50,968 [Thread-654] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:50,969 [Thread-654] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:50,970 [Thread-654] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:50,989 [Listener at localhost/39270] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44223
2020-12-03 07:20:50,990 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,990 [Listener at localhost/39270] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,990 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1bf5b014] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,990 [Listener at localhost/39270] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,991 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,994 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38947
2020-12-03 07:20:50,998 [Listener at localhost/38947] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:50,999 [Listener at localhost/38947] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,000 [Thread-676] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,010 [Thread-676] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,012 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,012 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,018 [Listener at localhost/38947] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:51,019 [Listener at localhost/38947] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:51,019 [Listener at localhost/38947] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:51,020 [Listener at localhost/38947] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,021 [Listener at localhost/38947] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,021 [Listener at localhost/38947] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,022 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,022 [Listener at localhost/38947] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,022 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,023 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33394
2020-12-03 07:20:51,023 [Listener at localhost/38947] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,023 [Listener at localhost/38947] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,024 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,025 [Listener at localhost/38947] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,026 [Listener at localhost/38947] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,026 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,028 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,028 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,028 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,028 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,029 [Listener at localhost/38947] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38700
2020-12-03 07:20:51,029 [Listener at localhost/38947] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,031 [Listener at localhost/38947] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@683fa6ab{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:51,031 [Listener at localhost/38947] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ce017ef{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:51,036 [Listener at localhost/38947] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26eff489{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,036 [Listener at localhost/38947] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6be1d4b7{HTTP/1.1,[http/1.1]}{localhost:38700}
2020-12-03 07:20:51,040 [Listener at localhost/38947] INFO  server.Server (Server.java:doStart(419)) - Started @14986ms
2020-12-03 07:20:51,055 [Listener at localhost/38947] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42134
2020-12-03 07:20:51,056 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,056 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@930b6b8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,056 [Listener at localhost/38947] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,057 [Listener at localhost/38947] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,057 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,061 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40872
2020-12-03 07:20:51,065 [Listener at localhost/40872] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:51,066 [Listener at localhost/40872] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,067 [Thread-699] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,067 [Thread-700] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:51,069 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,069 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,071 [Thread-676] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,071 [Thread-676] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,073 [Thread-676] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:51,077 [Thread-605] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,078 [Thread-605] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,078 [Thread-605] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:51,079 [Listener at localhost/40872] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:51,080 [Listener at localhost/40872] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:51,080 [Listener at localhost/40872] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:51,088 [Thread-699] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,089 [Listener at localhost/40872] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,090 [Listener at localhost/40872] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,090 [Listener at localhost/40872] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,091 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,091 [Listener at localhost/40872] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,091 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,095 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35247
2020-12-03 07:20:51,095 [Listener at localhost/40872] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,095 [Listener at localhost/40872] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,096 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,098 [Listener at localhost/40872] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,098 [Listener at localhost/40872] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,098 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,100 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,100 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,100 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,101 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,101 [Listener at localhost/40872] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35381
2020-12-03 07:20:51,101 [Listener at localhost/40872] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,103 [Listener at localhost/40872] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7506712f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:51,103 [Listener at localhost/40872] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@410f6b99{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:51,108 [Listener at localhost/40872] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b2cc0ad{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,109 [Listener at localhost/40872] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76c7b706{HTTP/1.1,[http/1.1]}{localhost:35381}
2020-12-03 07:20:51,110 [Listener at localhost/40872] INFO  server.Server (Server.java:doStart(419)) - Started @15055ms
2020-12-03 07:20:51,134 [Listener at localhost/40872] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40866
2020-12-03 07:20:51,135 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,135 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3dd91e65] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,135 [Listener at localhost/40872] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,135 [Listener at localhost/40872] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,136 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,140 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45815
2020-12-03 07:20:51,143 [Listener at localhost/45815] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:51,144 [Listener at localhost/45815] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,144 [Thread-722] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,146 [Thread-723] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:51,146 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,147 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,152 [Thread-722] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,153 [Listener at localhost/45815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:51,154 [Listener at localhost/45815] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:51,154 [Listener at localhost/45815] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:51,155 [Listener at localhost/45815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,156 [Listener at localhost/45815] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,156 [Listener at localhost/45815] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,157 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,157 [Listener at localhost/45815] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,157 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,158 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43921
2020-12-03 07:20:51,158 [Listener at localhost/45815] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,158 [Listener at localhost/45815] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,159 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,161 [Listener at localhost/45815] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,162 [Listener at localhost/45815] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,162 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,163 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,164 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,164 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,164 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,164 [Listener at localhost/45815] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37875
2020-12-03 07:20:51,165 [Listener at localhost/45815] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,166 [Listener at localhost/45815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15668629{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:51,166 [Listener at localhost/45815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d084767{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:51,171 [Listener at localhost/45815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@796ad650{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,171 [Listener at localhost/45815] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7cfea09f{HTTP/1.1,[http/1.1]}{localhost:37875}
2020-12-03 07:20:51,172 [Listener at localhost/45815] INFO  server.Server (Server.java:doStart(419)) - Started @15117ms
2020-12-03 07:20:51,176 [Thread-630] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,177 [Thread-630] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,176 [Thread-699] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,177 [Thread-699] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,178 [Thread-630] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:51,178 [Thread-699] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:51,187 [Listener at localhost/45815] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38088
2020-12-03 07:20:51,188 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c3a9752] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,188 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,188 [Listener at localhost/45815] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,188 [Listener at localhost/45815] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,189 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,192 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45041
2020-12-03 07:20:51,196 [Listener at localhost/45041] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:51,197 [Listener at localhost/45041] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,198 [Thread-745] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,198 [Thread-746] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:51,199 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,199 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,203 [Thread-745] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,204 [Listener at localhost/45041] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:51,205 [Listener at localhost/45041] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:51,205 [Listener at localhost/45041] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:51,206 [Listener at localhost/45041] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,207 [Listener at localhost/45041] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,207 [Listener at localhost/45041] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,208 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,208 [Listener at localhost/45041] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,208 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,209 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34735
2020-12-03 07:20:51,209 [Listener at localhost/45041] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,210 [Listener at localhost/45041] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,211 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,213 [Listener at localhost/45041] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,214 [Listener at localhost/45041] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,214 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,217 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,218 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,218 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,218 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,219 [Listener at localhost/45041] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38592
2020-12-03 07:20:51,220 [Thread-722] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,220 [Listener at localhost/45041] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,220 [Thread-722] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,221 [Thread-722] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-967262b4-e3bd-4e88-8755-c79daaf8394d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:51,222 [Listener at localhost/45041] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c6ac6dc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:51,223 [Listener at localhost/45041] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26f51391{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:51,228 [Listener at localhost/45041] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f4f6170{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,229 [Listener at localhost/45041] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a89d96e{HTTP/1.1,[http/1.1]}{localhost:38592}
2020-12-03 07:20:51,229 [Listener at localhost/45041] INFO  server.Server (Server.java:doStart(419)) - Started @15175ms
2020-12-03 07:20:51,246 [Listener at localhost/45041] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32884
2020-12-03 07:20:51,246 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,246 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@261199] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,246 [Listener at localhost/45041] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,247 [Listener at localhost/45041] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,248 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,250 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39163
2020-12-03 07:20:51,255 [Listener at localhost/39163] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:51,255 [Listener at localhost/39163] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,256 [Thread-768] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,256 [Thread-769] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:51,258 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,258 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,262 [Thread-769] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,262 [Listener at localhost/39163] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:51,263 [Listener at localhost/39163] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:51,264 [Listener at localhost/39163] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:51,264 [Listener at localhost/39163] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,265 [Listener at localhost/39163] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,265 [Listener at localhost/39163] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,266 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,266 [Listener at localhost/39163] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,266 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,267 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39446
2020-12-03 07:20:51,267 [Listener at localhost/39163] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,267 [Listener at localhost/39163] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,268 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,270 [Listener at localhost/39163] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,270 [Thread-654] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,270 [Thread-745] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,270 [Listener at localhost/39163] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,271 [Thread-745] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,271 [Thread-654] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,271 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:51,272 [Thread-654] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-084688e0-b696-4feb-9a70-bae1153c2c96 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:51,273 [Thread-745] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-deec0f73-9130-4324-b345-237719640551 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:51,273 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,273 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,273 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,274 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,275 [Listener at localhost/39163] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36336
2020-12-03 07:20:51,275 [Listener at localhost/39163] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,277 [Listener at localhost/39163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4727c35e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:51,277 [Listener at localhost/39163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@692e5915{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:51,280 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,280 [Thread-605] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,281 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,281 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,282 [Listener at localhost/39163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@500de106{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,283 [Listener at localhost/39163] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22f740e8{HTTP/1.1,[http/1.1]}{localhost:36336}
2020-12-03 07:20:51,284 [Listener at localhost/39163] INFO  server.Server (Server.java:doStart(419)) - Started @15230ms
2020-12-03 07:20:51,299 [Listener at localhost/39163] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36590
2020-12-03 07:20:51,300 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,300 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65d36970] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,300 [Listener at localhost/39163] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,300 [Listener at localhost/39163] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,301 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,304 [Listener at localhost/37495] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37495
2020-12-03 07:20:51,309 [Listener at localhost/37495] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:51,309 [Listener at localhost/37495] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:51,310 [Thread-791] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34660 starting to offer service
2020-12-03 07:20:51,310 [Thread-792] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:51,312 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,312 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,316 [Thread-791] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,323 [IPC Server handler 4 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,324 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,324 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,327 [Thread-769] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,328 [Thread-769] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,329 [Thread-769] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:51,402 [Thread-676] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,402 [Thread-791] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,402 [Thread-676] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,402 [Thread-791] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,404 [Thread-676] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:51,404 [Thread-791] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:20:51,413 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,414 [Thread-630] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,414 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,414 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,427 [IPC Server handler 8 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,428 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,428 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,530 [IPC Server handler 7 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,531 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,531 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,535 [Thread-699] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,535 [Thread-699] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,536 [Thread-699] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fb5435bb-b373-411d-8e79-cdbe269eccda for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:51,545 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,545 [Thread-605] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,545 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,545 [Thread-605] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,546 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,547 [Thread-654] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,547 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,547 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,587 [Thread-722] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,588 [Thread-722] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,589 [Thread-722] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b995a809-d7bf-4e34-8395-a1e2871d908f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:51,632 [IPC Server handler 6 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,633 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,633 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,646 [Thread-745] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,646 [Thread-745] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,650 [Thread-745] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:51,654 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,654 [Thread-676] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,654 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,654 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,656 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,657 [Thread-630] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,657 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,657 [Thread-630] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,734 [IPC Server handler 5 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,735 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,735 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,754 [Thread-769] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,754 [Thread-769] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,756 [Thread-769] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b61fcf2e-1339-4218-98c3-bf1b321df32f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:51,821 [Thread-791] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 5168@e0452826fee8
2020-12-03 07:20:51,821 [Thread-791] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 192976201. Formatting...
2020-12-03 07:20:51,821 [Thread-791] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:20:51,821 [Thread-605] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:51,830 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,830 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,830 [Thread-654] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,830 [Thread-699] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,830 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,830 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,830 [Thread-654] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,830 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,837 [IPC Server handler 9 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,837 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,838 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:51,884 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,884 [Thread-722] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,884 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,884 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,928 [Thread-630] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:51,936 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,936 [Thread-676] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,936 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,936 [Thread-676] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,939 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,939 [IPC Server handler 0 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:51,939 [Thread-745] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:51,939 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:51,939 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:51,939 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:51,940 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,004 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,004 [Thread-769] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,004 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,004 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,041 [IPC Server handler 1 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,042 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,042 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,064 [Thread-605] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,066 [Thread-654] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,067 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215
2020-12-03 07:20:52,069 [Thread-605] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:52,070 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ccabc258-30b1-427e-9aa2-7e007e3f4537
2020-12-03 07:20:52,070 [Thread-605] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:52,071 [Thread-605] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,072 [Thread-605] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:52,072 [Thread-605] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:52,072 [Thread-605] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:52,072 [Thread-605] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:52,073 [Thread-605] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,074 [Thread-806] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:52,074 [Thread-807] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:52,076 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,076 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,076 [Thread-699] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,076 [Thread-791] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,076 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,076 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,076 [Thread-699] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,076 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,103 [Thread-806] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 29ms
2020-12-03 07:20:52,103 [Thread-807] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 29ms
2020-12-03 07:20:52,104 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 31ms
2020-12-03 07:20:52,104 [Thread-810] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:52,104 [Thread-811] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:52,104 [Thread-810] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,104 [Thread-811] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,105 [Thread-811] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:20:52,105 [Thread-810] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:20:52,106 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 2ms
2020-12-03 07:20:52,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:52,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:52,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ccabc258-30b1-427e-9aa2-7e007e3f4537): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,107 [Thread-605] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:34 AM with interval of 21600000ms
2020-12-03 07:20:52,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ccabc258-30b1-427e-9aa2-7e007e3f4537): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,109 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,109 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,110 [IPC Server handler 2 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,111 [IPC Server handler 4 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,112 [IPC Server handler 2 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46404
2020-12-03 07:20:52,112 [IPC Server handler 2 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6695dc3f-842e-4be0-a335-736765d3d9f1 (127.0.0.1:46404).
2020-12-03 07:20:52,112 [IPC Server handler 4 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46404
2020-12-03 07:20:52,113 [IPC Server handler 4 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6695dc3f-842e-4be0-a335-736765d3d9f1 (127.0.0.1:46404).
2020-12-03 07:20:52,115 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,115 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,116 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,116 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,119 [IPC Server handler 3 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 for DN 127.0.0.1:46404
2020-12-03 07:20:52,119 [IPC Server handler 3 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 for DN 127.0.0.1:46404
2020-12-03 07:20:52,122 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe4947b5cd7427952: Processing first storage report for DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 from datanode 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,123 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 for DN 127.0.0.1:46404
2020-12-03 07:20:52,124 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe4947b5cd7427952: from storage DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 node DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,124 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 for DN 127.0.0.1:46404
2020-12-03 07:20:52,124 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe4947b5cd7427952: Processing first storage report for DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 from datanode 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,125 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe4947b5cd7427952: from storage DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 node DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,128 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe4947b5cd7427952,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,129 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf1cecd1fa34e9a3f: Processing first storage report for DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 from datanode 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf1cecd1fa34e9a3f: from storage DS-ccabc258-30b1-427e-9aa2-7e007e3f4537 node DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf1cecd1fa34e9a3f: Processing first storage report for DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 from datanode 6695dc3f-842e-4be0-a335-736765d3d9f1
2020-12-03 07:20:52,130 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf1cecd1fa34e9a3f: from storage DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215 node DatanodeRegistration(127.0.0.1:46404, datanodeUuid=6695dc3f-842e-4be0-a335-736765d3d9f1, infoPort=32972, infoSecurePort=0, ipcPort=39192, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,131 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf1cecd1fa34e9a3f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,143 [IPC Server handler 8 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,144 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,144 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,149 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,149 [Thread-722] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,149 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,149 [Thread-722] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,208 [Thread-630] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,208 [Thread-676] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,210 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192
2020-12-03 07:20:52,210 [Thread-630] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:52,212 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf
2020-12-03 07:20:52,212 [Thread-630] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:52,213 [Thread-630] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,214 [Thread-630] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:52,215 [Thread-630] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:52,215 [Thread-630] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:52,215 [Thread-630] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:52,216 [Thread-630] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,217 [Thread-817] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:52,217 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:52,219 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,219 [Thread-745] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,220 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,220 [Thread-745] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,246 [IPC Server handler 7 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,247 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,247 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,251 [Thread-818] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 34ms
2020-12-03 07:20:52,253 [Thread-817] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 36ms
2020-12-03 07:20:52,253 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 37ms
2020-12-03 07:20:52,253 [Thread-821] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:52,254 [Thread-822] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:52,254 [Thread-821] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,254 [Thread-822] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,254 [Thread-821] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:52,254 [Thread-822] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:52,254 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 1ms
2020-12-03 07:20:52,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:52,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:52,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,255 [Thread-630] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:52 AM with interval of 21600000ms
2020-12-03 07:20:52,257 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,257 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:52,258 [IPC Server handler 5 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,258 [IPC Server handler 6 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,258 [IPC Server handler 5 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43541
2020-12-03 07:20:52,259 [IPC Server handler 6 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43541
2020-12-03 07:20:52,259 [IPC Server handler 5 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1bf1d088-6d9c-46f6-a310-52937e730cae (127.0.0.1:43541).
2020-12-03 07:20:52,259 [IPC Server handler 6 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1bf1d088-6d9c-46f6-a310-52937e730cae (127.0.0.1:43541).
2020-12-03 07:20:52,260 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,260 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,260 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,260 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,263 [IPC Server handler 8 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 for DN 127.0.0.1:43541
2020-12-03 07:20:52,263 [IPC Server handler 5 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 for DN 127.0.0.1:43541
2020-12-03 07:20:52,265 [IPC Server handler 8 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf for DN 127.0.0.1:43541
2020-12-03 07:20:52,266 [IPC Server handler 5 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf for DN 127.0.0.1:43541
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x867be911478ac167: Processing first storage report for DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf from datanode 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x867be911478ac167: from storage DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf node DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x802d3dd52e4f1747: Processing first storage report for DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf from datanode 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x867be911478ac167: Processing first storage report for DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 from datanode 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x867be911478ac167: from storage DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 node DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x802d3dd52e4f1747: from storage DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf node DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,269 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x802d3dd52e4f1747: Processing first storage report for DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 from datanode 1bf1d088-6d9c-46f6-a310-52937e730cae
2020-12-03 07:20:52,269 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x802d3dd52e4f1747: from storage DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192 node DatanodeRegistration(127.0.0.1:43541, datanodeUuid=1bf1d088-6d9c-46f6-a310-52937e730cae, infoPort=38023, infoSecurePort=0, ipcPort=40358, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,269 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x867be911478ac167,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,269 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x802d3dd52e4f1747,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,294 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,294 [Thread-769] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,295 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,295 [Thread-769] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,329 [Thread-699] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,333 [Thread-654] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,339 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3
2020-12-03 07:20:52,339 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:52,342 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,342 [Thread-791] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,342 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-084688e0-b696-4feb-9a70-bae1153c2c96
2020-12-03 07:20:52,343 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:52,343 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1253628075-172.17.0.3-1606980049384 is not formatted. Formatting ...
2020-12-03 07:20:52,343 [Thread-791] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1253628075-172.17.0.3-1606980049384 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1253628075-172.17.0.3-1606980049384/current
2020-12-03 07:20:52,343 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,344 [Thread-654] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:52,345 [Thread-654] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:52,345 [Thread-654] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:52,345 [Thread-654] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:52,346 [Thread-654] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,346 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:52,346 [Thread-829] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:52,349 [IPC Server handler 0 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,350 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,350 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,375 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 29ms
2020-12-03 07:20:52,375 [Thread-829] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 29ms
2020-12-03 07:20:52,375 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 29ms
2020-12-03 07:20:52,376 [Thread-832] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:52,376 [Thread-833] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:52,376 [Thread-832] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,376 [Thread-833] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,380 [Thread-832] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-12-03 07:20:52,380 [Thread-833] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:20:52,380 [Thread-654] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 5ms
2020-12-03 07:20:52,380 [Thread-722] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,380 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:52,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:52,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-084688e0-b696-4feb-9a70-bae1153c2c96): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,381 [Thread-654] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:16 PM with interval of 21600000ms
2020-12-03 07:20:52,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-084688e0-b696-4feb-9a70-bae1153c2c96): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,382 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,383 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,383 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:52,384 [IPC Server handler 0 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,384 [IPC Server handler 1 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,385 [IPC Server handler 0 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35665
2020-12-03 07:20:52,385 [IPC Server handler 1 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35665
2020-12-03 07:20:52,385 [IPC Server handler 0 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e5faabfb-a4f3-4152-a752-358d3e3868d8 (127.0.0.1:35665).
2020-12-03 07:20:52,385 [IPC Server handler 1 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e5faabfb-a4f3-4152-a752-358d3e3868d8 (127.0.0.1:35665).
2020-12-03 07:20:52,386 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,386 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,386 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,386 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,391 [IPC Server handler 7 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 for DN 127.0.0.1:35665
2020-12-03 07:20:52,392 [IPC Server handler 2 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 for DN 127.0.0.1:35665
2020-12-03 07:20:52,392 [IPC Server handler 7 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-084688e0-b696-4feb-9a70-bae1153c2c96 for DN 127.0.0.1:35665
2020-12-03 07:20:52,392 [IPC Server handler 2 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-084688e0-b696-4feb-9a70-bae1153c2c96 for DN 127.0.0.1:35665
2020-12-03 07:20:52,394 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe97f42b529dd4c26: Processing first storage report for DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 from datanode e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,395 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe97f42b529dd4c26: from storage DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 node DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,395 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe97f42b529dd4c26: Processing first storage report for DS-084688e0-b696-4feb-9a70-bae1153c2c96 from datanode e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,395 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe97f42b529dd4c26: from storage DS-084688e0-b696-4feb-9a70-bae1153c2c96 node DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,396 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a8bbbc21f107cd7: Processing first storage report for DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 from datanode e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,397 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a8bbbc21f107cd7: from storage DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3 node DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,397 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe97f42b529dd4c26,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,397 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a8bbbc21f107cd7: Processing first storage report for DS-084688e0-b696-4feb-9a70-bae1153c2c96 from datanode e5faabfb-a4f3-4152-a752-358d3e3868d8
2020-12-03 07:20:52,397 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a8bbbc21f107cd7: from storage DS-084688e0-b696-4feb-9a70-bae1153c2c96 node DatanodeRegistration(127.0.0.1:35665, datanodeUuid=e5faabfb-a4f3-4152-a752-358d3e3868d8, infoPort=39170, infoSecurePort=0, ipcPort=39270, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,398 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a8bbbc21f107cd7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,453 [Thread-676] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,453 [IPC Server handler 4 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,453 [Thread-745] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,454 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,455 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,458 [Thread-676] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9e29d8a7-1588-4411-8d21-7e427bfa3244
2020-12-03 07:20:52,458 [Thread-676] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:52,462 [Thread-676] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51
2020-12-03 07:20:52,462 [Thread-676] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:52,462 [Thread-676] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,464 [Thread-676] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:52,467 [Thread-676] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:52,467 [Thread-676] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:52,467 [Thread-676] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:52,474 [Thread-676] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,475 [Thread-839] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:52,475 [Thread-840] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:52,498 [Thread-769] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,507 [Thread-839] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 32ms
2020-12-03 07:20:52,507 [Thread-840] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 32ms
2020-12-03 07:20:52,507 [Thread-676] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 33ms
2020-12-03 07:20:52,508 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:52,508 [Thread-844] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:52,508 [Thread-843] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,508 [Thread-844] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,508 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:20:52,509 [Thread-844] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:20:52,525 [Thread-676] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 18ms
2020-12-03 07:20:52,526 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:52,526 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9e29d8a7-1588-4411-8d21-7e427bfa3244): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,526 [Thread-676] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:02 PM with interval of 21600000ms
2020-12-03 07:20:52,527 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:52,527 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9e29d8a7-1588-4411-8d21-7e427bfa3244): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:52,527 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,528 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:52,532 [Thread-677] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:40767 starting to offer service
2020-12-03 07:20:52,532 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,533 [IPC Server handler 8 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,534 [IPC Server handler 8 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34311
2020-12-03 07:20:52,535 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,535 [IPC Server handler 8 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8ba8531f-b428-4906-9dc4-80db19159019 (127.0.0.1:34311).
2020-12-03 07:20:52,536 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,536 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,536 [IPC Server handler 4 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,543 [IPC Server handler 4 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34311
2020-12-03 07:20:52,543 [Thread-791] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=192976201;bpid=BP-1253628075-172.17.0.3-1606980049384;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=192976201;c=1606980049384;bpid=BP-1253628075-172.17.0.3-1606980049384;dnuuid=null
2020-12-03 07:20:52,543 [IPC Server handler 4 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8ba8531f-b428-4906-9dc4-80db19159019 (127.0.0.1:34311).
2020-12-03 07:20:52,543 [Thread-699] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,544 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,544 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,545 [IPC Server handler 7 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 for DN 127.0.0.1:34311
2020-12-03 07:20:52,545 [IPC Server handler 7 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 for DN 127.0.0.1:34311
2020-12-03 07:20:52,547 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868
2020-12-03 07:20:52,548 [IPC Server handler 3 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 for DN 127.0.0.1:34311
2020-12-03 07:20:52,549 [Thread-699] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:52,549 [IPC Server handler 3 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 for DN 127.0.0.1:34311
2020-12-03 07:20:52,550 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1c9994106261aaa7: Processing first storage report for DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 from datanode 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,550 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fb5435bb-b373-411d-8e79-cdbe269eccda
2020-12-03 07:20:52,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1c9994106261aaa7: from storage DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 node DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,552 [Thread-699] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:52,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1c9994106261aaa7: Processing first storage report for DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 from datanode 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1c9994106261aaa7: from storage DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 node DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe73cf1765b722b8a: Processing first storage report for DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 from datanode 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,552 [Thread-699] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,552 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe73cf1765b722b8a: from storage DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51 node DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe73cf1765b722b8a: Processing first storage report for DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 from datanode 8ba8531f-b428-4906-9dc4-80db19159019
2020-12-03 07:20:52,553 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe73cf1765b722b8a: from storage DS-9e29d8a7-1588-4411-8d21-7e427bfa3244 node DatanodeRegistration(127.0.0.1:34311, datanodeUuid=8ba8531f-b428-4906-9dc4-80db19159019, infoPort=44223, infoSecurePort=0, ipcPort=38947, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,553 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1c9994106261aaa7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,553 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe73cf1765b722b8a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,553 [Thread-699] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:52,554 [Thread-699] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:52,554 [Thread-699] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:52,554 [Thread-699] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:52,554 [Thread-699] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,555 [Thread-850] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:52,555 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:52,556 [IPC Server handler 5 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,557 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,557 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,580 [Thread-722] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,582 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-967262b4-e3bd-4e88-8755-c79daaf8394d
2020-12-03 07:20:52,582 [Thread-722] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:52,584 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b995a809-d7bf-4e34-8395-a1e2871d908f
2020-12-03 07:20:52,584 [Thread-722] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:52,584 [Thread-851] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 29ms
2020-12-03 07:20:52,589 [Thread-722] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,594 [Thread-722] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:52,594 [Thread-850] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 39ms
2020-12-03 07:20:52,595 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 40ms
2020-12-03 07:20:52,595 [Thread-722] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:52,595 [Thread-722] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:52,595 [Thread-856] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:52,596 [Thread-722] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:52,596 [Thread-856] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,596 [Thread-722] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,596 [Thread-856] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:20:52,596 [Thread-857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:52,597 [Thread-857] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,597 [Thread-859] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:52,597 [Thread-858] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:52,597 [Thread-857] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:20:52,597 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 2ms
2020-12-03 07:20:52,598 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:52,598 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,598 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:52,598 [Thread-699] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:58 AM with interval of 21600000ms
2020-12-03 07:20:52,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fb5435bb-b373-411d-8e79-cdbe269eccda): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:52,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fb5435bb-b373-411d-8e79-cdbe269eccda): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,605 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,609 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,609 [IPC Server handler 9 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,609 [IPC Server handler 9 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33394
2020-12-03 07:20:52,610 [IPC Server handler 9 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5ad93aba-72e9-4306-96f8-0a050f350e46 (127.0.0.1:33394).
2020-12-03 07:20:52,610 [IPC Server handler 5 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,610 [IPC Server handler 5 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33394
2020-12-03 07:20:52,610 [IPC Server handler 5 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5ad93aba-72e9-4306-96f8-0a050f350e46 (127.0.0.1:33394).
2020-12-03 07:20:52,611 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,611 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,611 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,612 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,614 [IPC Server handler 0 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 for DN 127.0.0.1:33394
2020-12-03 07:20:52,615 [IPC Server handler 0 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fb5435bb-b373-411d-8e79-cdbe269eccda for DN 127.0.0.1:33394
2020-12-03 07:20:52,618 [IPC Server handler 8 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 for DN 127.0.0.1:33394
2020-12-03 07:20:52,618 [IPC Server handler 8 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fb5435bb-b373-411d-8e79-cdbe269eccda for DN 127.0.0.1:33394
2020-12-03 07:20:52,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7a70c941277e283d: Processing first storage report for DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 from datanode 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7a70c941277e283d: from storage DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 node DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7a70c941277e283d: Processing first storage report for DS-fb5435bb-b373-411d-8e79-cdbe269eccda from datanode 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7a70c941277e283d: from storage DS-fb5435bb-b373-411d-8e79-cdbe269eccda node DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf029095f645ecc7: Processing first storage report for DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 from datanode 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf029095f645ecc7: from storage DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868 node DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,620 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7a70c941277e283d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf029095f645ecc7: Processing first storage report for DS-fb5435bb-b373-411d-8e79-cdbe269eccda from datanode 5ad93aba-72e9-4306-96f8-0a050f350e46
2020-12-03 07:20:52,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf029095f645ecc7: from storage DS-fb5435bb-b373-411d-8e79-cdbe269eccda node DatanodeRegistration(127.0.0.1:33394, datanodeUuid=5ad93aba-72e9-4306-96f8-0a050f350e46, infoPort=42134, infoSecurePort=0, ipcPort=40872, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,621 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf029095f645ecc7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,629 [Thread-745] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,630 [Thread-858] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 33ms
2020-12-03 07:20:52,631 [Thread-859] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 34ms
2020-12-03 07:20:52,631 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 35ms
2020-12-03 07:20:52,631 [Thread-865] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:52,631 [Thread-867] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:52,631 [Thread-865] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,631 [Thread-745] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-deec0f73-9130-4324-b345-237719640551
2020-12-03 07:20:52,631 [Thread-867] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,632 [Thread-745] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:52,632 [Thread-865] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:52,632 [Thread-867] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:52,632 [Thread-745] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a
2020-12-03 07:20:52,633 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 1ms
2020-12-03 07:20:52,633 [Thread-745] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:52,633 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:52,633 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:52,633 [Thread-745] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,633 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-967262b4-e3bd-4e88-8755-c79daaf8394d): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,633 [Thread-722] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:34 AM with interval of 21600000ms
2020-12-03 07:20:52,633 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-b995a809-d7bf-4e34-8395-a1e2871d908f): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,636 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,636 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,636 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-b995a809-d7bf-4e34-8395-a1e2871d908f): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:52,637 [Thread-745] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:52,637 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-967262b4-e3bd-4e88-8755-c79daaf8394d): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:52,637 [Thread-745] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:52,638 [Thread-745] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:52,638 [IPC Server handler 0 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,638 [Thread-745] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:52,638 [IPC Server handler 2 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,638 [IPC Server handler 0 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35247
2020-12-03 07:20:52,638 [Thread-745] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,638 [IPC Server handler 0 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6 (127.0.0.1:35247).
2020-12-03 07:20:52,638 [IPC Server handler 2 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35247
2020-12-03 07:20:52,638 [IPC Server handler 2 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6 (127.0.0.1:35247).
2020-12-03 07:20:52,639 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:52,639 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,640 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,645 [Thread-873] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:52,646 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-967262b4-e3bd-4e88-8755-c79daaf8394d for DN 127.0.0.1:35247
2020-12-03 07:20:52,646 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b995a809-d7bf-4e34-8395-a1e2871d908f for DN 127.0.0.1:35247
2020-12-03 07:20:52,648 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,648 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,652 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x20962fd6161fbe7f: Processing first storage report for DS-b995a809-d7bf-4e34-8395-a1e2871d908f from datanode aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,653 [IPC Server handler 7 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-967262b4-e3bd-4e88-8755-c79daaf8394d for DN 127.0.0.1:35247
2020-12-03 07:20:52,653 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x20962fd6161fbe7f: from storage DS-b995a809-d7bf-4e34-8395-a1e2871d908f node DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,653 [IPC Server handler 7 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b995a809-d7bf-4e34-8395-a1e2871d908f for DN 127.0.0.1:35247
2020-12-03 07:20:52,653 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x20962fd6161fbe7f: Processing first storage report for DS-967262b4-e3bd-4e88-8755-c79daaf8394d from datanode aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,653 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x20962fd6161fbe7f: from storage DS-967262b4-e3bd-4e88-8755-c79daaf8394d node DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,654 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x20962fd6161fbe7f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,659 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6d1ebf8f7f53b3f: Processing first storage report for DS-b995a809-d7bf-4e34-8395-a1e2871d908f from datanode aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,659 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6d1ebf8f7f53b3f: from storage DS-b995a809-d7bf-4e34-8395-a1e2871d908f node DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,659 [IPC Server handler 8 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,659 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6d1ebf8f7f53b3f: Processing first storage report for DS-967262b4-e3bd-4e88-8755-c79daaf8394d from datanode aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6
2020-12-03 07:20:52,659 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6d1ebf8f7f53b3f: from storage DS-967262b4-e3bd-4e88-8755-c79daaf8394d node DatanodeRegistration(127.0.0.1:35247, datanodeUuid=aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6, infoPort=40866, infoSecurePort=0, ipcPort=45815, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,660 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb6d1ebf8f7f53b3f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,660 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:52,660 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:52,661 [Thread-769] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,663 [Thread-769] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0
2020-12-03 07:20:52,663 [Thread-769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:52,664 [Thread-769] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b61fcf2e-1339-4218-98c3-bf1b321df32f
2020-12-03 07:20:52,664 [Thread-769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:52,665 [Thread-769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,665 [Thread-769] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:52,666 [Thread-769] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:52,666 [Thread-769] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:52,666 [Thread-769] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:52,667 [Thread-769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,667 [Thread-878] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:52,667 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:52,673 [Thread-873] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 28ms
2020-12-03 07:20:52,674 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 35ms
2020-12-03 07:20:52,674 [Thread-745] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 36ms
2020-12-03 07:20:52,675 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:52,675 [Thread-880] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,675 [Thread-881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:52,676 [Thread-881] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,676 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:20:52,676 [Thread-881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:20:52,676 [Thread-745] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 2ms
2020-12-03 07:20:52,676 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:52,677 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:52,677 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,677 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-deec0f73-9130-4324-b345-237719640551): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,677 [Thread-745] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:44 PM with interval of 21600000ms
2020-12-03 07:20:52,677 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,678 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-deec0f73-9130-4324-b345-237719640551): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,678 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,680 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,681 [IPC Server handler 7 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,682 [IPC Server handler 2 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,682 [IPC Server handler 7 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43921
2020-12-03 07:20:52,682 [IPC Server handler 7 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f5c9f6c1-cf5f-4a10-920a-f87690ff80ad (127.0.0.1:43921).
2020-12-03 07:20:52,682 [IPC Server handler 2 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43921
2020-12-03 07:20:52,682 [IPC Server handler 2 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f5c9f6c1-cf5f-4a10-920a-f87690ff80ad (127.0.0.1:43921).
2020-12-03 07:20:52,683 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,683 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,683 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,683 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,686 [IPC Server handler 6 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-deec0f73-9130-4324-b345-237719640551 for DN 127.0.0.1:43921
2020-12-03 07:20:52,687 [IPC Server handler 6 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a for DN 127.0.0.1:43921
2020-12-03 07:20:52,688 [IPC Server handler 4 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-deec0f73-9130-4324-b345-237719640551 for DN 127.0.0.1:43921
2020-12-03 07:20:52,688 [IPC Server handler 4 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a for DN 127.0.0.1:43921
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70958cde1bc390de: Processing first storage report for DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a from datanode f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70958cde1bc390de: from storage DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a node DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x743c83cb35a7885a: Processing first storage report for DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a from datanode f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70958cde1bc390de: Processing first storage report for DS-deec0f73-9130-4324-b345-237719640551 from datanode f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x743c83cb35a7885a: from storage DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a node DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70958cde1bc390de: from storage DS-deec0f73-9130-4324-b345-237719640551 node DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x743c83cb35a7885a: Processing first storage report for DS-deec0f73-9130-4324-b345-237719640551 from datanode f5c9f6c1-cf5f-4a10-920a-f87690ff80ad
2020-12-03 07:20:52,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x743c83cb35a7885a: from storage DS-deec0f73-9130-4324-b345-237719640551 node DatanodeRegistration(127.0.0.1:43921, datanodeUuid=f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, infoPort=38088, infoSecurePort=0, ipcPort=45041, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,691 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x70958cde1bc390de,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,691 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x743c83cb35a7885a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,695 [Thread-791] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,697 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6
2020-12-03 07:20:52,698 [Thread-791] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:52,699 [Thread-878] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 32ms
2020-12-03 07:20:52,699 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed
2020-12-03 07:20:52,699 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 32ms
2020-12-03 07:20:52,699 [Thread-791] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:52,699 [Thread-769] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 32ms
2020-12-03 07:20:52,700 [Thread-791] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:52,701 [Thread-889] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:52,701 [Thread-890] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:52,701 [Thread-889] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,701 [Thread-890] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,701 [Thread-889] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:52,701 [Thread-890] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:20:52,701 [Thread-769] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 1ms
2020-12-03 07:20:52,702 [Thread-791] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:52,702 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:52,702 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:52,702 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,702 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-b61fcf2e-1339-4218-98c3-bf1b321df32f): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,702 [Thread-769] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:31 AM with interval of 21600000ms
2020-12-03 07:20:52,702 [Thread-791] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:52,703 [Thread-791] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:52,703 [Thread-791] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:52,703 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-b61fcf2e-1339-4218-98c3-bf1b321df32f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,703 [Thread-791] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,703 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,705 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,705 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,706 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:52,706 [Thread-895] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:52,707 [IPC Server handler 9 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,707 [IPC Server handler 1 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,707 [IPC Server handler 9 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34735
2020-12-03 07:20:52,707 [IPC Server handler 1 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34735
2020-12-03 07:20:52,708 [IPC Server handler 9 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a09deaa-68eb-44eb-b61e-633f7c7c4312 (127.0.0.1:34735).
2020-12-03 07:20:52,708 [IPC Server handler 1 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a09deaa-68eb-44eb-b61e-633f7c7c4312 (127.0.0.1:34735).
2020-12-03 07:20:52,708 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,709 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,712 [IPC Server handler 0 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 for DN 127.0.0.1:34735
2020-12-03 07:20:52,713 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,713 [IPC Server handler 0 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b61fcf2e-1339-4218-98c3-bf1b321df32f for DN 127.0.0.1:34735
2020-12-03 07:20:52,713 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,716 [IPC Server handler 5 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 for DN 127.0.0.1:34735
2020-12-03 07:20:52,716 [IPC Server handler 5 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b61fcf2e-1339-4218-98c3-bf1b321df32f for DN 127.0.0.1:34735
2020-12-03 07:20:52,717 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x696239358dc050a8: Processing first storage report for DS-b61fcf2e-1339-4218-98c3-bf1b321df32f from datanode 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,718 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x696239358dc050a8: from storage DS-b61fcf2e-1339-4218-98c3-bf1b321df32f node DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,718 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x696239358dc050a8: Processing first storage report for DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 from datanode 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,718 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x696239358dc050a8: from storage DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 node DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,718 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x696239358dc050a8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,719 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3fd4861d5afcc4a3: Processing first storage report for DS-b61fcf2e-1339-4218-98c3-bf1b321df32f from datanode 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,720 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3fd4861d5afcc4a3: from storage DS-b61fcf2e-1339-4218-98c3-bf1b321df32f node DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,720 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3fd4861d5afcc4a3: Processing first storage report for DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 from datanode 7a09deaa-68eb-44eb-b61e-633f7c7c4312
2020-12-03 07:20:52,720 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3fd4861d5afcc4a3: from storage DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0 node DatanodeRegistration(127.0.0.1:34735, datanodeUuid=7a09deaa-68eb-44eb-b61e-633f7c7c4312, infoPort=32884, infoSecurePort=0, ipcPort=39163, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,721 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3fd4861d5afcc4a3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,738 [Thread-895] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 32ms
2020-12-03 07:20:52,738 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1253628075-172.17.0.3-1606980049384 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 32ms
2020-12-03 07:20:52,738 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1253628075-172.17.0.3-1606980049384: 33ms
2020-12-03 07:20:52,739 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:52,739 [Thread-899] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:52,739 [Thread-898] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,739 [Thread-899] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1253628075-172.17.0.3-1606980049384/current/replicas doesn't exist 
2020-12-03 07:20:52,739 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:20:52,740 [Thread-899] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:20:52,740 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1253628075-172.17.0.3-1606980049384: 1ms
2020-12-03 07:20:52,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:52,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1253628075-172.17.0.3-1606980049384 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:52,740 [Thread-791] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:23 AM with interval of 21600000ms
2020-12-03 07:20:52,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed): finished scanning block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:52,741 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:34660 beginning handshake with NN
2020-12-03 07:20:52,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:52,743 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:40767 beginning handshake with NN
2020-12-03 07:20:52,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:52,744 [IPC Server handler 9 on default port 40767] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,744 [IPC Server handler 9 on default port 40767] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39446
2020-12-03 07:20:52,744 [IPC Server handler 9 on default port 40767] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 551485fd-9dd9-406c-8dc8-621b8b449112 (127.0.0.1:39446).
2020-12-03 07:20:52,745 [IPC Server handler 2 on default port 34660] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384) storage 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,745 [IPC Server handler 2 on default port 34660] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39446
2020-12-03 07:20:52,745 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:40767 successfully registered with NN
2020-12-03 07:20:52,746 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40767 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,745 [IPC Server handler 2 on default port 34660] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 551485fd-9dd9-406c-8dc8-621b8b449112 (127.0.0.1:39446).
2020-12-03 07:20:52,748 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:34660 successfully registered with NN
2020-12-03 07:20:52,748 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34660 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:52,750 [IPC Server handler 0 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 for DN 127.0.0.1:39446
2020-12-03 07:20:52,750 [IPC Server handler 0 on default port 40767] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed for DN 127.0.0.1:39446
2020-12-03 07:20:52,752 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 for DN 127.0.0.1:39446
2020-12-03 07:20:52,752 [IPC Server handler 3 on default port 34660] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed for DN 127.0.0.1:39446
2020-12-03 07:20:52,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x48beb5c35b297f92: Processing first storage report for DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 from datanode 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x48beb5c35b297f92: from storage DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 node DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x48beb5c35b297f92: Processing first storage report for DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed from datanode 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x48beb5c35b297f92: from storage DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed node DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x27fe5b3127125cdb: Processing first storage report for DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 from datanode 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x27fe5b3127125cdb: from storage DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6 node DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,754 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x48beb5c35b297f92,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x27fe5b3127125cdb: Processing first storage report for DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed from datanode 551485fd-9dd9-406c-8dc8-621b8b449112
2020-12-03 07:20:52,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x27fe5b3127125cdb: from storage DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed node DatanodeRegistration(127.0.0.1:39446, datanodeUuid=551485fd-9dd9-406c-8dc8-621b8b449112, infoPort=36590, infoSecurePort=0, ipcPort=37495, storageInfo=lv=-57;cid=testClusterID;nsid=192976201;c=1606980049384), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:52,755 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x27fe5b3127125cdb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:52,762 [IPC Server handler 8 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,770 [IPC Server handler 6 on default port 40767] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,772 [Listener at localhost/37495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:52,774 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:52,775 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:52,778 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:52,779 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:20:52,779 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:52,779 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:52,779 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:20:52,782 [Listener at localhost/37495] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:20:52,809 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:20:52,809 [Listener at localhost/37495] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:52,810 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:20:52,810 [Listener at localhost/37495] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:52,822 [Listener at localhost/37495] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:52,823 [Listener at localhost/37495] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:52,826 [CacheReplicationMonitor(871549148)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:52,826 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-12-03 07:20:52,832 [IPC Server handler 7 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,835 [IPC Server handler 6 on default port 34660] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:20:52,835 [IPC Server handler 6 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,838 [IPC Server handler 5 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:52,841 [IPC Server handler 9 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:52,847 [IPC Server handler 0 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/ec/ecFile	dst=null	perm=null	proto=rpc
2020-12-03 07:20:52,881 [IPC Server handler 1 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/ecFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:52,951 [IPC Server handler 2 on default port 34660] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:34735, 127.0.0.1:35665, 127.0.0.1:35247, 127.0.0.1:33394, 127.0.0.1:34311, 127.0.0.1:39446, 127.0.0.1:43541, 127.0.0.1:43921, 127.0.0.1:46404 for /ec/ecFile
2020-12-03 07:20:52,979 [Thread-918] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:52,979 [Thread-916] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:52,979 [Thread-917] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:52,979 [Thread-910] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,070 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:55674 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001 src: /127.0.0.1:55674 dest: /127.0.0.1:34735
2020-12-03 07:20:53,081 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:52602 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001 src: /127.0.0.1:52602 dest: /127.0.0.1:43541
2020-12-03 07:20:53,082 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:40292 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001 src: /127.0.0.1:40292 dest: /127.0.0.1:43921
2020-12-03 07:20:53,081 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:51428 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001 src: /127.0.0.1:51428 dest: /127.0.0.1:46404
2020-12-03 07:20:53,178 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55674, dest: /127.0.0.1:34735, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: 7a09deaa-68eb-44eb-b61e-633f7c7c4312, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001, duration(ns): 37874078
2020-12-03 07:20:53,178 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,184 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52602, dest: /127.0.0.1:43541, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: 1bf1d088-6d9c-46f6-a310-52937e730cae, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001, duration(ns): 65091537
2020-12-03 07:20:53,186 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,192 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40292, dest: /127.0.0.1:43921, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001, duration(ns): 54332338
2020-12-03 07:20:53,193 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,197 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51428, dest: /127.0.0.1:46404, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: 6695dc3f-842e-4be0-a335-736765d3d9f1, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001, duration(ns): 77368792
2020-12-03 07:20:53,197 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,241 [IPC Server handler 1 on default port 34660] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /ec/ecFile is closed by DFSClient_NONMAPREDUCE_276418183_2991
2020-12-03 07:20:53,249 [IPC Server handler 2 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,262 [IPC Server handler 8 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/ec/ecFile	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,274 [Listener at localhost/37495] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /ec/ecFile verified to have all internalBlocks.
2020-12-03 07:20:53,276 [IPC Server handler 3 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/ec/ecFile	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,281 [IPC Server handler 4 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/replicated	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:53,287 [IPC Server handler 7 on default port 34660] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1002, replicas=127.0.0.1:39446, 127.0.0.1:43921, 127.0.0.1:35665 for /ec/replicated
2020-12-03 07:20:53,294 [Thread-932] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,300 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:60962 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002 src: /127.0.0.1:60962 dest: /127.0.0.1:39446
2020-12-03 07:20:53,302 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:60962 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,304 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:40298 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002 src: /127.0.0.1:40298 dest: /127.0.0.1:43921
2020-12-03 07:20:53,305 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:40298 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,306 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:45264 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002 src: /127.0.0.1:45264 dest: /127.0.0.1:35665
2020-12-03 07:20:53,327 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45264, dest: /127.0.0.1:35665, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: e5faabfb-a4f3-4152-a752-358d3e3868d8, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, duration(ns): 18411711
2020-12-03 07:20:53,328 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,329 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35665]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40298, dest: /127.0.0.1:43921, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, duration(ns): 19835095
2020-12-03 07:20:53,330 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35665]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35665] terminating
2020-12-03 07:20:53,332 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43921, 127.0.0.1:35665]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60962, dest: /127.0.0.1:39446, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: 551485fd-9dd9-406c-8dc8-621b8b449112, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, duration(ns): 21865021
2020-12-03 07:20:53,332 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43921, 127.0.0.1:35665]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_1073741825_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43921, 127.0.0.1:35665] terminating
2020-12-03 07:20:53,335 [IPC Server handler 5 on default port 34660] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /ec/replicated is closed by DFSClient_NONMAPREDUCE_276418183_2991
2020-12-03 07:20:53,338 [IPC Server handler 1 on default port 34660] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/RS-3-2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:53,345 [IPC Server handler 2 on default port 34660] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775776_1003, replicas=127.0.0.1:34311, 127.0.0.1:34735, 127.0.0.1:46404, 127.0.0.1:43921, 127.0.0.1:35665 for /ec/RS-3-2
2020-12-03 07:20:53,350 [Thread-940] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,350 [Thread-944] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,350 [Thread-943] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:53,351 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:40302 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003 src: /127.0.0.1:40302 dest: /127.0.0.1:43921
2020-12-03 07:20:53,351 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:51526 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003 src: /127.0.0.1:51526 dest: /127.0.0.1:34311
2020-12-03 07:20:53,351 [DataXceiver for client DFSClient_NONMAPREDUCE_276418183_2991 at /127.0.0.1:45268 [Receiving block BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003 src: /127.0.0.1:45268 dest: /127.0.0.1:35665
2020-12-03 07:20:53,376 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51526, dest: /127.0.0.1:34311, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: 8ba8531f-b428-4906-9dc4-80db19159019, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003, duration(ns): 22265334
2020-12-03 07:20:53,377 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775776_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,380 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40302, dest: /127.0.0.1:43921, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: f5c9f6c1-cf5f-4a10-920a-f87690ff80ad, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003, duration(ns): 26435385
2020-12-03 07:20:53,381 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775773_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,384 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45268, dest: /127.0.0.1:35665, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_276418183_2991, offset: 0, srvID: e5faabfb-a4f3-4152-a752-358d3e3868d8, blockid: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003, duration(ns): 30088883
2020-12-03 07:20:53,384 [PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1253628075-172.17.0.3-1606980049384:blk_-9223372036854775772_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:53,387 [IPC Server handler 7 on default port 34660] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /ec/RS-3-2 is closed by DFSClient_NONMAPREDUCE_276418183_2991
2020-12-03 07:20:53,388 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:53,388 [Listener at localhost/37495] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 20
2020-12-03 07:20:53,388 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@550f1b6f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:53,388 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@611dd52a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:53,389 [Listener at localhost/37495] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 21 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 4 Number of syncs: 18 SyncTimes(ms): 3 2 2 
2020-12-03 07:20:53,389 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000021
2020-12-03 07:20:53,390 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000021
2020-12-03 07:20:53,390 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000021
2020-12-03 07:20:53,391 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:53,391 [CacheReplicationMonitor(871549148)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:53,391 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:53,391 [Listener at localhost/37495] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:53,392 [Listener at localhost/37495] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:53,392 [Listener at localhost/37495] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:53,393 [Listener at localhost/37495] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:53,393 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:53,393 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:53,394 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:53,394 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:20:53,395 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current
2020-12-03 07:20:53,395 [Listener at localhost/37495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current
2020-12-03 07:20:53,395 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:20:53,408 [Listener at localhost/37495] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@17123995 expecting start txid #1
2020-12-03 07:20:53,408 [Listener at localhost/37495] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000021 maxTxnsToRead = 9223372036854775807
2020-12-03 07:20:53,409 [Listener at localhost/37495] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000021' to transaction ID 1
2020-12-03 07:20:53,456 [Listener at localhost/37495] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000021) of total size 1439.0, total edits 21.0, total load time 19.0 ms
2020-12-03 07:20:53,456 [Listener at localhost/37495] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:20:53,457 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:20:53,457 [Listener at localhost/37495] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:53,457 [Listener at localhost/37495] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 22
2020-12-03 07:20:53,458 [Listener at localhost/37495] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 22
2020-12-03 07:20:53,468 [Listener at localhost/37495] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:53,470 [Listener at localhost/37495] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=5
storage space=46
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:53,472 [CacheReplicationMonitor(1296639129)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:53,487 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:20:53,488 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:53,488 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:53,488 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:53,488 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:53,488 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 31 msec
2020-12-03 07:20:53,493 [IPC Server handler 2 on default port 40767] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,495 [IPC Server handler 3 on default port 40767] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,497 [IPC Server handler 4 on default port 40767] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:53,498 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:53,499 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:20:53,500 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,500 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ec932ad] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,501 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4c763f8c-f23c-4e4e-835e-2f1d7c2e91ed) exiting.
2020-12-03 07:20:53,501 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-6b0d2439-6a5c-4c8a-ab34-913424a1c0b6) exiting.
2020-12-03 07:20:53,524 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@500de106{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,525 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22f740e8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,526 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@692e5915{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,527 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4727c35e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,530 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37495
2020-12-03 07:20:53,535 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,535 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 551485fd-9dd9-406c-8dc8-621b8b449112)
2020-12-03 07:20:53,537 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,539 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,539 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,544 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,544 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,545 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,545 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,547 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,547 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:53,548 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,548 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2dd6a4f4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,549 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-b61fcf2e-1339-4218-98c3-bf1b321df32f) exiting.
2020-12-03 07:20:53,549 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-b2a3026b-e854-41d3-9965-462fa6e8c6a0) exiting.
2020-12-03 07:20:53,571 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f4f6170{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,572 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a89d96e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,573 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26f51391{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,574 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c6ac6dc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,577 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39163
2020-12-03 07:20:53,587 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,588 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,589 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,589 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,590 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,591 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,591 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 7a09deaa-68eb-44eb-b61e-633f7c7c4312)
2020-12-03 07:20:53,591 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,592 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,592 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,596 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,597 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,598 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,598 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,600 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,600 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:53,600 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,600 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@308da91c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,601 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-3e9d6bca-8dd8-484b-ac12-819f09a3410a) exiting.
2020-12-03 07:20:53,601 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-deec0f73-9130-4324-b345-237719640551) exiting.
2020-12-03 07:20:53,624 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@796ad650{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,624 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7cfea09f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,626 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d084767{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,627 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15668629{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,630 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45041
2020-12-03 07:20:53,632 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,635 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid f5c9f6c1-cf5f-4a10-920a-f87690ff80ad)
2020-12-03 07:20:53,635 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,636 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,636 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,642 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,642 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,643 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,643 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,646 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,646 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:53,646 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,646 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1a186129] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,648 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-967262b4-e3bd-4e88-8755-c79daaf8394d) exiting.
2020-12-03 07:20:53,648 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-b995a809-d7bf-4e34-8395-a1e2871d908f) exiting.
2020-12-03 07:20:53,671 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b2cc0ad{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,672 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76c7b706{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,675 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@410f6b99{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,677 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7506712f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,680 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45815
2020-12-03 07:20:53,687 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,687 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,692 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,692 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,692 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,693 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,693 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid aaa5d2ac-c637-4a9b-808f-2e5fc2f687f6)
2020-12-03 07:20:53,693 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,694 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,694 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,700 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,701 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,702 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,702 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,705 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,705 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:53,706 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,706 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@33b6db5a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,707 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fb5435bb-b373-411d-8e79-cdbe269eccda) exiting.
2020-12-03 07:20:53,707 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5dc7a14b-2ac9-46e2-8daa-aa6be232d868) exiting.
2020-12-03 07:20:53,729 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26eff489{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,730 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6be1d4b7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,732 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ce017ef{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,733 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@683fa6ab{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,738 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40872
2020-12-03 07:20:53,741 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,742 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,757 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,757 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,757 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,757 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,758 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 5ad93aba-72e9-4306-96f8-0a050f350e46)
2020-12-03 07:20:53,758 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,759 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,766 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,769 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,770 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,771 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,772 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,783 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,783 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:53,783 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,783 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3ef40596] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,790 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9e29d8a7-1588-4411-8d21-7e427bfa3244) exiting.
2020-12-03 07:20:53,790 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bef83b3d-792f-424e-9bbf-8cd47c2a1c51) exiting.
2020-12-03 07:20:53,846 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@597f87ba{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,846 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@95bc572{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:53,850 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@46492430{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:53,859 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69a4b8bf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:53,898 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38947
2020-12-03 07:20:53,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:53,902 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,902 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:53,902 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:53,903 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:34660
2020-12-03 07:20:53,903 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019) service to localhost/127.0.0.1:40767
2020-12-03 07:20:53,903 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 8ba8531f-b428-4906-9dc4-80db19159019)
2020-12-03 07:20:53,905 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:53,906 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,929 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:53,947 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:53,947 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:53,959 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:53,959 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:53,960 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:53,960 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:53,960 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:53,960 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ac17067] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:53,961 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-084688e0-b696-4feb-9a70-bae1153c2c96) exiting.
2020-12-03 07:20:53,961 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5e31177a-f7e4-41d9-a63f-c4e6d2986fe3) exiting.
2020-12-03 07:20:53,982 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c964831{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:53,982 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1ca332ca{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:54,005 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22824406{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:54,006 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ca4fea9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:54,007 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39270
2020-12-03 07:20:54,016 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:54,016 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:54,016 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,016 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,017 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:34660
2020-12-03 07:20:54,017 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8) service to localhost/127.0.0.1:40767
2020-12-03 07:20:54,017 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid e5faabfb-a4f3-4152-a752-358d3e3868d8)
2020-12-03 07:20:54,020 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:54,021 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,021 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,036 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:54,036 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:54,036 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:54,036 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:54,037 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:54,037 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:54,037 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:54,037 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7f71c2a8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:54,038 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8c7e4d5c-1e95-48a5-b504-abd9b3495192) exiting.
2020-12-03 07:20:54,038 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f0fb0378-27dc-4f79-b091-f9c6a592c2cf) exiting.
2020-12-03 07:20:54,059 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@54afdbbc{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:54,060 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1cba6856{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:54,060 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@545e2c83{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:54,061 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d5e2194{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:54,062 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40358
2020-12-03 07:20:54,066 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:54,067 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:54,067 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,067 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,067 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:34660
2020-12-03 07:20:54,067 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae) service to localhost/127.0.0.1:40767
2020-12-03 07:20:54,067 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 1bf1d088-6d9c-46f6-a310-52937e730cae)
2020-12-03 07:20:54,070 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:54,071 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,071 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,073 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:54,074 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:54,074 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:54,074 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:54,074 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:54,075 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:54,075 [Listener at localhost/40180] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:54,075 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@616e3fcb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:54,075 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ccabc258-30b1-427e-9aa2-7e007e3f4537) exiting.
2020-12-03 07:20:54,075 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8ae16f37-2bfd-4e2c-8468-67fc8f32c215) exiting.
2020-12-03 07:20:54,096 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6372bf60{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:54,100 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1684c1d7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:54,101 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a09052d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:54,101 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7eaa5e40{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:54,102 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39192
2020-12-03 07:20:54,106 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:54,106 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:54,107 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,107 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:54,107 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:34660] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:34660
2020-12-03 07:20:54,107 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1) service to localhost/127.0.0.1:40767
2020-12-03 07:20:54,107 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1253628075-172.17.0.3-1606980049384 (Datanode Uuid 6695dc3f-842e-4be0-a335-736765d3d9f1)
2020-12-03 07:20:54,112 [BP-1253628075-172.17.0.3-1606980049384 heartbeating to localhost/127.0.0.1:40767] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1253628075-172.17.0.3-1606980049384
2020-12-03 07:20:54,113 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,116 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1253628075-172.17.0.3-1606980049384] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:54,116 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:54,116 [Listener at localhost/40180] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:54,116 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:54,116 [Listener at localhost/40180] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:54,117 [Listener at localhost/40180] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:54,117 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:54,117 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:54,120 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:54,121 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34660
2020-12-03 07:20:54,124 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:54,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:54,125 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:54,125 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:54,140 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:54,152 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:54,154 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@64979a6e{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:54,155 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f7fabcc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:54,155 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58fe55cc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:54,155 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8299c43{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:54,163 [Listener at localhost/40180] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:54,163 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:54,163 [Listener at localhost/40180] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 22, 22
2020-12-03 07:20:54,163 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7d72ac67] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:54,163 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@203433bf] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:54,173 [Listener at localhost/40180] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 21 Number of syncs: 3 SyncTimes(ms): 1 2 1 
2020-12-03 07:20:54,176 [Listener at localhost/40180] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000022 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000022-0000000000000000023
2020-12-03 07:20:54,179 [Listener at localhost/40180] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_inprogress_0000000000000000022 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_0000000000000000022-0000000000000000023
2020-12-03 07:20:54,182 [Listener at localhost/40180] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_inprogress_0000000000000000022 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_0000000000000000022-0000000000000000023
2020-12-03 07:20:54,182 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:54,182 [CacheReplicationMonitor(1296639129)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:54,214 [Listener at localhost/40180] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40767
2020-12-03 07:20:54,219 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:54,219 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:54,220 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:54,220 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:54,230 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:54,230 [Listener at localhost/40180] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:54,232 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a23c548{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:54,233 [Listener at localhost/40180] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@95d300e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:54,233 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f643de8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:54,234 [Listener at localhost/40180] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1549620b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:54,234 [Listener at localhost/40180] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:54,236 [Listener at localhost/40180] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:54,236 [Listener at localhost/40180] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
