2020-12-03 07:23:17,565 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:23:17,836 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:18,006 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:18,007 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:23:18,238 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:18,255 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:18,272 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1799ms
2020-12-03 07:23:18,463 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:18,517 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:18,517 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:18,533 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:18,539 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:18,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:18,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:18,574 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37102
2020-12-03 07:23:18,577 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:18,635 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:18,637 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:18,680 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@740cae06{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:18,690 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:37102}
2020-12-03 07:23:18,691 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2218ms
2020-12-03 07:23:18,693 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:18,728 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:18,747 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:19,095 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:19,095 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:19,099 [Listener at localhost/41275] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:19,109 [Listener at localhost/41275] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:19,109 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:19,113 [Listener at localhost/41275] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:19,114 [Listener at localhost/41275] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:19,114 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:19,119 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:19,120 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:19,121 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:19,121 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:19,123 [Listener at localhost/41275] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38907
2020-12-03 07:23:19,124 [Listener at localhost/41275] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:19,129 [Listener at localhost/41275] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:19,130 [Listener at localhost/41275] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:19,142 [Listener at localhost/41275] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4397ad89{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:19,143 [Listener at localhost/41275] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59cba5a{HTTP/1.1,[http/1.1]}{localhost:38907}
2020-12-03 07:23:19,143 [Listener at localhost/41275] INFO  server.Server (Server.java:doStart(419)) - Started @2671ms
2020-12-03 07:23:19,145 [Listener at localhost/41275] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:19,145 [Listener at localhost/41275] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:19,146 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:19,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:19,150 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:19,205 [Listener at localhost/38384] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:19,209 [Listener at localhost/38384] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:19,209 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:19,212 [Listener at localhost/38384] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:19,213 [Listener at localhost/38384] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:19,213 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:19,216 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:19,217 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:19,217 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:19,217 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:19,219 [Listener at localhost/38384] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41004
2020-12-03 07:23:19,219 [Listener at localhost/38384] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:19,222 [Listener at localhost/38384] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79dc5318{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:19,223 [Listener at localhost/38384] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37e4d7bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:19,233 [Listener at localhost/38384] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69f1a286{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:19,235 [Listener at localhost/38384] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7922d892{HTTP/1.1,[http/1.1]}{localhost:41004}
2020-12-03 07:23:19,236 [Listener at localhost/38384] INFO  server.Server (Server.java:doStart(419)) - Started @2763ms
2020-12-03 07:23:19,238 [Listener at localhost/38384] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:19,238 [Listener at localhost/38384] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:19,240 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:19,246 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:19,246 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:19,954 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 98: Call -> /127.0.0.1:34256: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:19,955 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 96: Call -> /127.0.0.1:41275: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:19,955 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 97: Call -> /127.0.0.1:38384: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,005 [IPC Server handler 0 on default port 41275] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/waitactive
2020-12-03 07:23:20,005 [IPC Server handler 0 on default port 34256] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/waitactive
2020-12-03 07:23:20,005 [IPC Server handler 0 on default port 38384] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/waitactive
2020-12-03 07:23:20,022 [IPC Server handler 0 on default port 38384] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/waitactive does not exist
2020-12-03 07:23:20,022 [IPC Server handler 0 on default port 41275] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/waitactive does not exist
2020-12-03 07:23:20,022 [IPC Server handler 0 on default port 34256] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/waitactive does not exist
2020-12-03 07:23:20,027 [IPC Server handler 0 on default port 34256] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,028 [IPC Server handler 0 on default port 38384] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,028 [IPC Server handler 0 on default port 41275] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,064 [IPC Server handler 0 on default port 38384] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,065 [IPC Server handler 0 on default port 38384] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,067 [IPC Server handler 0 on default port 41275] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,068 [IPC Server handler 0 on default port 41275] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,065 [IPC Server handler 0 on default port 34256] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,071 [IPC Server handler 0 on default port 34256] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,074 [Logger channel (from single-thread executor) to /127.0.0.1:38384] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 247ms
2020-12-03 07:23:20,075 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 97: Response <- /127.0.0.1:38384: isFormatted {isFormatted: false}
2020-12-03 07:23:20,075 [Logger channel (from single-thread executor) to /127.0.0.1:34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 248ms
2020-12-03 07:23:20,076 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 98: Response <- /127.0.0.1:34256: isFormatted {isFormatted: false}
2020-12-03 07:23:20,076 [Logger channel (from single-thread executor) to /127.0.0.1:41275] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 249ms
2020-12-03 07:23:20,077 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 96: Response <- /127.0.0.1:41275: isFormatted {isFormatted: false}
2020-12-03 07:23:20,087 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 106: Call -> /127.0.0.1:41275: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,087 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 108: Call -> /127.0.0.1:34256: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,088 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 107: Call -> /127.0.0.1:38384: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,092 [Logger channel (from single-thread executor) to /127.0.0.1:34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 5ms
2020-12-03 07:23:20,092 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 108: Response <- /127.0.0.1:34256: isFormatted {isFormatted: false}
2020-12-03 07:23:20,098 [Logger channel (from single-thread executor) to /127.0.0.1:41275] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 11ms
2020-12-03 07:23:20,099 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 106: Response <- /127.0.0.1:41275: isFormatted {isFormatted: false}
2020-12-03 07:23:20,099 [Logger channel (from single-thread executor) to /127.0.0.1:38384] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 11ms
2020-12-03 07:23:20,100 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 107: Response <- /127.0.0.1:38384: isFormatted {isFormatted: false}
2020-12-03 07:23:20,107 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 117: Call -> /127.0.0.1:34256: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,107 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 116: Call -> /127.0.0.1:38384: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,107 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 115: Call -> /127.0.0.1:41275: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:20,110 [Logger channel (from single-thread executor) to /127.0.0.1:41275] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 3ms
2020-12-03 07:23:20,111 [Logger channel (from single-thread executor) to /127.0.0.1:41275] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 115: Response <- /127.0.0.1:41275: isFormatted {isFormatted: false}
2020-12-03 07:23:20,111 [Logger channel (from single-thread executor) to /127.0.0.1:34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 4ms
2020-12-03 07:23:20,112 [Logger channel (from single-thread executor) to /127.0.0.1:34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 117: Response <- /127.0.0.1:34256: isFormatted {isFormatted: false}
2020-12-03 07:23:20,112 [Logger channel (from single-thread executor) to /127.0.0.1:38384] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 5ms
2020-12-03 07:23:20,112 [Logger channel (from single-thread executor) to /127.0.0.1:38384] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 116: Response <- /127.0.0.1:38384: isFormatted {isFormatted: false}
2020-12-03 07:23:20,357 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41275: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:20,376 [IPC Server handler 2 on default port 41275] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal
2020-12-03 07:23:20,377 [IPC Server handler 2 on default port 41275] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal does not exist
2020-12-03 07:23:20,377 [IPC Server handler 2 on default port 41275] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,387 [IPC Server handler 2 on default port 41275] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,388 [IPC Server handler 2 on default port 41275] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,389 [IPC Server handler 2 on default port 41275] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:20,389 [IPC Server handler 2 on default port 41275] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal does not exist. Creating ...
2020-12-03 07:23:20,443 [IPC Server handler 2 on default port 41275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:20,444 [IPC Server handler 2 on default port 41275] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal; location= null with nsid: 12345
2020-12-03 07:23:20,494 [IPC Server handler 2 on default port 41275] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/current/paxos
2020-12-03 07:23:20,561 [IPC Server handler 2 on default port 41275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:20,563 [IPC Server handler 2 on default port 41275] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,564 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 210ms
2020-12-03 07:23:20,566 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:41275: format {}
2020-12-03 07:23:20,570 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38384: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:20,573 [IPC Server handler 0 on default port 38384] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal
2020-12-03 07:23:20,574 [IPC Server handler 0 on default port 38384] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal does not exist
2020-12-03 07:23:20,574 [IPC Server handler 0 on default port 38384] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,580 [IPC Server handler 0 on default port 38384] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,580 [IPC Server handler 0 on default port 38384] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,581 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:20,581 [IPC Server handler 0 on default port 38384] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal does not exist. Creating ...
2020-12-03 07:23:20,629 [IPC Server handler 0 on default port 38384] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:20,630 [IPC Server handler 0 on default port 38384] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal; location= null with nsid: 12345
2020-12-03 07:23:20,740 [IPC Server handler 0 on default port 38384] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/paxos
2020-12-03 07:23:20,810 [IPC Server handler 0 on default port 38384] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:20,811 [IPC Server handler 0 on default port 38384] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,812 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 243ms
2020-12-03 07:23:20,812 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38384: format {}
2020-12-03 07:23:20,816 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:34256: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:20,828 [IPC Server handler 0 on default port 34256] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal
2020-12-03 07:23:20,828 [IPC Server handler 0 on default port 34256] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal does not exist
2020-12-03 07:23:20,829 [IPC Server handler 0 on default port 34256] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:20,836 [IPC Server handler 0 on default port 34256] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:20,837 [IPC Server handler 0 on default port 34256] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:20,837 [IPC Server handler 0 on default port 34256] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:20,837 [IPC Server handler 0 on default port 34256] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal does not exist. Creating ...
2020-12-03 07:23:20,926 [IPC Server handler 0 on default port 34256] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:20,927 [IPC Server handler 0 on default port 34256] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal; location= null with nsid: 12345
2020-12-03 07:23:21,036 [IPC Server handler 0 on default port 34256] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/paxos
2020-12-03 07:23:21,137 [IPC Server handler 0 on default port 34256] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:21,138 [IPC Server handler 0 on default port 34256] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:21,139 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 324ms
2020-12-03 07:23:21,139 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:34256: format {}
2020-12-03 07:23:21,140 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:21,144 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41275: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:21,164 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 21ms
2020-12-03 07:23:21,165 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:41275: getJournalState {lastPromisedEpoch: 0 httpPort: 37102 fromURL: "http://localhost:37102"}
2020-12-03 07:23:21,170 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38384: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:21,180 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 11ms
2020-12-03 07:23:21,181 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38384: getJournalState {lastPromisedEpoch: 0 httpPort: 38907 fromURL: "http://localhost:38907"}
2020-12-03 07:23:21,183 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:34256: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:21,195 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 13ms
2020-12-03 07:23:21,195 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:34256: getJournalState {lastPromisedEpoch: 0 httpPort: 41004 fromURL: "http://localhost:41004"}
2020-12-03 07:23:21,204 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:21,211 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:21,283 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal)
2020-12-03 07:23:21,285 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal)
2020-12-03 07:23:21,286 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 85ms
2020-12-03 07:23:21,288 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: newEpoch {}
2020-12-03 07:23:21,289 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:21,301 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:21,357 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal)
2020-12-03 07:23:21,357 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal)
2020-12-03 07:23:21,358 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 69ms
2020-12-03 07:23:21,359 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: newEpoch {}
2020-12-03 07:23:21,361 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:21,368 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:21,450 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal)
2020-12-03 07:23:21,451 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal)
2020-12-03 07:23:21,451 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 91ms
2020-12-03 07:23:21,452 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: newEpoch {}
2020-12-03 07:23:21,454 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:23:21,461 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:21,470 [IPC Server handler 4 on default port 41275] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:21,865 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 405ms
2020-12-03 07:23:21,866 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: startLogSegment {}
2020-12-03 07:23:21,867 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:21,871 [IPC Server handler 1 on default port 38384] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:21,972 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 105ms
2020-12-03 07:23:21,973 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: startLogSegment {}
2020-12-03 07:23:21,974 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:21,982 [IPC Server handler 2 on default port 34256] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:22,102 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 128ms
2020-12-03 07:23:22,103 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: startLogSegment {}
2020-12-03 07:23:22,204 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:22,209 [IPC Server handler 3 on default port 41275] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:22,233 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 30ms
2020-12-03 07:23:22,234 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: journal {}
2020-12-03 07:23:22,237 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:22,242 [IPC Server handler 0 on default port 38384] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:22,254 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 18ms
2020-12-03 07:23:22,255 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: journal {}
2020-12-03 07:23:22,257 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:22,272 [IPC Server handler 1 on default port 34256] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:22,293 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 37ms
2020-12-03 07:23:22,294 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: journal {}
2020-12-03 07:23:22,300 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:22,312 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 13ms
2020-12-03 07:23:22,312 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: journal {}
2020-12-03 07:23:22,314 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:22,332 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 18ms
2020-12-03 07:23:22,333 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: journal {}
2020-12-03 07:23:22,336 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:22,376 [IPC Server handler 4 on default port 41275] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 4 on default port 41275, call Call#26 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.journal from 127.0.0.1:34976
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:22,382 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: journal {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
}
2020-12-03 07:23:22,397 [Listener at localhost/34256] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(400)) - Remote journal 127.0.0.1:41275 failed to write txns 5-5. Will try to write to this JN again after the next log roll.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:191)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:397)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:390)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:57)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at org.apache.hadoop.hdfs.qjournal.client.DirectExecutorService.execute(DirectExecutorService.java:152)
	at com.google.common.util.concurrent.MoreExecutors$ListeningDecorator.execute(MoreExecutors.java:525)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134)
	at com.google.common.util.concurrent.AbstractListeningExecutorService.submit(AbstractListeningExecutorService.java:66)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.sendEdits(IPCLoggerChannel.java:390)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01.CGLIB$sendEdits$7(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01$$FastClassByMockitoWithCGLIB$$70d642a7.invoke(<generated>)
	at org.mockito.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:216)
	at org.mockito.internal.creation.AbstractMockitoMethodProxy.invokeSuper(AbstractMockitoMethodProxy.java:10)
	at org.mockito.internal.invocation.realmethod.CGLIBProxyRealMethod.invoke(CGLIBProxyRealMethod.java:22)
	at org.mockito.internal.invocation.realmethod.FilteredCGLIBProxyRealMethod.invoke(FilteredCGLIBProxyRealMethod.java:27)
	at org.mockito.internal.invocation.Invocation.callRealMethod(Invocation.java:211)
	at org.mockito.internal.stubbing.answers.CallsRealMethods.answer(CallsRealMethods.java:36)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:99)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$4a4bcd01.sendEdits(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:110)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:115)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:109)
	at org.apache.hadoop.hdfs.qjournal.QJMTestUtil.writeTxns(QJMTestUtil.java:112)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setupLoggers345(TestQuorumJournalManager.java:579)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testRecoverAfterIncompleteRecovery(TestQuorumJournalManager.java:524)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:22,402 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 3 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:22,457 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 56ms
2020-12-03 07:23:22,458 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: journal {}
2020-12-03 07:23:22,462 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34256
2020-12-03 07:23:22,464 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:22,466 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:22,478 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69f1a286{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:22,488 [Listener at localhost/34256] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7922d892{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:22,489 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37e4d7bb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:22,489 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79dc5318{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:22,497 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/waitactive; location= null
2020-12-03 07:23:22,497 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal; location= null
2020-12-03 07:23:22,507 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:22,509 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41275: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:22,515 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 6ms
2020-12-03 07:23:22,515 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:41275: getJournalState {lastPromisedEpoch: 1 httpPort: 37102 fromURL: "http://localhost:37102"}
2020-12-03 07:23:22,520 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38384: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:22,525 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 5ms
2020-12-03 07:23:22,526 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38384: getJournalState {lastPromisedEpoch: 1 httpPort: 38907 fromURL: "http://localhost:38907"}
2020-12-03 07:23:22,528 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:34256: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:22,533 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:34256: getJournalState {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:34256 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:22,535 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:22,540 [IPC Server handler 1 on default port 41275] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:22,618 [IPC Server handler 1 on default port 41275] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal)
2020-12-03 07:23:22,652 [IPC Server handler 1 on default port 41275] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:22,653 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 118ms
2020-12-03 07:23:22,656 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:22,657 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:22,661 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:22,725 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal)
2020-12-03 07:23:22,730 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:22,731 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 74ms
2020-12-03 07:23:22,733 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:22,735 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:22,736 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:34256: newEpoch {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:34256 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:22,738 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:23:22,739 [Listener at localhost/34256] DEBUG client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(482)) - newEpoch(2) responses:
127.0.0.1:38384: lastSegmentTxId: 1
127.0.0.1:41275: lastSegmentTxId: 1
2020-12-03 07:23:22,739 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 1
2020-12-03 07:23:22,743 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:22,761 [IPC Server handler 2 on default port 41275] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 3 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:22,763 [IPC Server handler 2 on default port 41275] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4 ; journal id: test-journal
2020-12-03 07:23:22,764 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 22ms
2020-12-03 07:23:22,765 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: prepareRecovery {segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4}
2020-12-03 07:23:22,765 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:22,772 [IPC Server handler 3 on default port 38384] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:22,773 [IPC Server handler 3 on default port 38384] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3 ; journal id: test-journal
2020-12-03 07:23:22,773 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 8ms
2020-12-03 07:23:22,774 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: prepareRecovery {segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3}
2020-12-03 07:23:22,775 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:22,777 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:34256: getJournalState {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:34256 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:22,779 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:38384: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3
127.0.0.1:41275: segmentState { startTxId: 1 endTxId: 3 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4
2020-12-03 07:23:22,785 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:38384=segmentState {
  startTxId: 1
  endTxId: 4
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 3

2020-12-03 07:23:22,793 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:22,808 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000003,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 3 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:22,808 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Synchronizing log startTxId: 1 endTxId: 4 isInProgress: true: old segment startTxId: 1 endTxId: 3 isInProgress: true is not the right length ; journal id: test-journal
2020-12-03 07:23:22,811 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:syncLog(995)) - Synchronizing log startTxId: 1 endTxId: 4 isInProgress: true from http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true
2020-12-03 07:23:22,981 [qtp1622458036-66] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:23,074 [IPC Server handler 3 on default port 41275] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.03s. The file download took 0.03s at 33032.26 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal/current/edits_inprogress_0000000000000000001.epoch=2 took 0.00s.
2020-12-03 07:23:23,185 [IPC Server handler 3 on default port 41275] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:23,187 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 395ms
2020-12-03 07:23:23,189 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41275: acceptRecovery {}
2020-12-03 07:23:23,190 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:23,200 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:23,201 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 4 isInProgress: true: already have up-to-date logs ; journal id: test-journal
2020-12-03 07:23:23,290 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:23,291 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 101ms
2020-12-03 07:23:23,292 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: acceptRecovery {}
2020-12-03 07:23:23,293 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:23,294 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:34256: acceptRecovery {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:34256 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,297 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41275
2020-12-03 07:23:23,297 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:23,297 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:23,298 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@740cae06{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:23,300 [Listener at localhost/34256] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:23,300 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:23,301 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:23,301 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/waitactive; location= null
2020-12-03 07:23:23,302 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal; location= null
2020-12-03 07:23:23,303 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34256
2020-12-03 07:23:23,303 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/waitactive; location= null
2020-12-03 07:23:23,304 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal; location= null
2020-12-03 07:23:23,304 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JournalNode metrics system...
2020-12-03 07:23:23,305 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JournalNode metrics system stopped.
2020-12-03 07:23:23,305 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - JournalNode metrics system shutdown complete.
2020-12-03 07:23:23,309 [Listener at localhost/34256] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:23,316 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:23,316 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:23:23,319 [Listener at localhost/34256] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:41004
2020-12-03 07:23:23,319 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:23,322 [Listener at localhost/34256] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:23,323 [Listener at localhost/34256] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:23,323 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:23,327 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:23,328 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:23,328 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:23,328 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:23,330 [Listener at localhost/34256] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41004
2020-12-03 07:23:23,330 [Listener at localhost/34256] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:23,333 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b1f29fa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:23,334 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40f70521{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:23,344 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@20a14b55{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:23,346 [Listener at localhost/34256] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39ad977d{HTTP/1.1,[http/1.1]}{localhost:41004}
2020-12-03 07:23:23,346 [Listener at localhost/34256] INFO  server.Server (Server.java:doStart(419)) - Started @6873ms
2020-12-03 07:23:23,347 [Listener at localhost/34256] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:34256
2020-12-03 07:23:23,348 [Listener at localhost/34256] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:23,349 [Socket Reader #1 for port 34256] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 34256
2020-12-03 07:23:23,356 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:23,356 [IPC Server listener on 34256] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 34256: starting
2020-12-03 07:23:23,361 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:23,364 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41275: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:23,366 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: getJournalState {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:41275 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,368 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:38384: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:23,385 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 17ms
2020-12-03 07:23:23,386 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:38384: getJournalState {lastPromisedEpoch: 2 httpPort: 38907 fromURL: "http://localhost:38907"}
2020-12-03 07:23:23,389 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:34256: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:23,394 [IPC Server handler 0 on default port 34256] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal
2020-12-03 07:23:23,426 [IPC Server handler 0 on default port 34256] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/in_use.lock acquired by nodename 6479@a09807707542
2020-12-03 07:23:23,426 [IPC Server handler 0 on default port 34256] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:23,432 [IPC Server handler 0 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal)
2020-12-03 07:23:23,433 [IPC Server handler 0 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:23,433 [IPC Server handler 0 on default port 34256] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:23,434 [IPC Server handler 0 on default port 34256] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:23,435 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 46ms
2020-12-03 07:23:23,436 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:34256: getJournalState {lastPromisedEpoch: 1 httpPort: 41004 fromURL: "http://localhost:41004"}
2020-12-03 07:23:23,439 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 3}
2020-12-03 07:23:23,440 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: newEpoch {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:41275 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,441 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 3}
2020-12-03 07:23:23,444 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:23,477 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal)
2020-12-03 07:23:23,481 [IPC Server handler 4 on default port 38384] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:23,481 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 40ms
2020-12-03 07:23:23,482 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:23,483 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 3}
2020-12-03 07:23:23,486 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 3 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:23,519 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal)
2020-12-03 07:23:23,520 [IPC Server handler 1 on default port 34256] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:23,521 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 39ms
2020-12-03 07:23:23,521 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:23,523 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 3
2020-12-03 07:23:23,523 [Listener at localhost/34256] DEBUG client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(482)) - newEpoch(3) responses:
127.0.0.1:34256: lastSegmentTxId: 1
127.0.0.1:38384: lastSegmentTxId: 1
2020-12-03 07:23:23,523 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 1
2020-12-03 07:23:23,524 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:23,525 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: getJournalState {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:41275 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,528 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:23,535 [IPC Server handler 3 on default port 38384] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:23,536 [IPC Server handler 3 on default port 38384] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 2 lastWriterEpoch: 1 lastCommittedTxId: 3 ; journal id: test-journal
2020-12-03 07:23:23,536 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 10ms
2020-12-03 07:23:23,537 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: prepareRecovery {segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 2 lastWriterEpoch: 1 lastCommittedTxId: 3}
2020-12-03 07:23:23,538 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:23,541 [IPC Server handler 2 on default port 34256] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:23,541 [IPC Server handler 2 on default port 34256] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4 ; journal id: test-journal
2020-12-03 07:23:23,544 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 7ms
2020-12-03 07:23:23,545 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: prepareRecovery {segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4}
2020-12-03 07:23:23,546 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:34256: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4
127.0.0.1:38384: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 2 lastWriterEpoch: 1 lastCommittedTxId: 3
2020-12-03 07:23:23,547 [Listener at localhost/34256] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(342)) - Using already-accepted recovery for segment starting at txid 1: 127.0.0.1:38384=segmentState {
  startTxId: 1
  endTxId: 4
  isInProgress: true
}
acceptedInEpoch: 2
lastWriterEpoch: 1
lastCommittedTxId: 3

2020-12-03 07:23:23,548 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 0 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:23,549 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: acceptRecovery {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:41275 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,550 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:23,559 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:23,559 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 4 isInProgress: true: already have up-to-date logs ; journal id: test-journal
2020-12-03 07:23:23,603 [IPC Server handler 0 on default port 38384] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 3 ; journal id: test-journal
2020-12-03 07:23:23,604 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 54ms
2020-12-03 07:23:23,605 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: acceptRecovery {}
2020-12-03 07:23:23,606 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 4 isInProgress: true } fromURL: "http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:23,614 [IPC Server handler 3 on default port 34256] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:23,615 [IPC Server handler 3 on default port 34256] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Synchronizing log startTxId: 1 endTxId: 4 isInProgress: true: old segment startTxId: 1 endTxId: 5 isInProgress: true is not the right length ; journal id: test-journal
2020-12-03 07:23:23,615 [IPC Server handler 3 on default port 34256] INFO  server.Journal (Journal.java:syncLog(995)) - Synchronizing log startTxId: 1 endTxId: 4 isInProgress: true from http://localhost:38907/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true
2020-12-03 07:23:23,654 [qtp1622458036-153] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:23,712 [IPC Server handler 3 on default port 34256] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.02s. The file download took 0.02s at 44521.74 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001.epoch=3 took 0.00s.
2020-12-03 07:23:23,746 [IPC Server handler 3 on default port 34256] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } acceptedInEpoch: 3 ; journal id: test-journal
2020-12-03 07:23:23,747 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 141ms
2020-12-03 07:23:23,748 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: acceptRecovery {}
2020-12-03 07:23:23,753 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41275: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 1 } startTxId: 1 endTxId: 4}
2020-12-03 07:23:23,755 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41275: finalizeLogSegment {java.net.ConnectException: Call From a09807707542/172.17.0.9 to localhost:41275 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:23,756 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:38384: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 2 } startTxId: 1 endTxId: 4}
2020-12-03 07:23:23,760 [IPC Server handler 1 on default port 38384] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:23,765 [IPC Server handler 1 on default port 38384] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:23,791 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 35ms
2020-12-03 07:23:23,792 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:38384: finalizeLogSegment {}
2020-12-03 07:23:23,793 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:34256: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 3 ipcSerialNumber: 2 } startTxId: 1 endTxId: 4}
2020-12-03 07:23:23,796 [IPC Server handler 4 on default port 34256] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:23,800 [IPC Server handler 4 on default port 34256] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:23,801 [Listener at localhost/34256] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 8ms
2020-12-03 07:23:23,801 [Listener at localhost/34256] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:34256: finalizeLogSegment {}
2020-12-03 07:23:23,811 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41275
2020-12-03 07:23:23,812 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/waitactive; location= null
2020-12-03 07:23:23,812 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-0/test-journal; location= null
2020-12-03 07:23:23,813 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JournalNode metrics system...
2020-12-03 07:23:23,814 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JournalNode metrics system stopped.
2020-12-03 07:23:23,815 [Listener at localhost/34256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - JournalNode metrics system shutdown complete.
2020-12-03 07:23:23,815 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38384
2020-12-03 07:23:23,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:23,816 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:23,818 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4397ad89{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:23,822 [Listener at localhost/34256] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59cba5a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:23,823 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:23,824 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:23,825 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/waitactive; location= null
2020-12-03 07:23:23,825 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-1/test-journal; location= null
2020-12-03 07:23:23,827 [Listener at localhost/34256] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34256
2020-12-03 07:23:23,828 [IPC Server listener on 34256] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 34256
2020-12-03 07:23:23,829 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:23,831 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@20a14b55{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:23,833 [Listener at localhost/34256] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39ad977d{HTTP/1.1,[http/1.1]}{localhost:41004}
2020-12-03 07:23:23,834 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40f70521{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:23,834 [Listener at localhost/34256] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b1f29fa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:23,839 [Listener at localhost/34256] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/HZrJe042LG/journalnode-2/test-journal; location= null
msx-rc 0
