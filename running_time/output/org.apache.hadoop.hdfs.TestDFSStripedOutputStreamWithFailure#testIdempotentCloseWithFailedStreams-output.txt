1: length=-1, (b, c, d) = (0, 0, -1)
2: length=0, (b, c, d) = (0, 0, 0)
3: length=1, (b, c, d) = (0, 0, 1)
4: length=65535, (b, c, d) = (0, 1, -1)
5: length=65536, (b, c, d) = (0, 1, 0)
6: length=65537, (b, c, d) = (0, 1, 1)
7: length=131071, (b, c, d) = (0, 2, -1)
8: length=131072, (b, c, d) = (0, 2, 0)
9: length=131073, (b, c, d) = (0, 2, 1)
10: length=196607, (b, c, d) = (0, 3, -1)
11: length=196608, (b, c, d) = (0, 3, 0)
12: length=196609, (b, c, d) = (0, 3, 1)
13: length=262143, (b, c, d) = (0, 4, -1)
14: length=262144, (b, c, d) = (0, 4, 0)
15: length=262145, (b, c, d) = (0, 4, 1)
16: length=327679, (b, c, d) = (0, 5, -1)
17: length=327680, (b, c, d) = (0, 5, 0)
18: length=327681, (b, c, d) = (0, 5, 1)
19: length=393215, (b, c, d) = (0, 6, -1)
20: length=393216, (b, c, d) = (0, 6, 0)
21: length=393217, (b, c, d) = (0, 6, 1)
22: length=458751, (b, c, d) = (0, 7, -1)
23: length=458752, (b, c, d) = (0, 7, 0)
24: length=458753, (b, c, d) = (0, 7, 1)
25: length=524287, (b, c, d) = (0, 8, -1)
26: length=524288, (b, c, d) = (0, 8, 0)
27: length=524289, (b, c, d) = (0, 8, 1)
28: length=589823, (b, c, d) = (0, 9, -1)
29: length=589824, (b, c, d) = (0, 9, 0)
30: length=589825, (b, c, d) = (0, 9, 1)
31: length=655359, (b, c, d) = (0, 10, -1)
32: length=655360, (b, c, d) = (0, 10, 0)
33: length=655361, (b, c, d) = (0, 10, 1)
34: length=720895, (b, c, d) = (0, 11, -1)
35: length=720896, (b, c, d) = (0, 11, 0)
36: length=720897, (b, c, d) = (0, 11, 1)
37: length=786431, (b, c, d) = (0, 12, -1)
38: length=786432, (b, c, d) = (0, 12, 0)
39: length=786433, (b, c, d) = (0, 12, 1)
40: length=851967, (b, c, d) = (0, 13, -1)
41: length=851968, (b, c, d) = (0, 13, 0)
42: length=851969, (b, c, d) = (0, 13, 1)
43: length=917503, (b, c, d) = (0, 14, -1)
44: length=917504, (b, c, d) = (0, 14, 0)
45: length=917505, (b, c, d) = (0, 14, 1)
46: length=983039, (b, c, d) = (0, 15, -1)
47: length=983040, (b, c, d) = (0, 15, 0)
48: length=983041, (b, c, d) = (0, 15, 1)
49: length=1048575, (b, c, d) = (0, 16, -1)
50: length=1048576, (b, c, d) = (0, 16, 0)
51: length=1048577, (b, c, d) = (0, 16, 1)
52: length=1114111, (b, c, d) = (0, 17, -1)
53: length=1114112, (b, c, d) = (0, 17, 0)
54: length=1114113, (b, c, d) = (0, 17, 1)
55: length=1179647, (b, c, d) = (0, 18, -1)
56: length=1179648, (b, c, d) = (0, 18, 0)
57: length=1179649, (b, c, d) = (0, 18, 1)
58: length=1245183, (b, c, d) = (0, 19, -1)
59: length=1245184, (b, c, d) = (0, 19, 0)
60: length=1245185, (b, c, d) = (0, 19, 1)
61: length=1310719, (b, c, d) = (0, 20, -1)
62: length=1310720, (b, c, d) = (0, 20, 0)
63: length=1310721, (b, c, d) = (0, 20, 1)
64: length=1376255, (b, c, d) = (0, 21, -1)
65: length=1376256, (b, c, d) = (0, 21, 0)
66: length=1376257, (b, c, d) = (0, 21, 1)
67: length=1441791, (b, c, d) = (0, 22, -1)
68: length=1441792, (b, c, d) = (0, 22, 0)
69: length=1441793, (b, c, d) = (0, 22, 1)
70: length=1507327, (b, c, d) = (0, 23, -1)
71: length=1507328, (b, c, d) = (0, 23, 0)
72: length=1507329, (b, c, d) = (0, 23, 1)
73: length=1572863, (b, c, d) = (1, 0, -1)
74: length=1572864, (b, c, d) = (1, 0, 0)
75: length=1572865, (b, c, d) = (1, 0, 1)
76: length=1638399, (b, c, d) = (1, 1, -1)
77: length=1638400, (b, c, d) = (1, 1, 0)
78: length=1638401, (b, c, d) = (1, 1, 1)
79: length=1703935, (b, c, d) = (1, 2, -1)
80: length=1703936, (b, c, d) = (1, 2, 0)
81: length=1703937, (b, c, d) = (1, 2, 1)
82: length=1769471, (b, c, d) = (1, 3, -1)
83: length=1769472, (b, c, d) = (1, 3, 0)
84: length=1769473, (b, c, d) = (1, 3, 1)
85: length=1835007, (b, c, d) = (1, 4, -1)
86: length=1835008, (b, c, d) = (1, 4, 0)
87: length=1835009, (b, c, d) = (1, 4, 1)
88: length=1900543, (b, c, d) = (1, 5, -1)
89: length=1900544, (b, c, d) = (1, 5, 0)
90: length=1900545, (b, c, d) = (1, 5, 1)
91: length=1966079, (b, c, d) = (1, 6, -1)
92: length=1966080, (b, c, d) = (1, 6, 0)
93: length=1966081, (b, c, d) = (1, 6, 1)
94: length=2031615, (b, c, d) = (1, 7, -1)
95: length=2031616, (b, c, d) = (1, 7, 0)
96: length=2031617, (b, c, d) = (1, 7, 1)
97: length=2097151, (b, c, d) = (1, 8, -1)
98: length=2097152, (b, c, d) = (1, 8, 0)
99: length=2097153, (b, c, d) = (1, 8, 1)
100: length=2162687, (b, c, d) = (1, 9, -1)
101: length=2162688, (b, c, d) = (1, 9, 0)
102: length=2162689, (b, c, d) = (1, 9, 1)
103: length=2228223, (b, c, d) = (1, 10, -1)
104: length=2228224, (b, c, d) = (1, 10, 0)
105: length=2228225, (b, c, d) = (1, 10, 1)
106: length=2293759, (b, c, d) = (1, 11, -1)
107: length=2293760, (b, c, d) = (1, 11, 0)
108: length=2293761, (b, c, d) = (1, 11, 1)
109: length=2359295, (b, c, d) = (1, 12, -1)
110: length=2359296, (b, c, d) = (1, 12, 0)
111: length=2359297, (b, c, d) = (1, 12, 1)
112: length=2424831, (b, c, d) = (1, 13, -1)
113: length=2424832, (b, c, d) = (1, 13, 0)
114: length=2424833, (b, c, d) = (1, 13, 1)
115: length=2490367, (b, c, d) = (1, 14, -1)
116: length=2490368, (b, c, d) = (1, 14, 0)
117: length=2490369, (b, c, d) = (1, 14, 1)
118: length=2555903, (b, c, d) = (1, 15, -1)
119: length=2555904, (b, c, d) = (1, 15, 0)
120: length=2555905, (b, c, d) = (1, 15, 1)
121: length=2621439, (b, c, d) = (1, 16, -1)
122: length=2621440, (b, c, d) = (1, 16, 0)
123: length=2621441, (b, c, d) = (1, 16, 1)
124: length=2686975, (b, c, d) = (1, 17, -1)
125: length=2686976, (b, c, d) = (1, 17, 0)
126: length=2686977, (b, c, d) = (1, 17, 1)
127: length=2752511, (b, c, d) = (1, 18, -1)
128: length=2752512, (b, c, d) = (1, 18, 0)
129: length=2752513, (b, c, d) = (1, 18, 1)
130: length=2818047, (b, c, d) = (1, 19, -1)
131: length=2818048, (b, c, d) = (1, 19, 0)
132: length=2818049, (b, c, d) = (1, 19, 1)
133: length=2883583, (b, c, d) = (1, 20, -1)
134: length=2883584, (b, c, d) = (1, 20, 0)
135: length=2883585, (b, c, d) = (1, 20, 1)
136: length=2949119, (b, c, d) = (1, 21, -1)
137: length=2949120, (b, c, d) = (1, 21, 0)
138: length=2949121, (b, c, d) = (1, 21, 1)
139: length=3014655, (b, c, d) = (1, 22, -1)
140: length=3014656, (b, c, d) = (1, 22, 0)
141: length=3014657, (b, c, d) = (1, 22, 1)
142: length=3080191, (b, c, d) = (1, 23, -1)
143: length=3080192, (b, c, d) = (1, 23, 0)
144: length=3080193, (b, c, d) = (1, 23, 1)
145: length=3145727, (b, c, d) = (2, 0, -1)
146: length=3145728, (b, c, d) = (2, 0, 0)
147: length=3145729, (b, c, d) = (2, 0, 1)
148: length=3211263, (b, c, d) = (2, 1, -1)
149: length=3211264, (b, c, d) = (2, 1, 0)
150: length=3211265, (b, c, d) = (2, 1, 1)
151: length=3276799, (b, c, d) = (2, 2, -1)
152: length=3276800, (b, c, d) = (2, 2, 0)
153: length=3276801, (b, c, d) = (2, 2, 1)
154: length=3342335, (b, c, d) = (2, 3, -1)
155: length=3342336, (b, c, d) = (2, 3, 0)
156: length=3342337, (b, c, d) = (2, 3, 1)
157: length=3407871, (b, c, d) = (2, 4, -1)
158: length=3407872, (b, c, d) = (2, 4, 0)
159: length=3407873, (b, c, d) = (2, 4, 1)
160: length=3473407, (b, c, d) = (2, 5, -1)
161: length=3473408, (b, c, d) = (2, 5, 0)
162: length=3473409, (b, c, d) = (2, 5, 1)
163: length=3538943, (b, c, d) = (2, 6, -1)
164: length=3538944, (b, c, d) = (2, 6, 0)
165: length=3538945, (b, c, d) = (2, 6, 1)
166: length=3604479, (b, c, d) = (2, 7, -1)
167: length=3604480, (b, c, d) = (2, 7, 0)
168: length=3604481, (b, c, d) = (2, 7, 1)
169: length=3670015, (b, c, d) = (2, 8, -1)
170: length=3670016, (b, c, d) = (2, 8, 0)
171: length=3670017, (b, c, d) = (2, 8, 1)
172: length=3735551, (b, c, d) = (2, 9, -1)
173: length=3735552, (b, c, d) = (2, 9, 0)
174: length=3735553, (b, c, d) = (2, 9, 1)
175: length=3801087, (b, c, d) = (2, 10, -1)
176: length=3801088, (b, c, d) = (2, 10, 0)
177: length=3801089, (b, c, d) = (2, 10, 1)
178: length=3866623, (b, c, d) = (2, 11, -1)
179: length=3866624, (b, c, d) = (2, 11, 0)
180: length=3866625, (b, c, d) = (2, 11, 1)
181: length=3932159, (b, c, d) = (2, 12, -1)
182: length=3932160, (b, c, d) = (2, 12, 0)
183: length=3932161, (b, c, d) = (2, 12, 1)
184: length=3997695, (b, c, d) = (2, 13, -1)
185: length=3997696, (b, c, d) = (2, 13, 0)
186: length=3997697, (b, c, d) = (2, 13, 1)
187: length=4063231, (b, c, d) = (2, 14, -1)
188: length=4063232, (b, c, d) = (2, 14, 0)
189: length=4063233, (b, c, d) = (2, 14, 1)
190: length=4128767, (b, c, d) = (2, 15, -1)
191: length=4128768, (b, c, d) = (2, 15, 0)
192: length=4128769, (b, c, d) = (2, 15, 1)
193: length=4194303, (b, c, d) = (2, 16, -1)
194: length=4194304, (b, c, d) = (2, 16, 0)
195: length=4194305, (b, c, d) = (2, 16, 1)
196: length=4259839, (b, c, d) = (2, 17, -1)
197: length=4259840, (b, c, d) = (2, 17, 0)
198: length=4259841, (b, c, d) = (2, 17, 1)
199: length=4325375, (b, c, d) = (2, 18, -1)
200: length=4325376, (b, c, d) = (2, 18, 0)
201: length=4325377, (b, c, d) = (2, 18, 1)
202: length=4390911, (b, c, d) = (2, 19, -1)
203: length=4390912, (b, c, d) = (2, 19, 0)
204: length=4390913, (b, c, d) = (2, 19, 1)
205: length=4456447, (b, c, d) = (2, 20, -1)
206: length=4456448, (b, c, d) = (2, 20, 0)
207: length=4456449, (b, c, d) = (2, 20, 1)
208: length=4521983, (b, c, d) = (2, 21, -1)
209: length=4521984, (b, c, d) = (2, 21, 0)
210: length=4521985, (b, c, d) = (2, 21, 1)
211: length=4587519, (b, c, d) = (2, 22, -1)
212: length=4587520, (b, c, d) = (2, 22, 0)
213: length=4587521, (b, c, d) = (2, 22, 1)
214: length=4653055, (b, c, d) = (2, 23, -1)
215: length=4653056, (b, c, d) = (2, 23, 0)
216: length=4653057, (b, c, d) = (2, 23, 1)
NUM_DATA_BLOCKS  = 6
NUM_PARITY_BLOCKS= 3
CELL_SIZE        = 65536 (=64 KB)
BLOCK_SIZE       = 262144 (=256 KB)
BLOCK_GROUP_SIZE = 1572864 (=1.50 MB)
2020-12-03 07:24:23,018 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:24:23,764 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:23,778 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:23,779 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:23,780 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:23,787 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:23,787 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:23,788 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:23,788 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:23,842 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:23,849 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:24:23,849 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:23,849 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:23,856 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:23,857 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:23
2020-12-03 07:24:23,859 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:23,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:24:23,862 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:23,885 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:23,885 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:23,894 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:23,895 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:23,895 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:23,895 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:23,896 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:23,896 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:23,897 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:23,897 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:23,897 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:23,897 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:23,898 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:23,937 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:24:23,937 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,938 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,938 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,962 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:23,962 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:24:23,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:23,970 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:23,970 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:23,970 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:23,971 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:23,977 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:23,979 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:23,984 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:23,985 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,985 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:24:23,985 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:23,995 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:23,995 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:23,995 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:24,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:24,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:24,004 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:24,004 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:24,005 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:24:24,005 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:24,043 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:24,232 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:24:24,400 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:24:24,434 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:24,434 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:24,559 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:24,559 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:24,640 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:24:24,644 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:25,022 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:25,108 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:25,109 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:25,140 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:25,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cebbb30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:25,203 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:25,210 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:25,227 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3275ms
2020-12-03 07:24:25,367 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:25,371 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:25,371 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:25,379 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:25,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:25,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:25,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:25,411 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:25,412 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:25,421 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39137
2020-12-03 07:24:25,423 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:25,467 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@508dec2b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:25,468 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37313c65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:25,509 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@266374ef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:25,519 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f81aa00{HTTP/1.1,[http/1.1]}{localhost:39137}
2020-12-03 07:24:25,520 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3568ms
2020-12-03 07:24:25,531 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:25,531 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:25,531 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:25,532 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:25,532 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:25,532 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:25,532 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:25,533 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:25,533 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:25,534 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:25,534 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:25,535 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:25,535 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:25
2020-12-03 07:24:25,535 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:25,535 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,536 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:25,536 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:25,541 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:25,541 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:25,542 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:25,542 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:25,542 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:25,542 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:25,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:25,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:25,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:25,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:25,543 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:25,544 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:25,544 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:25,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:25,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:25,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:25,548 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:25,548 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:25,548 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:25,549 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:25,549 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:25,549 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:25,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:25,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,550 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:25,550 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:25,551 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:25,551 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:25,551 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:25,552 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:25,552 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:25,552 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:25,552 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,553 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:25,553 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:25,627 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:25,681 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:25,684 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:25,685 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:25,685 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:24:25,686 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:25,716 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:25,722 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:25,723 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:25,727 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:25,728 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:24:25,852 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:25,852 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 298 msecs
2020-12-03 07:24:26,057 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:26,112 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:26,130 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:26,400 [Listener at localhost/40480] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:40480 to access this namenode/service.
2020-12-03 07:24:26,404 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:26,422 [Listener at localhost/40480] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:26,437 [Listener at localhost/40480] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:26,438 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:26,439 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:26,439 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:26,455 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:26,455 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2020-12-03 07:24:26,486 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:26,486 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:26,492 [Listener at localhost/40480] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40480
2020-12-03 07:24:26,496 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:26,497 [Listener at localhost/40480] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:26,562 [Listener at localhost/40480] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 65 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:26,567 [CacheReplicationMonitor(1664161582)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:26,575 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:26,641 [Listener at localhost/40480] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:26,657 [Listener at localhost/40480] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:26,678 [Listener at localhost/40480] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:26,682 [Listener at localhost/40480] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,686 [Listener at localhost/40480] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:26,690 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:26,691 [Listener at localhost/40480] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,695 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:26,702 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35554
2020-12-03 07:24:26,705 [Listener at localhost/40480] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:26,705 [Listener at localhost/40480] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:26,724 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,726 [Listener at localhost/40480] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:26,727 [Listener at localhost/40480] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:26,727 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,729 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:26,730 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:26,731 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:26,731 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:26,734 [Listener at localhost/40480] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41446
2020-12-03 07:24:26,735 [Listener at localhost/40480] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:26,736 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61526469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:26,737 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76ba13c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:26,744 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@235f4c10{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:26,746 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@743cb8e0{HTTP/1.1,[http/1.1]}{localhost:41446}
2020-12-03 07:24:26,747 [Listener at localhost/40480] INFO  server.Server (Server.java:doStart(419)) - Started @4795ms
2020-12-03 07:24:27,407 [Listener at localhost/40480] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38861
2020-12-03 07:24:27,408 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3277e499] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,409 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,409 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,424 [Listener at localhost/40480] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,425 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,432 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44314
2020-12-03 07:24:27,450 [Listener at localhost/44314] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,451 [Listener at localhost/44314] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,467 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:27,473 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,473 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,479 [Listener at localhost/44314] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:27,484 [Listener at localhost/44314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:27,485 [Listener at localhost/44314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:27,486 [Listener at localhost/44314] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,487 [Listener at localhost/44314] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,487 [Listener at localhost/44314] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,488 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,488 [Listener at localhost/44314] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,489 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,490 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40041
2020-12-03 07:24:27,490 [Listener at localhost/44314] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,490 [Listener at localhost/44314] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,492 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,495 [Listener at localhost/44314] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,496 [Listener at localhost/44314] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,497 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,526 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,527 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,528 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,528 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,529 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46674
2020-12-03 07:24:27,529 [Listener at localhost/44314] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,532 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5af9926a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,532 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@fac80{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,539 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1827a871{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,540 [Listener at localhost/44314] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48e64352{HTTP/1.1,[http/1.1]}{localhost:46674}
2020-12-03 07:24:27,542 [Listener at localhost/44314] INFO  server.Server (Server.java:doStart(419)) - Started @5590ms
2020-12-03 07:24:27,616 [Listener at localhost/44314] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46273
2020-12-03 07:24:27,617 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,617 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4362d7df] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,617 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,618 [Listener at localhost/44314] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,619 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,625 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40150
2020-12-03 07:24:27,636 [Listener at localhost/40150] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,637 [Listener at localhost/40150] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,638 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:27,639 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,639 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,647 [Listener at localhost/40150] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:27,649 [Listener at localhost/40150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:27,650 [Listener at localhost/40150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:27,651 [Listener at localhost/40150] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,653 [Listener at localhost/40150] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,653 [Listener at localhost/40150] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,653 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,654 [Listener at localhost/40150] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,654 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,655 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37666
2020-12-03 07:24:27,655 [Listener at localhost/40150] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,655 [Listener at localhost/40150] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,657 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,659 [Listener at localhost/40150] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,661 [Listener at localhost/40150] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,661 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,664 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,666 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,667 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,667 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,668 [Listener at localhost/40150] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46004
2020-12-03 07:24:27,668 [Listener at localhost/40150] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,671 [Listener at localhost/40150] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65f87a2c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,672 [Listener at localhost/40150] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ce1f601{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,681 [Listener at localhost/40150] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ec2bf82{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,682 [Listener at localhost/40150] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@cc62a3b{HTTP/1.1,[http/1.1]}{localhost:46004}
2020-12-03 07:24:27,683 [Listener at localhost/40150] INFO  server.Server (Server.java:doStart(419)) - Started @5731ms
2020-12-03 07:24:27,714 [Listener at localhost/40150] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36668
2020-12-03 07:24:27,714 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,714 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29539e36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,714 [Listener at localhost/40150] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,716 [Listener at localhost/40150] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,717 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,723 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42521
2020-12-03 07:24:27,730 [Listener at localhost/42521] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,731 [Listener at localhost/42521] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,732 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:27,733 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,733 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,736 [Listener at localhost/42521] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:27,739 [Listener at localhost/42521] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:27,740 [Listener at localhost/42521] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:27,741 [Listener at localhost/42521] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,749 [Listener at localhost/42521] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,750 [Listener at localhost/42521] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,750 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,750 [Listener at localhost/42521] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,751 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,752 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34518
2020-12-03 07:24:27,752 [Listener at localhost/42521] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,752 [Listener at localhost/42521] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,754 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,756 [Listener at localhost/42521] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,756 [Listener at localhost/42521] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,757 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,759 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,760 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,760 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,760 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,761 [Listener at localhost/42521] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41074
2020-12-03 07:24:27,761 [Listener at localhost/42521] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,763 [Listener at localhost/42521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@581d969c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,764 [Listener at localhost/42521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b46a8c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,770 [Listener at localhost/42521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58a55449{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,771 [Listener at localhost/42521] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5949eba8{HTTP/1.1,[http/1.1]}{localhost:41074}
2020-12-03 07:24:27,773 [Listener at localhost/42521] INFO  server.Server (Server.java:doStart(419)) - Started @5821ms
2020-12-03 07:24:27,842 [Listener at localhost/42521] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35899
2020-12-03 07:24:27,843 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58dea0a5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,843 [Listener at localhost/42521] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,844 [Listener at localhost/42521] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,845 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,850 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40320
2020-12-03 07:24:27,855 [Listener at localhost/40320] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,856 [Listener at localhost/40320] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,856 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:27,858 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,859 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,866 [Listener at localhost/40320] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:27,868 [Listener at localhost/40320] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:27,869 [Listener at localhost/40320] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:27,872 [Listener at localhost/40320] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,872 [Listener at localhost/40320] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,873 [Listener at localhost/40320] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,873 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,873 [Listener at localhost/40320] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,875 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,876 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37118
2020-12-03 07:24:27,876 [Listener at localhost/40320] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,877 [Listener at localhost/40320] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,880 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,887 [Listener at localhost/40320] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,889 [Listener at localhost/40320] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,889 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,892 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,893 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,893 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,893 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,895 [Listener at localhost/40320] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44941
2020-12-03 07:24:27,895 [Listener at localhost/40320] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,900 [Listener at localhost/40320] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@475b7792{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,902 [Listener at localhost/40320] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@160c3ec1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,913 [Listener at localhost/40320] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e392345{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,915 [Listener at localhost/40320] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12f3afb5{HTTP/1.1,[http/1.1]}{localhost:44941}
2020-12-03 07:24:27,916 [Listener at localhost/40320] INFO  server.Server (Server.java:doStart(419)) - Started @5964ms
2020-12-03 07:24:27,924 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:27,924 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:27,924 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:27,924 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:27,927 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,927 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,927 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,927 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,936 [Listener at localhost/40320] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34733
2020-12-03 07:24:27,937 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c22a348] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,937 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,937 [Listener at localhost/40320] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,938 [Listener at localhost/40320] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,939 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,945 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33852
2020-12-03 07:24:27,950 [Listener at localhost/33852] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,951 [Listener at localhost/33852] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,952 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:27,954 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,954 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,958 [Listener at localhost/33852] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:27,958 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:27,959 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,960 [Listener at localhost/33852] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:27,961 [Listener at localhost/33852] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:27,963 [Listener at localhost/33852] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,964 [Listener at localhost/33852] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,965 [Listener at localhost/33852] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,965 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,965 [Listener at localhost/33852] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,966 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,966 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40540
2020-12-03 07:24:27,967 [Listener at localhost/33852] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,967 [Listener at localhost/33852] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,968 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,970 [Listener at localhost/33852] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,970 [Listener at localhost/33852] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,971 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,973 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,973 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,974 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,974 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,974 [Listener at localhost/33852] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46677
2020-12-03 07:24:27,975 [Listener at localhost/33852] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,976 [Listener at localhost/33852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3301500b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,977 [Listener at localhost/33852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15deb1dc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,983 [Listener at localhost/33852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c1e3314{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,984 [Listener at localhost/33852] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b770e40{HTTP/1.1,[http/1.1]}{localhost:46677}
2020-12-03 07:24:27,984 [Listener at localhost/33852] INFO  server.Server (Server.java:doStart(419)) - Started @6033ms
2020-12-03 07:24:27,998 [Listener at localhost/33852] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42732
2020-12-03 07:24:27,999 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54a3ab8f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,999 [Listener at localhost/33852] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,000 [Listener at localhost/33852] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,001 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,004 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40608
2020-12-03 07:24:28,009 [Listener at localhost/40608] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,009 [Listener at localhost/40608] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,010 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:28,011 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,013 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,014 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:28,015 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,016 [Listener at localhost/40608] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:28,017 [Listener at localhost/40608] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:28,018 [Listener at localhost/40608] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:28,019 [Listener at localhost/40608] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:28,019 [Listener at localhost/40608] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,020 [Listener at localhost/40608] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,020 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,020 [Listener at localhost/40608] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,021 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,021 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38080
2020-12-03 07:24:28,021 [Listener at localhost/40608] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,021 [Listener at localhost/40608] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,023 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,023 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,023 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,023 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,023 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,025 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,025 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,025 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,025 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,025 [Listener at localhost/40608] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,026 [Listener at localhost/40608] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,026 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,027 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7836c789-3df3-4ade-8fb6-3afebc5d4302 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:24:28,027 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1cba7238-1c9a-46d1-813e-57194888ccfc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:24:28,027 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-da165306-2297-46a9-9796-fadbcb076d32 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:24:28,027 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8782261c-8974-4d10-8758-b15a171ad8ac for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:24:28,029 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,030 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,030 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,030 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,031 [Listener at localhost/40608] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41836
2020-12-03 07:24:28,032 [Listener at localhost/40608] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,034 [Listener at localhost/40608] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51abf713{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,035 [Listener at localhost/40608] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d4d48a6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,043 [Listener at localhost/40608] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@65ef722a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,044 [Listener at localhost/40608] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5fd9b663{HTTP/1.1,[http/1.1]}{localhost:41836}
2020-12-03 07:24:28,044 [Listener at localhost/40608] INFO  server.Server (Server.java:doStart(419)) - Started @6093ms
2020-12-03 07:24:28,059 [Listener at localhost/40608] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35373
2020-12-03 07:24:28,060 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,060 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10567255] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,060 [Listener at localhost/40608] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,061 [Listener at localhost/40608] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,061 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,065 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42387
2020-12-03 07:24:28,069 [Listener at localhost/42387] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,069 [Listener at localhost/42387] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,070 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:28,072 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,072 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,075 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:28,076 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,076 [Listener at localhost/42387] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:28,077 [Listener at localhost/42387] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:28,078 [Listener at localhost/42387] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:28,079 [Listener at localhost/42387] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:28,080 [Listener at localhost/42387] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,080 [Listener at localhost/42387] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,081 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,081 [Listener at localhost/42387] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,081 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,082 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43169
2020-12-03 07:24:28,082 [Listener at localhost/42387] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,082 [Listener at localhost/42387] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,083 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,085 [Listener at localhost/42387] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,085 [Listener at localhost/42387] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,086 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,087 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,088 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,088 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,088 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,089 [Listener at localhost/42387] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33267
2020-12-03 07:24:28,089 [Listener at localhost/42387] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,090 [Listener at localhost/42387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59221b97{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,091 [Listener at localhost/42387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a772895{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,096 [Listener at localhost/42387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5215cd9a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,097 [Listener at localhost/42387] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@36b6964d{HTTP/1.1,[http/1.1]}{localhost:33267}
2020-12-03 07:24:28,098 [Listener at localhost/42387] INFO  server.Server (Server.java:doStart(419)) - Started @6146ms
2020-12-03 07:24:28,133 [Listener at localhost/42387] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35926
2020-12-03 07:24:28,134 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,134 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9257031] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,134 [Listener at localhost/42387] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,134 [Listener at localhost/42387] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,135 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,135 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,135 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,135 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,136 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,138 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:24:28,138 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:24:28,139 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44138
2020-12-03 07:24:28,144 [Listener at localhost/44138] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,145 [Listener at localhost/44138] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,145 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:28,147 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,148 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,151 [Listener at localhost/44138] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:28,152 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:28,152 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,153 [Listener at localhost/44138] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:28,153 [Listener at localhost/44138] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:28,154 [Listener at localhost/44138] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:28,155 [Listener at localhost/44138] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,155 [Listener at localhost/44138] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,156 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,156 [Listener at localhost/44138] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,156 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,157 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35974
2020-12-03 07:24:28,157 [Listener at localhost/44138] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,157 [Listener at localhost/44138] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,158 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,160 [Listener at localhost/44138] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,160 [Listener at localhost/44138] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,160 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,162 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,163 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,163 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,163 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,164 [Listener at localhost/44138] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33415
2020-12-03 07:24:28,164 [Listener at localhost/44138] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,165 [Listener at localhost/44138] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30457e14{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,166 [Listener at localhost/44138] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@632aa1a3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,171 [Listener at localhost/44138] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@251ebf23{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,173 [Listener at localhost/44138] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29b732a2{HTTP/1.1,[http/1.1]}{localhost:33415}
2020-12-03 07:24:28,173 [Listener at localhost/44138] INFO  server.Server (Server.java:doStart(419)) - Started @6221ms
2020-12-03 07:24:28,190 [Listener at localhost/44138] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37166
2020-12-03 07:24:28,191 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51671b08] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,191 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,191 [Listener at localhost/44138] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,192 [Listener at localhost/44138] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,192 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,196 [Listener at localhost/41345] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41345
2020-12-03 07:24:28,200 [Listener at localhost/41345] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,200 [Listener at localhost/41345] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,201 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480 starting to offer service
2020-12-03 07:24:28,205 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,205 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,206 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,207 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,208 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40480
2020-12-03 07:24:28,208 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:24:28,209 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,215 [Listener at localhost/41345] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:28,306 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,306 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,307 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:24:28,382 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,382 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,383 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-17a76543-dba4-4ae5-84a9-0771cb770f9c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:24:28,586 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,586 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,586 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,586 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,586 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,586 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,587 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,587 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,588 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fefa4c44-5937-4442-ad31-fa122a612ca5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:24:28,588 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:24:28,588 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-82dcdbbf-769b-4c56-925d-0357f7677a83 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:24:28,588 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1df59b54-af62-4785-bea2-f260be54184a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:24:28,670 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,678 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,678 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,680 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,680 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,680 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,680 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,682 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c4809f2c-b656-44a7-9fe9-d388d4198e13 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:24:28,682 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:24:28,769 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,769 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,772 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:24:28,781 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,782 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,782 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,855 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,855 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,858 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:24:28,884 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,885 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,885 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,956 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:28,956 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1691034356. Formatting...
2020-12-03 07:24:28,958 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9284d452-ec75-4d32-a5db-cf325205e975 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:24:28,969 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,969 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,969 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,969 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,970 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,970 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:28,970 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:28,970 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:28,970 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,970 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:28,971 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:28,971 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:28,974 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,974 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:28,975 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:28,975 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:28,987 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,988 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,988 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,066 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,067 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,067 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,067 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,070 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,070 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,070 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,070 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,090 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,091 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,091 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,170 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,170 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,170 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,170 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,193 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,194 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,194 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,263 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,263 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,264 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,264 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,297 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,298 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,298 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,348 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,349 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,349 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,349 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,350 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,350 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,351 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,351 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,351 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,351 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,351 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,351 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,352 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,353 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,353 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,353 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,353 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,353 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,354 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,354 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,401 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,401 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,402 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,467 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,467 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,468 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,468 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,468 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,468 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,468 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,468 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,504 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,504 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,504 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,598 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,599 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,599 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,599 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,606 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,607 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,608 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,702 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,703 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,703 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,703 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,713 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,714 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,714 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,782 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,782 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,782 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,783 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,793 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,793 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:29,793 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-497026648-172.17.0.6-1606980264031 is not formatted. Formatting ...
2020-12-03 07:24:29,793 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-497026648-172.17.0.6-1606980264031 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-497026648-172.17.0.6-1606980264031/current
2020-12-03 07:24:29,816 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,817 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,817 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,883 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,883 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:29,920 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,921 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,921 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,988 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:30,023 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,024 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,024 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,079 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:30,126 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,127 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,127 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,170 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c08f2fc4-9604-4e66-a1b6-0f200d2b7603
2020-12-03 07:24:30,170 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 957f7558-ddcd-47f1-a9be-9e76d14b462c
2020-12-03 07:24:30,170 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d7436b20-5bd0-4f50-a32a-8fa1fa61a85e
2020-12-03 07:24:30,170 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2c935922-34bc-4749-81d4-c6a73148b9a4
2020-12-03 07:24:30,173 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1691034356;bpid=BP-497026648-172.17.0.6-1606980264031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1691034356;c=1606980264031;bpid=BP-497026648-172.17.0.6-1606980264031;dnuuid=null
2020-12-03 07:24:30,230 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,230 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,231 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,245 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:30,245 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9262f02d-1544-4d2a-b652-a51a74f462c3
2020-12-03 07:24:30,302 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8782261c-8974-4d10-8758-b15a171ad8ac
2020-12-03 07:24:30,305 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1cba7238-1c9a-46d1-813e-57194888ccfc
2020-12-03 07:24:30,303 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c
2020-12-03 07:24:30,314 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7836c789-3df3-4ade-8fb6-3afebc5d4302
2020-12-03 07:24:30,315 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:30,315 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-da165306-2297-46a9-9796-fadbcb076d32
2020-12-03 07:24:30,320 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:30,312 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6
2020-12-03 07:24:30,322 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1df59b54-af62-4785-bea2-f260be54184a
2020-12-03 07:24:30,319 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:30,319 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:30,319 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:30,324 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:30,322 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:24:30,325 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fefa4c44-5937-4442-ad31-fa122a612ca5
2020-12-03 07:24:30,325 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:30,326 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:30,328 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-82dcdbbf-769b-4c56-925d-0357f7677a83
2020-12-03 07:24:30,328 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:30,330 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5
2020-12-03 07:24:30,333 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:24:30,333 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc
2020-12-03 07:24:30,333 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:24:30,335 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,336 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,336 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,336 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3
2020-12-03 07:24:30,337 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:30,339 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,339 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,339 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,339 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,339 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,340 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c4809f2c-b656-44a7-9fe9-d388d4198e13
2020-12-03 07:24:30,340 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:30,342 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,348 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,351 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,352 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,353 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,355 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,356 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6ccef453-d6ce-4e51-bca2-7301b8846a01
2020-12-03 07:24:30,357 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:24:30,357 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,357 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,359 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,366 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,369 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,366 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,369 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,371 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,371 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,371 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,369 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,369 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,369 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,372 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,372 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,371 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,371 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,371 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,371 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,374 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,374 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,374 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,373 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,373 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,372 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,375 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,375 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,375 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:30,374 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,375 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:30,376 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:30,376 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,376 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,376 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,379 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:30,380 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:30,380 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:30,381 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:30,382 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:30,382 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:30,383 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30
2020-12-03 07:24:30,383 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:24:30,385 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:30,384 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:30,384 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:30,384 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:30,388 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:30,388 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:30,389 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4e86e337-980c-423c-ad80-f723a5dbe6f4
2020-12-03 07:24:30,390 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:24:30,391 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,392 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,392 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,393 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,393 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,394 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,395 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:30,395 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:30,445 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 63ms
2020-12-03 07:24:30,445 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,445 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:30,458 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 70ms
2020-12-03 07:24:30,459 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 72ms
2020-12-03 07:24:30,465 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,465 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,503 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-17a76543-dba4-4ae5-84a9-0771cb770f9c
2020-12-03 07:24:30,503 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:30,514 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9284d452-ec75-4d32-a5db-cf325205e975
2020-12-03 07:24:30,514 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:30,515 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,518 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,519 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,519 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,519 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,519 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,520 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:30,520 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:30,526 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 138ms
2020-12-03 07:24:30,528 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 147ms
2020-12-03 07:24:30,529 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 143ms
2020-12-03 07:24:30,537 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 162ms
2020-12-03 07:24:30,539 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 152ms
2020-12-03 07:24:30,540 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:30,540 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:30,540 [Thread-303] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,541 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 166ms
2020-12-03 07:24:30,545 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 149ms
2020-12-03 07:24:30,546 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 170ms
2020-12-03 07:24:30,546 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 172ms
2020-12-03 07:24:30,548 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 169ms
2020-12-03 07:24:30,548 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 168ms
2020-12-03 07:24:30,549 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 173ms
2020-12-03 07:24:30,549 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 173ms
2020-12-03 07:24:30,549 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:30,549 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 10ms
2020-12-03 07:24:30,540 [Thread-304] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,550 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,554 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:30,554 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 15ms
2020-12-03 07:24:30,554 [Thread-305] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,555 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:30,555 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:30,555 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 16ms
2020-12-03 07:24:30,556 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:30,556 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,555 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,556 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,556 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 6ms
2020-12-03 07:24:30,557 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:24:30,557 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:30,557 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 2ms
2020-12-03 07:24:30,561 [Thread-312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,557 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:24:30,568 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 22ms
2020-12-03 07:24:30,568 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 13ms
2020-12-03 07:24:30,573 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 12ms
2020-12-03 07:24:30,573 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,575 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,575 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 25ms
2020-12-03 07:24:30,575 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 26ms
2020-12-03 07:24:30,575 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,575 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,573 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-1df59b54-af62-4785-bea2-f260be54184a): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,576 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,578 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c4809f2c-b656-44a7-9fe9-d388d4198e13): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,578 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-fefa4c44-5937-4442-ad31-fa122a612ca5): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,573 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,578 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8782261c-8974-4d10-8758-b15a171ad8ac): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,578 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-da165306-2297-46a9-9796-fadbcb076d32): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,578 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,584 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 189ms
2020-12-03 07:24:30,585 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 190ms
2020-12-03 07:24:30,585 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,585 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:30,585 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,586 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,586 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:24:30,589 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:30,589 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,589 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 202ms
2020-12-03 07:24:30,589 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 213ms
2020-12-03 07:24:30,590 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 214ms
2020-12-03 07:24:30,590 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 215ms
2020-12-03 07:24:30,589 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 200ms
2020-12-03 07:24:30,590 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:30,591 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 215ms
2020-12-03 07:24:30,590 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:24:30,591 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,591 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 7ms
2020-12-03 07:24:30,592 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:24:30,592 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,592 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,592 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4e86e337-980c-423c-ad80-f723a5dbe6f4): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,592 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,593 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 73ms
2020-12-03 07:24:30,592 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-497026648-172.17.0.6-1606980264031 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 73ms
2020-12-03 07:24:30,597 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-497026648-172.17.0.6-1606980264031: 78ms
2020-12-03 07:24:30,597 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:30,598 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:30,598 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:30,598 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,599 [Thread-329] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,598 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,600 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:30,600 [Thread-326] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,599 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:30,599 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:30,600 [Thread-331] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,600 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:24:30,600 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:30,600 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:24:30,601 [Thread-330] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,600 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-12-03 07:24:30,600 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:24:30,600 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 0ms
2020-12-03 07:24:30,600 [Thread-332] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-497026648-172.17.0.6-1606980264031/current/replicas doesn't exist 
2020-12-03 07:24:30,601 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 11ms
2020-12-03 07:24:30,601 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:24:30,601 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 12ms
2020-12-03 07:24:30,603 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 5ms
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-17a76543-dba4-4ae5-84a9-0771cb770f9c): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,602 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 2ms
2020-12-03 07:24:30,604 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-497026648-172.17.0.6-1606980264031: 12ms
2020-12-03 07:24:30,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-9284d452-ec75-4d32-a5db-cf325205e975): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-6ccef453-d6ce-4e51-bca2-7301b8846a01): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1cba7238-1c9a-46d1-813e-57194888ccfc): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-497026648-172.17.0.6-1606980264031 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-82dcdbbf-769b-4c56-925d-0357f7677a83): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7836c789-3df3-4ade-8fb6-3afebc5d4302): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,605 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3): finished scanning block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-da165306-2297-46a9-9796-fadbcb076d32): no suitable block pools found to scan.  Waiting 1814399954 ms.
2020-12-03 07:24:30,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-17a76543-dba4-4ae5-84a9-0771cb770f9c): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:24:30,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1cba7238-1c9a-46d1-813e-57194888ccfc): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:24:30,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-82dcdbbf-769b-4c56-925d-0357f7677a83): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:24:30,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-1df59b54-af62-4785-bea2-f260be54184a): no suitable block pools found to scan.  Waiting 1814399954 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c4809f2c-b656-44a7-9fe9-d388d4198e13): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4e86e337-980c-423c-ad80-f723a5dbe6f4): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:24:30,620 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:02 PM with interval of 21600000ms
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-9284d452-ec75-4d32-a5db-cf325205e975): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-fefa4c44-5937-4442-ad31-fa122a612ca5): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7836c789-3df3-4ade-8fb6-3afebc5d4302): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:24:30,620 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8782261c-8974-4d10-8758-b15a171ad8ac): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-03 07:24:30,622 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:24:30,622 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:23 AM with interval of 21600000ms
2020-12-03 07:24:30,622 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:25 AM with interval of 21600000ms
2020-12-03 07:24:30,624 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:02 AM with interval of 21600000ms
2020-12-03 07:24:30,624 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:22 AM with interval of 21600000ms
2020-12-03 07:24:30,625 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:57 AM with interval of 21600000ms
2020-12-03 07:24:30,625 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:45 AM with interval of 21600000ms
2020-12-03 07:24:30,625 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:54 AM with interval of 21600000ms
2020-12-03 07:24:30,625 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:28 AM with interval of 21600000ms
2020-12-03 07:24:30,625 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-6ccef453-d6ce-4e51-bca2-7301b8846a01): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-12-03 07:24:30,625 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid c08f2fc4-9604-4e66-a1b6-0f200d2b7603) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 957f7558-ddcd-47f1-a9be-9e76d14b462c) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 2c935922-34bc-4749-81d4-c6a73148b9a4) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid d7436b20-5bd0-4f50-a32a-8fa1fa61a85e) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:30,654 [IPC Server handler 5 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35554, datanodeUuid=c08f2fc4-9604-4e66-a1b6-0f200d2b7603, infoPort=38861, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage c08f2fc4-9604-4e66-a1b6-0f200d2b7603
2020-12-03 07:24:30,661 [IPC Server handler 5 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35554
2020-12-03 07:24:30,661 [IPC Server handler 5 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c08f2fc4-9604-4e66-a1b6-0f200d2b7603 (127.0.0.1:35554).
2020-12-03 07:24:30,664 [IPC Server handler 8 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:30,664 [IPC Server handler 8 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37118
2020-12-03 07:24:30,664 [IPC Server handler 8 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ef278207-33f0-460f-ad85-df1b9dfc23ce (127.0.0.1:37118).
2020-12-03 07:24:30,665 [IPC Server handler 3 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40540, datanodeUuid=9262f02d-1544-4d2a-b652-a51a74f462c3, infoPort=42732, infoSecurePort=0, ipcPort=40608, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 9262f02d-1544-4d2a-b652-a51a74f462c3
2020-12-03 07:24:30,665 [IPC Server handler 3 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40540
2020-12-03 07:24:30,665 [IPC Server handler 3 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9262f02d-1544-4d2a-b652-a51a74f462c3 (127.0.0.1:40540).
2020-12-03 07:24:30,666 [IPC Server handler 6 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:30,666 [IPC Server handler 6 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43169
2020-12-03 07:24:30,666 [IPC Server handler 6 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ff4f43b1-8422-4ae6-ad05-7845f3383624 (127.0.0.1:43169).
2020-12-03 07:24:30,666 [IPC Server handler 7 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34518, datanodeUuid=2c935922-34bc-4749-81d4-c6a73148b9a4, infoPort=35899, infoSecurePort=0, ipcPort=40320, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 2c935922-34bc-4749-81d4-c6a73148b9a4
2020-12-03 07:24:30,667 [IPC Server handler 7 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34518
2020-12-03 07:24:30,667 [IPC Server handler 7 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2c935922-34bc-4749-81d4-c6a73148b9a4 (127.0.0.1:34518).
2020-12-03 07:24:30,667 [IPC Server handler 4 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:30,667 [IPC Server handler 4 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38080
2020-12-03 07:24:30,667 [IPC Server handler 4 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 652d02fb-83eb-4483-ac0b-9eff8a764461 (127.0.0.1:38080).
2020-12-03 07:24:30,667 [IPC Server handler 9 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:30,668 [IPC Server handler 9 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35974
2020-12-03 07:24:30,668 [IPC Server handler 9 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3b4af1e9-74d5-4cdf-a020-46743c53cff1 (127.0.0.1:35974).
2020-12-03 07:24:30,668 [IPC Server handler 2 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37666, datanodeUuid=d7436b20-5bd0-4f50-a32a-8fa1fa61a85e, infoPort=36668, infoSecurePort=0, ipcPort=42521, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage d7436b20-5bd0-4f50-a32a-8fa1fa61a85e
2020-12-03 07:24:30,668 [IPC Server handler 2 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37666
2020-12-03 07:24:30,669 [IPC Server handler 2 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d7436b20-5bd0-4f50-a32a-8fa1fa61a85e (127.0.0.1:37666).
2020-12-03 07:24:30,669 [IPC Server handler 1 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40041, datanodeUuid=957f7558-ddcd-47f1-a9be-9e76d14b462c, infoPort=46273, infoSecurePort=0, ipcPort=40150, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 957f7558-ddcd-47f1-a9be-9e76d14b462c
2020-12-03 07:24:30,669 [IPC Server handler 1 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40041
2020-12-03 07:24:30,669 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 957f7558-ddcd-47f1-a9be-9e76d14b462c (127.0.0.1:40041).
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid c08f2fc4-9604-4e66-a1b6-0f200d2b7603) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 957f7558-ddcd-47f1-a9be-9e76d14b462c) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 2c935922-34bc-4749-81d4-c6a73148b9a4) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,670 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid d7436b20-5bd0-4f50-a32a-8fa1fa61a85e) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,673 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:30,672 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,672 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,672 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,672 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,674 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,674 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40480 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:30,694 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,707 [IPC Server handler 8 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7836c789-3df3-4ade-8fb6-3afebc5d4302 for DN 127.0.0.1:35554
2020-12-03 07:24:30,708 [IPC Server handler 8 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-82dcdbbf-769b-4c56-925d-0357f7677a83 for DN 127.0.0.1:35554
2020-12-03 07:24:30,709 [IPC Server handler 4 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1cba7238-1c9a-46d1-813e-57194888ccfc for DN 127.0.0.1:37666
2020-12-03 07:24:30,710 [IPC Server handler 4 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3 for DN 127.0.0.1:37666
2020-12-03 07:24:30,711 [IPC Server handler 9 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17a76543-dba4-4ae5-84a9-0771cb770f9c for DN 127.0.0.1:35974
2020-12-03 07:24:30,711 [IPC Server handler 9 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9284d452-ec75-4d32-a5db-cf325205e975 for DN 127.0.0.1:35974
2020-12-03 07:24:30,711 [IPC Server handler 5 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 for DN 127.0.0.1:43169
2020-12-03 07:24:30,711 [IPC Server handler 5 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 for DN 127.0.0.1:43169
2020-12-03 07:24:30,711 [IPC Server handler 2 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 for DN 127.0.0.1:38080
2020-12-03 07:24:30,711 [IPC Server handler 2 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 for DN 127.0.0.1:38080
2020-12-03 07:24:30,712 [IPC Server handler 7 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 for DN 127.0.0.1:37118
2020-12-03 07:24:30,712 [IPC Server handler 7 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc for DN 127.0.0.1:37118
2020-12-03 07:24:30,712 [IPC Server handler 6 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8782261c-8974-4d10-8758-b15a171ad8ac for DN 127.0.0.1:34518
2020-12-03 07:24:30,712 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:34518
2020-12-03 07:24:30,712 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,712 [IPC Server handler 6 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fefa4c44-5937-4442-ad31-fa122a612ca5 for DN 127.0.0.1:34518
2020-12-03 07:24:30,713 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-da165306-2297-46a9-9796-fadbcb076d32 for DN 127.0.0.1:40041
2020-12-03 07:24:30,713 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1df59b54-af62-4785-bea2-f260be54184a for DN 127.0.0.1:40041
2020-12-03 07:24:30,713 [IPC Server handler 3 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c for DN 127.0.0.1:40540
2020-12-03 07:24:30,714 [IPC Server handler 3 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c4809f2c-b656-44a7-9fe9-d388d4198e13 for DN 127.0.0.1:40540
2020-12-03 07:24:30,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5691f98e5198f8ca: Processing first storage report for DS-82dcdbbf-769b-4c56-925d-0357f7677a83 from datanode c08f2fc4-9604-4e66-a1b6-0f200d2b7603
2020-12-03 07:24:30,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5691f98e5198f8ca: from storage DS-82dcdbbf-769b-4c56-925d-0357f7677a83 node DatanodeRegistration(127.0.0.1:35554, datanodeUuid=c08f2fc4-9604-4e66-a1b6-0f200d2b7603, infoPort=38861, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xefa4bc4df62da711: Processing first storage report for DS-1cba7238-1c9a-46d1-813e-57194888ccfc from datanode d7436b20-5bd0-4f50-a32a-8fa1fa61a85e
2020-12-03 07:24:30,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xefa4bc4df62da711: from storage DS-1cba7238-1c9a-46d1-813e-57194888ccfc node DatanodeRegistration(127.0.0.1:37666, datanodeUuid=d7436b20-5bd0-4f50-a32a-8fa1fa61a85e, infoPort=36668, infoSecurePort=0, ipcPort=42521, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x122fb8e2443c23ae: Processing first storage report for DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 from datanode ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x122fb8e2443c23ae: from storage DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 node DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe71bf33ee9b88d53: Processing first storage report for DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 from datanode ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe71bf33ee9b88d53: from storage DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 node DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cced64f92cffb3b: Processing first storage report for DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 from datanode 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cced64f92cffb3b: from storage DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 node DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd576e86131b96de9: Processing first storage report for DS-17a76543-dba4-4ae5-84a9-0771cb770f9c from datanode 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd576e86131b96de9: from storage DS-17a76543-dba4-4ae5-84a9-0771cb770f9c node DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5691f98e5198f8ca: Processing first storage report for DS-7836c789-3df3-4ade-8fb6-3afebc5d4302 from datanode c08f2fc4-9604-4e66-a1b6-0f200d2b7603
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5691f98e5198f8ca: from storage DS-7836c789-3df3-4ade-8fb6-3afebc5d4302 node DatanodeRegistration(127.0.0.1:35554, datanodeUuid=c08f2fc4-9604-4e66-a1b6-0f200d2b7603, infoPort=38861, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xefa4bc4df62da711: Processing first storage report for DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3 from datanode d7436b20-5bd0-4f50-a32a-8fa1fa61a85e
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xefa4bc4df62da711: from storage DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3 node DatanodeRegistration(127.0.0.1:37666, datanodeUuid=d7436b20-5bd0-4f50-a32a-8fa1fa61a85e, infoPort=36668, infoSecurePort=0, ipcPort=42521, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x122fb8e2443c23ae: Processing first storage report for DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 from datanode ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x122fb8e2443c23ae: from storage DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 node DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe71bf33ee9b88d53: Processing first storage report for DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc from datanode ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe71bf33ee9b88d53: from storage DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc node DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cced64f92cffb3b: Processing first storage report for DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 from datanode 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:30,754 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cced64f92cffb3b: from storage DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 node DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,755 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd576e86131b96de9: Processing first storage report for DS-9284d452-ec75-4d32-a5db-cf325205e975 from datanode 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:30,755 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd576e86131b96de9: from storage DS-9284d452-ec75-4d32-a5db-cf325205e975 node DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5691f98e5198f8ca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x122fb8e2443c23ae,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xefa4bc4df62da711,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,775 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd576e86131b96de9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,775 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe71bf33ee9b88d53,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1cced64f92cffb3b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,774 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,776 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,776 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:30,817 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,820 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:30,826 [Listener at localhost/41345] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:30,828 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,829 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:30,830 [Listener at localhost/41345] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:30,900 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-6-3-64k]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,917 [IPC Server handler 8 on default port 40480] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-6-3-64k
2020-12-03 07:24:30,917 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-64k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,922 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,924 [IPC Server handler 2 on default port 40480] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:24:30,924 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,925 [IPC Server handler 6 on default port 40480] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:30,925 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-LEGACY-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,927 [IPC Server handler 0 on default port 40480] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:24:30,927 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,928 [IPC Server handler 1 on default port 40480] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:24:30,929 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,931 [Listener at localhost/41345] DEBUG hdfs.DFSClient (DFSClient.java:primitiveMkdir(2423)) - /TestDFSStripedOutputStreamWithFailureBase: masked={ masked: rwxr-xr-x, unmasked: rwxrwxrwx }
2020-12-03 07:24:30,943 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:30,958 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:30,961 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:35554 from a total of 9 datanodes.
2020-12-03 07:24:30,962 [Listener at localhost/41345] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:30,962 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b40bb6e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:30,964 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-82dcdbbf-769b-4c56-925d-0357f7677a83) exiting.
2020-12-03 07:24:30,964 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7836c789-3df3-4ade-8fb6-3afebc5d4302) exiting.
2020-12-03 07:24:31,083 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@235f4c10{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,088 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@743cb8e0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,091 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76ba13c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,095 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61526469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,105 [Listener at localhost/41345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44314
2020-12-03 07:24:31,113 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,115 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,116 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,116 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid c08f2fc4-9604-4e66-a1b6-0f200d2b7603) service to localhost/127.0.0.1:40480
2020-12-03 07:24:31,116 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid c08f2fc4-9604-4e66-a1b6-0f200d2b7603)
2020-12-03 07:24:31,116 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:31,124 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,125 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,129 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,129 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,130 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,130 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,144 [Listener at localhost/41345] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,145 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:40041 from a total of 8 datanodes.
2020-12-03 07:24:31,145 [Listener at localhost/41345] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:31,145 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@384fc774] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,148 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-da165306-2297-46a9-9796-fadbcb076d32) exiting.
2020-12-03 07:24:31,148 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-1df59b54-af62-4785-bea2-f260be54184a) exiting.
2020-12-03 07:24:31,218 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1827a871{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,220 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48e64352{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,220 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@fac80{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,221 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5af9926a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,222 [Listener at localhost/41345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40150
2020-12-03 07:24:31,238 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,238 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,238 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,242 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 957f7558-ddcd-47f1-a9be-9e76d14b462c) service to localhost/127.0.0.1:40480
2020-12-03 07:24:31,242 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 957f7558-ddcd-47f1-a9be-9e76d14b462c)
2020-12-03 07:24:31,242 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:31,243 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,243 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,248 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,249 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,260 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,260 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,263 [Listener at localhost/41345] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,263 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:37666 from a total of 7 datanodes.
2020-12-03 07:24:31,263 [Listener at localhost/41345] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:31,263 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bbc9f97] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1c68f775-fc54-4387-8bd5-c34f41ed42e3) exiting.
2020-12-03 07:24:31,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-1cba7238-1c9a-46d1-813e-57194888ccfc) exiting.
2020-12-03 07:24:31,287 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ec2bf82{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,288 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@cc62a3b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,289 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ce1f601{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,290 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65f87a2c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,291 [Listener at localhost/41345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42521
2020-12-03 07:24:31,294 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,294 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,296 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,296 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid d7436b20-5bd0-4f50-a32a-8fa1fa61a85e) service to localhost/127.0.0.1:40480
2020-12-03 07:24:31,296 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid d7436b20-5bd0-4f50-a32a-8fa1fa61a85e)
2020-12-03 07:24:31,296 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:31,297 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,297 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,302 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,302 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,304 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,304 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,307 [Listener at localhost/41345] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,307 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:34518 from a total of 6 datanodes.
2020-12-03 07:24:31,307 [Listener at localhost/41345] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:31,307 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@329a1243] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,309 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-fefa4c44-5937-4442-ad31-fa122a612ca5) exiting.
2020-12-03 07:24:31,309 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-8782261c-8974-4d10-8758-b15a171ad8ac) exiting.
2020-12-03 07:24:31,327 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58a55449{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,328 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5949eba8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,328 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b46a8c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,328 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@581d969c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,330 [Listener at localhost/41345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40320
2020-12-03 07:24:31,335 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,335 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,336 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,336 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 2c935922-34bc-4749-81d4-c6a73148b9a4) service to localhost/127.0.0.1:40480
2020-12-03 07:24:31,338 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 2c935922-34bc-4749-81d4-c6a73148b9a4)
2020-12-03 07:24:31,338 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:31,338 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,338 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,345 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,346 [Listener at localhost/41345] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,347 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,347 [Listener at localhost/41345] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,350 [Listener at localhost/41345] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,350 [Listener at localhost/41345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:31,350 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:31,351 [Listener at localhost/41345] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 10
2020-12-03 07:24:31,351 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7a8fa663] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:31,356 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3a62c01e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:31,356 [Listener at localhost/41345] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 11 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 0 Number of syncs: 12 SyncTimes(ms): 1 1 
2020-12-03 07:24:31,360 [Listener at localhost/41345] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:24:31,361 [Listener at localhost/41345] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:24:31,362 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:31,363 [CacheReplicationMonitor(1664161582)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:31,417 [Listener at localhost/41345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40480
2020-12-03 07:24:31,420 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,423 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,424 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:31,424 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:31,466 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:31,466 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:31,468 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@266374ef{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:31,470 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f81aa00{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,470 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37313c65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,471 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@508dec2b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,484 [Listener at localhost/41345] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:31,484 [Listener at localhost/41345] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:24:31,485 [Listener at localhost/41345] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:40480
2020-12-03 07:24:31,485 [Listener at localhost/41345] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:40480 to access this namenode/service.
2020-12-03 07:24:31,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37fdfb05] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:31,510 [Listener at localhost/41345] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:39137
2020-12-03 07:24:31,510 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,512 [Listener at localhost/41345] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:31,513 [Listener at localhost/41345] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:31,513 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,515 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:31,516 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:31,517 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:31,517 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:31,518 [Listener at localhost/41345] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:31,519 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:31,519 [Listener at localhost/41345] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39137
2020-12-03 07:24:31,519 [Listener at localhost/41345] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:31,522 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70abf9b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:31,523 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@476ec9d0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:31,530 [Listener at localhost/41345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29f0c4f2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:31,534 [Listener at localhost/41345] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f63f4f9{HTTP/1.1,[http/1.1]}{localhost:39137}
2020-12-03 07:24:31,534 [Listener at localhost/41345] INFO  server.Server (Server.java:doStart(419)) - Started @9583ms
2020-12-03 07:24:31,537 [Listener at localhost/41345] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:31,538 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:31,539 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:31,539 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:31,539 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:31,539 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:31,539 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:31,540 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:31,540 [Listener at localhost/41345] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:31,540 [Listener at localhost/41345] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:31,541 [Listener at localhost/41345] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:31,541 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:31,542 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:31
2020-12-03 07:24:31,542 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:31,542 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:31,542 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:31,543 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:31,547 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:31,548 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:31,548 [Listener at localhost/41345] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:31,548 [Listener at localhost/41345] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:31,548 [Listener at localhost/41345] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:31,548 [Listener at localhost/41345] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:31,549 [Listener at localhost/41345] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:31,550 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:31,550 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:31,550 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:31,551 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:31,553 [Listener at localhost/41345] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:31,553 [Listener at localhost/41345] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:31,553 [Listener at localhost/41345] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:31,554 [Listener at localhost/41345] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:31,554 [Listener at localhost/41345] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:31,554 [Listener at localhost/41345] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:31,554 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:31,554 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:31,555 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:31,555 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:31,557 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:31,558 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:31,558 [Listener at localhost/41345] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:31,608 [Listener at localhost/41345] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:31,636 [Listener at localhost/41345] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17750@796e7be4bc1c
2020-12-03 07:24:31,641 [Listener at localhost/41345] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:31,643 [Listener at localhost/41345] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:31,651 [Listener at localhost/41345] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:31,656 [Listener at localhost/41345] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:31,658 [Listener at localhost/41345] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:31,658 [Listener at localhost/41345] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:31,696 [Listener at localhost/41345] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@24fabd0f expecting start txid #1
2020-12-03 07:24:31,696 [Listener at localhost/41345] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:31,697 [Listener at localhost/41345] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011' to transaction ID 1
2020-12-03 07:24:31,711 [Listener at localhost/41345] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-6-3-64k
2020-12-03 07:24:31,712 [Listener at localhost/41345] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:24:31,712 [Listener at localhost/41345] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:31,712 [Listener at localhost/41345] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:24:31,712 [Listener at localhost/41345] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:24:31,840 [Listener at localhost/41345] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011) of total size 665.0, total edits 11.0, total load time 18.0 ms
2020-12-03 07:24:31,841 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:31,842 [Listener at localhost/41345] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 12
2020-12-03 07:24:31,928 [Listener at localhost/41345] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:31,929 [Listener at localhost/41345] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 369 msecs
2020-12-03 07:24:31,929 [Listener at localhost/41345] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:40480
2020-12-03 07:24:31,930 [Listener at localhost/41345] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:31,931 [Socket Reader #1 for port 40480] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 40480
2020-12-03 07:24:31,937 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:31,987 [Listener at localhost/40480] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:31,989 [Listener at localhost/40480] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:31,989 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:31,989 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:31,990 [Listener at localhost/40480] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:31,995 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:24:31,998 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:31,998 [IPC Server listener on 40480] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 40480: starting
2020-12-03 07:24:32,008 [Listener at localhost/40480] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40480
2020-12-03 07:24:32,009 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:32,009 [Listener at localhost/40480] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:32,010 [Listener at localhost/40480] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=2
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:32,016 [CacheReplicationMonitor(674703128)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:32,021 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:32,026 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:32,035 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,040 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,040 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,145 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,147 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,147 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,248 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,249 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,249 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,351 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,352 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,352 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,453 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,454 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,454 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,556 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,557 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,557 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,675 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,676 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,676 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,778 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,779 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,780 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,881 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,882 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,882 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,983 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,984 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,984 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,086 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,086 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,087 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,197 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,198 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,198 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,300 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,301 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,301 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,403 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,403 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,403 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,505 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,506 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,506 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,607 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,608 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,608 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,675 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "796e7be4bc1c/172.17.0.6"; destination host is: "localhost":40480; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy23.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:24:33,680 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:40480 with active state
2020-12-03 07:24:33,679 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:40480 with active state
2020-12-03 07:24:33,679 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:40480 with active state
2020-12-03 07:24:33,679 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:40480 with active state
2020-12-03 07:24:33,681 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:33,681 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:33,682 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:33,682 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:33,682 [IPC Server handler 5 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:33,683 [IPC Server handler 5 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38080
2020-12-03 07:24:33,683 [IPC Server handler 5 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 652d02fb-83eb-4483-ac0b-9eff8a764461 (127.0.0.1:38080).
2020-12-03 07:24:33,684 [IPC Server handler 6 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:33,684 [IPC Server handler 6 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37118
2020-12-03 07:24:33,684 [IPC Server handler 6 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ef278207-33f0-460f-ad85-df1b9dfc23ce (127.0.0.1:37118).
2020-12-03 07:24:33,685 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:33,685 [IPC Server handler 8 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:33,685 [IPC Server handler 8 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43169
2020-12-03 07:24:33,685 [IPC Server handler 8 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ff4f43b1-8422-4ae6-ad05-7845f3383624 (127.0.0.1:43169).
2020-12-03 07:24:33,685 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:33,685 [IPC Server handler 9 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:33,686 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:33,687 [IPC Server handler 9 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35974
2020-12-03 07:24:33,687 [IPC Server handler 9 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3b4af1e9-74d5-4cdf-a020-46743c53cff1 (127.0.0.1:35974).
2020-12-03 07:24:33,688 [IPC Server handler 7 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 for DN 127.0.0.1:38080
2020-12-03 07:24:33,688 [IPC Server handler 7 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 for DN 127.0.0.1:38080
2020-12-03 07:24:33,689 [IPC Server handler 0 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 for DN 127.0.0.1:37118
2020-12-03 07:24:33,689 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:33,690 [IPC Server handler 0 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc for DN 127.0.0.1:37118
2020-12-03 07:24:33,690 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 for DN 127.0.0.1:43169
2020-12-03 07:24:33,690 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 for DN 127.0.0.1:43169
2020-12-03 07:24:33,691 [IPC Server handler 2 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-17a76543-dba4-4ae5-84a9-0771cb770f9c for DN 127.0.0.1:35974
2020-12-03 07:24:33,691 [IPC Server handler 2 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9284d452-ec75-4d32-a5db-cf325205e975 for DN 127.0.0.1:35974
2020-12-03 07:24:33,692 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cced64f92cffb3c: Processing first storage report for DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 from datanode 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:33,692 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cced64f92cffb3c: from storage DS-6ccef453-d6ce-4e51-bca2-7301b8846a01 node DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe71bf33ee9b88d54: Processing first storage report for DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 from datanode ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe71bf33ee9b88d54: from storage DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6 node DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x122fb8e2443c23af: Processing first storage report for DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 from datanode ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x122fb8e2443c23af: from storage DS-4e86e337-980c-423c-ad80-f723a5dbe6f4 node DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cced64f92cffb3c: Processing first storage report for DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 from datanode 652d02fb-83eb-4483-ac0b-9eff8a764461
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cced64f92cffb3c: from storage DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5 node DatanodeRegistration(127.0.0.1:38080, datanodeUuid=652d02fb-83eb-4483-ac0b-9eff8a764461, infoPort=35373, infoSecurePort=0, ipcPort=42387, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe71bf33ee9b88d54: Processing first storage report for DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc from datanode ef278207-33f0-460f-ad85-df1b9dfc23ce
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe71bf33ee9b88d54: from storage DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc node DatanodeRegistration(127.0.0.1:37118, datanodeUuid=ef278207-33f0-460f-ad85-df1b9dfc23ce, infoPort=34733, infoSecurePort=0, ipcPort=33852, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x122fb8e2443c23af: Processing first storage report for DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 from datanode ff4f43b1-8422-4ae6-ad05-7845f3383624
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x122fb8e2443c23af: from storage DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30 node DatanodeRegistration(127.0.0.1:43169, datanodeUuid=ff4f43b1-8422-4ae6-ad05-7845f3383624, infoPort=35926, infoSecurePort=0, ipcPort=44138, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd576e86131b96dea: Processing first storage report for DS-17a76543-dba4-4ae5-84a9-0771cb770f9c from datanode 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd576e86131b96dea: from storage DS-17a76543-dba4-4ae5-84a9-0771cb770f9c node DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd576e86131b96dea: Processing first storage report for DS-9284d452-ec75-4d32-a5db-cf325205e975 from datanode 3b4af1e9-74d5-4cdf-a020-46743c53cff1
2020-12-03 07:24:33,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd576e86131b96dea: from storage DS-9284d452-ec75-4d32-a5db-cf325205e975 node DatanodeRegistration(127.0.0.1:35974, datanodeUuid=3b4af1e9-74d5-4cdf-a020-46743c53cff1, infoPort=37166, infoSecurePort=0, ipcPort=41345, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x122fb8e2443c23af,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1cced64f92cffb3c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe71bf33ee9b88d54,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd576e86131b96dea,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:33,695 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:33,709 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,710 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,711 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,812 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,813 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,813 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,914 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,915 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,915 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,017 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,018 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,018 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,120 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,121 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,121 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,222 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,223 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,223 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,324 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,325 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,325 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,427 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,428 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,428 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,530 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,531 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,531 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,632 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,634 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,634 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,736 [IPC Server handler 9 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,737 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,737 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,839 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,840 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,840 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,941 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,943 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,943 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,044 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,045 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,045 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,147 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,148 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,148 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,249 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,251 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,251 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,352 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,353 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,354 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,455 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,461 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,461 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,563 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,564 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,564 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,665 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,667 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,667 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,769 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,770 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,770 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,872 [IPC Server handler 0 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,873 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,873 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,974 [IPC Server handler 1 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,975 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,976 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,077 [IPC Server handler 5 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,078 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,078 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,179 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,180 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,180 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,282 [IPC Server handler 4 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,283 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,284 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,385 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,385 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,385 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,487 [IPC Server handler 6 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,489 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,489 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,590 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,591 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,591 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,674 [IPC Server handler 9 on default port 40480] WARN  blockmanagement.BlockManager (BlockManager.java:requestBlockReportLeaseId(2438)) - Failed to find datanode DatanodeRegistration(127.0.0.1:40540, datanodeUuid=9262f02d-1544-4d2a-b652-a51a74f462c3, infoPort=42732, infoSecurePort=0, ipcPort=40608, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031)
2020-12-03 07:24:36,675 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:40480 with active state
2020-12-03 07:24:36,676 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3) service to localhost/127.0.0.1:40480 beginning handshake with NN
2020-12-03 07:24:36,677 [IPC Server handler 0 on default port 40480] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40540, datanodeUuid=9262f02d-1544-4d2a-b652-a51a74f462c3, infoPort=42732, infoSecurePort=0, ipcPort=40608, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031) storage 9262f02d-1544-4d2a-b652-a51a74f462c3
2020-12-03 07:24:36,677 [IPC Server handler 0 on default port 40480] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40540
2020-12-03 07:24:36,677 [IPC Server handler 0 on default port 40480] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9262f02d-1544-4d2a-b652-a51a74f462c3 (127.0.0.1:40540).
2020-12-03 07:24:36,678 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3) service to localhost/127.0.0.1:40480 successfully registered with NN
2020-12-03 07:24:36,680 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c for DN 127.0.0.1:40540
2020-12-03 07:24:36,680 [IPC Server handler 1 on default port 40480] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c4809f2c-b656-44a7-9fe9-d388d4198e13 for DN 127.0.0.1:40540
2020-12-03 07:24:36,681 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x855b74740e657876: Processing first storage report for DS-c4809f2c-b656-44a7-9fe9-d388d4198e13 from datanode 9262f02d-1544-4d2a-b652-a51a74f462c3
2020-12-03 07:24:36,682 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x855b74740e657876: from storage DS-c4809f2c-b656-44a7-9fe9-d388d4198e13 node DatanodeRegistration(127.0.0.1:40540, datanodeUuid=9262f02d-1544-4d2a-b652-a51a74f462c3, infoPort=42732, infoSecurePort=0, ipcPort=40608, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,682 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x855b74740e657876: Processing first storage report for DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c from datanode 9262f02d-1544-4d2a-b652-a51a74f462c3
2020-12-03 07:24:36,682 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x855b74740e657876: from storage DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c node DatanodeRegistration(127.0.0.1:40540, datanodeUuid=9262f02d-1544-4d2a-b652-a51a74f462c3, infoPort=42732, infoSecurePort=0, ipcPort=40608, storageInfo=lv=-57;cid=testClusterID;nsid=1691034356;c=1606980264031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,682 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x855b74740e657876,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:36,683 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:36,694 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,695 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:37,198 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/ecfile-1: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:37,227 [IPC Server handler 2 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:37,239 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-1, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,240 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/ecfile-1
2020-12-03 07:24:37,247 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-1, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,262 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:37,267 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:37,275 [IPC Server handler 4 on default port 40480] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=5}
2020-12-03 07:24:37,277 [IPC Server handler 4 on default port 40480] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 4 on default port 40480, call Call#147 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:48500
java.io.IOException: File /TestDFSStripedOutputStreamWithFailureBase/ecfile-1 could only be written to 5 of the 6 required nodes for RS-6-3-64k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:24:37,283 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #0: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:155)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:174)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,284 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/ecfile-3: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:37,286 [IPC Server handler 3 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:37,287 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-3, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,287 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/ecfile-3
2020-12-03 07:24:37,288 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-3, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,291 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:37,294 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:37,295 [IPC Server handler 6 on default port 40480] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=5}
2020-12-03 07:24:37,296 [IPC Server handler 6 on default port 40480] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 6 on default port 40480, call Call#149 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:48500
java.io.IOException: File /TestDFSStripedOutputStreamWithFailureBase/ecfile-3 could only be written to 5 of the 6 required nodes for RS-6-3-64k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:24:37,299 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #0: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:155)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,299 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #1: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:155)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,300 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #2: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:155)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,301 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/ecfile-4: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:37,303 [IPC Server handler 8 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:37,304 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-4, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,304 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/ecfile-4
2020-12-03 07:24:37,305 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-4, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,306 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:37,308 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:37,310 [IPC Server handler 9 on default port 40480] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=5}
2020-12-03 07:24:37,310 [IPC Server handler 9 on default port 40480] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 9 on default port 40480, call Call#151 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:48500
java.io.IOException: File /TestDFSStripedOutputStreamWithFailureBase/ecfile-4 could only be written to 5 of the 6 required nodes for RS-6-3-64k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:24:37,315 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #0: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:176)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,315 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #1: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:176)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,316 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #2: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:176)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,316 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #3: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:176)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,317 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/ecfile-6: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:37,319 [IPC Server handler 7 on default port 40480] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-6	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:37,320 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-6, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,320 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/ecfile-6
2020-12-03 07:24:37,321 [Listener at localhost/40480] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/ecfile-6, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,324 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:37,327 [Listener at localhost/40480] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:37,328 [IPC Server handler 0 on default port 40480] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=5}
2020-12-03 07:24:37,330 [IPC Server handler 0 on default port 40480] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 0 on default port 40480, call Call#153 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:48500
java.io.IOException: File /TestDFSStripedOutputStreamWithFailureBase/ecfile-6 could only be written to 5 of the 6 required nodes for RS-6-3-64k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:24:37,333 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #0: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,333 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #1: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,334 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #2: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,334 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #3: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,335 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #4: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,335 [Listener at localhost/40480] TRACE hdfs.DataStreamer (DataStreamer.java:check(298)) - Got Exception while checking, #5: failed, block==null
java.lang.Throwable: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer.check(DataStreamer.java:298)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1160)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:401)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:150)
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: injected failure
	at org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testCloseWithExceptionsInStreamer(TestDFSStripedOutputStreamWithFailure.java:145)
	... 27 more
2020-12-03 07:24:37,336 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:37,336 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:24:37,336 [Listener at localhost/40480] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,336 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54e81b21] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,337 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-17a76543-dba4-4ae5-84a9-0771cb770f9c) exiting.
2020-12-03 07:24:37,337 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-9284d452-ec75-4d32-a5db-cf325205e975) exiting.
2020-12-03 07:24:37,355 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@251ebf23{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,355 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@29b732a2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,356 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@632aa1a3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,356 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30457e14{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,360 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41345
2020-12-03 07:24:37,361 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,361 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,362 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,362 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1) service to localhost/127.0.0.1:40480
2020-12-03 07:24:37,363 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 3b4af1e9-74d5-4cdf-a020-46743c53cff1)
2020-12-03 07:24:37,363 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:37,363 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,363 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,366 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,366 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,366 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,367 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,368 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,368 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:24:37,368 [Listener at localhost/40480] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,368 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3add81c4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,369 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4e86e337-980c-423c-ad80-f723a5dbe6f4) exiting.
2020-12-03 07:24:37,369 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-641a414d-d58a-43a1-898d-6f0dd5d5bb30) exiting.
2020-12-03 07:24:37,386 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5215cd9a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,387 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@36b6964d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,387 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a772895{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,387 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59221b97{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,388 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44138
2020-12-03 07:24:37,390 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,390 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,391 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,391 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624) service to localhost/127.0.0.1:40480
2020-12-03 07:24:37,392 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ff4f43b1-8422-4ae6-ad05-7845f3383624)
2020-12-03 07:24:37,392 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:37,392 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,392 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,395 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,396 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,396 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,396 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,398 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,398 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:24:37,398 [Listener at localhost/40480] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,398 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77b325b3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-6ccef453-d6ce-4e51-bca2-7301b8846a01) exiting.
2020-12-03 07:24:37,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfd1272a-bd39-472c-8e60-6406a8aa2be5) exiting.
2020-12-03 07:24:37,419 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@65ef722a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,420 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5fd9b663{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,421 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d4d48a6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,421 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51abf713{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,422 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42387
2020-12-03 07:24:37,424 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,424 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,425 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,425 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461) service to localhost/127.0.0.1:40480
2020-12-03 07:24:37,425 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 652d02fb-83eb-4483-ac0b-9eff8a764461)
2020-12-03 07:24:37,425 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:37,426 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,426 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,430 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,430 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,431 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,431 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,433 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,433 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:24:37,433 [Listener at localhost/40480] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,433 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3a7704c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c4809f2c-b656-44a7-9fe9-d388d4198e13) exiting.
2020-12-03 07:24:37,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-75cf6593-5f46-4df0-aa37-6fabed9cf59c) exiting.
2020-12-03 07:24:37,450 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c1e3314{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,451 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b770e40{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,451 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15deb1dc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,452 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3301500b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,453 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40608
2020-12-03 07:24:37,455 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,456 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,456 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,457 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3) service to localhost/127.0.0.1:40480
2020-12-03 07:24:37,457 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid 9262f02d-1544-4d2a-b652-a51a74f462c3)
2020-12-03 07:24:37,457 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:37,457 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,457 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,464 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,464 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,465 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,465 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,467 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,468 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:37,468 [Listener at localhost/40480] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,468 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3a7b503d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,469 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5f57f894-8c31-4898-a91b-0ed3b199f2f6) exiting.
2020-12-03 07:24:37,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c5e5ef5e-6c4f-48dd-9324-7465655e12cc) exiting.
2020-12-03 07:24:37,485 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e392345{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,486 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12f3afb5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,486 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@160c3ec1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,487 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@475b7792{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,488 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33852
2020-12-03 07:24:37,491 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,493 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,493 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce) service to localhost/127.0.0.1:40480
2020-12-03 07:24:37,493 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-497026648-172.17.0.6-1606980264031 (Datanode Uuid ef278207-33f0-460f-ad85-df1b9dfc23ce)
2020-12-03 07:24:37,493 [BP-497026648-172.17.0.6-1606980264031 heartbeating to localhost/127.0.0.1:40480] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-497026648-172.17.0.6-1606980264031
2020-12-03 07:24:37,494 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,494 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-497026648-172.17.0.6-1606980264031] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,510 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,510 [Listener at localhost/40480] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,511 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,512 [Listener at localhost/40480] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,515 [Listener at localhost/40480] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,515 [Listener at localhost/40480] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:37,515 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:37,515 [Listener at localhost/40480] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 12, 16
2020-12-03 07:24:37,515 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7e7f0f0a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:37,515 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7ec58feb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:37,516 [Listener at localhost/40480] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 6 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 11 Number of syncs: 7 SyncTimes(ms): 4 2 
2020-12-03 07:24:37,516 [Listener at localhost/40480] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000012 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000012-0000000000000000017
2020-12-03 07:24:37,517 [Listener at localhost/40480] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000012 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000012-0000000000000000017
2020-12-03 07:24:37,517 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:37,517 [CacheReplicationMonitor(674703128)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:37,519 [Listener at localhost/40480] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40480
2020-12-03 07:24:37,523 [IPC Server listener on 40480] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 40480
2020-12-03 07:24:37,527 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,528 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:37,528 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:37,537 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:37,537 [Listener at localhost/40480] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:37,539 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29f0c4f2{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:37,540 [Listener at localhost/40480] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f63f4f9{HTTP/1.1,[http/1.1]}{localhost:39137}
2020-12-03 07:24:37,540 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@476ec9d0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,541 [Listener at localhost/40480] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70abf9b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,542 [Listener at localhost/40480] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:24:37,554 [Listener at localhost/40480] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:24:37,555 [Listener at localhost/40480] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
