2020-12-03 07:20:44,289 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=12
Formatting using clusterid: testClusterID
2020-12-03 07:20:45,132 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:45,148 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:45,150 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:45,150 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:45,159 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:45,159 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:45,160 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:45,161 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:45,161 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:45,221 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:45,227 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:45,227 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:45,228 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:45,234 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:45,235 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:45
2020-12-03 07:20:45,238 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:45,238 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:45,240 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:45,241 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:45,261 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:45,262 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:45,270 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:45,271 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:45,271 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:45,271 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:45,272 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:45,272 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:45,273 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:45,273 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:45,273 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:45,273 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:45,273 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:45,308 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:45,309 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:45,309 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:45,309 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:45,330 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:45,331 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:45,331 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:45,332 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:45,338 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:45,338 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:45,339 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:45,339 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:45,346 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:45,349 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:45,355 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:45,355 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:45,355 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:45,356 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:45,367 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:45,367 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:45,367 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:45,372 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:45,373 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:45,375 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:45,375 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:45,376 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:45,376 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:45,419 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:45,692 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:45,905 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:45,938 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:45,938 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:46,080 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:46,080 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:46,145 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:46,150 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:46,225 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:20:46,567 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:20:46,567 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:46,598 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:46,640 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@41f69e84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:46,655 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:46,673 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3450ms
2020-12-03 07:20:46,782 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:46,786 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:46,795 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:46,798 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:46,798 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:46,798 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:46,827 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:46,827 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:46,840 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46803
2020-12-03 07:20:46,842 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:46,885 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@571c5681{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:46,886 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d278d2b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:47,182 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34158c08{/,file:///tmp/jetty-localhost-46803-hdfs-_-any-6813244151306000649.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:47,189 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@b7c4869{HTTP/1.1,[http/1.1]}{localhost:46803}
2020-12-03 07:20:47,190 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3967ms
2020-12-03 07:20:47,199 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:47,200 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:47,200 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:47,200 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:47,201 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:47,201 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:47,201 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:47,201 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:47,202 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:47,202 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:47,203 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:47,203 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:47,203 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:47,204 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:47
2020-12-03 07:20:47,204 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:47,204 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:47,205 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:47,205 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:47,208 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:47,209 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:47,209 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:47,209 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:47,210 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:47,210 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:47,210 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:47,210 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:47,211 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:47,211 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:47,211 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:47,211 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:47,211 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:47,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:47,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:47,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:47,213 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:47,215 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:47,215 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:47,215 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:47,216 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:47,216 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:47,216 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:47,216 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:47,217 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:47,217 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:47,217 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:47,219 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:47,219 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:47,219 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:47,219 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:47,219 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:47,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:47,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:47,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:47,220 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:47,347 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:47,480 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:47,484 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:47,484 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:47,485 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:47,485 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:47,519 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:47,527 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:47,527 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:47,533 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:47,534 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:47,753 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:47,753 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 531 msecs
2020-12-03 07:20:47,952 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:47,993 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:48,015 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:48,314 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:45212 to access this namenode/service.
2020-12-03 07:20:48,317 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:48,333 [Listener at 0.0.0.0/45212] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:48,345 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:48,345 [Listener at 0.0.0.0/45212] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:48,346 [Listener at 0.0.0.0/45212] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:48,346 [Listener at 0.0.0.0/45212] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:48,349 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:48,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:48,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:48,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:48,350 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:48,350 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:48,376 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:48,376 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:48,379 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45212
2020-12-03 07:20:48,382 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:48,382 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:48,390 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
Formatting using clusterid: testClusterID
2020-12-03 07:20:48,399 [Listener at 0.0.0.0/45212] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:48,400 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:48,400 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:48,400 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:48,400 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:48,400 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:48,401 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:48,401 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:48,402 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:48,403 [Listener at 0.0.0.0/45212] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:48,403 [Listener at 0.0.0.0/45212] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:48,403 [Listener at 0.0.0.0/45212] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:48,404 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:48,405 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:48
2020-12-03 07:20:48,405 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:48,405 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,406 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:48,407 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:48,406 [CacheReplicationMonitor(1675456618)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:48,421 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:48,422 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:48,423 [Listener at 0.0.0.0/45212] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:48,423 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:48,424 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:48,424 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:48,424 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:48,425 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:48,425 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:48,425 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:48,426 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:48,426 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:48,426 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:48,427 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:48,427 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,428 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:48,428 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:48,436 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:48,436 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:48,436 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:48,437 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:48,437 [Listener at 0.0.0.0/45212] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:48,437 [Listener at 0.0.0.0/45212] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:48,438 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:48,438 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,438 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:48,439 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:48,441 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:48,441 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:48,442 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:48,442 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:48,442 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:48,442 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:48,442 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:48,443 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:48,443 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:48,446 [Listener at 0.0.0.0/45212] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:48,601 [Listener at 0.0.0.0/45212] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 has been successfully formatted.
2020-12-03 07:20:48,729 [Listener at 0.0.0.0/45212] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 has been successfully formatted.
2020-12-03 07:20:48,744 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:48,744 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:48,752 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:48,752 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:48,799 [Listener at 0.0.0.0/45212] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:48,803 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:48,804 [Listener at 0.0.0.0/45212] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:48,805 [Listener at 0.0.0.0/45212] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:49,005 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@681aad3b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:49,006 [Listener at 0.0.0.0/45212] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:49,013 [Listener at 0.0.0.0/45212] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:49,015 [Listener at 0.0.0.0/45212] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:49,019 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:49,021 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:49,021 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:49,021 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:49,025 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:49,025 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:49,026 [Listener at 0.0.0.0/45212] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37447
2020-12-03 07:20:49,026 [Listener at 0.0.0.0/45212] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:49,031 [Listener at 0.0.0.0/45212] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:49,032 [Listener at 0.0.0.0/45212] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56b78e55{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:49,215 [Listener at 0.0.0.0/45212] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@13006998{/,file:///tmp/jetty-localhost-37447-hdfs-_-any-7566002255428485826.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:49,218 [Listener at 0.0.0.0/45212] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37fbe4a8{HTTP/1.1,[http/1.1]}{localhost:37447}
2020-12-03 07:20:49,220 [Listener at 0.0.0.0/45212] INFO  server.Server (Server.java:doStart(419)) - Started @5997ms
2020-12-03 07:20:49,226 [Listener at 0.0.0.0/45212] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:49,227 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:49,227 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:49,228 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:49,228 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:49,228 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:49,229 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:49,229 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:49,229 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:49,230 [Listener at 0.0.0.0/45212] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,231 [Listener at 0.0.0.0/45212] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:49,231 [Listener at 0.0.0.0/45212] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:49,232 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:49,232 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:49
2020-12-03 07:20:49,232 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:49,233 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,233 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:49,233 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:49,245 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:49,245 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:49,246 [Listener at 0.0.0.0/45212] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:49,246 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:49,246 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:49,246 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:49,246 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:49,247 [Listener at 0.0.0.0/45212] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:49,248 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:49,249 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,249 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:49,249 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:49,255 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:49,256 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:49,256 [Listener at 0.0.0.0/45212] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:49,256 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:49,257 [Listener at 0.0.0.0/45212] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:49,257 [Listener at 0.0.0.0/45212] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:49,257 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:49,257 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,258 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:49,258 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:49,261 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:49,261 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:49,261 [Listener at 0.0.0.0/45212] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:49,261 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:49,261 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:49,262 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:49,262 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:49,262 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:49,262 [Listener at 0.0.0.0/45212] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:49,339 [Listener at 0.0.0.0/45212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:49,399 [Listener at 0.0.0.0/45212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:49,402 [Listener at 0.0.0.0/45212] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current
2020-12-03 07:20:49,403 [Listener at 0.0.0.0/45212] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current
2020-12-03 07:20:49,404 [Listener at 0.0.0.0/45212] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:49,404 [Listener at 0.0.0.0/45212] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:49,406 [Listener at 0.0.0.0/45212] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:49,408 [Listener at 0.0.0.0/45212] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:49,408 [Listener at 0.0.0.0/45212] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000
2020-12-03 07:20:49,409 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:49,409 [Listener at 0.0.0.0/45212] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:49,562 [Listener at 0.0.0.0/45212] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:49,563 [Listener at 0.0.0.0/45212] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 297 msecs
2020-12-03 07:20:49,564 [Listener at 0.0.0.0/45212] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:49,565 [Listener at 0.0.0.0/45212] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:49,566 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:49,572 [Listener at 0.0.0.0/35772] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35772 to access this namenode/service.
2020-12-03 07:20:49,572 [Listener at 0.0.0.0/35772] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:49,653 [Listener at 0.0.0.0/35772] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:49,655 [Listener at 0.0.0.0/35772] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:49,655 [Listener at 0.0.0.0/35772] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:49,656 [Listener at 0.0.0.0/35772] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:49,656 [Listener at 0.0.0.0/35772] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:49,660 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:49,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:49,669 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:49,673 [Listener at 0.0.0.0/35772] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35772
2020-12-03 07:20:49,674 [Listener at 0.0.0.0/35772] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:49,674 [Listener at 0.0.0.0/35772] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:49,676 [Listener at 0.0.0.0/35772] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:49,678 [CacheReplicationMonitor(244917827)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:49,687 [Listener at 0.0.0.0/35772] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:49,759 [Listener at 0.0.0.0/35772] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:49,774 [Listener at 0.0.0.0/35772] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:49,794 [Listener at 0.0.0.0/35772] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:49,800 [Listener at 0.0.0.0/35772] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,804 [Listener at 0.0.0.0/35772] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:49,808 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:49,809 [Listener at 0.0.0.0/35772] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:49,814 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:49,821 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40573
2020-12-03 07:20:49,824 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:49,824 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:49,862 [Listener at 0.0.0.0/35772] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:49,864 [Listener at 0.0.0.0/35772] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:49,867 [Listener at 0.0.0.0/35772] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:49,868 [Listener at 0.0.0.0/35772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:49,868 [Listener at 0.0.0.0/35772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:49,869 [Listener at 0.0.0.0/35772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:49,875 [Listener at 0.0.0.0/35772] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39988
2020-12-03 07:20:49,875 [Listener at 0.0.0.0/35772] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:49,877 [Listener at 0.0.0.0/35772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fc08eec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:49,878 [Listener at 0.0.0.0/35772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b02e036{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:50,078 [Listener at 0.0.0.0/35772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e27ba81{/,file:///tmp/jetty-localhost-39988-datanode-_-any-7152695697242927080.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,079 [Listener at 0.0.0.0/35772] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{localhost:39988}
2020-12-03 07:20:50,079 [Listener at 0.0.0.0/35772] INFO  server.Server (Server.java:doStart(419)) - Started @6856ms
2020-12-03 07:20:50,641 [Listener at 0.0.0.0/35772] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37707
2020-12-03 07:20:50,641 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61942c1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,642 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,643 [Listener at 0.0.0.0/35772] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,659 [Listener at 0.0.0.0/35772] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,660 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,667 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39348
2020-12-03 07:20:50,684 [Listener at localhost/39348] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:50,686 [Listener at localhost/39348] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:50,698 [Thread-100] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:50,698 [Thread-101] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:50,704 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,705 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,709 [Listener at localhost/39348] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:50,711 [Listener at localhost/39348] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:50,711 [Listener at localhost/39348] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:50,714 [Listener at localhost/39348] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,714 [Listener at localhost/39348] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,714 [Listener at localhost/39348] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,715 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,715 [Listener at localhost/39348] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,715 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,716 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35453
2020-12-03 07:20:50,717 [Listener at localhost/39348] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,717 [Listener at localhost/39348] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,720 [Listener at localhost/39348] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,722 [Listener at localhost/39348] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,724 [Listener at localhost/39348] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,725 [Listener at localhost/39348] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,725 [Listener at localhost/39348] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,725 [Listener at localhost/39348] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,726 [Listener at localhost/39348] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40699
2020-12-03 07:20:50,726 [Listener at localhost/39348] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,729 [Listener at localhost/39348] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@781a9412{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:50,729 [Listener at localhost/39348] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13e698c7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:50,907 [Listener at localhost/39348] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@577f9109{/,file:///tmp/jetty-localhost-40699-datanode-_-any-6802783183244090087.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:50,909 [Listener at localhost/39348] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4303b7f0{HTTP/1.1,[http/1.1]}{localhost:40699}
2020-12-03 07:20:50,909 [Listener at localhost/39348] INFO  server.Server (Server.java:doStart(419)) - Started @7686ms
2020-12-03 07:20:50,956 [Thread-100] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:50,956 [Thread-101] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:50,958 [Thread-101] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:50,965 [Listener at localhost/39348] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34063
2020-12-03 07:20:50,966 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:50,966 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@779de014] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:50,966 [Listener at localhost/39348] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:50,967 [Listener at localhost/39348] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:50,968 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:50,971 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43785
2020-12-03 07:20:50,976 [Listener at localhost/43785] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:50,977 [Listener at localhost/43785] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:50,977 [Thread-125] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:50,978 [Thread-126] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:50,979 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:50,979 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:50,983 [Thread-125] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:50,983 [Thread-126] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:50,983 [Thread-125] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:50,983 [Listener at localhost/43785] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:50,985 [Listener at localhost/43785] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:50,986 [Listener at localhost/43785] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:50,987 [Listener at localhost/43785] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:50,988 [Listener at localhost/43785] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,988 [Listener at localhost/43785] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:50,988 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:50,988 [Listener at localhost/43785] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:50,989 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:50,989 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41756
2020-12-03 07:20:50,989 [Listener at localhost/43785] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:50,989 [Listener at localhost/43785] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:50,992 [Listener at localhost/43785] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:50,993 [Listener at localhost/43785] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:50,995 [Listener at localhost/43785] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:50,996 [Listener at localhost/43785] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:50,996 [Listener at localhost/43785] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:50,996 [Listener at localhost/43785] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:50,997 [Listener at localhost/43785] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39036
2020-12-03 07:20:50,997 [Listener at localhost/43785] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:50,999 [Listener at localhost/43785] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3068b369{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:51,000 [Listener at localhost/43785] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5491f68b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:51,508 [Listener at localhost/43785] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@648ee871{/,file:///tmp/jetty-localhost-39036-datanode-_-any-8575778623459738155.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,509 [Listener at localhost/43785] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@375b5b7f{HTTP/1.1,[http/1.1]}{localhost:39036}
2020-12-03 07:20:51,510 [Listener at localhost/43785] INFO  server.Server (Server.java:doStart(419)) - Started @8287ms
2020-12-03 07:20:51,533 [Listener at localhost/43785] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41633
2020-12-03 07:20:51,534 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28cb9120] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,534 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,534 [Listener at localhost/43785] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,535 [Listener at localhost/43785] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,535 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,539 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46294
2020-12-03 07:20:51,542 [Listener at localhost/46294] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:51,543 [Listener at localhost/46294] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:51,544 [Thread-148] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:51,544 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:51,545 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,545 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,548 [Thread-148] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:51,548 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:51,548 [Thread-148] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,655 [Listener at localhost/46294] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:51,656 [Listener at localhost/46294] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:51,658 [Listener at localhost/46294] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:51,659 [Listener at localhost/46294] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,659 [Listener at localhost/46294] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,660 [Listener at localhost/46294] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,660 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,660 [Listener at localhost/46294] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,661 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,661 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35725
2020-12-03 07:20:51,662 [Listener at localhost/46294] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,662 [Listener at localhost/46294] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,665 [Listener at localhost/46294] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,665 [Listener at localhost/46294] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,667 [Listener at localhost/46294] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,668 [Listener at localhost/46294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,668 [Listener at localhost/46294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,668 [Listener at localhost/46294] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,669 [Listener at localhost/46294] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34925
2020-12-03 07:20:51,669 [Listener at localhost/46294] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,671 [Listener at localhost/46294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18fdb6cf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:51,672 [Listener at localhost/46294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60baef24{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:51,825 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:51,825 [Thread-125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:51,826 [Thread-125] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:51,826 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:51,831 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:20:51,832 [Thread-125] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:20:51,839 [Listener at localhost/46294] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2d7e1102{/,file:///tmp/jetty-localhost-34925-datanode-_-any-4054718734333022994.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:51,840 [Listener at localhost/46294] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65327f5{HTTP/1.1,[http/1.1]}{localhost:34925}
2020-12-03 07:20:51,840 [Listener at localhost/46294] INFO  server.Server (Server.java:doStart(419)) - Started @8617ms
2020-12-03 07:20:51,886 [Listener at localhost/46294] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34703
2020-12-03 07:20:51,887 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@301d8120] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:51,887 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:51,887 [Listener at localhost/46294] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:51,888 [Listener at localhost/46294] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:51,888 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:51,892 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36807
2020-12-03 07:20:51,896 [Listener at localhost/36807] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:51,896 [Listener at localhost/36807] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:51,897 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:51,898 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:51,899 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:51,900 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:51,902 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:51,902 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:51,902 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:51,903 [Listener at localhost/36807] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:51,904 [Listener at localhost/36807] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:51,905 [Listener at localhost/36807] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:51,906 [Listener at localhost/36807] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:51,906 [Listener at localhost/36807] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,906 [Listener at localhost/36807] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:51,907 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:51,907 [Listener at localhost/36807] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:51,907 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:51,908 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42577
2020-12-03 07:20:51,908 [Listener at localhost/36807] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:51,908 [Listener at localhost/36807] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:51,910 [Thread-148] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:51,910 [Thread-148] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:51,911 [Listener at localhost/36807] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:51,911 [Listener at localhost/36807] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:51,912 [Thread-148] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:20:51,914 [Listener at localhost/36807] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:51,914 [Listener at localhost/36807] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:51,914 [Listener at localhost/36807] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:51,915 [Listener at localhost/36807] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:51,915 [Listener at localhost/36807] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37669
2020-12-03 07:20:51,915 [Listener at localhost/36807] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:51,917 [Listener at localhost/36807] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29182679{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:51,918 [Listener at localhost/36807] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cbb84b1{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,032 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,033 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,036 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-20d815f8-ddfd-4f58-be2f-8799459929e6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:20:52,088 [Listener at localhost/36807] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7808fb9{/,file:///tmp/jetty-localhost-37669-datanode-_-any-3515853800957481361.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,090 [Listener at localhost/36807] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@8747840{HTTP/1.1,[http/1.1]}{localhost:37669}
2020-12-03 07:20:52,090 [Listener at localhost/36807] INFO  server.Server (Server.java:doStart(419)) - Started @8867ms
2020-12-03 07:20:52,107 [Listener at localhost/36807] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45031
2020-12-03 07:20:52,107 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b580b88] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,108 [Listener at localhost/36807] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,108 [Listener at localhost/36807] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,109 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,116 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43609
2020-12-03 07:20:52,122 [Listener at localhost/43609] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,122 [Listener at localhost/43609] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,129 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:52,129 [Thread-195] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:52,147 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,147 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,158 [Listener at localhost/43609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:52,158 [Thread-195] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:52,158 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:52,159 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,160 [Listener at localhost/43609] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:52,160 [Listener at localhost/43609] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:52,164 [Listener at localhost/43609] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,165 [Listener at localhost/43609] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,165 [Listener at localhost/43609] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,166 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,166 [Listener at localhost/43609] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,167 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,167 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41298
2020-12-03 07:20:52,168 [Listener at localhost/43609] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,168 [Listener at localhost/43609] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,171 [Listener at localhost/43609] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,171 [Listener at localhost/43609] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,173 [Listener at localhost/43609] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,174 [Listener at localhost/43609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,174 [Listener at localhost/43609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,174 [Listener at localhost/43609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,175 [Listener at localhost/43609] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43109
2020-12-03 07:20:52,175 [Listener at localhost/43609] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,177 [Listener at localhost/43609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40021799{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,178 [Listener at localhost/43609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@332f25c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,307 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,308 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,310 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e231bf77-0898-42e1-8227-49ab023ed7c7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 
2020-12-03 07:20:52,353 [Listener at localhost/43609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5c20ffa8{/,file:///tmp/jetty-localhost-43109-datanode-_-any-6188138600953286117.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,355 [Listener at localhost/43609] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fedfe27{HTTP/1.1,[http/1.1]}{localhost:43109}
2020-12-03 07:20:52,355 [Listener at localhost/43609] INFO  server.Server (Server.java:doStart(419)) - Started @9132ms
2020-12-03 07:20:52,368 [Listener at localhost/43609] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44550
2020-12-03 07:20:52,369 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,369 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d4664d7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,369 [Listener at localhost/43609] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,370 [Listener at localhost/43609] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,371 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,374 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43700
2020-12-03 07:20:52,378 [Listener at localhost/43700] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,378 [Listener at localhost/43700] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,379 [Thread-217] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:52,380 [Thread-218] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:52,382 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,382 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,385 [Thread-217] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:52,385 [Thread-218] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:52,386 [Thread-217] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,387 [Listener at localhost/43700] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:52,388 [Listener at localhost/43700] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:52,389 [Listener at localhost/43700] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:52,390 [Listener at localhost/43700] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,391 [Listener at localhost/43700] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,391 [Listener at localhost/43700] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,391 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,392 [Listener at localhost/43700] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,392 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,392 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43287
2020-12-03 07:20:52,393 [Listener at localhost/43700] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,393 [Listener at localhost/43700] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,395 [Listener at localhost/43700] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,396 [Listener at localhost/43700] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,398 [Listener at localhost/43700] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,399 [Listener at localhost/43700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,399 [Listener at localhost/43700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,399 [Listener at localhost/43700] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,400 [Listener at localhost/43700] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46531
2020-12-03 07:20:52,400 [Listener at localhost/43700] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,404 [Listener at localhost/43700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27b22f74{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,405 [Listener at localhost/43700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e8a46b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,572 [Listener at localhost/43700] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@703feacd{/,file:///tmp/jetty-localhost-46531-datanode-_-any-7728701123357840065.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,574 [Listener at localhost/43700] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7051777c{HTTP/1.1,[http/1.1]}{localhost:46531}
2020-12-03 07:20:52,574 [Listener at localhost/43700] INFO  server.Server (Server.java:doStart(419)) - Started @9351ms
2020-12-03 07:20:52,579 [Thread-217] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,579 [Thread-125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,579 [Thread-217] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,579 [Thread-125] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,580 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,580 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:52,582 [Thread-217] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 
2020-12-03 07:20:52,582 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-678eaaea-fcb6-41f1-85cb-a5b487675668 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:20:52,582 [Thread-125] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:20:52,589 [Listener at localhost/43700] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46094
2020-12-03 07:20:52,590 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ecba515] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,590 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,590 [Listener at localhost/43700] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,590 [Listener at localhost/43700] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,591 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,595 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35604
2020-12-03 07:20:52,600 [Listener at localhost/35604] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,601 [Listener at localhost/35604] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,601 [Thread-240] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:52,601 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:52,605 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,606 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,609 [Thread-241] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:52,609 [Thread-240] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:52,610 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,611 [Listener at localhost/35604] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:52,612 [Listener at localhost/35604] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:52,612 [Listener at localhost/35604] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:52,613 [Listener at localhost/35604] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,614 [Listener at localhost/35604] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,614 [Listener at localhost/35604] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,614 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,615 [Listener at localhost/35604] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,615 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,616 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43970
2020-12-03 07:20:52,616 [Listener at localhost/35604] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,616 [Listener at localhost/35604] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,619 [Listener at localhost/35604] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,620 [Listener at localhost/35604] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,622 [Listener at localhost/35604] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,622 [Listener at localhost/35604] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,622 [Listener at localhost/35604] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,623 [Listener at localhost/35604] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,624 [Listener at localhost/35604] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34706
2020-12-03 07:20:52,624 [Listener at localhost/35604] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,625 [Listener at localhost/35604] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d195ee4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,626 [Listener at localhost/35604] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21ab988f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:52,733 [Thread-148] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,733 [Thread-148] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,737 [Thread-148] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-97616c51-42e9-4287-bc37-325f7763d342 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:20:52,804 [Listener at localhost/35604] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@997d532{/,file:///tmp/jetty-localhost-34706-datanode-_-any-4965393831735504065.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:52,805 [Listener at localhost/35604] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@273842a6{HTTP/1.1,[http/1.1]}{localhost:34706}
2020-12-03 07:20:52,805 [Listener at localhost/35604] INFO  server.Server (Server.java:doStart(419)) - Started @9582ms
2020-12-03 07:20:52,830 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,830 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:52,830 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:52,831 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:52,833 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:20:52,833 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 
2020-12-03 07:20:52,871 [Listener at localhost/35604] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33491
2020-12-03 07:20:52,872 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:52,872 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7a18e8d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:52,872 [Listener at localhost/35604] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:52,872 [Listener at localhost/35604] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:52,873 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:52,876 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43250
2020-12-03 07:20:52,881 [Listener at localhost/43250] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:52,882 [Listener at localhost/43250] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:52,882 [Thread-263] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:52,883 [Thread-264] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:52,885 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:52,885 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:52,889 [Thread-264] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:52,889 [Thread-263] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:52,889 [Thread-264] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:52,890 [Listener at localhost/43250] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:52,892 [Listener at localhost/43250] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:52,892 [Listener at localhost/43250] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:52,893 [Listener at localhost/43250] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:52,894 [Listener at localhost/43250] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,894 [Listener at localhost/43250] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:52,895 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:52,895 [Listener at localhost/43250] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:52,895 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:52,896 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33318
2020-12-03 07:20:52,896 [Listener at localhost/43250] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:52,896 [Listener at localhost/43250] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:52,899 [Listener at localhost/43250] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:52,900 [Listener at localhost/43250] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:52,902 [Listener at localhost/43250] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:52,903 [Listener at localhost/43250] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:52,903 [Listener at localhost/43250] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:52,904 [Listener at localhost/43250] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:52,905 [Listener at localhost/43250] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39041
2020-12-03 07:20:52,905 [Listener at localhost/43250] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:52,907 [Listener at localhost/43250] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b3871d6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:52,907 [Listener at localhost/43250] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2eb79cbe{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,084 [Listener at localhost/43250] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d235104{/,file:///tmp/jetty-localhost-39041-datanode-_-any-1078069075768480012.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,085 [Listener at localhost/43250] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e8e8621{HTTP/1.1,[http/1.1]}{localhost:39041}
2020-12-03 07:20:53,086 [Listener at localhost/43250] INFO  server.Server (Server.java:doStart(419)) - Started @9863ms
2020-12-03 07:20:53,087 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,087 [Thread-264] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,088 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:53,088 [Thread-264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:53,091 [Thread-264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-79915494-c363-4b00-9e24-01995a3641ee for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 
2020-12-03 07:20:53,092 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 
2020-12-03 07:20:53,100 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:53,100 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,100 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:53,101 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,101 [Listener at localhost/43250] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35149
2020-12-03 07:20:53,102 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,102 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3af356f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,102 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,102 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:53,102 [Listener at localhost/43250] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,102 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:53,102 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:53,103 [Listener at localhost/43250] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,104 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,108 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45181
2020-12-03 07:20:53,115 [Listener at localhost/45181] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,116 [Listener at localhost/45181] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,117 [Thread-286] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:53,117 [Thread-287] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:53,131 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,131 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,135 [Listener at localhost/45181] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:20:53,136 [Thread-286] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:53,137 [Thread-286] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,137 [Thread-287] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:53,137 [Listener at localhost/45181] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:20:53,137 [Listener at localhost/45181] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:20:53,139 [Listener at localhost/45181] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,140 [Listener at localhost/45181] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,140 [Listener at localhost/45181] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,140 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,140 [Listener at localhost/45181] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,140 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,141 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34933
2020-12-03 07:20:53,141 [Listener at localhost/45181] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,141 [Listener at localhost/45181] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,144 [Listener at localhost/45181] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,144 [Listener at localhost/45181] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,146 [Listener at localhost/45181] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,146 [Listener at localhost/45181] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,147 [Listener at localhost/45181] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,147 [Listener at localhost/45181] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,147 [Listener at localhost/45181] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43634
2020-12-03 07:20:53,148 [Listener at localhost/45181] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,149 [Listener at localhost/45181] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5aae8eb5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,150 [Listener at localhost/45181] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24a298a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,268 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,269 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,269 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,269 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:53,339 [Listener at localhost/45181] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1763992e{/,file:///tmp/jetty-localhost-43634-datanode-_-any-3601419653629758048.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,341 [Listener at localhost/45181] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5c92166b{HTTP/1.1,[http/1.1]}{localhost:43634}
2020-12-03 07:20:53,341 [Listener at localhost/45181] INFO  server.Server (Server.java:doStart(419)) - Started @10118ms
2020-12-03 07:20:53,356 [Listener at localhost/45181] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45744
2020-12-03 07:20:53,357 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,357 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4cd1c1dc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,357 [Listener at localhost/45181] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,358 [Listener at localhost/45181] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,359 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,385 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35913
2020-12-03 07:20:53,393 [Listener at localhost/35913] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,393 [Listener at localhost/35913] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,396 [Thread-309] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:53,397 [Thread-310] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:53,418 [Thread-217] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,429 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,429 [Thread-286] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,429 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,430 [Thread-217] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:53,430 [Thread-286] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:53,430 [Thread-217] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-22327937-c188-495d-9a1f-cd2c8c3a7246 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 
2020-12-03 07:20:53,430 [Thread-286] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ec0b88a2-0480-4f86-9300-058041cee39c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 
2020-12-03 07:20:53,431 [Thread-310] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:53,439 [Thread-310] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,440 [Listener at localhost/35913] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:53,440 [Thread-309] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:53,441 [Listener at localhost/35913] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:53,442 [Listener at localhost/35913] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:53,443 [Listener at localhost/35913] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,444 [Listener at localhost/35913] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,444 [Listener at localhost/35913] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,445 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,445 [Listener at localhost/35913] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,445 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,446 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35614
2020-12-03 07:20:53,446 [Listener at localhost/35913] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,446 [Listener at localhost/35913] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,447 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,448 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,448 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,448 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:53,449 [Listener at localhost/35913] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,450 [Listener at localhost/35913] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,452 [Listener at localhost/35913] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,453 [Listener at localhost/35913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,453 [Listener at localhost/35913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,453 [Listener at localhost/35913] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,454 [Listener at localhost/35913] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39126
2020-12-03 07:20:53,454 [Listener at localhost/35913] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,456 [Listener at localhost/35913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bcf67e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,457 [Listener at localhost/35913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53692008{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,622 [Listener at localhost/35913] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@677b8e13{/,file:///tmp/jetty-localhost-39126-datanode-_-any-947611950935858220.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,624 [Listener at localhost/35913] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a9486c0{HTTP/1.1,[http/1.1]}{localhost:39126}
2020-12-03 07:20:53,624 [Listener at localhost/35913] INFO  server.Server (Server.java:doStart(419)) - Started @10401ms
2020-12-03 07:20:53,643 [Listener at localhost/35913] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46006
2020-12-03 07:20:53,643 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,643 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40ee0a22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,643 [Listener at localhost/35913] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,644 [Listener at localhost/35913] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,645 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,648 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41770
2020-12-03 07:20:53,655 [Listener at localhost/41770] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,656 [Listener at localhost/41770] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,656 [Thread-332] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:53,658 [Thread-333] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:53,660 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,660 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,663 [Thread-332] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:53,664 [Thread-332] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,664 [Thread-333] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:53,665 [Listener at localhost/41770] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 11 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:20:53,666 [Listener at localhost/41770] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:20:53,666 [Listener at localhost/41770] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:20:53,667 [Listener at localhost/41770] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:53,668 [Listener at localhost/41770] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,668 [Listener at localhost/41770] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:53,669 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:53,669 [Listener at localhost/41770] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:53,669 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:53,670 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35355
2020-12-03 07:20:53,670 [Listener at localhost/41770] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:53,670 [Listener at localhost/41770] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:53,673 [Listener at localhost/41770] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:53,673 [Listener at localhost/41770] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:53,675 [Listener at localhost/41770] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:53,676 [Listener at localhost/41770] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:53,676 [Listener at localhost/41770] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:53,676 [Listener at localhost/41770] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:53,677 [Listener at localhost/41770] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39192
2020-12-03 07:20:53,677 [Listener at localhost/41770] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:53,679 [Listener at localhost/41770] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@773c0293{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:53,679 [Listener at localhost/41770] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b569985{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:53,781 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,781 [Thread-310] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,782 [Thread-310] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:53,781 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:53,785 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-899047bb-3862-419c-a750-7ef6d1be7fd6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 
2020-12-03 07:20:53,785 [Thread-310] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 
2020-12-03 07:20:53,800 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,800 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,800 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,800 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:53,800 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,800 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,801 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:53,801 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,800 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:53,801 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:53,801 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:53,801 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:53,857 [Listener at localhost/41770] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@353efdbf{/,file:///tmp/jetty-localhost-39192-datanode-_-any-8425970563131159633.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:53,858 [Listener at localhost/41770] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@55cff952{HTTP/1.1,[http/1.1]}{localhost:39192}
2020-12-03 07:20:53,859 [Listener at localhost/41770] INFO  server.Server (Server.java:doStart(419)) - Started @10636ms
2020-12-03 07:20:53,878 [Listener at localhost/41770] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35774
2020-12-03 07:20:53,879 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a55a6e8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:53,879 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:53,879 [Listener at localhost/41770] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:53,880 [Listener at localhost/41770] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:53,880 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:53,884 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38374
2020-12-03 07:20:53,891 [Listener at localhost/38374] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:53,892 [Listener at localhost/38374] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:53,892 [Thread-355] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212 starting to offer service
2020-12-03 07:20:53,894 [Thread-356] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772 starting to offer service
2020-12-03 07:20:53,896 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:53,896 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:53,899 [Thread-356] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35772
2020-12-03 07:20:53,901 [Thread-356] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:53,901 [Thread-355] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45212
2020-12-03 07:20:53,963 [Thread-332] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:53,963 [Thread-332] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:53,967 [Thread-332] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dabe19a4-c133-447f-ad17-75bf077581e1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 
2020-12-03 07:20:53,974 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,974 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:53,974 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:53,974 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,136 [Thread-264] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:54,136 [Thread-356] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:54,136 [Thread-264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:54,136 [Thread-356] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:54,140 [Thread-356] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 
2020-12-03 07:20:54,140 [Thread-264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bb6d252b-337c-47db-8776-c335078b2bd5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 
2020-12-03 07:20:54,146 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,146 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,146 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:54,146 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,147 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,147 [Thread-217] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,147 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:54,147 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,352 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,361 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,361 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,465 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,466 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,466 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,513 [Thread-286] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:54,513 [Thread-286] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:54,513 [Thread-101] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:54,513 [Thread-125] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:54,515 [Thread-126] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,515 [Thread-100] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,515 [Thread-126] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:20:54,515 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:20:54,516 [Thread-126] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:20:54,516 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:20:54,517 [Thread-286] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 
2020-12-03 07:20:54,525 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,525 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,526 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,525 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,526 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,526 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,526 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:54,526 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:54,526 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,526 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,526 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:54,526 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:54,526 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:54,527 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,527 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:54,527 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,569 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,570 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,570 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,672 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,673 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,673 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,725 [Thread-148] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:54,726 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:54,726 [Thread-149] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:20:54,726 [Thread-149] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:20:54,737 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,737 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,738 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:54,738 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:54,776 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,777 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,777 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,879 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,880 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,880 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:54,933 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:54,937 [Thread-310] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:54,937 [Thread-310] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:54,938 [Thread-310] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 
2020-12-03 07:20:54,950 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,950 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,950 [Thread-264] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:54,950 [Thread-217] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:54,950 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:54,950 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:54,951 [Thread-217] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:54,950 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:54,984 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:54,985 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:54,985 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,088 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,089 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,089 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,117 [Thread-332] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:55,118 [Thread-332] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 is not formatted for namespace 1128000539. Formatting...
2020-12-03 07:20:55,122 [Thread-332] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 
2020-12-03 07:20:55,192 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,193 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,193 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,295 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,296 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,296 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,318 [Thread-356] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/in_use.lock acquired by nodename 2353@47e84f296739
2020-12-03 07:20:55,318 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:55,319 [Thread-195] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:55,319 [Thread-356] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 is not formatted for namespace 2093699753. Formatting...
2020-12-03 07:20:55,319 [Thread-195] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 has already been used.
2020-12-03 07:20:55,320 [Thread-195] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 has already been used.
2020-12-03 07:20:55,322 [Thread-356] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 
2020-12-03 07:20:55,329 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,329 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,329 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:55,329 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:55,329 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,330 [Thread-286] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,330 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,330 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,330 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:55,330 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,330 [Thread-195] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,330 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:55,331 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,331 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,331 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,331 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,333 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,333 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,333 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,333 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,398 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,399 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,399 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,493 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,493 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,494 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,494 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,502 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,502 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,503 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,605 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,606 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,606 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,703 [Thread-217] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:55,706 [Thread-218] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:55,706 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:55,706 [Thread-218] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 has already been used.
2020-12-03 07:20:55,706 [Thread-218] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 has already been used.
2020-12-03 07:20:55,709 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,710 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,710 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,765 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,766 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,766 [Thread-218] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,766 [Thread-264] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,766 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,769 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,769 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,775 [Thread-264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,779 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,794 [Thread-310] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,794 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,794 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:55,813 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,814 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,814 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,901 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20d815f8-ddfd-4f58-be2f-8799459929e6
2020-12-03 07:20:55,903 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:55,904 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c
2020-12-03 07:20:55,904 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:55,910 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:55,923 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:55,924 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:55,926 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:55,926 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:55,927 [Thread-172] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:20:55,927 [Thread-172] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:20:55,926 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:55,944 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:55,947 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:55,947 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:55,958 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,958 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,956 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,960 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:55,960 [Thread-332] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:55,961 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:55,962 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:55,960 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:55,960 [Thread-372] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:55,962 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:55,962 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,010 [Thread-372] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 48ms
2020-12-03 07:20:56,010 [Thread-373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 48ms
2020-12-03 07:20:56,011 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 51ms
2020-12-03 07:20:56,012 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:56,012 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:56,013 [Thread-376] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:56,013 [Thread-377] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:56,014 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 2ms
2020-12-03 07:20:56,015 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:56,015 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 3ms
2020-12-03 07:20:56,017 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:56,017 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:56,018 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,018 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-20d815f8-ddfd-4f58-be2f-8799459929e6): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,034 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,035 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,035 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,039 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-20d815f8-ddfd-4f58-be2f-8799459929e6): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-12-03 07:20:56,039 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-12-03 07:20:56,096 [Thread-126] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:56,097 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:56,098 [Thread-240] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:56,099 [Thread-240] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 has already been used.
2020-12-03 07:20:56,099 [Thread-240] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 has already been used.
2020-12-03 07:20:56,103 [Thread-100] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:56,107 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,108 [Thread-356] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,108 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:56,108 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,109 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,109 [Thread-240] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,109 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:56,109 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:56,110 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,110 [Thread-195] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,110 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:56,110 [Thread-195] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,113 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,113 [Thread-286] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,113 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:56,113 [Thread-286] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:56,137 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,137 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,138 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,239 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,240 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,240 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,341 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,342 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,342 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,404 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:56,444 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,444 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,445 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,546 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,547 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,547 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,620 [Thread-264] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:56,621 [Thread-263] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:56,621 [Thread-263] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 has already been used.
2020-12-03 07:20:56,622 [Thread-263] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 has already been used.
2020-12-03 07:20:56,630 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,630 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,630 [Thread-263] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,631 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:56,631 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:56,631 [Thread-218] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,631 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,631 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:56,631 [Thread-218] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,631 [Thread-310] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,632 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:56,632 [Thread-310] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,648 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,649 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,649 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,750 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,751 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,751 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,853 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,853 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,853 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:56,870 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,870 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,871 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:56,871 [Thread-332] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:56,871 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:56,871 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:56,871 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:56,871 [Thread-332] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:56,955 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:56,955 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:56,956 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,057 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,058 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,058 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,101 [Thread-101] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,103 [Thread-287] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,104 [Thread-287] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 has already been used.
2020-12-03 07:20:57,104 [Thread-287] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 has already been used.
2020-12-03 07:20:57,102 [Thread-286] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:57,103 [Thread-195] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:57,105 [Thread-125] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,108 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd
2020-12-03 07:20:57,108 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:57,110 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86
2020-12-03 07:20:57,110 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:57,113 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-678eaaea-fcb6-41f1-85cb-a5b487675668
2020-12-03 07:20:57,114 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:57,115 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:57,116 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dbb1599d-f6de-4801-864b-1b89c793b3f2
2020-12-03 07:20:57,116 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:57,117 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:57,118 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:57,118 [Thread-100] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,118 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:57,118 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:57,119 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,119 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:57,119 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:57,119 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:57,120 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:57,121 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,121 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:57,121 [Thread-240] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,121 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:57,121 [Thread-240] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:57,120 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:57,121 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:57,120 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:57,122 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:57,122 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,123 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,123 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,123 [Thread-287] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,123 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,123 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:57,123 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:57,124 [Thread-356] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,124 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:57,124 [Thread-356] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:57,162 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,163 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,163 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,170 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 52ms
2020-12-03 07:20:57,170 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 48ms
2020-12-03 07:20:57,170 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 50ms
2020-12-03 07:20:57,170 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 51ms
2020-12-03 07:20:57,171 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 52ms
2020-12-03 07:20:57,171 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 53ms
2020-12-03 07:20:57,171 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:57,172 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:57,172 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:57,172 [Thread-393] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,172 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:57,172 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:57,172 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:57,172 [Thread-392] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,172 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,172 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:57,172 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:20:57,172 [Thread-390] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,173 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:20:57,172 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:57,172 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:57,173 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 2ms
2020-12-03 07:20:57,174 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:20:57,175 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 4ms
2020-12-03 07:20:57,175 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:57,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:57,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:57,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:57,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:57,178 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:57,178 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-678eaaea-fcb6-41f1-85cb-a5b487675668): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,179 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-678eaaea-fcb6-41f1-85cb-a5b487675668): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:57,179 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-dbb1599d-f6de-4801-864b-1b89c793b3f2): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,180 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-dbb1599d-f6de-4801-864b-1b89c793b3f2): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:57,207 [Thread-100] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:56 AM with interval of 21600000ms
2020-12-03 07:20:57,207 [Thread-126] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:28 AM with interval of 21600000ms
2020-12-03 07:20:57,215 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:57,215 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:57,232 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 60ms
2020-12-03 07:20:57,232 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 60ms
2020-12-03 07:20:57,234 [IPC Server handler 1 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,235 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 63ms
2020-12-03 07:20:57,235 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:57,235 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:57,236 [IPC Server handler 3 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,236 [Thread-409] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,236 [Thread-408] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,237 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:20:57,238 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 66ms
2020-12-03 07:20:57,238 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 2ms
2020-12-03 07:20:57,238 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 3ms
2020-12-03 07:20:57,238 [IPC Server handler 1 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40573
2020-12-03 07:20:57,238 [IPC Server handler 3 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35453
2020-12-03 07:20:57,238 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:57,238 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f (127.0.0.1:35453).
2020-12-03 07:20:57,238 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:57,239 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,238 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:57,238 [IPC Server handler 1 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4 (127.0.0.1:40573).
2020-12-03 07:20:57,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-dbb1599d-f6de-4801-864b-1b89c793b3f2): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86): no suitable block pools found to scan.  Waiting 1814399936 ms.
2020-12-03 07:20:57,240 [Thread-397] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 67ms
2020-12-03 07:20:57,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-dbb1599d-f6de-4801-864b-1b89c793b3f2): no suitable block pools found to scan.  Waiting 1814399936 ms.
2020-12-03 07:20:57,240 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 69ms
2020-12-03 07:20:57,241 [Thread-410] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:57,241 [Thread-411] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:57,241 [Thread-410] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,241 [Thread-411] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,241 [IPC Server handler 3 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,241 [Thread-410] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:20:57,241 [Thread-411] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:20:57,242 [IPC Server handler 3 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35453
2020-12-03 07:20:57,242 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:57,242 [IPC Server handler 3 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f (127.0.0.1:35453).
2020-12-03 07:20:57,242 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:57,242 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:57,242 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:57,242 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,242 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-678eaaea-fcb6-41f1-85cb-a5b487675668): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,243 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-678eaaea-fcb6-41f1-85cb-a5b487675668): no suitable block pools found to scan.  Waiting 1814399932 ms.
2020-12-03 07:20:57,243 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd): no suitable block pools found to scan.  Waiting 1814399932 ms.
2020-12-03 07:20:57,243 [IPC Server handler 4 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,244 [IPC Server handler 4 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40573
2020-12-03 07:20:57,245 [IPC Server handler 4 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4 (127.0.0.1:40573).
2020-12-03 07:20:57,245 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:57,245 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:57,246 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:57,246 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,246 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,246 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,246 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:57,246 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,264 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 for DN 127.0.0.1:35453
2020-12-03 07:20:57,264 [IPC Server handler 2 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 for DN 127.0.0.1:35453
2020-12-03 07:20:57,266 [IPC Server handler 2 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 for DN 127.0.0.1:35453
2020-12-03 07:20:57,266 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 for DN 127.0.0.1:35453
2020-12-03 07:20:57,267 [IPC Server handler 6 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd for DN 127.0.0.1:40573
2020-12-03 07:20:57,267 [IPC Server handler 4 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd for DN 127.0.0.1:40573
2020-12-03 07:20:57,268 [IPC Server handler 6 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-678eaaea-fcb6-41f1-85cb-a5b487675668 for DN 127.0.0.1:40573
2020-12-03 07:20:57,269 [IPC Server handler 4 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-678eaaea-fcb6-41f1-85cb-a5b487675668 for DN 127.0.0.1:40573
2020-12-03 07:20:57,269 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,275 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,275 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xde8e2c2f697e2579: Processing first storage report for DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 from datanode bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x377c86a109b7b25a: Processing first storage report for DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 from datanode bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xde8e2c2f697e2579: from storage DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 node DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x377c86a109b7b25a: from storage DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86 node DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8594ab2728a307a4: Processing first storage report for DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd from datanode fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x591e31c235eb3eda: Processing first storage report for DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd from datanode fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8594ab2728a307a4: from storage DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd node DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x591e31c235eb3eda: from storage DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd node DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xde8e2c2f697e2579: Processing first storage report for DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 from datanode bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x377c86a109b7b25a: Processing first storage report for DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 from datanode bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xde8e2c2f697e2579: from storage DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 node DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x377c86a109b7b25a: from storage DS-dbb1599d-f6de-4801-864b-1b89c793b3f2 node DatanodeRegistration(127.0.0.1:35453, datanodeUuid=bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f, infoPort=34063, infoSecurePort=0, ipcPort=43785, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8594ab2728a307a4: Processing first storage report for DS-678eaaea-fcb6-41f1-85cb-a5b487675668 from datanode fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x591e31c235eb3eda: Processing first storage report for DS-678eaaea-fcb6-41f1-85cb-a5b487675668 from datanode fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4
2020-12-03 07:20:57,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8594ab2728a307a4: from storage DS-678eaaea-fcb6-41f1-85cb-a5b487675668 node DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x591e31c235eb3eda: from storage DS-678eaaea-fcb6-41f1-85cb-a5b487675668 node DatanodeRegistration(127.0.0.1:40573, datanodeUuid=fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4, infoPort=37707, infoSecurePort=0, ipcPort=39348, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,327 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x591e31c235eb3eda,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,327 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x377c86a109b7b25a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,327 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8594ab2728a307a4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,327 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xde8e2c2f697e2579,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,327 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,327 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,327 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,328 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,352 [Thread-148] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,356 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9
2020-12-03 07:20:57,357 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:57,359 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-97616c51-42e9-4287-bc37-325f7763d342
2020-12-03 07:20:57,360 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:57,360 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:57,362 [Thread-148] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,362 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,362 [Thread-148] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,362 [Thread-148] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:57,362 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,363 [Thread-148] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:57,364 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,364 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:57,364 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,364 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:57,365 [Thread-415] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:57,377 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,378 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,378 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,406 [Thread-415] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 41ms
2020-12-03 07:20:57,408 [Thread-414] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 43ms
2020-12-03 07:20:57,408 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 44ms
2020-12-03 07:20:57,409 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:57,409 [Thread-419] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:57,409 [Thread-418] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,409 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:57,409 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:57,409 [Thread-420] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:57,409 [Thread-420] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:20:57,409 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:20:57,410 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 2ms
2020-12-03 07:20:57,411 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,411 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:57,411 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,411 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-97616c51-42e9-4287-bc37-325f7763d342): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,411 [Thread-148] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:08 PM with interval of 21600000ms
2020-12-03 07:20:57,412 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:57,412 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-97616c51-42e9-4287-bc37-325f7763d342): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:57,413 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:57,415 [IPC Server handler 6 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,415 [IPC Server handler 6 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41756
2020-12-03 07:20:57,415 [IPC Server handler 6 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f7ee202f-625f-4189-8aac-3eb4071b030c (127.0.0.1:41756).
2020-12-03 07:20:57,416 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:57,416 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,420 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 for DN 127.0.0.1:41756
2020-12-03 07:20:57,420 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-97616c51-42e9-4287-bc37-325f7763d342 for DN 127.0.0.1:41756
2020-12-03 07:20:57,450 [Thread-421] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 41ms
2020-12-03 07:20:57,451 [Thread-419] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 42ms
2020-12-03 07:20:57,451 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 43ms
2020-12-03 07:20:57,452 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:57,452 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:57,452 [Thread-427] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,452 [Thread-428] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,453 [Thread-427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:20:57,454 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:20:57,454 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:57,455 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:57,455 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:57,455 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:57,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa134d08929a11e30: Processing first storage report for DS-97616c51-42e9-4287-bc37-325f7763d342 from datanode f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,455 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-97616c51-42e9-4287-bc37-325f7763d342): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,455 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa134d08929a11e30: from storage DS-97616c51-42e9-4287-bc37-325f7763d342 node DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa134d08929a11e30: Processing first storage report for DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 from datanode f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa134d08929a11e30: from storage DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 node DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,456 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-97616c51-42e9-4287-bc37-325f7763d342): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:20:57,456 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:20:57,456 [IPC Server handler 9 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,457 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa134d08929a11e30,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 31 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,457 [IPC Server handler 9 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41756
2020-12-03 07:20:57,457 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,457 [IPC Server handler 9 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f7ee202f-625f-4189-8aac-3eb4071b030c (127.0.0.1:41756).
2020-12-03 07:20:57,458 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:57,458 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,461 [IPC Server handler 0 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 for DN 127.0.0.1:41756
2020-12-03 07:20:57,461 [IPC Server handler 0 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-97616c51-42e9-4287-bc37-325f7763d342 for DN 127.0.0.1:41756
2020-12-03 07:20:57,463 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8119071944f4147b: Processing first storage report for DS-97616c51-42e9-4287-bc37-325f7763d342 from datanode f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8119071944f4147b: from storage DS-97616c51-42e9-4287-bc37-325f7763d342 node DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8119071944f4147b: Processing first storage report for DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 from datanode f7ee202f-625f-4189-8aac-3eb4071b030c
2020-12-03 07:20:57,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8119071944f4147b: from storage DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9 node DatanodeRegistration(127.0.0.1:41756, datanodeUuid=f7ee202f-625f-4189-8aac-3eb4071b030c, infoPort=41633, infoSecurePort=0, ipcPort=46294, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,465 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8119071944f4147b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,465 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,479 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,480 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,480 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,575 [Thread-310] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:57,577 [Thread-309] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:57,578 [Thread-309] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 has already been used.
2020-12-03 07:20:57,578 [Thread-218] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:57,578 [Thread-309] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 has already been used.
2020-12-03 07:20:57,582 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,583 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,583 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,588 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,589 [Thread-263] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,589 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:57,589 [Thread-263] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:57,590 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,590 [Thread-309] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,590 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:57,590 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:57,685 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,686 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,686 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,788 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,789 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,789 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,832 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,832 [Thread-332] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:57,833 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:05 AM with interval of 21600000ms
2020-12-03 07:20:57,840 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,840 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:57,841 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:57,841 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:57,842 [IPC Server handler 7 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,842 [IPC Server handler 7 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35725
2020-12-03 07:20:57,842 [IPC Server handler 7 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c885456-8bc7-4774-be2e-ce1f58eb2e0d (127.0.0.1:35725).
2020-12-03 07:20:57,843 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:57,843 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,847 [IPC Server handler 5 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20d815f8-ddfd-4f58-be2f-8799459929e6 for DN 127.0.0.1:35725
2020-12-03 07:20:57,847 [IPC Server handler 5 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c for DN 127.0.0.1:35725
2020-12-03 07:20:57,891 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,892 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,892 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:57,894 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 53ms
2020-12-03 07:20:57,894 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 53ms
2020-12-03 07:20:57,894 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 54ms
2020-12-03 07:20:57,894 [Thread-436] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:57,895 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:57,895 [Thread-436] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,895 [Thread-437] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:57,895 [Thread-436] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:20:57,895 [Thread-437] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:20:57,895 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 1ms
2020-12-03 07:20:57,895 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4a59acf9b326f8c: Processing first storage report for DS-20d815f8-ddfd-4f58-be2f-8799459929e6 from datanode 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4a59acf9b326f8c: from storage DS-20d815f8-ddfd-4f58-be2f-8799459929e6 node DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:57,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4a59acf9b326f8c: Processing first storage report for DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c from datanode 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,897 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:57,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:57,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,897 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4a59acf9b326f8c: from storage DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c node DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-20d815f8-ddfd-4f58-be2f-8799459929e6): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,898 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c): no suitable block pools found to scan.  Waiting 1814398119 ms.
2020-12-03 07:20:57,898 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-20d815f8-ddfd-4f58-be2f-8799459929e6): no suitable block pools found to scan.  Waiting 1814398119 ms.
2020-12-03 07:20:57,898 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4a59acf9b326f8c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 46 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,898 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:57,898 [IPC Server handler 2 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,899 [IPC Server handler 2 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35725
2020-12-03 07:20:57,899 [IPC Server handler 2 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c885456-8bc7-4774-be2e-ce1f58eb2e0d (127.0.0.1:35725).
2020-12-03 07:20:57,899 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:57,900 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:57,902 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20d815f8-ddfd-4f58-be2f-8799459929e6 for DN 127.0.0.1:35725
2020-12-03 07:20:57,903 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c for DN 127.0.0.1:35725
2020-12-03 07:20:57,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x575d1bd45ea89552: Processing first storage report for DS-20d815f8-ddfd-4f58-be2f-8799459929e6 from datanode 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x575d1bd45ea89552: from storage DS-20d815f8-ddfd-4f58-be2f-8799459929e6 node DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x575d1bd45ea89552: Processing first storage report for DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c from datanode 8c885456-8bc7-4774-be2e-ce1f58eb2e0d
2020-12-03 07:20:57,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x575d1bd45ea89552: from storage DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c node DatanodeRegistration(127.0.0.1:35725, datanodeUuid=8c885456-8bc7-4774-be2e-ce1f58eb2e0d, infoPort=34703, infoSecurePort=0, ipcPort=36807, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:57,906 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x575d1bd45ea89552,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:57,906 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:57,994 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:57,995 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:57,995 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,066 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,069 [Thread-355] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:58,067 [Thread-356] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:58,069 [Thread-240] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:58,069 [Thread-355] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 has already been used.
2020-12-03 07:20:58,069 [Thread-355] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 has already been used.
2020-12-03 07:20:58,078 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e231bf77-0898-42e1-8227-49ab023ed7c7
2020-12-03 07:20:58,078 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:58,079 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,079 [Thread-355] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,079 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:58,080 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:58,080 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64
2020-12-03 07:20:58,081 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:58,082 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:58,083 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,083 [Thread-287] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,083 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:58,083 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:58,083 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,083 [Thread-195] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,084 [Thread-195] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,084 [Thread-195] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:58,084 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,085 [Thread-195] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:58,086 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:58,086 [Thread-195] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,086 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,087 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:20:58,087 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:20:58,097 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,099 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,099 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,126 [Thread-440] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 39ms
2020-12-03 07:20:58,128 [Thread-441] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 41ms
2020-12-03 07:20:58,128 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 42ms
2020-12-03 07:20:58,128 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:20:58,128 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:20:58,128 [Thread-444] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:58,128 [Thread-445] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:58,129 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:20:58,129 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:20:58,129 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:20:58,130 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 1ms
2020-12-03 07:20:58,130 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:20:58,131 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:58,131 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,132 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,132 [Thread-195] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:08 AM with interval of 21600000ms
2020-12-03 07:20:58,133 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:58,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:58,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-e231bf77-0898-42e1-8227-49ab023ed7c7): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,134 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-e231bf77-0898-42e1-8227-49ab023ed7c7): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:58,134 [IPC Server handler 6 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,135 [IPC Server handler 6 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42577
2020-12-03 07:20:58,135 [IPC Server handler 6 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 818c66a4-eec4-478c-9ce0-965c18404f8a (127.0.0.1:42577).
2020-12-03 07:20:58,135 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:58,136 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:58,140 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e231bf77-0898-42e1-8227-49ab023ed7c7 for DN 127.0.0.1:42577
2020-12-03 07:20:58,140 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 for DN 127.0.0.1:42577
2020-12-03 07:20:58,165 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 36ms
2020-12-03 07:20:58,170 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 39ms
2020-12-03 07:20:58,171 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 42ms
2020-12-03 07:20:58,171 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9...
2020-12-03 07:20:58,171 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10...
2020-12-03 07:20:58,172 [Thread-453] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,172 [Thread-454] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,176 [Thread-453] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9: 4ms
2020-12-03 07:20:58,176 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10: 4ms
2020-12-03 07:20:58,180 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 9ms
2020-12-03 07:20:58,180 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa075a701bfda9b84: Processing first storage report for DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 from datanode 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,180 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10
2020-12-03 07:20:58,180 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa075a701bfda9b84: from storage DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 node DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,180 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:58,180 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9
2020-12-03 07:20:58,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-e231bf77-0898-42e1-8227-49ab023ed7c7): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:20:58,181 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-e231bf77-0898-42e1-8227-49ab023ed7c7): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:20:58,182 [IPC Server handler 1 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,182 [IPC Server handler 1 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42577
2020-12-03 07:20:58,182 [IPC Server handler 1 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 818c66a4-eec4-478c-9ce0-965c18404f8a (127.0.0.1:42577).
2020-12-03 07:20:58,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa075a701bfda9b84: Processing first storage report for DS-e231bf77-0898-42e1-8227-49ab023ed7c7 from datanode 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,183 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa075a701bfda9b84: from storage DS-e231bf77-0898-42e1-8227-49ab023ed7c7 node DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,183 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:58,183 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:58,183 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa075a701bfda9b84,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 31 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:58,183 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,186 [IPC Server handler 9 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e231bf77-0898-42e1-8227-49ab023ed7c7 for DN 127.0.0.1:42577
2020-12-03 07:20:58,186 [IPC Server handler 9 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 for DN 127.0.0.1:42577
2020-12-03 07:20:58,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb59b73e84f754a70: Processing first storage report for DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 from datanode 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb59b73e84f754a70: from storage DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64 node DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb59b73e84f754a70: Processing first storage report for DS-e231bf77-0898-42e1-8227-49ab023ed7c7 from datanode 818c66a4-eec4-478c-9ce0-965c18404f8a
2020-12-03 07:20:58,189 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb59b73e84f754a70: from storage DS-e231bf77-0898-42e1-8227-49ab023ed7c7 node DatanodeRegistration(127.0.0.1:42577, datanodeUuid=818c66a4-eec4-478c-9ce0-965c18404f8a, infoPort=45031, infoSecurePort=0, ipcPort=43609, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,191 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb59b73e84f754a70,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:58,191 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,200 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,202 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,202 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,304 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,305 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,305 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,408 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,409 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,410 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,492 [Thread-217] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,492 [Thread-263] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:58,494 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1
2020-12-03 07:20:58,495 [Thread-217] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:58,499 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-22327937-c188-495d-9a1f-cd2c8c3a7246
2020-12-03 07:20:58,500 [Thread-217] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:58,500 [Thread-217] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:58,505 [Thread-217] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,505 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,505 [Thread-218] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,506 [Thread-309] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,506 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:58,506 [Thread-309] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:58,507 [Thread-217] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,507 [Thread-217] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,507 [Thread-218] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,507 [Thread-218] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,507 [Thread-217] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,507 [Thread-218] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,509 [Thread-218] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,509 [Thread-217] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,509 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:20:58,510 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:20:58,511 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,513 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,513 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,551 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 42ms
2020-12-03 07:20:58,551 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 41ms
2020-12-03 07:20:58,552 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 43ms
2020-12-03 07:20:58,552 [Thread-462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:20:58,552 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:20:58,552 [Thread-461] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:58,552 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:20:58,553 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:20:58,553 [Thread-464] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:58,553 [Thread-461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:58,554 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:58,554 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:58,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,556 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,556 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-22327937-c188-495d-9a1f-cd2c8c3a7246): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,556 [Thread-218] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:36 AM with interval of 21600000ms
2020-12-03 07:20:58,556 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:58,556 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-22327937-c188-495d-9a1f-cd2c8c3a7246): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:58,558 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:58,559 [IPC Server handler 2 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,560 [IPC Server handler 2 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41298
2020-12-03 07:20:58,560 [IPC Server handler 2 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a31dec30-b921-41c5-a9f2-5c552b91d1fb (127.0.0.1:41298).
2020-12-03 07:20:58,560 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:58,561 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:58,565 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 for DN 127.0.0.1:41298
2020-12-03 07:20:58,565 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22327937-c188-495d-9a1f-cd2c8c3a7246 for DN 127.0.0.1:41298
2020-12-03 07:20:58,587 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 34ms
2020-12-03 07:20:58,591 [Thread-462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 39ms
2020-12-03 07:20:58,592 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 40ms
2020-12-03 07:20:58,592 [Thread-470] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11...
2020-12-03 07:20:58,592 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12...
2020-12-03 07:20:58,592 [Thread-470] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,592 [Thread-471] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,593 [Thread-470] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:58,593 [Thread-471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:58,593 [Thread-217] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 1ms
2020-12-03 07:20:58,593 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12
2020-12-03 07:20:58,593 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11
2020-12-03 07:20:58,593 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:58,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6630927068de7363: Processing first storage report for DS-22327937-c188-495d-9a1f-cd2c8c3a7246 from datanode a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-22327937-c188-495d-9a1f-cd2c8c3a7246): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6630927068de7363: from storage DS-22327937-c188-495d-9a1f-cd2c8c3a7246 node DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6630927068de7363: Processing first storage report for DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 from datanode a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:20:58,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-22327937-c188-495d-9a1f-cd2c8c3a7246): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:20:58,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6630927068de7363: from storage DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 node DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,594 [IPC Server handler 6 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,595 [IPC Server handler 6 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41298
2020-12-03 07:20:58,595 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6630927068de7363,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:58,595 [IPC Server handler 6 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a31dec30-b921-41c5-a9f2-5c552b91d1fb (127.0.0.1:41298).
2020-12-03 07:20:58,595 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,596 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:58,596 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:58,601 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 for DN 127.0.0.1:41298
2020-12-03 07:20:58,601 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22327937-c188-495d-9a1f-cd2c8c3a7246 for DN 127.0.0.1:41298
2020-12-03 07:20:58,604 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9496b4949bd6ea5c: Processing first storage report for DS-22327937-c188-495d-9a1f-cd2c8c3a7246 from datanode a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,604 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9496b4949bd6ea5c: from storage DS-22327937-c188-495d-9a1f-cd2c8c3a7246 node DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,604 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9496b4949bd6ea5c: Processing first storage report for DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 from datanode a31dec30-b921-41c5-a9f2-5c552b91d1fb
2020-12-03 07:20:58,604 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9496b4949bd6ea5c: from storage DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1 node DatanodeRegistration(127.0.0.1:41298, datanodeUuid=a31dec30-b921-41c5-a9f2-5c552b91d1fb, infoPort=44550, infoSecurePort=0, ipcPort=43700, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:58,606 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9496b4949bd6ea5c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:58,606 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,614 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,616 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,616 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,717 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,719 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,719 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,750 [Thread-332] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:20:58,753 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dabe19a4-c133-447f-ad17-75bf077581e1
2020-12-03 07:20:58,753 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:20:58,757 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf
2020-12-03 07:20:58,759 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:20:58,760 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:58,762 [Thread-332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:58,765 [Thread-333] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:58,765 [Thread-333] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 has already been used.
2020-12-03 07:20:58,766 [Thread-333] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 has already been used.
2020-12-03 07:20:58,768 [Thread-332] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:58,768 [Thread-332] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:58,768 [Thread-332] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:58,777 [Thread-332] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,778 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:20:58,778 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:20:58,787 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,787 [Thread-333] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:58,787 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:58,787 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:58,817 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 38ms
2020-12-03 07:20:58,819 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 41ms
2020-12-03 07:20:58,819 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 41ms
2020-12-03 07:20:58,820 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:20:58,821 [Thread-479] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,821 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,821 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 1ms
2020-12-03 07:20:58,821 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:20:58,821 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:58,823 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 2ms
2020-12-03 07:20:58,823 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 3ms
2020-12-03 07:20:58,823 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:20:58,823 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:20:58,824 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,824 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-dabe19a4-c133-447f-ad17-75bf077581e1): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,824 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,824 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-dabe19a4-c133-447f-ad17-75bf077581e1): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:58,824 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,824 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:58,926 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:58,927 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:58,928 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:58,959 [Thread-241] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:58,959 [Thread-287] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=null
2020-12-03 07:20:58,967 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,967 [Thread-355] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:58,967 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24 and block pool id BP-516642031-172.17.0.7-1606980045403 is not formatted. Formatting ...
2020-12-03 07:20:58,967 [Thread-355] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-516642031-172.17.0.7-1606980045403 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-516642031-172.17.0.7-1606980045403/current
2020-12-03 07:20:59,029 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,030 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,031 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,049 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00
2020-12-03 07:20:59,049 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:59,053 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-899047bb-3862-419c-a750-7ef6d1be7fd6
2020-12-03 07:20:59,053 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:59,055 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,057 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,057 [Thread-240] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,057 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,057 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,057 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,058 [Thread-483] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,058 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,059 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,099 [Thread-482] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 42ms
2020-12-03 07:20:59,101 [Thread-483] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 41ms
2020-12-03 07:20:59,101 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 44ms
2020-12-03 07:20:59,101 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,101 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,101 [Thread-486] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,102 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,102 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,102 [Thread-488] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,102 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:20:59,102 [Thread-488] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:20:59,102 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 1ms
2020-12-03 07:20:59,104 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,104 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,104 [Thread-240] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:45 AM with interval of 21600000ms
2020-12-03 07:20:59,105 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:59,106 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-899047bb-3862-419c-a750-7ef6d1be7fd6): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,107 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:59,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-899047bb-3862-419c-a750-7ef6d1be7fd6): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:20:59,108 [IPC Server handler 5 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,108 [IPC Server handler 5 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43287
2020-12-03 07:20:59,109 [IPC Server handler 5 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7acbf593-955c-4a82-a9fa-d13614cef4e7 (127.0.0.1:43287).
2020-12-03 07:20:59,110 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:59,110 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,115 [IPC Server handler 8 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 for DN 127.0.0.1:43287
2020-12-03 07:20:59,115 [IPC Server handler 8 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-899047bb-3862-419c-a750-7ef6d1be7fd6 for DN 127.0.0.1:43287
2020-12-03 07:20:59,132 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,134 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,134 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,140 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 38ms
2020-12-03 07:20:59,148 [Thread-487] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 47ms
2020-12-03 07:20:59,148 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 47ms
2020-12-03 07:20:59,149 [Thread-495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13...
2020-12-03 07:20:59,149 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14...
2020-12-03 07:20:59,149 [Thread-495] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,149 [Thread-496] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,149 [Thread-495] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13: 0ms
2020-12-03 07:20:59,149 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:20:59,150 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:59,150 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13
2020-12-03 07:20:59,150 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14
2020-12-03 07:20:59,150 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:59,150 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x514c27a0ff096daf: Processing first storage report for DS-899047bb-3862-419c-a750-7ef6d1be7fd6 from datanode 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,150 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-899047bb-3862-419c-a750-7ef6d1be7fd6): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,150 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x514c27a0ff096daf: from storage DS-899047bb-3862-419c-a750-7ef6d1be7fd6 node DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,150 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,151 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x514c27a0ff096daf: Processing first storage report for DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 from datanode 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,151 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x514c27a0ff096daf: from storage DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 node DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,151 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-03 07:20:59,151 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-899047bb-3862-419c-a750-7ef6d1be7fd6): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-03 07:20:59,151 [IPC Server handler 8 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,152 [IPC Server handler 8 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43287
2020-12-03 07:20:59,152 [IPC Server handler 8 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7acbf593-955c-4a82-a9fa-d13614cef4e7 (127.0.0.1:43287).
2020-12-03 07:20:59,152 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x514c27a0ff096daf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 32 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,152 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,153 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:59,153 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,155 [IPC Server handler 7 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 for DN 127.0.0.1:43287
2020-12-03 07:20:59,155 [IPC Server handler 7 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-899047bb-3862-419c-a750-7ef6d1be7fd6 for DN 127.0.0.1:43287
2020-12-03 07:20:59,158 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaaebf7c1fb424d04: Processing first storage report for DS-899047bb-3862-419c-a750-7ef6d1be7fd6 from datanode 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,158 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaaebf7c1fb424d04: from storage DS-899047bb-3862-419c-a750-7ef6d1be7fd6 node DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,158 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaaebf7c1fb424d04: Processing first storage report for DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 from datanode 7acbf593-955c-4a82-a9fa-d13614cef4e7
2020-12-03 07:20:59,158 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaaebf7c1fb424d04: from storage DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00 node DatanodeRegistration(127.0.0.1:43287, datanodeUuid=7acbf593-955c-4a82-a9fa-d13614cef4e7, infoPort=46094, infoSecurePort=0, ipcPort=35604, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,159 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaaebf7c1fb424d04,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,160 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,236 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,237 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,238 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,339 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,341 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,341 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,419 [Thread-263] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,420 [Thread-309] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:59,422 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-79915494-c363-4b00-9e24-01995a3641ee
2020-12-03 07:20:59,424 [Thread-263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:59,426 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bb6d252b-337c-47db-8776-c335078b2bd5
2020-12-03 07:20:59,426 [Thread-263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:59,426 [Thread-263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,428 [Thread-263] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:59,430 [Thread-263] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:59,430 [Thread-264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,430 [Thread-263] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:59,431 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:20:59,431 [Thread-263] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:59,431 [Thread-263] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,431 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:20:59,445 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,446 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,447 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,473 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 42ms
2020-12-03 07:20:59,482 [Thread-499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 51ms
2020-12-03 07:20:59,482 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 52ms
2020-12-03 07:20:59,483 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:20:59,483 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:20:59,483 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:20:59,483 [Thread-503] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,483 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:20:59,483 [Thread-505] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,483 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:59,484 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:20:59,484 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:59,485 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:59,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-79915494-c363-4b00-9e24-01995a3641ee): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,486 [Thread-264] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:20 AM with interval of 21600000ms
2020-12-03 07:20:59,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-79915494-c363-4b00-9e24-01995a3641ee): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:59,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:59,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-bb6d252b-337c-47db-8776-c335078b2bd5): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-bb6d252b-337c-47db-8776-c335078b2bd5): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:59,489 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:59,490 [IPC Server handler 2 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,490 [IPC Server handler 2 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43970
2020-12-03 07:20:59,491 [IPC Server handler 2 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66 (127.0.0.1:43970).
2020-12-03 07:20:59,492 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:59,492 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,507 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-79915494-c363-4b00-9e24-01995a3641ee for DN 127.0.0.1:43970
2020-12-03 07:20:59,508 [IPC Server handler 3 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bb6d252b-337c-47db-8776-c335078b2bd5 for DN 127.0.0.1:43970
2020-12-03 07:20:59,524 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 41ms
2020-12-03 07:20:59,524 [Thread-506] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 41ms
2020-12-03 07:20:59,524 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 42ms
2020-12-03 07:20:59,525 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15...
2020-12-03 07:20:59,525 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16...
2020-12-03 07:20:59,525 [Thread-512] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,525 [Thread-513] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,525 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:20:59,525 [Thread-512] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:59,527 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 3ms
2020-12-03 07:20:59,527 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15
2020-12-03 07:20:59,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc0d014aeaf0a4b: Processing first storage report for DS-79915494-c363-4b00-9e24-01995a3641ee from datanode 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,528 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16
2020-12-03 07:20:59,528 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:59,528 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-bb6d252b-337c-47db-8776-c335078b2bd5): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,528 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc0d014aeaf0a4b: from storage DS-79915494-c363-4b00-9e24-01995a3641ee node DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,528 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-79915494-c363-4b00-9e24-01995a3641ee): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc0d014aeaf0a4b: Processing first storage report for DS-bb6d252b-337c-47db-8776-c335078b2bd5 from datanode 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,529 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-bb6d252b-337c-47db-8776-c335078b2bd5): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:20:59,529 [IPC Server handler 4 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,529 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc0d014aeaf0a4b: from storage DS-bb6d252b-337c-47db-8776-c335078b2bd5 node DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,529 [IPC Server handler 4 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43970
2020-12-03 07:20:59,529 [IPC Server handler 4 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66 (127.0.0.1:43970).
2020-12-03 07:20:59,530 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdc0d014aeaf0a4b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 16 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,530 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,529 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-79915494-c363-4b00-9e24-01995a3641ee): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:20:59,531 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:59,531 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,535 [IPC Server handler 2 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-79915494-c363-4b00-9e24-01995a3641ee for DN 127.0.0.1:43970
2020-12-03 07:20:59,535 [IPC Server handler 2 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bb6d252b-337c-47db-8776-c335078b2bd5 for DN 127.0.0.1:43970
2020-12-03 07:20:59,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x38bb39a3fb6119bf: Processing first storage report for DS-79915494-c363-4b00-9e24-01995a3641ee from datanode 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x38bb39a3fb6119bf: from storage DS-79915494-c363-4b00-9e24-01995a3641ee node DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x38bb39a3fb6119bf: Processing first storage report for DS-bb6d252b-337c-47db-8776-c335078b2bd5 from datanode 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66
2020-12-03 07:20:59,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x38bb39a3fb6119bf: from storage DS-bb6d252b-337c-47db-8776-c335078b2bd5 node DatanodeRegistration(127.0.0.1:43970, datanodeUuid=10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66, infoPort=33491, infoSecurePort=0, ipcPort=43250, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,540 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x38bb39a3fb6119bf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,540 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,548 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,550 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,550 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,625 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,625 [Thread-333] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,625 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22 and block pool id BP-945936126-172.17.0.7-1606980048446 is not formatted. Formatting ...
2020-12-03 07:20:59,625 [Thread-333] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-945936126-172.17.0.7-1606980048446 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-945936126-172.17.0.7-1606980048446/current
2020-12-03 07:20:59,652 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,656 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,657 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,759 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,762 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,762 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,794 [Thread-355] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1128000539;bpid=BP-516642031-172.17.0.7-1606980045403;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1128000539;c=1606980045403;bpid=BP-516642031-172.17.0.7-1606980045403;dnuuid=null
2020-12-03 07:20:59,803 [Thread-286] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,806 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ec0b88a2-0480-4f86-9300-058041cee39c
2020-12-03 07:20:59,807 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:59,808 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb
2020-12-03 07:20:59,808 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:59,808 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:59,814 [Thread-286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,814 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,815 [Thread-516] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,815 [Thread-517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,815 [Thread-286] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,815 [Thread-286] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,816 [Thread-286] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,816 [Thread-286] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,852 [Thread-517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 37ms
2020-12-03 07:20:59,860 [Thread-516] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 45ms
2020-12-03 07:20:59,860 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 45ms
2020-12-03 07:20:59,861 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,861 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,861 [Thread-520] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,861 [Thread-522] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,861 [Thread-522] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:20:59,861 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:20:59,862 [Thread-522] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:20:59,862 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 2ms
2020-12-03 07:20:59,861 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,864 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,864 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,864 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-ec0b88a2-0480-4f86-9300-058041cee39c): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,864 [Thread-287] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:36 AM with interval of 21600000ms
2020-12-03 07:20:59,864 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,866 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:20:59,866 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,869 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:20:59,871 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-ec0b88a2-0480-4f86-9300-058041cee39c): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:20:59,871 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,872 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:59,872 [IPC Server handler 6 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,873 [IPC Server handler 6 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33318
2020-12-03 07:20:59,873 [IPC Server handler 6 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 92b0dd91-6e0d-49a0-96f3-d20d703e8493 (127.0.0.1:33318).
2020-12-03 07:20:59,875 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:20:59,875 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,880 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec0b88a2-0480-4f86-9300-058041cee39c for DN 127.0.0.1:33318
2020-12-03 07:20:59,881 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb for DN 127.0.0.1:33318
2020-12-03 07:20:59,899 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 38ms
2020-12-03 07:20:59,901 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 38ms
2020-12-03 07:20:59,901 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 41ms
2020-12-03 07:20:59,901 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17...
2020-12-03 07:20:59,902 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18...
2020-12-03 07:20:59,902 [Thread-529] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,902 [Thread-530] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:20:59,913 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18: 11ms
2020-12-03 07:20:59,913 [Thread-529] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17: 12ms
2020-12-03 07:20:59,915 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 14ms
2020-12-03 07:20:59,915 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x55ecdb816ab91f7b: Processing first storage report for DS-ec0b88a2-0480-4f86-9300-058041cee39c from datanode 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x55ecdb816ab91f7b: from storage DS-ec0b88a2-0480-4f86-9300-058041cee39c node DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x55ecdb816ab91f7b: Processing first storage report for DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb from datanode 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,916 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17
2020-12-03 07:20:59,916 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-ec0b88a2-0480-4f86-9300-058041cee39c): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,917 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18
2020-12-03 07:20:59,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x55ecdb816ab91f7b: from storage DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb node DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,916 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:20:59,917 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,917 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-ec0b88a2-0480-4f86-9300-058041cee39c): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-12-03 07:20:59,918 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:20:59,919 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x55ecdb816ab91f7b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 19 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,919 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:20:59,920 [IPC Server handler 3 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,920 [IPC Server handler 3 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33318
2020-12-03 07:20:59,920 [IPC Server handler 3 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 92b0dd91-6e0d-49a0-96f3-d20d703e8493 (127.0.0.1:33318).
2020-12-03 07:20:59,921 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:20:59,922 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:59,925 [IPC Server handler 1 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec0b88a2-0480-4f86-9300-058041cee39c for DN 127.0.0.1:33318
2020-12-03 07:20:59,925 [IPC Server handler 1 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb for DN 127.0.0.1:33318
2020-12-03 07:20:59,927 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b061bdcd103a2cc: Processing first storage report for DS-ec0b88a2-0480-4f86-9300-058041cee39c from datanode 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,928 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b061bdcd103a2cc: from storage DS-ec0b88a2-0480-4f86-9300-058041cee39c node DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,928 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b061bdcd103a2cc: Processing first storage report for DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb from datanode 92b0dd91-6e0d-49a0-96f3-d20d703e8493
2020-12-03 07:20:59,928 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b061bdcd103a2cc: from storage DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb node DatanodeRegistration(127.0.0.1:33318, datanodeUuid=92b0dd91-6e0d-49a0-96f3-d20d703e8493, infoPort=35149, infoSecurePort=0, ipcPort=45181, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:59,929 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b061bdcd103a2cc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:59,929 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:20:59,973 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:59,975 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:59,975 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,077 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,078 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,078 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,151 [Thread-310] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,154 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10
2020-12-03 07:21:00,154 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:21:00,158 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8
2020-12-03 07:21:00,159 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:21:00,160 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:00,161 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:00,161 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:00,161 [Thread-310] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:00,162 [Thread-310] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:00,164 [Thread-310] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,163 [Thread-309] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,165 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:00,165 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:00,181 [IPC Server handler 7 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,182 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,183 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,203 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 38ms
2020-12-03 07:21:00,208 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 43ms
2020-12-03 07:21:00,208 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 44ms
2020-12-03 07:21:00,208 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:00,209 [Thread-538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:00,209 [Thread-537] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,209 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:00,213 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:00,213 [Thread-539] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,214 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 4ms
2020-12-03 07:21:00,214 [Thread-539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:21:00,214 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 6ms
2020-12-03 07:21:00,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:00,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:00,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,215 [Thread-310] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:05 PM with interval of 21600000ms
2020-12-03 07:21:00,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,217 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:21:00,217 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:00,217 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:00,218 [IPC Server handler 0 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,219 [IPC Server handler 0 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34933
2020-12-03 07:21:00,219 [IPC Server handler 0 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 801cbe46-25b7-42e8-b0f5-32819d8db15b (127.0.0.1:34933).
2020-12-03 07:21:00,220 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:21:00,220 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,226 [IPC Server handler 1 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 for DN 127.0.0.1:34933
2020-12-03 07:21:00,227 [IPC Server handler 1 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 for DN 127.0.0.1:34933
2020-12-03 07:21:00,262 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 49ms
2020-12-03 07:21:00,262 [Thread-538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 53ms
2020-12-03 07:21:00,262 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 54ms
2020-12-03 07:21:00,263 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19...
2020-12-03 07:21:00,263 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20...
2020-12-03 07:21:00,263 [Thread-546] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:21:00,263 [Thread-547] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:21:00,264 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:21:00,264 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:21:00,264 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 2ms
2020-12-03 07:21:00,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20
2020-12-03 07:21:00,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19
2020-12-03 07:21:00,267 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:21:00,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x34c4aa15d965acac: Processing first storage report for DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 from datanode 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34c4aa15d965acac: from storage DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 node DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x34c4aa15d965acac: Processing first storage report for DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 from datanode 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34c4aa15d965acac: from storage DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 node DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,268 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-12-03 07:21:00,268 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-12-03 07:21:00,268 [IPC Server handler 6 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,268 [IPC Server handler 6 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34933
2020-12-03 07:21:00,268 [IPC Server handler 6 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 801cbe46-25b7-42e8-b0f5-32819d8db15b (127.0.0.1:34933).
2020-12-03 07:21:00,269 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x34c4aa15d965acac,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 35 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,269 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,269 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:21:00,269 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,273 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 for DN 127.0.0.1:34933
2020-12-03 07:21:00,273 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 for DN 127.0.0.1:34933
2020-12-03 07:21:00,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf59b73f40347b21: Processing first storage report for DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 from datanode 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf59b73f40347b21: from storage DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10 node DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf59b73f40347b21: Processing first storage report for DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 from datanode 801cbe46-25b7-42e8-b0f5-32819d8db15b
2020-12-03 07:21:00,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf59b73f40347b21: from storage DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8 node DatanodeRegistration(127.0.0.1:34933, datanodeUuid=801cbe46-25b7-42e8-b0f5-32819d8db15b, infoPort=45744, infoSecurePort=0, ipcPort=35913, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,276 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbf59b73f40347b21,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,276 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,284 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,285 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,285 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,340 [Thread-333] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2093699753;bpid=BP-945936126-172.17.0.7-1606980048446;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2093699753;c=1606980048446;bpid=BP-945936126-172.17.0.7-1606980048446;dnuuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,341 [Thread-332] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:11 AM with interval of 21600000ms
2020-12-03 07:21:00,342 [Thread-333] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,343 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:21:00,343 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:21:00,343 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:21:00,345 [IPC Server handler 9 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,345 [IPC Server handler 9 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35614
2020-12-03 07:21:00,345 [IPC Server handler 9 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b1a2964f-977e-4c85-beb5-4b8ecfcd5fab (127.0.0.1:35614).
2020-12-03 07:21:00,346 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:21:00,346 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,350 [IPC Server handler 4 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dabe19a4-c133-447f-ad17-75bf077581e1 for DN 127.0.0.1:35614
2020-12-03 07:21:00,350 [IPC Server handler 4 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf for DN 127.0.0.1:35614
2020-12-03 07:21:00,387 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,389 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,389 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,390 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 47ms
2020-12-03 07:21:00,395 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 52ms
2020-12-03 07:21:00,396 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 52ms
2020-12-03 07:21:00,396 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21...
2020-12-03 07:21:00,396 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22...
2020-12-03 07:21:00,396 [Thread-555] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,396 [Thread-556] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,396 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21: 0ms
2020-12-03 07:21:00,397 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22: 1ms
2020-12-03 07:21:00,397 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 1ms
2020-12-03 07:21:00,398 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd63e86b6cd3b2a0a: Processing first storage report for DS-dabe19a4-c133-447f-ad17-75bf077581e1 from datanode b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,398 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd63e86b6cd3b2a0a: from storage DS-dabe19a4-c133-447f-ad17-75bf077581e1 node DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,398 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd63e86b6cd3b2a0a: Processing first storage report for DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf from datanode b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,399 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd63e86b6cd3b2a0a: from storage DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf node DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,403 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21
2020-12-03 07:21:00,403 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:21:00,404 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22
2020-12-03 07:21:00,404 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-dabe19a4-c133-447f-ad17-75bf077581e1): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,404 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,404 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd63e86b6cd3b2a0a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 45 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,404 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,405 [IPC Server handler 6 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,405 [IPC Server handler 6 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35614
2020-12-03 07:21:00,405 [IPC Server handler 6 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b1a2964f-977e-4c85-beb5-4b8ecfcd5fab (127.0.0.1:35614).
2020-12-03 07:21:00,406 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:21:00,407 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,407 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-dabe19a4-c133-447f-ad17-75bf077581e1): no suitable block pools found to scan.  Waiting 1814398416 ms.
2020-12-03 07:21:00,407 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf): no suitable block pools found to scan.  Waiting 1814398416 ms.
2020-12-03 07:21:00,411 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dabe19a4-c133-447f-ad17-75bf077581e1 for DN 127.0.0.1:35614
2020-12-03 07:21:00,411 [IPC Server handler 5 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf for DN 127.0.0.1:35614
2020-12-03 07:21:00,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa19246c274b3559e: Processing first storage report for DS-dabe19a4-c133-447f-ad17-75bf077581e1 from datanode b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa19246c274b3559e: from storage DS-dabe19a4-c133-447f-ad17-75bf077581e1 node DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa19246c274b3559e: Processing first storage report for DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf from datanode b1a2964f-977e-4c85-beb5-4b8ecfcd5fab
2020-12-03 07:21:00,414 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa19246c274b3559e: from storage DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf node DatanodeRegistration(127.0.0.1:35614, datanodeUuid=b1a2964f-977e-4c85-beb5-4b8ecfcd5fab, infoPort=46006, infoSecurePort=0, ipcPort=41770, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,415 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa19246c274b3559e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,415 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,491 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,494 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:00,494 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,495 [Thread-356] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,498 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f
2020-12-03 07:21:00,500 [Thread-356] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, StorageType: DISK
2020-12-03 07:21:00,502 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786
2020-12-03 07:21:00,503 [Thread-356] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, StorageType: DISK
2020-12-03 07:21:00,503 [Thread-356] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:00,505 [Thread-356] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:00,505 [Thread-355] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,507 [Thread-356] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:00,507 [Thread-356] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:00,508 [Thread-356] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:00,509 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:00,509 [Thread-356] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,509 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:00,545 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 36ms
2020-12-03 07:21:00,551 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-516642031-172.17.0.7-1606980045403 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 42ms
2020-12-03 07:21:00,551 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-516642031-172.17.0.7-1606980045403: 46ms
2020-12-03 07:21:00,553 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:00,553 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:00,554 [Thread-563] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:21:00,554 [Thread-564] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-516642031-172.17.0.7-1606980045403/current/replicas doesn't exist 
2020-12-03 07:21:00,554 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 1ms
2020-12-03 07:21:00,554 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 1ms
2020-12-03 07:21:00,554 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:00,554 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-516642031-172.17.0.7-1606980045403: 3ms
2020-12-03 07:21:00,554 [Thread-566] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:00,556 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:00,557 [Thread-355] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:38 AM with interval of 21600000ms
2020-12-03 07:21:00,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-516642031-172.17.0.7-1606980045403 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:00,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f): finished scanning block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,558 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:21:00,559 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:00,560 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:45212 beginning handshake with NN
2020-12-03 07:21:00,561 [IPC Server handler 6 on default port 45212] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403) storage b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,562 [IPC Server handler 6 on default port 45212] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35355
2020-12-03 07:21:00,562 [IPC Server handler 6 on default port 45212] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b2e54c14-4141-4f23-9f9d-28873a56abd7 (127.0.0.1:35355).
2020-12-03 07:21:00,564 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:45212 successfully registered with NN
2020-12-03 07:21:00,564 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45212 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,574 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f for DN 127.0.0.1:35355
2020-12-03 07:21:00,574 [IPC Server handler 0 on default port 45212] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 for DN 127.0.0.1:35355
2020-12-03 07:21:00,595 [Thread-566] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 39ms
2020-12-03 07:21:00,595 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-945936126-172.17.0.7-1606980048446 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 40ms
2020-12-03 07:21:00,596 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-945936126-172.17.0.7-1606980048446: 43ms
2020-12-03 07:21:00,596 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,598 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2789)) - !dn.datanode.isDatanodeFullyStarted()
2020-12-03 07:21:00,598 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc52c76f64924bbb: Processing first storage report for DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f from datanode b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc52c76f64924bbb: from storage DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f node DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdc52c76f64924bbb: Processing first storage report for DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 from datanode b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdc52c76f64924bbb: from storage DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 node DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1128000539;c=1606980045403), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,601 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdc52c76f64924bbb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 21 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,601 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:00,700 [IPC Server handler 9 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,701 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2789)) - !dn.datanode.isDatanodeFullyStarted()
2020-12-03 07:21:00,701 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:00,707 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23...
2020-12-03 07:21:00,707 [Thread-572] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,707 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23: 0ms
2020-12-03 07:21:00,707 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24...
2020-12-03 07:21:00,708 [Thread-573] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-945936126-172.17.0.7-1606980048446/current/replicas doesn't exist 
2020-12-03 07:21:00,708 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24: 0ms
2020-12-03 07:21:00,708 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-945936126-172.17.0.7-1606980048446: 112ms
2020-12-03 07:21:00,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24
2020-12-03 07:21:00,709 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:35772 beginning handshake with NN
2020-12-03 07:21:00,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786): no suitable block pools found to scan.  Waiting 1814399846 ms.
2020-12-03 07:21:00,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-945936126-172.17.0.7-1606980048446 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23
2020-12-03 07:21:00,710 [IPC Server handler 9 on default port 35772] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446) storage b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,711 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f): finished scanning block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,711 [IPC Server handler 9 on default port 35772] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35355
2020-12-03 07:21:00,711 [IPC Server handler 9 on default port 35772] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b2e54c14-4141-4f23-9f9d-28873a56abd7 (127.0.0.1:35355).
2020-12-03 07:21:00,711 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f): no suitable block pools found to scan.  Waiting 1814399845 ms.
2020-12-03 07:21:00,712 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:35772 successfully registered with NN
2020-12-03 07:21:00,712 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35772 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:00,720 [IPC Server handler 0 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f for DN 127.0.0.1:35355
2020-12-03 07:21:00,720 [IPC Server handler 0 on default port 35772] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 for DN 127.0.0.1:35355
2020-12-03 07:21:00,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x262f9a2fb15832fc: Processing first storage report for DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f from datanode b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x262f9a2fb15832fc: from storage DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f node DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x262f9a2fb15832fc: Processing first storage report for DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 from datanode b2e54c14-4141-4f23-9f9d-28873a56abd7
2020-12-03 07:21:00,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x262f9a2fb15832fc: from storage DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786 node DatanodeRegistration(127.0.0.1:35355, datanodeUuid=b2e54c14-4141-4f23-9f9d-28873a56abd7, infoPort=35774, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=2093699753;c=1606980048446), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:00,724 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x262f9a2fb15832fc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:00,724 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:00,803 [IPC Server handler 4 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,816 [IPC Server handler 2 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,818 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:00,827 [IPC Server handler 2 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,839 [IPC Server handler 3 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:00,843 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:00,896 [Listener at localhost/38374] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:00,898 [Listener at localhost/38374] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,899 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:00,913 [Listener at 0.0.0.0/33367] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:00,913 [Listener at 0.0.0.0/33367] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:00,914 [Listener at 0.0.0.0/33367] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:00,923 [Listener at 0.0.0.0/33367] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:00,929 [Listener at 0.0.0.0/33367] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:21:00,955 [Listener at 0.0.0.0/33367] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:00,957 [Listener at 0.0.0.0/33367] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,958 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:00,966 [Listener at 0.0.0.0/43152] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:00,966 [Listener at 0.0.0.0/43152] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:00,966 [Listener at 0.0.0.0/43152] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:00,967 [Listener at 0.0.0.0/43152] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:00,969 [Listener at 0.0.0.0/43152] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:21:00,982 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@68b58644] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:00,982 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:00,982 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:00,985 [Listener at 0.0.0.0/43152] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:33367
2020-12-03 07:21:01,002 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-2
2020-12-03 07:21:01,003 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-2
2020-12-03 07:21:01,004 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-2
2020-12-03 07:21:01,004 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-2
2020-12-03 07:21:01,013 [Listener at 0.0.0.0/43152] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:21:01,014 [Listener at 0.0.0.0/43152] ERROR metrics.FederationMetrics (FederationMetrics.java:<init>(137)) - State store not available
2020-12-03 07:21:01,014 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d48673] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:01,014 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:01,015 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:01,019 [Listener at 0.0.0.0/43152] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:43152
2020-12-03 07:21:01,020 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-3
2020-12-03 07:21:01,020 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-3
2020-12-03 07:21:01,021 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-3
2020-12-03 07:21:01,021 [Listener at 0.0.0.0/43152] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-3
2020-12-03 07:21:01,022 [Listener at 0.0.0.0/43152] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:21:01,022 [Listener at 0.0.0.0/43152] ERROR metrics.FederationMetrics (FederationMetrics.java:<init>(137)) - State store not available
2020-12-03 07:21:01,072 [IPC Server handler 5 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,085 [IPC Server handler 8 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,091 [IPC Server handler 6 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,093 [IPC Server handler 5 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,121 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/target-ns0/testdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:01,157 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns0/testdir	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,166 [IPC Server handler 7 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/target-ns1/testdir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:01,172 [IPC Server handler 9 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns1/testdir	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,274 [Listener at 0.0.0.0/43152] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(249)) - Connecting to router at hdfs://0.0.0.0:43152
2020-12-03 07:21:01,338 [Listener at 0.0.0.0/43152] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(357)) - Connecting to namenode at hdfs://localhost:45212
2020-12-03 07:21:01,375 [IPC Server handler 3 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/target-ns0/testdir/testfile-1926008118	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-12-03 07:21:01,426 [IPC Server handler 9 on default port 45212] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41298 for /target-ns0/testdir/testfile-1926008118
2020-12-03 07:21:01,446 [Thread-603] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:01,530 [DataXceiver for client DFSClient_NONMAPREDUCE_-1959682654_1 at /127.0.0.1:37776 [Receiving block BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001 src: /127.0.0.1:37776 dest: /127.0.0.1:41298
2020-12-03 07:21:01,648 [PacketResponder: BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37776, dest: /127.0.0.1:41298, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1959682654_1, offset: 0, srvID: a31dec30-b921-41c5-a9f2-5c552b91d1fb, blockid: BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001, duration(ns): 17736968
2020-12-03 07:21:01,649 [PacketResponder: BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-516642031-172.17.0.7-1606980045403:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:01,661 [IPC Server handler 5 on default port 45212] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /target-ns0/testdir/testfile-1926008118 is closed by DFSClient_NONMAPREDUCE_-1959682654_1
2020-12-03 07:21:01,667 [IPC Server handler 6 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/target-ns0/testdir/testfile-1926008118	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,702 [IPC Server handler 0 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,712 [IPC Server handler 1 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,741 [IPC Server handler 2 on default port 35772] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,756 [IPC Server handler 1 on default port 45212] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,815 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:01,815 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 11
2020-12-03 07:21:01,816 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:01,816 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@383f1975] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:01,820 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24, DS-181f65e4-2ba7-4cf2-aca7-4f74cb75c786) exiting.
2020-12-03 07:21:01,821 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23, DS-a5578b52-b91a-4e47-b5af-a2c7fe237e8f) exiting.
2020-12-03 07:21:01,876 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@353efdbf{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:01,888 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@55cff952{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:01,889 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b569985{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:01,889 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@773c0293{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:01,896 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38374
2020-12-03 07:21:01,908 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:01,908 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:01,910 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:01,910 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:01,911 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:45212
2020-12-03 07:21:01,911 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7) service to localhost/127.0.0.1:35772
2020-12-03 07:21:01,911 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7)
2020-12-03 07:21:01,911 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b2e54c14-4141-4f23-9f9d-28873a56abd7)
2020-12-03 07:21:01,911 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:01,912 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:01,912 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:01,912 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:01,918 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data23/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:01,919 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:01,919 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data24/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:01,919 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:01,920 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:01,920 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:01,927 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:01,928 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:21:01,928 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:01,928 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4c98a6d5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:01,933 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22, DS-4ae08f49-b19e-4fd2-91ec-3f35b0406caf) exiting.
2020-12-03 07:21:01,933 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21, DS-dabe19a4-c133-447f-ad17-75bf077581e1) exiting.
2020-12-03 07:21:01,988 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@677b8e13{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:01,989 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a9486c0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:01,990 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53692008{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:01,991 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bcf67e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,001 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41770
2020-12-03 07:21:02,030 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,030 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,031 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,031 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,031 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,031 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,031 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab)
2020-12-03 07:21:02,031 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,031 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid b1a2964f-977e-4c85-beb5-4b8ecfcd5fab)
2020-12-03 07:21:02,032 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,032 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,032 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,033 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data21/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,033 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data22/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,062 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,062 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,065 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,065 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,073 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,074 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:21:02,074 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4cbd03e7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,074 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,084 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20, DS-9fb16eeb-9069-4782-9f0e-fd264f9237d8) exiting.
2020-12-03 07:21:02,088 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19, DS-faf448c3-4363-4cc7-ab36-8ca5d9d68e10) exiting.
2020-12-03 07:21:02,146 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1763992e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,147 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5c92166b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,148 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24a298a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,148 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5aae8eb5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,153 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35913
2020-12-03 07:21:02,170 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,173 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,174 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,174 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,174 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,174 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,175 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b)
2020-12-03 07:21:02,175 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 801cbe46-25b7-42e8-b0f5-32819d8db15b)
2020-12-03 07:21:02,175 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,176 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,176 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,177 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,178 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data19/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,178 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data20/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,196 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,196 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,199 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,199 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,205 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,206 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:21:02,206 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,206 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77ee25f1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,207 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18, DS-5384fdf3-a37e-4be4-8fad-f70b6ba6fbbb) exiting.
2020-12-03 07:21:02,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17, DS-ec0b88a2-0480-4f86-9300-058041cee39c) exiting.
2020-12-03 07:21:02,245 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d235104{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,246 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e8e8621{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,246 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2eb79cbe{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,246 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b3871d6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,251 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45181
2020-12-03 07:21:02,257 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,260 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,260 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,260 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,260 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,261 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,261 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493)
2020-12-03 07:21:02,261 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 92b0dd91-6e0d-49a0-96f3-d20d703e8493)
2020-12-03 07:21:02,261 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,262 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,262 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,262 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,262 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data17/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,262 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data18/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,286 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,287 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,290 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,290 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,297 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,297 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:21:02,297 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,297 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@78411116] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15, DS-79915494-c363-4b00-9e24-01995a3641ee) exiting.
2020-12-03 07:21:02,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16, DS-bb6d252b-337c-47db-8776-c335078b2bd5) exiting.
2020-12-03 07:21:02,331 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@997d532{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,333 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@273842a6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,333 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21ab988f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,334 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d195ee4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,339 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43250
2020-12-03 07:21:02,344 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,359 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,360 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,360 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,360 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,360 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,360 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66)
2020-12-03 07:21:02,360 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 10b3b5b9-27e2-4d9f-bb6b-bae7d6328d66)
2020-12-03 07:21:02,360 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,361 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,361 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,362 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,362 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data15/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,362 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data16/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,430 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,431 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,435 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,435 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,444 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,444 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:21:02,445 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,452 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14, DS-899047bb-3862-419c-a750-7ef6d1be7fd6) exiting.
2020-12-03 07:21:02,454 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5d58c727] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13, DS-2ba10a7c-42a5-4864-b000-9e9ac0faef00) exiting.
2020-12-03 07:21:02,633 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@703feacd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,641 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7051777c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,642 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e8a46b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,642 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27b22f74{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,644 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35604
2020-12-03 07:21:02,650 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,650 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,654 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,655 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,655 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7)
2020-12-03 07:21:02,655 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,656 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,656 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,656 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 7acbf593-955c-4a82-a9fa-d13614cef4e7)
2020-12-03 07:21:02,656 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,656 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,662 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,663 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data13/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,663 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data14/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,692 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,692 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,697 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,697 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,709 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,710 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:21:02,710 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@ddf20fd] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,711 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,715 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11, DS-55af9431-4d57-416a-8fb2-b99cf0d4d9b1) exiting.
2020-12-03 07:21:02,721 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12, DS-22327937-c188-495d-9a1f-cd2c8c3a7246) exiting.
2020-12-03 07:21:02,744 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5c20ffa8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,747 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fedfe27{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,748 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@332f25c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,749 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40021799{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,752 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43700
2020-12-03 07:21:02,754 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,761 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,761 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,761 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,761 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb)
2020-12-03 07:21:02,762 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,764 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,765 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,765 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,765 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,765 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid a31dec30-b921-41c5-a9f2-5c552b91d1fb)
2020-12-03 07:21:02,765 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,766 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data11/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,766 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data12/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,793 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,793 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,798 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,798 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,810 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,810 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:21:02,811 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,811 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42f22995] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,812 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10, DS-042e6ef1-04a6-48fd-baf0-8e31aed2dd64) exiting.
2020-12-03 07:21:02,812 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9, DS-e231bf77-0898-42e1-8227-49ab023ed7c7) exiting.
2020-12-03 07:21:02,839 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7808fb9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:02,840 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@8747840{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:02,841 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cbb84b1{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:02,841 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29182679{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:02,843 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43609
2020-12-03 07:21:02,857 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:02,866 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:02,866 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,866 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:35772
2020-12-03 07:21:02,866 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a)
2020-12-03 07:21:02,867 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:02,867 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,867 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,869 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:02,869 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a) service to localhost/127.0.0.1:45212
2020-12-03 07:21:02,869 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 818c66a4-eec4-478c-9ce0-965c18404f8a)
2020-12-03 07:21:02,869 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:02,870 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data10/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,871 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data9/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:02,950 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:02,951 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:02,958 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:02,958 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:02,973 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:02,974 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:21:02,974 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:02,975 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-1ebd1bfa-386f-4d80-a7d9-bdfd61b52b4c) exiting.
2020-12-03 07:21:02,976 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ee29c84] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:02,976 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-20d815f8-ddfd-4f58-be2f-8799459929e6) exiting.
2020-12-03 07:21:03,009 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2d7e1102{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,010 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65327f5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,010 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60baef24{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,010 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18fdb6cf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,012 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36807
2020-12-03 07:21:03,020 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,020 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,020 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,021 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:35772
2020-12-03 07:21:03,021 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d)
2020-12-03 07:21:03,021 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:03,022 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,020 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,022 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d) service to localhost/127.0.0.1:45212
2020-12-03 07:21:03,022 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid 8c885456-8bc7-4774-be2e-ce1f58eb2e0d)
2020-12-03 07:21:03,022 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:03,034 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,034 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,034 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,081 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,081 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,088 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,088 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,102 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,103 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:03,103 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,103 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@534ca02b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-0b40bdd1-df1e-418a-8adc-979db7faf9e9) exiting.
2020-12-03 07:21:03,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-97616c51-42e9-4287-bc37-325f7763d342) exiting.
2020-12-03 07:21:03,154 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@648ee871{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,155 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@375b5b7f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,156 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5491f68b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,157 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3068b369{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,199 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46294
2020-12-03 07:21:03,205 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,227 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,228 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,228 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,228 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:35772
2020-12-03 07:21:03,229 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c) service to localhost/127.0.0.1:45212
2020-12-03 07:21:03,229 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c)
2020-12-03 07:21:03,229 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid f7ee202f-625f-4189-8aac-3eb4071b030c)
2020-12-03 07:21:03,229 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:03,230 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,230 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:03,231 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,232 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,232 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,249 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,249 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,261 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,261 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,298 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,298 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:03,302 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,303 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@73d69c0f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,315 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-0ec324ee-e1c8-4fbe-87b6-b2de187fbd86) exiting.
2020-12-03 07:21:03,317 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-dbb1599d-f6de-4801-864b-1b89c793b3f2) exiting.
2020-12-03 07:21:03,457 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@577f9109{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,458 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4303b7f0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,458 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13e698c7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,459 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@781a9412{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,464 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43785
2020-12-03 07:21:03,473 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,481 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,481 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,481 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,482 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:45212
2020-12-03 07:21:03,482 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f) service to localhost/127.0.0.1:35772
2020-12-03 07:21:03,482 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f)
2020-12-03 07:21:03,482 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid bf269fe7-15e0-4ac6-9e1a-c518fee9dc0f)
2020-12-03 07:21:03,482 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:03,483 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,483 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,483 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:03,484 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,484 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,490 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,490 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,495 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,495 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,498 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,498 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:03,499 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@106faf11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,500 [Listener at 0.0.0.0/43152] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,500 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-61d1b420-fe40-42c4-8fb2-d11a4fc0d0bd) exiting.
2020-12-03 07:21:03,500 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-678eaaea-fcb6-41f1-85cb-a5b487675668) exiting.
2020-12-03 07:21:03,539 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e27ba81{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,540 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,540 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b02e036{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:03,541 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fc08eec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:03,543 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39348
2020-12-03 07:21:03,544 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,568 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,569 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,569 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,569 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:45212
2020-12-03 07:21:03,569 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4) service to localhost/127.0.0.1:35772
2020-12-03 07:21:03,569 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-516642031-172.17.0.7-1606980045403 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4)
2020-12-03 07:21:03,569 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-945936126-172.17.0.7-1606980048446 (Datanode Uuid fc0a57c2-b3f4-4de4-b8c0-c1971aa906a4)
2020-12-03 07:21:03,569 [BP-516642031-172.17.0.7-1606980045403 heartbeating to localhost/127.0.0.1:45212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-516642031-172.17.0.7-1606980045403
2020-12-03 07:21:03,571 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,571 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-516642031-172.17.0.7-1606980045403] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,572 [BP-945936126-172.17.0.7-1606980048446 heartbeating to localhost/127.0.0.1:35772] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-945936126-172.17.0.7-1606980048446
2020-12-03 07:21:03,573 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,573 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-945936126-172.17.0.7-1606980048446] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,582 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,582 [Listener at 0.0.0.0/43152] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,591 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,591 [Listener at 0.0.0.0/43152] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,593 [Listener at 0.0.0.0/43152] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,593 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:03,593 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:03,594 [Listener at 0.0.0.0/43152] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:21:03,595 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@62d363ab] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:03,595 [Listener at 0.0.0.0/43152] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 2 2 
2020-12-03 07:21:03,597 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5ef8df1e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:03,598 [Listener at 0.0.0.0/43152] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:21:03,599 [Listener at 0.0.0.0/43152] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:21:03,600 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:03,600 [CacheReplicationMonitor(1675456618)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:03,733 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45212
2020-12-03 07:21:03,743 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,794 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:03,794 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:03,856 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:03,856 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:03,859 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34158c08{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:04,058 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@b7c4869{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,059 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d278d2b{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,059 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@571c5681{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,185 [Listener at 0.0.0.0/43152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:04,185 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:04,186 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5489c777] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:04,186 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3676ac27] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:04,186 [Listener at 0.0.0.0/43152] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 3
2020-12-03 07:21:04,187 [Listener at 0.0.0.0/43152] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 1 Number of syncs: 4 SyncTimes(ms): 2 1 
2020-12-03 07:21:04,188 [Listener at 0.0.0.0/43152] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:21:04,262 [Listener at 0.0.0.0/43152] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:21:04,287 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:04,391 [CacheReplicationMonitor(244917827)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:04,788 [Listener at 0.0.0.0/43152] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35772
2020-12-03 07:21:04,807 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,807 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:04,807 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:04,827 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,841 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:04,842 [Listener at 0.0.0.0/43152] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:04,846 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@13006998{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:04,849 [Listener at 0.0.0.0/43152] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@37fbe4a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,850 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56b78e55{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:04,851 [Listener at 0.0.0.0/43152] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b58ff9e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:04,926 [Thread-614] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33367
2020-12-03 07:21:04,930 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,935 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:05,894 [Thread-615] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:21:05,896 [Thread-615] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:21:05,897 [Thread-615] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:21:05,899 [Thread-615] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43152
2020-12-03 07:21:05,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:05,905 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
msx-rc 0
