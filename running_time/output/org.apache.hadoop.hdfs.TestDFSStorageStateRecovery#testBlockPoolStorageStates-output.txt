2020-12-03 07:23:32,754 [main] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:setUp(448)) - Setting up the directory structures.
2020-12-03 07:23:33,406 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:33,408 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
Formatting using clusterid: testClusterID
2020-12-03 07:23:33,451 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:33,471 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:33,473 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:33,476 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:33,484 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:33,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:33,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:33,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:33,540 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:33,562 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:33,563 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:33,569 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:33,570 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:33
2020-12-03 07:23:33,573 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:33,574 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,576 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:33,576 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:33,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:33,597 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:33,604 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2020-12-03 07:23:33,605 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:33,605 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:33,605 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 30000
2020-12-03 07:23:33,606 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:33,606 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:33,606 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:33,607 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:33,607 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:33,607 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:33,607 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:33,641 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:33,642 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:33,642 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:33,642 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:33,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:33,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:33,658 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:33,664 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:33,664 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:33,664 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:33,665 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:33,676 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:33,679 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:33,684 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:33,684 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,684 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:33,685 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:33,695 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:33,696 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:33,696 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:33,700 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:33,701 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:33,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:33,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,704 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:33,704 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:33,740 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:33,842 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster has been successfully formatted.
2020-12-03 07:23:33,875 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:33,995 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:23:34,045 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:34,054 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:23:34,215 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:34,217 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:34,320 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:34,556 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:34,557 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:34,589 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:34,632 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de76cc7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:34,647 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:34,652 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:34,665 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2433ms
2020-12-03 07:23:34,782 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:34,786 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:34,786 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:34,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:34,799 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:34,799 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:34,799 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:34,830 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:34,831 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:34,841 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35212
2020-12-03 07:23:34,842 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:34,886 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:34,887 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:34,924 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a3793c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:34,932 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:35212}
2020-12-03 07:23:34,933 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2701ms
2020-12-03 07:23:34,933 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:34,934 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:34,934 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:34,935 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:34,935 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:34,935 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:34,944 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:34,944 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:34,944 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:34,945 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:34,945 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:34,945 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:34,945 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:34,946 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:34,947 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:34,947 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:34,948 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:34,948 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:34,948 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:34,949 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:34
2020-12-03 07:23:34,949 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:34,949 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,950 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:34,950 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:34,955 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:34,955 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:34,956 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:34,956 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:34,957 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:34,957 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:34,957 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:23:34,958 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:34,958 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:34,958 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:34,958 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:34,959 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:34,959 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:34,960 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:34,960 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,961 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:34,961 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:34,963 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:34,963 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:34,964 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:34,964 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:34,964 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:34,964 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:34,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:34,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:34,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:34,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:34,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:34,966 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:34,967 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:34,967 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:34,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:34,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:34,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:35,036 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:35,040 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current
2020-12-03 07:23:35,040 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:35,040 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:35,070 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:35,076 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:35,077 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage_0000000000000000000
2020-12-03 07:23:35,081 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:35,082 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:35,128 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:35,129 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 158 msecs
2020-12-03 07:23:35,351 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:35,410 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:35,427 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:35,701 [Listener at localhost/35569] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35569 to access this namenode/service.
2020-12-03 07:23:35,705 [Listener at localhost/35569] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:35,706 [Listener at localhost/35569] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:23:35,716 [Listener at localhost/35569] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:35,728 [Listener at localhost/35569] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:35,728 [Listener at localhost/35569] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:35,729 [Listener at localhost/35569] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:35,729 [Listener at localhost/35569] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:35,732 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:35,732 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:35,732 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:35,733 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:35,733 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:35,733 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-12-03 07:23:35,761 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:35,762 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:35,766 [Listener at localhost/35569] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35569
2020-12-03 07:23:35,770 [Listener at localhost/35569] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:35,770 [Listener at localhost/35569] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:35,779 [Listener at localhost/35569] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:35,784 [CacheReplicationMonitor(1939547158)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:35,792 [Listener at localhost/35569] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:23:35,862 [Listener at localhost/35569] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:23:35,895 [Listener at localhost/35569] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:35,900 [Listener at localhost/35569] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:35,903 [Listener at localhost/35569] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:35,907 [Listener at localhost/35569] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:35,908 [Listener at localhost/35569] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:35,913 [Listener at localhost/35569] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:35,919 [Listener at localhost/35569] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34459
2020-12-03 07:23:35,922 [Listener at localhost/35569] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:35,922 [Listener at localhost/35569] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:35,943 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:35,945 [Listener at localhost/35569] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:35,946 [Listener at localhost/35569] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:35,946 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:35,949 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:35,950 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:35,950 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:35,950 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:35,955 [Listener at localhost/35569] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37759
2020-12-03 07:23:35,955 [Listener at localhost/35569] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:35,960 [Listener at localhost/35569] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a3591c5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:35,961 [Listener at localhost/35569] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@346a361{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:35,968 [Listener at localhost/35569] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b58ed3c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:35,969 [Listener at localhost/35569] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24faea88{HTTP/1.1,[http/1.1]}{localhost:37759}
2020-12-03 07:23:35,970 [Listener at localhost/35569] INFO  server.Server (Server.java:doStart(419)) - Started @3738ms
2020-12-03 07:23:36,246 [Listener at localhost/35569] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35696
2020-12-03 07:23:36,247 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71f67a79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:36,248 [Listener at localhost/35569] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:36,249 [Listener at localhost/35569] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:36,274 [Listener at localhost/35569] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:36,276 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:36,291 [Listener at localhost/37545] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37545
2020-12-03 07:23:36,477 [Listener at localhost/37545] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:36,479 [Listener at localhost/37545] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:36,491 [Thread-58] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35569 starting to offer service
2020-12-03 07:23:36,498 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:36,498 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:36,774 [Thread-58] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35569
2020-12-03 07:23:36,777 [Thread-58] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:36,804 [Thread-58] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:36,805 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster is not formatted for namespace 170866041. Formatting...
2020-12-03 07:23:36,806 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-713cabed-c859-49b3-bef1-53b932f655d0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster 
2020-12-03 07:23:36,877 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:36,878 [Thread-58] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:36,878 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster and block pool id BP-552726158-172.17.0.2-1606980213726 is not formatted. Formatting ...
2020-12-03 07:23:36,878 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-552726158-172.17.0.2-1606980213726 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-552726158-172.17.0.2-1606980213726/current
2020-12-03 07:23:36,947 [Thread-58] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=null
2020-12-03 07:23:36,999 [Thread-58] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:37,072 [IPC Server handler 1 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:37,090 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:37,090 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:37,139 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-713cabed-c859-49b3-bef1-53b932f655d0
2020-12-03 07:23:37,140 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, StorageType: DISK
2020-12-03 07:23:37,146 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:37,154 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:23:37,162 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:23:37,165 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:37,166 [Thread-75] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster...
2020-12-03 07:23:37,195 [IPC Server handler 2 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:37,197 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:37,198 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:37,199 [Thread-75] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster: 33ms
2020-12-03 07:23:37,200 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 34ms
2020-12-03 07:23:37,203 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster...
2020-12-03 07:23:37,203 [Thread-77] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-552726158-172.17.0.2-1606980213726/current/replicas doesn't exist 
2020-12-03 07:23:37,205 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster: 1ms
2020-12-03 07:23:37,205 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 3ms
2020-12-03 07:23:37,208 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:23:37,214 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-713cabed-c859-49b3-bef1-53b932f655d0): finished scanning block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:37,232 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-713cabed-c859-49b3-bef1-53b932f655d0): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:23:37,238 [Thread-58] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:25 AM with interval of 21600000ms
2020-12-03 07:23:37,246 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35569 beginning handshake with NN
2020-12-03 07:23:37,261 [IPC Server handler 3 on default port 35569] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34459, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=35696, infoSecurePort=0, ipcPort=37545, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:37,263 [IPC Server handler 3 on default port 35569] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34459
2020-12-03 07:23:37,264 [IPC Server handler 3 on default port 35569] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:34459).
2020-12-03 07:23:37,270 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35569 successfully registered with NN
2020-12-03 07:23:37,270 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35569 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:37,293 [IPC Server handler 5 on default port 35569] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-713cabed-c859-49b3-bef1-53b932f655d0 for DN 127.0.0.1:34459
2020-12-03 07:23:37,302 [IPC Server handler 7 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:37,317 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:37,337 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa8301dd8af00ee32: Processing first storage report for DS-713cabed-c859-49b3-bef1-53b932f655d0 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:37,339 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa8301dd8af00ee32: from storage DS-713cabed-c859-49b3-bef1-53b932f655d0 node DatanodeRegistration(127.0.0.1:34459, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=35696, infoSecurePort=0, ipcPort=37545, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:37,353 [IPC Server handler 6 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestUpgrade	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:37,375 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa8301dd8af00ee32,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 59 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:37,375 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:37,414 [IPC Server handler 8 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:37,455 [IPC Server handler 9 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34459 for /TestUpgrade/file1
2020-12-03 07:23:37,472 [Thread-81] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,541 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37844 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001 src: /127.0.0.1:37844 dest: /127.0.0.1:34459
2020-12-03 07:23:37,597 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37844, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001, duration(ns): 12525116
2020-12-03 07:23:37,598 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,606 [IPC Server handler 1 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34459 for /TestUpgrade/file1
2020-12-03 07:23:37,608 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,612 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37846 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002 src: /127.0.0.1:37846 dest: /127.0.0.1:34459
2020-12-03 07:23:37,634 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37846, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002, duration(ns): 12039254
2020-12-03 07:23:37,634 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,644 [IPC Server handler 5 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:34459 for /TestUpgrade/file1
2020-12-03 07:23:37,647 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,654 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37848 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003 src: /127.0.0.1:37848 dest: /127.0.0.1:34459
2020-12-03 07:23:37,661 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37848, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003, duration(ns): 3906481
2020-12-03 07:23:37,661 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,663 [IPC Server handler 8 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:34459 for /TestUpgrade/file1
2020-12-03 07:23:37,667 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,669 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37850 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004 src: /127.0.0.1:37850 dest: /127.0.0.1:34459
2020-12-03 07:23:37,683 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37850, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004, duration(ns): 9988002
2020-12-03 07:23:37,683 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,692 [IPC Server handler 0 on default port 35569] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file1 is closed by DFSClient_NONMAPREDUCE_-808003939_1
2020-12-03 07:23:37,699 [IPC Server handler 1 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:37,704 [IPC Server handler 2 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:34459 for /TestUpgrade/file2
2020-12-03 07:23:37,706 [Thread-95] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37852 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005 src: /127.0.0.1:37852 dest: /127.0.0.1:34459
2020-12-03 07:23:37,718 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37852, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005, duration(ns): 7360210
2020-12-03 07:23:37,718 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,722 [IPC Server handler 3 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:34459 for /TestUpgrade/file2
2020-12-03 07:23:37,725 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,727 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37854 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006 src: /127.0.0.1:37854 dest: /127.0.0.1:34459
2020-12-03 07:23:37,739 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37854, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006, duration(ns): 9800635
2020-12-03 07:23:37,740 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,744 [IPC Server handler 6 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:34459 for /TestUpgrade/file2
2020-12-03 07:23:37,746 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,748 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37856 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007 src: /127.0.0.1:37856 dest: /127.0.0.1:34459
2020-12-03 07:23:37,754 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37856, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007, duration(ns): 4294469
2020-12-03 07:23:37,755 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,764 [IPC Server handler 4 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:34459 for /TestUpgrade/file2
2020-12-03 07:23:37,767 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,768 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37858 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008 src: /127.0.0.1:37858 dest: /127.0.0.1:34459
2020-12-03 07:23:37,787 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37858, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008, duration(ns): 14815301
2020-12-03 07:23:37,787 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:37,799 [IPC Server handler 0 on default port 35569] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file2 is closed by DFSClient_NONMAPREDUCE_-808003939_1
2020-12-03 07:23:37,801 [Listener at localhost/37545] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4674)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-12-03 07:23:37,801 [Listener at localhost/37545] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:23:37,801 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 30
2020-12-03 07:23:37,802 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 31 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 11 Number of syncs: 21 SyncTimes(ms): 3 
2020-12-03 07:23:37,803 [Listener at localhost/37545] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_0000000000000000001-0000000000000000031
2020-12-03 07:23:37,813 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000031 using no compression
2020-12-03 07:23:37,830 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000031 of size 716 bytes saved in 0 seconds .
2020-12-03 07:23:37,874 [Listener at localhost/37545] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:23:37,915 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 32
2020-12-03 07:23:37,959 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4500)) - New namespace image has been created
2020-12-03 07:23:37,959 [Listener at localhost/37545] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 2 secs
2020-12-03 07:23:37,959 [Listener at localhost/37545] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:37,960 [Listener at localhost/37545] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:37,963 [IPC Server handler 1 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:37,970 [IPC Server handler 2 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:34459 for /TestUpgrade/file3
2020-12-03 07:23:37,978 [Thread-108] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:37,985 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37860 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009 src: /127.0.0.1:37860 dest: /127.0.0.1:34459
2020-12-03 07:23:38,024 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37860, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009, duration(ns): 36662384
2020-12-03 07:23:38,025 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,028 [IPC Server handler 5 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:34459 for /TestUpgrade/file3
2020-12-03 07:23:38,030 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,031 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37862 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010 src: /127.0.0.1:37862 dest: /127.0.0.1:34459
2020-12-03 07:23:38,045 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37862, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010, duration(ns): 11392357
2020-12-03 07:23:38,046 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,051 [IPC Server handler 6 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:34459 for /TestUpgrade/file3
2020-12-03 07:23:38,053 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,055 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37864 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011 src: /127.0.0.1:37864 dest: /127.0.0.1:34459
2020-12-03 07:23:38,072 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37864, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011, duration(ns): 13536201
2020-12-03 07:23:38,073 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,075 [IPC Server handler 4 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34459 for /TestUpgrade/file3
2020-12-03 07:23:38,078 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,079 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37866 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012 src: /127.0.0.1:37866 dest: /127.0.0.1:34459
2020-12-03 07:23:38,097 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37866, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012, duration(ns): 15646352
2020-12-03 07:23:38,097 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,104 [IPC Server handler 0 on default port 35569] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741836_1012 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /TestUpgrade/file3
2020-12-03 07:23:38,515 [IPC Server handler 1 on default port 35569] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file3 is closed by DFSClient_NONMAPREDUCE_-808003939_1
2020-12-03 07:23:38,519 [IPC Server handler 2 on default port 35569] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:38,523 [IPC Server handler 3 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34459 for /TestUpgrade/file4
2020-12-03 07:23:38,526 [Thread-121] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,528 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37868 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013 src: /127.0.0.1:37868 dest: /127.0.0.1:34459
2020-12-03 07:23:38,556 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37868, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013, duration(ns): 12628007
2020-12-03 07:23:38,557 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,562 [IPC Server handler 5 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:34459 for /TestUpgrade/file4
2020-12-03 07:23:38,564 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,566 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37870 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014 src: /127.0.0.1:37870 dest: /127.0.0.1:34459
2020-12-03 07:23:38,579 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37870, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014, duration(ns): 10417441
2020-12-03 07:23:38,579 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,597 [IPC Server handler 8 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:34459 for /TestUpgrade/file4
2020-12-03 07:23:38,603 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,609 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37872 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015 src: /127.0.0.1:37872 dest: /127.0.0.1:34459
2020-12-03 07:23:38,621 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37872, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015, duration(ns): 7545694
2020-12-03 07:23:38,622 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,646 [IPC Server handler 9 on default port 35569] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:34459 for /TestUpgrade/file4
2020-12-03 07:23:38,649 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,653 [DataXceiver for client DFSClient_NONMAPREDUCE_-808003939_1 at /127.0.0.1:37874 [Receiving block BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016 src: /127.0.0.1:37874 dest: /127.0.0.1:34459
2020-12-03 07:23:38,686 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37874, dest: /127.0.0.1:34459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-808003939_1, offset: 0, srvID: 8c680083-5d1f-4061-9fe5-a63a727e294b, blockid: BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016, duration(ns): 27359239
2020-12-03 07:23:38,687 [PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-552726158-172.17.0.2-1606980213726:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:38,693 [IPC Server handler 1 on default port 35569] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file4 is closed by DFSClient_NONMAPREDUCE_-808003939_1
2020-12-03 07:23:38,700 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:38,701 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:38,702 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ce61929] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:38,701 [Listener at localhost/37545] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:38,704 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-713cabed-c859-49b3-bef1-53b932f655d0) exiting.
2020-12-03 07:23:38,743 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b58ed3c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:38,748 [Listener at localhost/37545] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24faea88{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,749 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@346a361{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,749 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a3591c5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,753 [Listener at localhost/37545] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37545
2020-12-03 07:23:38,755 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,756 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,757 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:38,757 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35569
2020-12-03 07:23:38,777 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:38,778 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35569] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:38,781 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,791 [Listener at localhost/37545] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:38,792 [Listener at localhost/37545] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:38,793 [Listener at localhost/37545] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:38,793 [Listener at localhost/37545] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:38,804 [Listener at localhost/37545] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:38,804 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:38,805 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:38,806 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@47605f2f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:38,808 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 32, 60
2020-12-03 07:23:38,808 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2ece4966] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:38,809 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 30 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 12 Number of syncs: 19 SyncTimes(ms): 1 
2020-12-03 07:23:38,810 [Listener at localhost/37545] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_inprogress_0000000000000000032 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_0000000000000000032-0000000000000000061
2020-12-03 07:23:38,811 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:38,811 [CacheReplicationMonitor(1939547158)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:38,815 [Listener at localhost/37545] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35569
2020-12-03 07:23:38,817 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:38,827 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,827 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,827 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:38,890 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:38,892 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:38,898 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a3793c7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:38,902 [Listener at localhost/37545] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,903 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,903 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,908 [Listener at localhost/37545] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:38,911 [Listener at localhost/37545] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:38,911 [Listener at localhost/37545] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:38,945 [Listener at localhost/37545] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:38,946 [Listener at localhost/37545] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 0*** BLOCK_POOL recovery: numDirs=1 testCase=0 current=true previous=false previous.tmp=false removed.tmp=false should recover=true current exists after=true previous exists after=false
2020-12-03 07:23:39,063 [Listener at localhost/37545] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:39,064 [Listener at localhost/37545] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,066 [Listener at localhost/37545] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:39,072 [Listener at localhost/37545] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:39,075 [Listener at localhost/37545] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:39,075 [Listener at localhost/37545] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:39,076 [Listener at localhost/37545] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:39,087 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c779e5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:39,087 [Listener at localhost/37545] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:39,087 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,089 [Listener at localhost/37545] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:39,090 [Listener at localhost/37545] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:39,090 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,093 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:39,094 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:39,094 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:39,094 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:39,096 [Listener at localhost/37545] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:39,096 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:39,097 [Listener at localhost/37545] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40923
2020-12-03 07:23:39,097 [Listener at localhost/37545] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:39,107 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68e62ca4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:39,111 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b78fdb1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:39,138 [Listener at localhost/37545] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71a3a190{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:39,139 [Listener at localhost/37545] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@588ffeb{HTTP/1.1,[http/1.1]}{localhost:40923}
2020-12-03 07:23:39,140 [Listener at localhost/37545] INFO  server.Server (Server.java:doStart(419)) - Started @6908ms
2020-12-03 07:23:39,140 [Listener at localhost/37545] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,141 [Listener at localhost/37545] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,141 [Listener at localhost/37545] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:39,142 [Listener at localhost/37545] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:39,142 [Listener at localhost/37545] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,142 [Listener at localhost/37545] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,147 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:39,148 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:39,148 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:39,148 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:39,149 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:39,149 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:39,149 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:39,149 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:39,150 [Listener at localhost/37545] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:39,151 [Listener at localhost/37545] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:39,151 [Listener at localhost/37545] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:39,152 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:39,152 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:39
2020-12-03 07:23:39,152 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:39,153 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,153 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:39,153 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:39,168 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:39,169 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:39,170 [Listener at localhost/37545] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:39,170 [Listener at localhost/37545] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:39,170 [Listener at localhost/37545] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:39,171 [Listener at localhost/37545] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:39,171 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:39,171 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:39,171 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:39,172 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:39,172 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:39,172 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:39,172 [Listener at localhost/37545] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:39,173 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:39,173 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,174 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:39,174 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:39,182 [Listener at localhost/37545] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:39,182 [Listener at localhost/37545] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:39,182 [Listener at localhost/37545] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:39,182 [Listener at localhost/37545] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:39,182 [Listener at localhost/37545] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:39,183 [Listener at localhost/37545] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:39,183 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:39,183 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,183 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:39,184 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:39,186 [Listener at localhost/37545] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:39,186 [Listener at localhost/37545] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:39,186 [Listener at localhost/37545] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:39,187 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:39,187 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:39,187 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:39,187 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:39,188 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:39,188 [Listener at localhost/37545] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:39,217 [Listener at localhost/37545] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:39,219 [Listener at localhost/37545] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:39,220 [Listener at localhost/37545] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:39,224 [Listener at localhost/37545] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:39,228 [Listener at localhost/37545] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:39,228 [Listener at localhost/37545] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:39,232 [Listener at localhost/37545] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5b3f3ba0 expecting start txid #32
2020-12-03 07:23:39,233 [Listener at localhost/37545] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:39,234 [Listener at localhost/37545] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:39,291 [Listener at localhost/37545] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 29.0 ms
2020-12-03 07:23:39,292 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:39,293 [Listener at localhost/37545] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:39,364 [Listener at localhost/37545] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:39,365 [Listener at localhost/37545] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 175 msecs
2020-12-03 07:23:39,366 [Listener at localhost/37545] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:39,367 [Listener at localhost/37545] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,368 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,375 [Listener at localhost/37526] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37526 to access this namenode/service.
2020-12-03 07:23:39,376 [Listener at localhost/37526] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:39,377 [Listener at localhost/37526] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:39,388 [Listener at localhost/37526] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:39,391 [Listener at localhost/37526] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:39,397 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:39,403 [Listener at localhost/37526] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37526
2020-12-03 07:23:39,403 [Listener at localhost/37526] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:39,403 [Listener at localhost/37526] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:39,404 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:39,415 [Listener at localhost/37526] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 12 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:39,422 [CacheReplicationMonitor(8780073)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:39,463 [IPC Server handler 0 on default port 37526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,466 [Listener at localhost/37526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:39,826 [Listener at localhost/37526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:39,832 [Listener at localhost/37526] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:39,835 [Listener at localhost/37526] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:39,835 [Listener at localhost/37526] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:39,836 [Listener at localhost/37526] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:39,837 [Listener at localhost/37526] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:39,837 [Listener at localhost/37526] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:39,837 [Listener at localhost/37526] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:39,838 [Listener at localhost/37526] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39739
2020-12-03 07:23:39,839 [Listener at localhost/37526] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:39,839 [Listener at localhost/37526] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:39,841 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,843 [Listener at localhost/37526] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:39,845 [Listener at localhost/37526] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:39,845 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:39,852 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:39,853 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:39,854 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:39,854 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:39,855 [Listener at localhost/37526] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39690
2020-12-03 07:23:39,855 [Listener at localhost/37526] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:39,869 [Listener at localhost/37526] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72209d93{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:39,870 [Listener at localhost/37526] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1ded7b14{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:39,880 [Listener at localhost/37526] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b1e7ad3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:39,882 [Listener at localhost/37526] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63e5e5b4{HTTP/1.1,[http/1.1]}{localhost:39690}
2020-12-03 07:23:39,882 [Listener at localhost/37526] INFO  server.Server (Server.java:doStart(419)) - Started @7650ms
2020-12-03 07:23:39,996 [Listener at localhost/37526] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46798
2020-12-03 07:23:39,997 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a50ae65] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:39,997 [Listener at localhost/37526] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:39,997 [Listener at localhost/37526] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:39,998 [Listener at localhost/37526] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,999 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,013 [Listener at localhost/46600] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46600
2020-12-03 07:23:40,019 [Listener at localhost/46600] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:40,019 [Listener at localhost/46600] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:40,020 [Thread-183] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37526 starting to offer service
2020-12-03 07:23:40,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,048 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,068 [IPC Server handler 1 on default port 37526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,079 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:40,079 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:40,080 [Thread-183] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37526
2020-12-03 07:23:40,081 [Thread-183] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:40,111 [Thread-183] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:40,155 [Thread-183] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:40,156 [Thread-183] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:40,181 [IPC Server handler 4 on default port 37526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,182 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:40,182 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:40,187 [Thread-183] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:40,189 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-713cabed-c859-49b3-bef1-53b932f655d0
2020-12-03 07:23:40,189 [Thread-183] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:40,190 [Thread-183] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:40,191 [Thread-183] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:40,192 [Thread-183] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:40,192 [Thread-183] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:40,193 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:40,199 [Thread-195] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:23:40,211 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 18ms
2020-12-03 07:23:40,212 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 20ms
2020-12-03 07:23:40,215 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:40,219 [Thread-196] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:23:40,221 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 6ms
2020-12-03 07:23:40,223 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 10ms
2020-12-03 07:23:40,224 [Thread-183] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:44 AM with interval of 21600000ms
2020-12-03 07:23:40,230 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37526 beginning handshake with NN
2020-12-03 07:23:40,234 [IPC Server handler 5 on default port 37526] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39739, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=46798, infoSecurePort=0, ipcPort=46600, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:40,234 [IPC Server handler 5 on default port 37526] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39739
2020-12-03 07:23:40,234 [IPC Server handler 5 on default port 37526] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:39739).
2020-12-03 07:23:40,238 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37526 successfully registered with NN
2020-12-03 07:23:40,238 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37526 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:40,242 [IPC Server handler 6 on default port 37526] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-713cabed-c859-49b3-bef1-53b932f655d0 for DN 127.0.0.1:39739
2020-12-03 07:23:40,248 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6658ab6e8b467bd0: Processing first storage report for DS-713cabed-c859-49b3-bef1-53b932f655d0 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:40,250 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:40,251 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:40,251 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:40,251 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:40,251 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:40,257 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6658ab6e8b467bd0: from storage DS-713cabed-c859-49b3-bef1-53b932f655d0 node DatanodeRegistration(127.0.0.1:39739, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=46798, infoSecurePort=0, ipcPort=46600, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2020-12-03 07:23:40,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:40,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:40,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:40,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:40,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:40,266 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-12-03 07:23:40,268 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6658ab6e8b467bd0,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 1 msec to generate and 22 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:40,285 [IPC Server handler 9 on default port 37526] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,286 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:40,287 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:40,287 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:40,287 [Listener at localhost/46600] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:40,287 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60723d6a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:40,513 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b1e7ad3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:40,514 [Listener at localhost/46600] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63e5e5b4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:40,515 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1ded7b14{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:40,515 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72209d93{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:40,520 [Listener at localhost/46600] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46600
2020-12-03 07:23:40,535 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:40,536 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:40,537 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:40,540 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37526
2020-12-03 07:23:40,540 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:40,540 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37526] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:40,541 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:40,548 [Listener at localhost/46600] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:40,548 [Listener at localhost/46600] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:40,549 [Listener at localhost/46600] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:40,549 [Listener at localhost/46600] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:40,551 [Listener at localhost/46600] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:40,551 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:40,551 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:40,551 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@783ec989] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:40,552 [Listener at localhost/46600] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:40,552 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1ddd3478] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:40,553 [Listener at localhost/46600] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:40,554 [Listener at localhost/46600] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:40,555 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:40,555 [CacheReplicationMonitor(8780073)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:40,555 [Listener at localhost/46600] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37526
2020-12-03 07:23:40,557 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:40,558 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:40,588 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:40,589 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:40,609 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:40,610 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:40,612 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71a3a190{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:40,618 [Listener at localhost/46600] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@588ffeb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:40,619 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b78fdb1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:40,620 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68e62ca4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:40,629 [Listener at localhost/46600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:40,632 [Listener at localhost/46600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:40,633 [Listener at localhost/46600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:40,643 [Listener at localhost/46600] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:40,643 [Listener at localhost/46600] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 1*** BLOCK_POOL recovery: numDirs=1 testCase=1 current=true previous=true previous.tmp=false removed.tmp=false should recover=true current exists after=true previous exists after=true
2020-12-03 07:23:40,726 [Listener at localhost/46600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:40,726 [Listener at localhost/46600] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,727 [Listener at localhost/46600] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:40,731 [Listener at localhost/46600] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:40,740 [Listener at localhost/46600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:40,741 [Listener at localhost/46600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:40,742 [Listener at localhost/46600] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:40,755 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77ee25f1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,755 [Listener at localhost/46600] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:40,755 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,758 [Listener at localhost/46600] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,759 [Listener at localhost/46600] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:40,759 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,762 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,763 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:40,763 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,763 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,766 [Listener at localhost/46600] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:40,766 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:40,767 [Listener at localhost/46600] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46047
2020-12-03 07:23:40,767 [Listener at localhost/46600] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,779 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aa10649{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:40,779 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37095ded{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,786 [Listener at localhost/46600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@38548b19{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:40,787 [Listener at localhost/46600] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41aaedaa{HTTP/1.1,[http/1.1]}{localhost:46047}
2020-12-03 07:23:40,787 [Listener at localhost/46600] INFO  server.Server (Server.java:doStart(419)) - Started @8556ms
2020-12-03 07:23:40,788 [Listener at localhost/46600] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,788 [Listener at localhost/46600] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,788 [Listener at localhost/46600] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:40,788 [Listener at localhost/46600] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:40,789 [Listener at localhost/46600] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,789 [Listener at localhost/46600] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,790 [Listener at localhost/46600] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:40,791 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:40,792 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:40,795 [Listener at localhost/46600] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:40,795 [Listener at localhost/46600] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:40,796 [Listener at localhost/46600] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:40,796 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:40,797 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:40
2020-12-03 07:23:40,797 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:40,797 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:40,798 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:40,798 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:40,807 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:40,807 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:40,808 [Listener at localhost/46600] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:40,808 [Listener at localhost/46600] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:40,808 [Listener at localhost/46600] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:40,809 [Listener at localhost/46600] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:40,809 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:40,809 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:40,809 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:40,810 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:40,810 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:40,810 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:40,810 [Listener at localhost/46600] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:40,811 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:40,811 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:40,811 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:40,811 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:40,816 [Listener at localhost/46600] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:40,817 [Listener at localhost/46600] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:40,817 [Listener at localhost/46600] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:40,817 [Listener at localhost/46600] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:40,817 [Listener at localhost/46600] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:40,817 [Listener at localhost/46600] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:40,818 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:40,818 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:40,818 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:40,818 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:40,820 [Listener at localhost/46600] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:40,820 [Listener at localhost/46600] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:40,821 [Listener at localhost/46600] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:40,822 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:40,822 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:40,822 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:40,823 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:40,823 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:40,823 [Listener at localhost/46600] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:40,855 [Listener at localhost/46600] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:40,857 [Listener at localhost/46600] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:40,858 [Listener at localhost/46600] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:40,866 [Listener at localhost/46600] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:40,867 [Listener at localhost/46600] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:40,868 [Listener at localhost/46600] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:40,868 [Listener at localhost/46600] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@31fc71ab expecting start txid #32
2020-12-03 07:23:40,868 [Listener at localhost/46600] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:40,869 [Listener at localhost/46600] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:40,875 [Listener at localhost/46600] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 6.0 ms
2020-12-03 07:23:40,875 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:40,876 [Listener at localhost/46600] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:40,964 [Listener at localhost/46600] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:40,964 [Listener at localhost/46600] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 140 msecs
2020-12-03 07:23:40,965 [Listener at localhost/46600] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:40,966 [Listener at localhost/46600] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:40,972 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,978 [Listener at localhost/43640] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43640 to access this namenode/service.
2020-12-03 07:23:40,979 [Listener at localhost/43640] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:40,979 [Listener at localhost/43640] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:40,991 [Listener at localhost/43640] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:40,994 [Listener at localhost/43640] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:41,000 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:41,001 [Listener at localhost/43640] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43640
2020-12-03 07:23:41,002 [Listener at localhost/43640] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:41,008 [Listener at localhost/43640] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:41,010 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:41,013 [Listener at localhost/43640] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 4 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:41,035 [CacheReplicationMonitor(1295481680)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:41,048 [IPC Server handler 0 on default port 43640] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,051 [Listener at localhost/43640] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:41,461 [Listener at localhost/43640] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:41,463 [Listener at localhost/43640] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:41,464 [Listener at localhost/43640] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:41,464 [Listener at localhost/43640] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,464 [Listener at localhost/43640] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:41,465 [Listener at localhost/43640] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:41,465 [Listener at localhost/43640] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:41,466 [Listener at localhost/43640] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:41,467 [Listener at localhost/43640] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40823
2020-12-03 07:23:41,467 [Listener at localhost/43640] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:41,467 [Listener at localhost/43640] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:41,468 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,471 [Listener at localhost/43640] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:41,472 [Listener at localhost/43640] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:41,472 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:41,475 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:41,476 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:41,476 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:41,476 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:41,477 [Listener at localhost/43640] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45149
2020-12-03 07:23:41,478 [Listener at localhost/43640] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:41,480 [Listener at localhost/43640] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@659925f4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:41,481 [Listener at localhost/43640] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47f08b81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:41,498 [Listener at localhost/43640] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aa004a0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:41,499 [Listener at localhost/43640] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c98a6d5{HTTP/1.1,[http/1.1]}{localhost:45149}
2020-12-03 07:23:41,508 [Listener at localhost/43640] INFO  server.Server (Server.java:doStart(419)) - Started @9276ms
2020-12-03 07:23:41,543 [Listener at localhost/43640] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38434
2020-12-03 07:23:41,544 [Listener at localhost/43640] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:41,544 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f02251] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:41,544 [Listener at localhost/43640] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:41,545 [Listener at localhost/43640] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:41,546 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:41,561 [Listener at localhost/37030] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37030
2020-12-03 07:23:41,573 [Listener at localhost/37030] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:41,574 [Listener at localhost/37030] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:41,575 [Thread-254] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43640 starting to offer service
2020-12-03 07:23:41,575 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:41,576 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:41,630 [IPC Server handler 5 on default port 43640] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,647 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:41,649 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:41,657 [Thread-254] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43640
2020-12-03 07:23:41,668 [Thread-254] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:41,725 [Thread-254] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:41,752 [IPC Server handler 3 on default port 43640] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,754 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:41,754 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:41,762 [Thread-254] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:41,762 [Thread-254] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:41,802 [Thread-254] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:41,804 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c5a85d12-835f-4b30-a51d-2f20beda8b5e
2020-12-03 07:23:41,804 [Thread-254] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:41,804 [Thread-254] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:41,806 [Thread-254] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:41,807 [Thread-254] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:41,813 [Thread-254] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:41,814 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:41,829 [Thread-266] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:23:41,846 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 32ms
2020-12-03 07:23:41,848 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 35ms
2020-12-03 07:23:41,849 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:41,857 [IPC Server handler 6 on default port 43640] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,858 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:23:41,858 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 9ms
2020-12-03 07:23:41,858 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:41,858 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 10ms
2020-12-03 07:23:41,859 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:41,859 [Thread-254] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:24 AM with interval of 21600000ms
2020-12-03 07:23:41,861 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43640 beginning handshake with NN
2020-12-03 07:23:41,865 [IPC Server handler 2 on default port 43640] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40823, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=38434, infoSecurePort=0, ipcPort=37030, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:41,865 [IPC Server handler 2 on default port 43640] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40823
2020-12-03 07:23:41,865 [IPC Server handler 2 on default port 43640] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:40823).
2020-12-03 07:23:41,875 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43640 successfully registered with NN
2020-12-03 07:23:41,875 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43640 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:41,882 [IPC Server handler 1 on default port 43640] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5a85d12-835f-4b30-a51d-2f20beda8b5e for DN 127.0.0.1:40823
2020-12-03 07:23:41,886 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f45b6d8ab942215: Processing first storage report for DS-c5a85d12-835f-4b30-a51d-2f20beda8b5e from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:41,887 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:41,888 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:41,888 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:41,889 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:41,890 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:41,896 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f45b6d8ab942215: from storage DS-c5a85d12-835f-4b30-a51d-2f20beda8b5e node DatanodeRegistration(127.0.0.1:40823, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=38434, infoSecurePort=0, ipcPort=37030, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2020-12-03 07:23:41,904 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:41,905 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:41,905 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:41,905 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:41,905 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:41,905 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2020-12-03 07:23:41,908 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f45b6d8ab942215,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 22 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:41,961 [IPC Server handler 9 on default port 43640] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,962 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:41,963 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:41,963 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:41,963 [Listener at localhost/37030] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,964 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@48c4245d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:42,038 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@aa004a0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:42,046 [Listener at localhost/37030] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c98a6d5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:42,047 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47f08b81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:42,048 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@659925f4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:42,050 [Listener at localhost/37030] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37030
2020-12-03 07:23:42,058 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:42,058 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:42,059 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43640
2020-12-03 07:23:42,059 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:42,059 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43640] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:42,060 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:42,058 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:42,093 [Listener at localhost/37030] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:42,095 [Listener at localhost/37030] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:42,096 [Listener at localhost/37030] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:42,096 [Listener at localhost/37030] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:42,098 [Listener at localhost/37030] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:42,098 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:42,098 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:42,099 [Listener at localhost/37030] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:42,099 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@66596a88] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:42,101 [Listener at localhost/37030] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:23:42,102 [Listener at localhost/37030] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:42,103 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:42,103 [CacheReplicationMonitor(1295481680)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:42,104 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2a49fe] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:42,104 [Listener at localhost/37030] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43640
2020-12-03 07:23:42,120 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:42,121 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:42,122 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:42,122 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:42,161 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:42,162 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:42,163 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@38548b19{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:42,180 [Listener at localhost/37030] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41aaedaa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:42,181 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37095ded{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:42,182 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aa10649{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:42,186 [Listener at localhost/37030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:42,218 [Listener at localhost/37030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:42,219 [Listener at localhost/37030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:42,229 [Listener at localhost/37030] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:42,229 [Listener at localhost/37030] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 2*** BLOCK_POOL recovery: numDirs=1 testCase=2 current=true previous=false previous.tmp=true removed.tmp=false should recover=true current exists after=true previous exists after=true
2020-12-03 07:23:42,282 [Listener at localhost/37030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:42,283 [Listener at localhost/37030] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,284 [Listener at localhost/37030] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:42,287 [Listener at localhost/37030] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:42,289 [Listener at localhost/37030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:42,289 [Listener at localhost/37030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:42,290 [Listener at localhost/37030] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:42,299 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a627c80] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:42,299 [Listener at localhost/37030] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:42,299 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:42,301 [Listener at localhost/37030] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:42,302 [Listener at localhost/37030] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:42,302 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:42,305 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:42,306 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:42,306 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:42,307 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:42,309 [Listener at localhost/37030] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:42,309 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:42,310 [Listener at localhost/37030] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36839
2020-12-03 07:23:42,310 [Listener at localhost/37030] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:42,319 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67001148{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:42,320 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31cb96e1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:42,329 [Listener at localhost/37030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@af78c87{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:42,330 [Listener at localhost/37030] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@773dab28{HTTP/1.1,[http/1.1]}{localhost:36839}
2020-12-03 07:23:42,331 [Listener at localhost/37030] INFO  server.Server (Server.java:doStart(419)) - Started @10099ms
2020-12-03 07:23:42,331 [Listener at localhost/37030] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,331 [Listener at localhost/37030] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,332 [Listener at localhost/37030] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:42,332 [Listener at localhost/37030] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:42,338 [Listener at localhost/37030] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,339 [Listener at localhost/37030] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,341 [Listener at localhost/37030] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:42,341 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:42,342 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:42,342 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:42,342 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:42,343 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:42,343 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:42,343 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:42,344 [Listener at localhost/37030] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:42,344 [Listener at localhost/37030] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:42,345 [Listener at localhost/37030] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:42,345 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:42,346 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:42
2020-12-03 07:23:42,346 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:42,347 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:42,347 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:42,348 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:42,360 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:42,361 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:42,361 [Listener at localhost/37030] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:42,361 [Listener at localhost/37030] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:42,362 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:42,363 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:42,363 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:42,363 [Listener at localhost/37030] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:42,364 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:42,364 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:42,364 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:42,364 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:42,370 [Listener at localhost/37030] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:42,371 [Listener at localhost/37030] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:42,371 [Listener at localhost/37030] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:42,371 [Listener at localhost/37030] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:42,371 [Listener at localhost/37030] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:42,371 [Listener at localhost/37030] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:42,372 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:42,372 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:42,372 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:42,373 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:42,375 [Listener at localhost/37030] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:42,375 [Listener at localhost/37030] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:42,375 [Listener at localhost/37030] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:42,377 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:42,377 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:42,377 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:42,377 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:42,378 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:42,378 [Listener at localhost/37030] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:42,437 [Listener at localhost/37030] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:42,439 [Listener at localhost/37030] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:42,440 [Listener at localhost/37030] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:42,444 [Listener at localhost/37030] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:42,445 [Listener at localhost/37030] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:42,446 [Listener at localhost/37030] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:42,446 [Listener at localhost/37030] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@660591fb expecting start txid #32
2020-12-03 07:23:42,447 [Listener at localhost/37030] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:42,447 [Listener at localhost/37030] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:42,455 [Listener at localhost/37030] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 8.0 ms
2020-12-03 07:23:42,456 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:42,460 [Listener at localhost/37030] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:42,523 [Listener at localhost/37030] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:42,524 [Listener at localhost/37030] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 144 msecs
2020-12-03 07:23:42,524 [Listener at localhost/37030] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:42,525 [Listener at localhost/37030] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:42,527 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:42,539 [Listener at localhost/43293] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43293 to access this namenode/service.
2020-12-03 07:23:42,540 [Listener at localhost/43293] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:42,541 [Listener at localhost/43293] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:42,612 [Listener at localhost/43293] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:42,618 [Listener at localhost/43293] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:42,624 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:42,624 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:42,635 [Listener at localhost/43293] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43293
2020-12-03 07:23:42,638 [Listener at localhost/43293] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:42,638 [Listener at localhost/43293] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:42,646 [Listener at localhost/43293] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 7 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:42,672 [CacheReplicationMonitor(1521829280)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:42,689 [IPC Server handler 0 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:42,703 [Listener at localhost/43293] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:43,031 [Listener at localhost/43293] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:43,032 [Listener at localhost/43293] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:43,033 [Listener at localhost/43293] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:43,034 [Listener at localhost/43293] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:43,034 [Listener at localhost/43293] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:43,035 [Listener at localhost/43293] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:43,035 [Listener at localhost/43293] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:43,036 [Listener at localhost/43293] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:43,037 [Listener at localhost/43293] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40450
2020-12-03 07:23:43,037 [Listener at localhost/43293] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:43,037 [Listener at localhost/43293] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:43,040 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:43,042 [Listener at localhost/43293] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:43,043 [Listener at localhost/43293] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:43,044 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:43,046 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:43,047 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:43,047 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:43,048 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:43,050 [Listener at localhost/43293] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45126
2020-12-03 07:23:43,050 [Listener at localhost/43293] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:43,052 [Listener at localhost/43293] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@248deced{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:43,053 [Listener at localhost/43293] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e9804b9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:43,066 [Listener at localhost/43293] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29f0c4f2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:43,068 [Listener at localhost/43293] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7435a578{HTTP/1.1,[http/1.1]}{localhost:45126}
2020-12-03 07:23:43,068 [Listener at localhost/43293] INFO  server.Server (Server.java:doStart(419)) - Started @10836ms
2020-12-03 07:23:43,088 [Listener at localhost/43293] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41643
2020-12-03 07:23:43,089 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@13047d7d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:43,089 [Listener at localhost/43293] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:43,091 [Listener at localhost/43293] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:43,092 [Listener at localhost/43293] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:43,093 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:43,100 [Listener at localhost/39014] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39014
2020-12-03 07:23:43,106 [Listener at localhost/39014] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:43,107 [Listener at localhost/39014] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:43,108 [Thread-326] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43293 starting to offer service
2020-12-03 07:23:43,111 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:43,112 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:43,117 [IPC Server handler 2 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,145 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:43,145 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:43,146 [Thread-326] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43293
2020-12-03 07:23:43,148 [Thread-326] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:43,175 [Thread-326] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:43,247 [IPC Server handler 4 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,248 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:43,249 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:43,351 [IPC Server handler 5 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,352 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:43,352 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:43,356 [Thread-326] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:43,356 [Thread-326] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:43,357 [Thread-326] INFO  common.Storage (Storage.java:doRecover(792)) - Completing previous upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:43,455 [IPC Server handler 6 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,456 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:43,456 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:43,558 [IPC Server handler 7 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,559 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:43,559 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:43,602 [Thread-326] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:43,604 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a0901a0a-06c9-4212-a137-69472961f218
2020-12-03 07:23:43,605 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:43,605 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:43,607 [Thread-326] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:43,607 [Thread-326] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:43,608 [Thread-326] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:43,608 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:43,610 [Thread-338] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:23:43,620 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 11ms
2020-12-03 07:23:43,620 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 13ms
2020-12-03 07:23:43,621 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:43,627 [Thread-339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:23:43,628 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 7ms
2020-12-03 07:23:43,628 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 7ms
2020-12-03 07:23:43,629 [Thread-326] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:40 AM with interval of 21600000ms
2020-12-03 07:23:43,630 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43293 beginning handshake with NN
2020-12-03 07:23:43,633 [IPC Server handler 8 on default port 43293] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40450, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=41643, infoSecurePort=0, ipcPort=39014, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:43,634 [IPC Server handler 8 on default port 43293] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40450
2020-12-03 07:23:43,634 [IPC Server handler 8 on default port 43293] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:40450).
2020-12-03 07:23:43,645 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43293 successfully registered with NN
2020-12-03 07:23:43,645 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43293 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:43,650 [IPC Server handler 0 on default port 43293] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a0901a0a-06c9-4212-a137-69472961f218 for DN 127.0.0.1:40450
2020-12-03 07:23:43,656 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc5bbfa2ba7ab5cc0: Processing first storage report for DS-a0901a0a-06c9-4212-a137-69472961f218 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:43,657 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:43,667 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:43,672 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:23:43,672 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:43,673 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:43,682 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc5bbfa2ba7ab5cc0: from storage DS-a0901a0a-06c9-4212-a137-69472961f218 node DatanodeRegistration(127.0.0.1:40450, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=41643, infoSecurePort=0, ipcPort=39014, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 26 msecs, invalidatedBlocks: 0
2020-12-03 07:23:43,683 [IPC Server handler 3 on default port 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:43,684 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:43,685 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:43,685 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:43,686 [Listener at localhost/39014] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:43,686 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a10b263] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:43,694 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:43,700 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:43,700 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:43,700 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:43,701 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:43,701 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 28 msec
2020-12-03 07:23:43,747 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc5bbfa2ba7ab5cc0,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 53 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:43,763 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29f0c4f2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:43,764 [Listener at localhost/39014] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7435a578{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:43,765 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e9804b9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:43,765 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@248deced{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:43,773 [Listener at localhost/39014] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39014
2020-12-03 07:23:43,778 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:43,780 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:43,780 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:43,781 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43293
2020-12-03 07:23:43,781 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:43,781 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43293] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:43,796 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:43,816 [Listener at localhost/39014] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:43,816 [Listener at localhost/39014] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:43,817 [Listener at localhost/39014] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:43,817 [Listener at localhost/39014] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:43,819 [Listener at localhost/39014] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:43,819 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:43,819 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:43,820 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@765df79d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:43,820 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2bfbffb2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:43,820 [Listener at localhost/39014] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:43,822 [Listener at localhost/39014] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 11 
2020-12-03 07:23:43,824 [Listener at localhost/39014] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:43,824 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:43,824 [CacheReplicationMonitor(1521829280)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:43,825 [Listener at localhost/39014] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43293
2020-12-03 07:23:43,834 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:43,834 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:43,835 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:43,835 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:43,846 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:43,847 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:43,851 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@af78c87{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:43,852 [Listener at localhost/39014] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@773dab28{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:43,853 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31cb96e1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:43,854 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67001148{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:43,867 [Listener at localhost/39014] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:43,872 [Listener at localhost/39014] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:43,873 [Listener at localhost/39014] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:43,883 [Listener at localhost/39014] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:43,884 [Listener at localhost/39014] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 3*** BLOCK_POOL recovery: numDirs=1 testCase=3 current=true previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:43,943 [Listener at localhost/39014] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:43,944 [Listener at localhost/39014] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:43,945 [Listener at localhost/39014] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:43,949 [Listener at localhost/39014] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:43,951 [Listener at localhost/39014] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:43,951 [Listener at localhost/39014] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:43,952 [Listener at localhost/39014] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:43,963 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dcca8d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:43,963 [Listener at localhost/39014] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:43,964 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:43,966 [Listener at localhost/39014] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:43,973 [Listener at localhost/39014] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:43,974 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:43,977 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:43,979 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:43,980 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:43,980 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:43,982 [Listener at localhost/39014] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:43,982 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:43,983 [Listener at localhost/39014] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42554
2020-12-03 07:23:43,983 [Listener at localhost/39014] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:43,987 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e1f8469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:43,990 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b6c624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:44,009 [Listener at localhost/39014] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@46d8f407{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:44,010 [Listener at localhost/39014] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c0036b{HTTP/1.1,[http/1.1]}{localhost:42554}
2020-12-03 07:23:44,012 [Listener at localhost/39014] INFO  server.Server (Server.java:doStart(419)) - Started @11780ms
2020-12-03 07:23:44,012 [Listener at localhost/39014] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:44,013 [Listener at localhost/39014] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:44,013 [Listener at localhost/39014] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:44,013 [Listener at localhost/39014] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:44,014 [Listener at localhost/39014] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:44,021 [Listener at localhost/39014] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:44,023 [Listener at localhost/39014] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:44,023 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:44,023 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:44,024 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:44,024 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:44,024 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:44,024 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:44,025 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:44,026 [Listener at localhost/39014] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:44,026 [Listener at localhost/39014] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:44,026 [Listener at localhost/39014] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:44,027 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:44,027 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:44
2020-12-03 07:23:44,027 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:44,028 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:44,028 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:44,028 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:44,046 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:44,046 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:44,047 [Listener at localhost/39014] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:44,047 [Listener at localhost/39014] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:44,047 [Listener at localhost/39014] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:44,047 [Listener at localhost/39014] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:44,048 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:44,049 [Listener at localhost/39014] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:44,049 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:44,049 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:44,050 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:44,050 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:44,054 [Listener at localhost/39014] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:44,055 [Listener at localhost/39014] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:44,055 [Listener at localhost/39014] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:44,055 [Listener at localhost/39014] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:44,055 [Listener at localhost/39014] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:44,055 [Listener at localhost/39014] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:44,056 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:44,056 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:44,056 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:44,056 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:44,058 [Listener at localhost/39014] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:44,058 [Listener at localhost/39014] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:44,058 [Listener at localhost/39014] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:44,059 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:44,060 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:44,060 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:44,060 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:44,060 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:44,061 [Listener at localhost/39014] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:44,114 [Listener at localhost/39014] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:44,116 [Listener at localhost/39014] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:44,117 [Listener at localhost/39014] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:44,119 [Listener at localhost/39014] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:44,124 [Listener at localhost/39014] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:44,125 [Listener at localhost/39014] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:44,125 [Listener at localhost/39014] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@522ba524 expecting start txid #32
2020-12-03 07:23:44,125 [Listener at localhost/39014] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:44,125 [Listener at localhost/39014] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:44,130 [Listener at localhost/39014] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:23:44,130 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:44,131 [Listener at localhost/39014] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:44,186 [Listener at localhost/39014] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:44,186 [Listener at localhost/39014] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 124 msecs
2020-12-03 07:23:44,187 [Listener at localhost/39014] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:44,187 [Listener at localhost/39014] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:44,188 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:44,200 [Listener at localhost/35382] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35382 to access this namenode/service.
2020-12-03 07:23:44,216 [Listener at localhost/35382] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:44,218 [Listener at localhost/35382] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:44,283 [Listener at localhost/35382] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:44,286 [Listener at localhost/35382] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:44,292 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:44,292 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:44,296 [Listener at localhost/35382] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35382
2020-12-03 07:23:44,296 [Listener at localhost/35382] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:44,297 [Listener at localhost/35382] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:44,298 [Listener at localhost/35382] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:44,318 [CacheReplicationMonitor(1668423412)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:44,343 [IPC Server handler 0 on default port 35382] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:44,345 [Listener at localhost/35382] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:44,853 [Listener at localhost/35382] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:44,854 [Listener at localhost/35382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:44,855 [Listener at localhost/35382] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:44,855 [Listener at localhost/35382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:44,855 [Listener at localhost/35382] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:44,856 [Listener at localhost/35382] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:44,856 [Listener at localhost/35382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:44,856 [Listener at localhost/35382] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:44,857 [Listener at localhost/35382] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44368
2020-12-03 07:23:44,858 [Listener at localhost/35382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:44,858 [Listener at localhost/35382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:44,859 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:44,861 [Listener at localhost/35382] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:44,861 [Listener at localhost/35382] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:44,862 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:44,864 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:44,864 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:44,864 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:44,865 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:44,866 [Listener at localhost/35382] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34664
2020-12-03 07:23:44,866 [Listener at localhost/35382] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:44,867 [Listener at localhost/35382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a389173{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:44,868 [Listener at localhost/35382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ba89729{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:44,874 [Listener at localhost/35382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7c6442c2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:44,875 [Listener at localhost/35382] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2d746ce4{HTTP/1.1,[http/1.1]}{localhost:34664}
2020-12-03 07:23:44,875 [Listener at localhost/35382] INFO  server.Server (Server.java:doStart(419)) - Started @12644ms
2020-12-03 07:23:44,892 [Listener at localhost/35382] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37402
2020-12-03 07:23:44,892 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1948ea69] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:44,892 [Listener at localhost/35382] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:44,893 [Listener at localhost/35382] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:44,893 [Listener at localhost/35382] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:44,894 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:44,899 [Listener at localhost/33475] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33475
2020-12-03 07:23:44,905 [Listener at localhost/33475] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:44,905 [Listener at localhost/33475] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:44,906 [Thread-393] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35382 starting to offer service
2020-12-03 07:23:44,925 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:44,926 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:44,932 [IPC Server handler 1 on default port 35382] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:44,934 [Thread-393] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35382
2020-12-03 07:23:44,937 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:44,937 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:44,940 [Thread-393] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:44,984 [Thread-393] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:45,028 [Thread-393] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:45,028 [Thread-393] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:45,029 [Thread-393] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:45,031 [Thread-393] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:45,032 [Thread-393] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35382. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:45,032 [Thread-393] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35382
2020-12-03 07:23:45,032 [Thread-393] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:45,052 [IPC Server handler 3 on default port 35382] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,055 [Listener at localhost/33475] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:44368', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:35382
2020-12-03 07:23:45,056 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:45,056 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:45,056 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:45,060 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@9d200de] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:45,103 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7c6442c2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:45,104 [Listener at localhost/33475] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2d746ce4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,104 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ba89729{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:45,105 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a389173{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:45,105 [Listener at localhost/33475] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33475
2020-12-03 07:23:45,109 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,110 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,123 [Listener at localhost/33475] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:45,123 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:45,124 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:45,124 [Listener at localhost/33475] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:45,125 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6a9d5dff] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:45,127 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@48b22fd4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:45,127 [Listener at localhost/33475] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:45,128 [Listener at localhost/33475] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:45,129 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:45,129 [CacheReplicationMonitor(1668423412)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:45,130 [Listener at localhost/33475] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35382
2020-12-03 07:23:45,132 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,135 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:45,135 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,135 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:45,158 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:45,158 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:45,160 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@46d8f407{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:45,162 [Listener at localhost/33475] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c0036b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,163 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b6c624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:45,163 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e1f8469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:45,166 [Listener at localhost/33475] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:45,174 [Listener at localhost/33475] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:45,175 [Listener at localhost/33475] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:45,193 [Listener at localhost/33475] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:45,194 [Listener at localhost/33475] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 4*** BLOCK_POOL recovery: numDirs=1 testCase=4 current=true previous=true previous.tmp=true removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:45,247 [Listener at localhost/33475] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:45,248 [Listener at localhost/33475] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,249 [Listener at localhost/33475] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:45,251 [Listener at localhost/33475] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:45,253 [Listener at localhost/33475] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:45,253 [Listener at localhost/33475] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:45,254 [Listener at localhost/33475] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:45,265 [Listener at localhost/33475] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:45,265 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,265 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38a1c423] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:45,267 [Listener at localhost/33475] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:45,269 [Listener at localhost/33475] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:45,269 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,271 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:45,271 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:45,272 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:45,272 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:45,273 [Listener at localhost/33475] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:45,273 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:45,274 [Listener at localhost/33475] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40379
2020-12-03 07:23:45,274 [Listener at localhost/33475] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:45,276 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ac04654{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:45,277 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ed0918d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:45,283 [Listener at localhost/33475] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@b8a7e43{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:45,289 [Listener at localhost/33475] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@11f87beb{HTTP/1.1,[http/1.1]}{localhost:40379}
2020-12-03 07:23:45,290 [Listener at localhost/33475] INFO  server.Server (Server.java:doStart(419)) - Started @13058ms
2020-12-03 07:23:45,290 [Listener at localhost/33475] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,290 [Listener at localhost/33475] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,291 [Listener at localhost/33475] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:45,291 [Listener at localhost/33475] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:45,291 [Listener at localhost/33475] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,291 [Listener at localhost/33475] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,292 [Listener at localhost/33475] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:45,293 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:45,293 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:45,293 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:45,293 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:45,294 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:45,294 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:45,294 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:45,295 [Listener at localhost/33475] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:45,295 [Listener at localhost/33475] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:45,295 [Listener at localhost/33475] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:45,295 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:45,296 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:45
2020-12-03 07:23:45,296 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:45,296 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,297 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:45,297 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:45,309 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:45,309 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:45,310 [Listener at localhost/33475] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:45,310 [Listener at localhost/33475] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:45,310 [Listener at localhost/33475] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:45,310 [Listener at localhost/33475] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:45,310 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:45,311 [Listener at localhost/33475] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:45,312 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:45,312 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,312 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:45,313 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:45,320 [Listener at localhost/33475] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:45,321 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:45,321 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,322 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:45,322 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:45,325 [Listener at localhost/33475] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:45,325 [Listener at localhost/33475] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:45,325 [Listener at localhost/33475] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:45,326 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:45,326 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:45,327 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:45,327 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:45,327 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:45,327 [Listener at localhost/33475] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:45,361 [Listener at localhost/33475] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:45,363 [Listener at localhost/33475] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:45,364 [Listener at localhost/33475] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:45,366 [Listener at localhost/33475] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:45,373 [Listener at localhost/33475] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:45,374 [Listener at localhost/33475] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:45,374 [Listener at localhost/33475] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6fd1660 expecting start txid #32
2020-12-03 07:23:45,374 [Listener at localhost/33475] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:45,375 [Listener at localhost/33475] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:45,378 [Listener at localhost/33475] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:23:45,378 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:45,379 [Listener at localhost/33475] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:45,420 [Listener at localhost/33475] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:45,421 [Listener at localhost/33475] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 92 msecs
2020-12-03 07:23:45,421 [Listener at localhost/33475] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:45,422 [Listener at localhost/33475] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:45,424 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:45,432 [Listener at localhost/33281] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33281 to access this namenode/service.
2020-12-03 07:23:45,436 [Listener at localhost/33281] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:45,436 [Listener at localhost/33281] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:45,493 [Listener at localhost/33281] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:45,513 [Listener at localhost/33281] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:45,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:45,524 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:45,528 [Listener at localhost/33281] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33281
2020-12-03 07:23:45,529 [Listener at localhost/33281] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:45,529 [Listener at localhost/33281] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:45,568 [Listener at localhost/33281] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 39 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:45,578 [CacheReplicationMonitor(1633481870)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:45,588 [IPC Server handler 0 on default port 33281] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,608 [Listener at localhost/33281] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:46,429 [Listener at localhost/33281] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:46,430 [Listener at localhost/33281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:46,437 [Listener at localhost/33281] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:46,438 [Listener at localhost/33281] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,438 [Listener at localhost/33281] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:46,438 [Listener at localhost/33281] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:46,439 [Listener at localhost/33281] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,439 [Listener at localhost/33281] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:46,440 [Listener at localhost/33281] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34436
2020-12-03 07:23:46,440 [Listener at localhost/33281] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:46,440 [Listener at localhost/33281] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:46,443 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,445 [Listener at localhost/33281] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:46,448 [Listener at localhost/33281] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:46,449 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,452 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:46,452 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:46,453 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:46,453 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:46,454 [Listener at localhost/33281] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46673
2020-12-03 07:23:46,454 [Listener at localhost/33281] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:46,457 [Listener at localhost/33281] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ec25216{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:46,458 [Listener at localhost/33281] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a84bc3f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:46,477 [Listener at localhost/33281] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58294867{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:46,478 [Listener at localhost/33281] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67c277a0{HTTP/1.1,[http/1.1]}{localhost:46673}
2020-12-03 07:23:46,478 [Listener at localhost/33281] INFO  server.Server (Server.java:doStart(419)) - Started @14247ms
2020-12-03 07:23:46,515 [Listener at localhost/33281] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34414
2020-12-03 07:23:46,516 [Listener at localhost/33281] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:46,516 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fa76c61] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:46,516 [Listener at localhost/33281] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:46,521 [Listener at localhost/33281] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:46,522 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:46,532 [Listener at localhost/37127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37127
2020-12-03 07:23:46,552 [Listener at localhost/37127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:46,553 [Listener at localhost/37127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:46,554 [Thread-455] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33281 starting to offer service
2020-12-03 07:23:46,560 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,562 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:46,583 [IPC Server handler 0 on default port 33281] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:46,585 [Thread-455] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33281
2020-12-03 07:23:46,588 [Thread-455] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:46,588 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:46,589 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:46,645 [Thread-455] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:46,682 [Thread-455] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:46,682 [Thread-455] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:46,682 [Thread-455] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:46,683 [Thread-455] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:46,683 [Thread-455] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33281. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:46,683 [Thread-455] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33281
2020-12-03 07:23:46,684 [Thread-455] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:46,693 [IPC Server handler 2 on default port 33281] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:46,695 [Listener at localhost/37127] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:34436', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:33281
2020-12-03 07:23:46,696 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:46,696 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:46,696 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:46,696 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3cbcd8f3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:46,729 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58294867{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:46,730 [Listener at localhost/37127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67c277a0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,731 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a84bc3f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:46,731 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ec25216{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:46,732 [Listener at localhost/37127] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37127
2020-12-03 07:23:46,734 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,761 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,766 [Listener at localhost/37127] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:46,766 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:46,767 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,772 [Listener at localhost/37127] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:46,772 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4ed38226] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:46,772 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3d43fe] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:46,774 [Listener at localhost/37127] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:23:46,775 [Listener at localhost/37127] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:46,775 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:46,776 [CacheReplicationMonitor(1633481870)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:46,777 [Listener at localhost/37127] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33281
2020-12-03 07:23:46,779 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,780 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:46,780 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:46,783 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,794 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,797 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,798 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@b8a7e43{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:46,801 [Listener at localhost/37127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@11f87beb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,801 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ed0918d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:46,802 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ac04654{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:46,815 [Listener at localhost/37127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:46,821 [Listener at localhost/37127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:46,822 [Listener at localhost/37127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:46,837 [Listener at localhost/37127] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:46,838 [Listener at localhost/37127] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 5*** BLOCK_POOL recovery: numDirs=1 testCase=5 current=false previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:46,911 [Listener at localhost/37127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:46,911 [Listener at localhost/37127] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:46,912 [Listener at localhost/37127] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:46,923 [Listener at localhost/37127] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:46,925 [Listener at localhost/37127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:46,925 [Listener at localhost/37127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:46,926 [Listener at localhost/37127] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:46,935 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a0df195] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:46,935 [Listener at localhost/37127] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:46,935 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,937 [Listener at localhost/37127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:46,938 [Listener at localhost/37127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:46,938 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:46,944 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:46,945 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:46,945 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:46,945 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:46,947 [Listener at localhost/37127] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:46,947 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:46,948 [Listener at localhost/37127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43074
2020-12-03 07:23:46,948 [Listener at localhost/37127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:46,951 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f829c76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:46,952 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c3ebc6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:46,958 [Listener at localhost/37127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9d1a267{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:46,959 [Listener at localhost/37127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58a4a74d{HTTP/1.1,[http/1.1]}{localhost:43074}
2020-12-03 07:23:46,963 [Listener at localhost/37127] INFO  server.Server (Server.java:doStart(419)) - Started @14732ms
2020-12-03 07:23:46,964 [Listener at localhost/37127] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:46,964 [Listener at localhost/37127] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:46,964 [Listener at localhost/37127] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:46,964 [Listener at localhost/37127] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:46,965 [Listener at localhost/37127] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:46,965 [Listener at localhost/37127] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:46,966 [Listener at localhost/37127] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:46,966 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:46,967 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:46,967 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:46,967 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:46,967 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:46,967 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:46,968 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:46,968 [Listener at localhost/37127] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,968 [Listener at localhost/37127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:46,969 [Listener at localhost/37127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:46,969 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:46,969 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:46
2020-12-03 07:23:46,969 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:46,970 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,970 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:46,970 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:46,987 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:46,988 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:46,988 [Listener at localhost/37127] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:46,988 [Listener at localhost/37127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:46,988 [Listener at localhost/37127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:46,989 [Listener at localhost/37127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:46,989 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:46,989 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:46,989 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:46,996 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:46,996 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:46,997 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:46,997 [Listener at localhost/37127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:46,997 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:46,997 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,998 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:46,998 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:47,005 [Listener at localhost/37127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:47,005 [Listener at localhost/37127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:47,005 [Listener at localhost/37127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:47,006 [Listener at localhost/37127] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:47,006 [Listener at localhost/37127] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:47,006 [Listener at localhost/37127] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:47,006 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:47,007 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:47,007 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:47,007 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:47,010 [Listener at localhost/37127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:47,010 [Listener at localhost/37127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:47,010 [Listener at localhost/37127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:47,011 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:47,012 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:47,012 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:47,012 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:47,013 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:47,013 [Listener at localhost/37127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:47,105 [Listener at localhost/37127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:47,107 [Listener at localhost/37127] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:47,108 [Listener at localhost/37127] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:47,110 [Listener at localhost/37127] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:47,113 [Listener at localhost/37127] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:47,113 [Listener at localhost/37127] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:47,114 [Listener at localhost/37127] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3eee3e2b expecting start txid #32
2020-12-03 07:23:47,114 [Listener at localhost/37127] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:47,115 [Listener at localhost/37127] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:47,120 [Listener at localhost/37127] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 5.0 ms
2020-12-03 07:23:47,120 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:47,121 [Listener at localhost/37127] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:47,270 [Listener at localhost/37127] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:47,270 [Listener at localhost/37127] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 256 msecs
2020-12-03 07:23:47,271 [Listener at localhost/37127] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:47,272 [Listener at localhost/37127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:47,273 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:47,281 [Listener at localhost/44774] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:44774 to access this namenode/service.
2020-12-03 07:23:47,282 [Listener at localhost/44774] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:47,283 [Listener at localhost/44774] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:47,299 [Listener at localhost/44774] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:47,303 [Listener at localhost/44774] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:47,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:47,308 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:47,311 [Listener at localhost/44774] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44774
2020-12-03 07:23:47,313 [Listener at localhost/44774] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:47,313 [Listener at localhost/44774] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:47,316 [Listener at localhost/44774] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:47,320 [CacheReplicationMonitor(1884946610)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:47,328 [IPC Server handler 0 on default port 44774] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,346 [Listener at localhost/44774] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:47,814 [Listener at localhost/44774] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:47,815 [Listener at localhost/44774] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:47,817 [Listener at localhost/44774] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:47,817 [Listener at localhost/44774] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:47,817 [Listener at localhost/44774] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:47,818 [Listener at localhost/44774] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:47,818 [Listener at localhost/44774] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:47,818 [Listener at localhost/44774] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:47,819 [Listener at localhost/44774] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34156
2020-12-03 07:23:47,819 [Listener at localhost/44774] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:47,819 [Listener at localhost/44774] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:47,821 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:47,822 [Listener at localhost/44774] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:47,823 [Listener at localhost/44774] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:47,823 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:47,826 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:47,827 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:47,827 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:47,827 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:47,828 [Listener at localhost/44774] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42222
2020-12-03 07:23:47,829 [Listener at localhost/44774] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:47,831 [Listener at localhost/44774] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c6e0f32{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:47,832 [Listener at localhost/44774] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21a66d45{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:47,840 [Listener at localhost/44774] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4e61e4c2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:47,842 [Listener at localhost/44774] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c6a6c1d{HTTP/1.1,[http/1.1]}{localhost:42222}
2020-12-03 07:23:47,842 [Listener at localhost/44774] INFO  server.Server (Server.java:doStart(419)) - Started @15610ms
2020-12-03 07:23:47,889 [Listener at localhost/44774] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43201
2020-12-03 07:23:47,890 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4f82663e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:47,890 [Listener at localhost/44774] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:47,890 [Listener at localhost/44774] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:47,891 [Listener at localhost/44774] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:47,892 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:47,900 [Listener at localhost/44656] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44656
2020-12-03 07:23:47,907 [Listener at localhost/44656] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:47,908 [Listener at localhost/44656] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:47,909 [Thread-516] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44774 starting to offer service
2020-12-03 07:23:47,911 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:47,911 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:47,926 [IPC Server handler 2 on default port 44774] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:47,928 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:47,928 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:47,933 [Thread-516] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44774
2020-12-03 07:23:47,934 [Thread-516] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:48,003 [Thread-516] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:48,030 [IPC Server handler 3 on default port 44774] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,031 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:48,031 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:48,048 [Thread-516] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:48,048 [Thread-516] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:48,048 [Thread-516] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:48,049 [Thread-516] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:48,050 [Thread-516] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:44774. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:48,050 [Thread-516] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:44774
2020-12-03 07:23:48,050 [Thread-516] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:48,133 [IPC Server handler 4 on default port 44774] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,134 [Listener at localhost/44656] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:34156', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:44774
2020-12-03 07:23:48,135 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:48,135 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:48,135 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:48,136 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b29d52b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,205 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4e61e4c2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,209 [Listener at localhost/44656] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c6a6c1d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,210 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21a66d45{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,210 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c6e0f32{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,213 [Listener at localhost/44656] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44656
2020-12-03 07:23:48,214 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,227 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,229 [Listener at localhost/44656] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,230 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:48,230 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:48,236 [Listener at localhost/44656] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:48,236 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6a0659ac] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:48,236 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1dc2de84] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:48,238 [Listener at localhost/44656] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 4 
2020-12-03 07:23:48,249 [Listener at localhost/44656] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:48,260 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:48,260 [CacheReplicationMonitor(1884946610)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:48,266 [Listener at localhost/44656] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44774
2020-12-03 07:23:48,278 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,278 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:48,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,284 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:48,316 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:48,317 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:48,319 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9d1a267{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:48,321 [Listener at localhost/44656] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58a4a74d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,322 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c3ebc6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,322 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f829c76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,323 [Listener at localhost/44656] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:48,326 [Listener at localhost/44656] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:48,326 [Listener at localhost/44656] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:48,336 [Listener at localhost/44656] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:48,336 [Listener at localhost/44656] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 6*** BLOCK_POOL recovery: numDirs=1 testCase=6 current=false previous=true previous.tmp=true removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:48,396 [Listener at localhost/44656] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:48,396 [Listener at localhost/44656] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,397 [Listener at localhost/44656] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:48,401 [Listener at localhost/44656] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:48,402 [Listener at localhost/44656] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:48,403 [Listener at localhost/44656] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:48,403 [Listener at localhost/44656] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:48,412 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ee8dcd3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:48,412 [Listener at localhost/44656] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:48,413 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:48,415 [Listener at localhost/44656] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:48,416 [Listener at localhost/44656] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:48,416 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:48,419 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:48,423 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:48,424 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:48,425 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:48,427 [Listener at localhost/44656] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:48,429 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:48,430 [Listener at localhost/44656] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45778
2020-12-03 07:23:48,431 [Listener at localhost/44656] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:48,435 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16073fa8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:48,437 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cfbc8e8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:48,445 [Listener at localhost/44656] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@344426bf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:48,446 [Listener at localhost/44656] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5411dd90{HTTP/1.1,[http/1.1]}{localhost:45778}
2020-12-03 07:23:48,447 [Listener at localhost/44656] INFO  server.Server (Server.java:doStart(419)) - Started @16215ms
2020-12-03 07:23:48,448 [Listener at localhost/44656] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,463 [Listener at localhost/44656] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,464 [Listener at localhost/44656] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:48,464 [Listener at localhost/44656] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:48,464 [Listener at localhost/44656] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,465 [Listener at localhost/44656] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,467 [Listener at localhost/44656] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:48,467 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:48,467 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:48,468 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:48,468 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:48,468 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:48,468 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:48,469 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:48,469 [Listener at localhost/44656] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:48,470 [Listener at localhost/44656] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:48,470 [Listener at localhost/44656] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:48,470 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:48,471 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:48
2020-12-03 07:23:48,471 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:48,471 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,472 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:48,472 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:48,484 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:48,484 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:48,485 [Listener at localhost/44656] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:48,485 [Listener at localhost/44656] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:48,485 [Listener at localhost/44656] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:48,485 [Listener at localhost/44656] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:48,486 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:48,487 [Listener at localhost/44656] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:48,488 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:48,488 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,488 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:48,488 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:48,495 [Listener at localhost/44656] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:48,496 [Listener at localhost/44656] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:48,496 [Listener at localhost/44656] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:48,496 [Listener at localhost/44656] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:48,497 [Listener at localhost/44656] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:48,497 [Listener at localhost/44656] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:48,497 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:48,497 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,498 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:48,498 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:48,500 [Listener at localhost/44656] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:48,501 [Listener at localhost/44656] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:48,501 [Listener at localhost/44656] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:48,503 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:48,503 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:48,503 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:48,504 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,504 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:48,504 [Listener at localhost/44656] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:48,556 [Listener at localhost/44656] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:48,559 [Listener at localhost/44656] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:48,560 [Listener at localhost/44656] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:48,576 [Listener at localhost/44656] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:48,578 [Listener at localhost/44656] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:48,578 [Listener at localhost/44656] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:48,579 [Listener at localhost/44656] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@408b87aa expecting start txid #32
2020-12-03 07:23:48,579 [Listener at localhost/44656] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:48,579 [Listener at localhost/44656] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:48,592 [Listener at localhost/44656] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 12.0 ms
2020-12-03 07:23:48,593 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:48,596 [Listener at localhost/44656] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:48,639 [Listener at localhost/44656] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:48,639 [Listener at localhost/44656] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 134 msecs
2020-12-03 07:23:48,640 [Listener at localhost/44656] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:48,641 [Listener at localhost/44656] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:48,642 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:48,647 [Listener at localhost/36169] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36169 to access this namenode/service.
2020-12-03 07:23:48,657 [Listener at localhost/36169] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:48,657 [Listener at localhost/36169] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:48,691 [Listener at localhost/36169] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:48,695 [Listener at localhost/36169] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:48,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:48,700 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:48,728 [Listener at localhost/36169] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36169
2020-12-03 07:23:48,728 [Listener at localhost/36169] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:48,729 [Listener at localhost/36169] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:48,734 [Listener at localhost/36169] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 6 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:48,758 [CacheReplicationMonitor(984860123)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:48,778 [IPC Server handler 1 on default port 36169] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:48,780 [Listener at localhost/36169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:49,136 [Listener at localhost/36169] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:49,137 [Listener at localhost/36169] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:49,139 [Listener at localhost/36169] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:49,139 [Listener at localhost/36169] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:49,139 [Listener at localhost/36169] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:49,140 [Listener at localhost/36169] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:49,140 [Listener at localhost/36169] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:49,140 [Listener at localhost/36169] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:49,141 [Listener at localhost/36169] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43021
2020-12-03 07:23:49,141 [Listener at localhost/36169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:49,141 [Listener at localhost/36169] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:49,142 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,144 [Listener at localhost/36169] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:49,145 [Listener at localhost/36169] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:49,145 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,147 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:49,148 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:49,148 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:49,148 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:49,149 [Listener at localhost/36169] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38691
2020-12-03 07:23:49,149 [Listener at localhost/36169] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:49,153 [Listener at localhost/36169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@327c7bea{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:49,154 [Listener at localhost/36169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c65860d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:49,162 [Listener at localhost/36169] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34e20e6b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:49,163 [Listener at localhost/36169] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15ac59c2{HTTP/1.1,[http/1.1]}{localhost:38691}
2020-12-03 07:23:49,163 [Listener at localhost/36169] INFO  server.Server (Server.java:doStart(419)) - Started @16931ms
2020-12-03 07:23:49,198 [Listener at localhost/36169] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44785
2020-12-03 07:23:49,198 [Listener at localhost/36169] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:49,198 [Listener at localhost/36169] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:49,200 [Listener at localhost/36169] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:49,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6eb82908] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:49,201 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:49,228 [Listener at localhost/45786] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45786
2020-12-03 07:23:49,235 [Listener at localhost/45786] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:49,236 [Listener at localhost/45786] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:49,240 [Thread-577] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36169 starting to offer service
2020-12-03 07:23:49,245 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:49,245 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:49,289 [IPC Server handler 2 on default port 36169] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:49,291 [Thread-577] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36169
2020-12-03 07:23:49,292 [Thread-577] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:49,292 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:49,293 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:49,332 [Thread-577] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:49,392 [Thread-577] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:49,392 [Thread-577] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:49,392 [Thread-577] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:49,393 [Thread-577] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:49,393 [Thread-577] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36169. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:49,393 [Thread-577] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36169
2020-12-03 07:23:49,394 [Thread-577] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:49,395 [IPC Server handler 5 on default port 36169] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:49,395 [Listener at localhost/45786] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:43021', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:36169
2020-12-03 07:23:49,396 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:49,396 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:49,396 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:49,397 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3910fe11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:49,454 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34e20e6b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:49,455 [Listener at localhost/45786] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15ac59c2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:49,455 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c65860d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,455 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@327c7bea{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:49,481 [Listener at localhost/45786] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45786
2020-12-03 07:23:49,484 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,484 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,490 [Listener at localhost/45786] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:49,490 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:49,491 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:49,493 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3b05a99b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:49,493 [Listener at localhost/45786] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:49,493 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2c43eb8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:49,508 [Listener at localhost/45786] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 7 
2020-12-03 07:23:49,510 [Listener at localhost/45786] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:49,510 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:49,510 [CacheReplicationMonitor(984860123)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:49,528 [Listener at localhost/45786] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36169
2020-12-03 07:23:49,532 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,540 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,544 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:49,551 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:49,561 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:49,562 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:49,563 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@344426bf{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:49,565 [Listener at localhost/45786] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5411dd90{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:49,565 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cfbc8e8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,566 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16073fa8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:49,568 [Listener at localhost/45786] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:49,569 [Listener at localhost/45786] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:49,569 [Listener at localhost/45786] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:49,578 [Listener at localhost/45786] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:49,578 [Listener at localhost/45786] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 7*** BLOCK_POOL recovery: numDirs=1 testCase=7 current=false previous=false previous.tmp=false removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:49,637 [Listener at localhost/45786] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:49,638 [Listener at localhost/45786] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,639 [Listener at localhost/45786] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:49,642 [Listener at localhost/45786] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:49,643 [Listener at localhost/45786] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:49,644 [Listener at localhost/45786] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:49,645 [Listener at localhost/45786] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:49,653 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26f7cdf8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:49,653 [Listener at localhost/45786] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:49,654 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,656 [Listener at localhost/45786] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:49,656 [Listener at localhost/45786] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:49,657 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,659 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:49,660 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:49,660 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:49,660 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:49,662 [Listener at localhost/45786] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:49,663 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:49,663 [Listener at localhost/45786] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34460
2020-12-03 07:23:49,663 [Listener at localhost/45786] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:49,666 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29629fbb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:49,667 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3506d826{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:49,673 [Listener at localhost/45786] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@280e8a1a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:49,674 [Listener at localhost/45786] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@11e33bac{HTTP/1.1,[http/1.1]}{localhost:34460}
2020-12-03 07:23:49,675 [Listener at localhost/45786] INFO  server.Server (Server.java:doStart(419)) - Started @17443ms
2020-12-03 07:23:49,675 [Listener at localhost/45786] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,675 [Listener at localhost/45786] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,675 [Listener at localhost/45786] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:49,676 [Listener at localhost/45786] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:49,676 [Listener at localhost/45786] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,676 [Listener at localhost/45786] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,679 [Listener at localhost/45786] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:49,679 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:49,680 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:49,680 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:49,680 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:49,680 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:49,680 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:49,681 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:49,681 [Listener at localhost/45786] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:49,681 [Listener at localhost/45786] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:49,682 [Listener at localhost/45786] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:49,682 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:49,682 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:49
2020-12-03 07:23:49,682 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:49,683 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,683 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:49,683 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:49,698 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:49,698 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:49,699 [Listener at localhost/45786] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:49,699 [Listener at localhost/45786] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:49,699 [Listener at localhost/45786] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:49,699 [Listener at localhost/45786] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:49,700 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:49,701 [Listener at localhost/45786] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:49,701 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:49,701 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,701 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:49,702 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:49,714 [Listener at localhost/45786] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:49,714 [Listener at localhost/45786] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:49,714 [Listener at localhost/45786] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:49,715 [Listener at localhost/45786] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:49,715 [Listener at localhost/45786] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:49,715 [Listener at localhost/45786] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:49,715 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:49,715 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,716 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:49,716 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:49,719 [Listener at localhost/45786] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:49,719 [Listener at localhost/45786] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:49,719 [Listener at localhost/45786] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:49,720 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:49,720 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:49,721 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:49,721 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,721 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:49,721 [Listener at localhost/45786] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:49,754 [Listener at localhost/45786] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:49,757 [Listener at localhost/45786] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:49,760 [Listener at localhost/45786] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:49,762 [Listener at localhost/45786] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:49,766 [Listener at localhost/45786] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:49,767 [Listener at localhost/45786] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:49,767 [Listener at localhost/45786] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5ff2e84b expecting start txid #32
2020-12-03 07:23:49,767 [Listener at localhost/45786] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:49,768 [Listener at localhost/45786] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:49,771 [Listener at localhost/45786] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:23:49,771 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:49,774 [Listener at localhost/45786] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:49,805 [Listener at localhost/45786] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:49,805 [Listener at localhost/45786] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 83 msecs
2020-12-03 07:23:49,806 [Listener at localhost/45786] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:49,806 [Listener at localhost/45786] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:49,808 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:49,831 [Listener at localhost/33211] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33211 to access this namenode/service.
2020-12-03 07:23:49,831 [Listener at localhost/33211] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:49,832 [Listener at localhost/33211] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:49,844 [Listener at localhost/33211] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:49,846 [Listener at localhost/33211] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:49,850 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:49,855 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:49,858 [Listener at localhost/33211] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33211
2020-12-03 07:23:49,858 [Listener at localhost/33211] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:49,859 [Listener at localhost/33211] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:49,865 [Listener at localhost/33211] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:49,869 [CacheReplicationMonitor(2141418829)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:49,902 [IPC Server handler 0 on default port 33211] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:49,903 [Listener at localhost/33211] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:50,036 [Listener at localhost/33211] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:50,038 [Listener at localhost/33211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:50,041 [Listener at localhost/33211] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:50,041 [Listener at localhost/33211] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,042 [Listener at localhost/33211] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:50,042 [Listener at localhost/33211] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:50,042 [Listener at localhost/33211] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,043 [Listener at localhost/33211] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:50,044 [Listener at localhost/33211] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42563
2020-12-03 07:23:50,044 [Listener at localhost/33211] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:50,044 [Listener at localhost/33211] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:50,045 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,047 [Listener at localhost/33211] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,049 [Listener at localhost/33211] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:50,049 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,051 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,052 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:50,052 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,053 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,054 [Listener at localhost/33211] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38093
2020-12-03 07:23:50,054 [Listener at localhost/33211] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,056 [Listener at localhost/33211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@724c5cbe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,057 [Listener at localhost/33211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e889e9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,061 [Listener at localhost/33211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a55f148{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:50,062 [Listener at localhost/33211] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e2f720{HTTP/1.1,[http/1.1]}{localhost:38093}
2020-12-03 07:23:50,072 [Listener at localhost/33211] INFO  server.Server (Server.java:doStart(419)) - Started @17830ms
2020-12-03 07:23:50,095 [Listener at localhost/33211] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43547
2020-12-03 07:23:50,096 [Listener at localhost/33211] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:50,096 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f572c37] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,096 [Listener at localhost/33211] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:50,096 [Listener at localhost/33211] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:50,097 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:50,103 [Listener at localhost/40188] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40188
2020-12-03 07:23:50,111 [Listener at localhost/40188] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:50,111 [Listener at localhost/40188] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:50,112 [Thread-638] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33211 starting to offer service
2020-12-03 07:23:50,132 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,142 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,156 [IPC Server handler 1 on default port 33211] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,177 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,177 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,181 [Thread-638] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33211
2020-12-03 07:23:50,182 [Thread-638] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:50,231 [Thread-638] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:50,279 [IPC Server handler 3 on default port 33211] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,280 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,280 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,318 [Thread-638] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:50,318 [Thread-638] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:50,318 [Thread-638] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 and block pool id BP-552726158-172.17.0.2-1606980213726 is not formatted. Formatting ...
2020-12-03 07:23:50,319 [Thread-638] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-552726158-172.17.0.2-1606980213726 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current
2020-12-03 07:23:50,381 [IPC Server handler 4 on default port 33211] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,382 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:50,382 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:50,430 [Thread-638] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:50,432 [Thread-638] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8c6158e4-26a0-4c48-b679-c78f56a29c98
2020-12-03 07:23:50,432 [Thread-638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:50,433 [Thread-638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:50,434 [Thread-638] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:50,435 [Thread-638] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:50,435 [Thread-638] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:50,436 [Thread-650] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:50,457 [Thread-650] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 21ms
2020-12-03 07:23:50,458 [Thread-638] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 22ms
2020-12-03 07:23:50,458 [Thread-652] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:50,459 [Thread-652] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas doesn't exist 
2020-12-03 07:23:50,460 [Thread-652] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 2ms
2020-12-03 07:23:50,461 [Thread-638] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 3ms
2020-12-03 07:23:50,461 [Thread-638] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:31 AM with interval of 21600000ms
2020-12-03 07:23:50,463 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33211 beginning handshake with NN
2020-12-03 07:23:50,469 [IPC Server handler 5 on default port 33211] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42563, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=43547, infoSecurePort=0, ipcPort=40188, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:50,469 [IPC Server handler 5 on default port 33211] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42563
2020-12-03 07:23:50,469 [IPC Server handler 5 on default port 33211] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:42563).
2020-12-03 07:23:50,473 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33211 successfully registered with NN
2020-12-03 07:23:50,473 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33211 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:50,477 [IPC Server handler 6 on default port 33211] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8c6158e4-26a0-4c48-b679-c78f56a29c98 for DN 127.0.0.1:42563
2020-12-03 07:23:50,485 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdef928d47a0dc1f1: Processing first storage report for DS-8c6158e4-26a0-4c48-b679-c78f56a29c98 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:50,485 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdef928d47a0dc1f1: from storage DS-8c6158e4-26a0-4c48-b679-c78f56a29c98 node DatanodeRegistration(127.0.0.1:42563, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=43547, infoSecurePort=0, ipcPort=40188, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:50,486 [IPC Server handler 8 on default port 33211] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,487 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdef928d47a0dc1f1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 7 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:50,490 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:50,490 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:50,490 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:50,490 [Listener at localhost/40188] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:50,490 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21f8e55f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:50,548 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a55f148{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:50,549 [Listener at localhost/40188] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e2f720{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:50,549 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e889e9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:50,549 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@724c5cbe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:50,561 [Listener at localhost/40188] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40188
2020-12-03 07:23:50,561 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:50,572 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:50,572 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:50,572 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33211
2020-12-03 07:23:50,572 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:50,573 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:33211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:50,573 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:50,580 [Listener at localhost/40188] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:50,581 [Listener at localhost/40188] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:50,582 [Listener at localhost/40188] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:50,582 [Listener at localhost/40188] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:50,583 [Listener at localhost/40188] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:50,583 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:50,583 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:50,584 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@62ce72ff] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:50,584 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2bef09c0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:50,584 [Listener at localhost/40188] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:50,585 [Listener at localhost/40188] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:50,586 [Listener at localhost/40188] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:50,587 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:50,587 [CacheReplicationMonitor(2141418829)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:50,589 [Listener at localhost/40188] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33211
2020-12-03 07:23:50,591 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:50,591 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:50,591 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:50,592 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:50,606 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:50,607 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:50,608 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@280e8a1a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:50,610 [Listener at localhost/40188] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@11e33bac{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:50,611 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3506d826{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:50,612 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29629fbb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:50,623 [Listener at localhost/40188] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:50,627 [Listener at localhost/40188] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:50,628 [Listener at localhost/40188] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:50,635 [Listener at localhost/40188] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:50,636 [Listener at localhost/40188] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 8*** BLOCK_POOL recovery: numDirs=1 testCase=8 current=false previous=true previous.tmp=false removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:50,678 [Listener at localhost/40188] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:50,678 [Listener at localhost/40188] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,679 [Listener at localhost/40188] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:50,681 [Listener at localhost/40188] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:50,682 [Listener at localhost/40188] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:50,682 [Listener at localhost/40188] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:50,683 [Listener at localhost/40188] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:50,695 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ac8cf9b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,695 [Listener at localhost/40188] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:50,696 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,698 [Listener at localhost/40188] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,699 [Listener at localhost/40188] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:50,699 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,701 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,701 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:50,701 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,701 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,703 [Listener at localhost/40188] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:50,703 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:50,704 [Listener at localhost/40188] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42108
2020-12-03 07:23:50,704 [Listener at localhost/40188] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,707 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ce9b9a9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,708 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3533df16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,714 [Listener at localhost/40188] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72ee5d84{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:50,718 [Listener at localhost/40188] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@68c7ef83{HTTP/1.1,[http/1.1]}{localhost:42108}
2020-12-03 07:23:50,719 [Listener at localhost/40188] INFO  server.Server (Server.java:doStart(419)) - Started @18487ms
2020-12-03 07:23:50,719 [Listener at localhost/40188] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,720 [Listener at localhost/40188] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,720 [Listener at localhost/40188] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:50,720 [Listener at localhost/40188] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:50,721 [Listener at localhost/40188] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,721 [Listener at localhost/40188] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,722 [Listener at localhost/40188] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:50,722 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:50,722 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:50,723 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:50,723 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:50,723 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:50,723 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:50,723 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:50,724 [Listener at localhost/40188] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,724 [Listener at localhost/40188] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:50,724 [Listener at localhost/40188] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:50,725 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:50,725 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:50
2020-12-03 07:23:50,725 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:50,725 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,725 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:50,726 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:50,747 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:50,748 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:50,748 [Listener at localhost/40188] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:50,748 [Listener at localhost/40188] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:50,749 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:50,750 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:50,750 [Listener at localhost/40188] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:50,750 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:50,750 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,751 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:50,751 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:50,756 [Listener at localhost/40188] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:50,757 [Listener at localhost/40188] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:50,757 [Listener at localhost/40188] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:50,757 [Listener at localhost/40188] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:50,757 [Listener at localhost/40188] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:50,757 [Listener at localhost/40188] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:50,758 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:50,758 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,758 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:50,758 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:50,761 [Listener at localhost/40188] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:50,761 [Listener at localhost/40188] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:50,761 [Listener at localhost/40188] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:50,762 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:50,762 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:50,762 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:50,762 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,763 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:50,763 [Listener at localhost/40188] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:50,793 [Listener at localhost/40188] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:50,796 [Listener at localhost/40188] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:50,797 [Listener at localhost/40188] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:50,803 [Listener at localhost/40188] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:50,813 [Listener at localhost/40188] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:50,813 [Listener at localhost/40188] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:50,813 [Listener at localhost/40188] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@31e04b13 expecting start txid #32
2020-12-03 07:23:50,814 [Listener at localhost/40188] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:50,814 [Listener at localhost/40188] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:50,823 [Listener at localhost/40188] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 10.0 ms
2020-12-03 07:23:50,824 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:50,826 [Listener at localhost/40188] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:50,869 [Listener at localhost/40188] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:50,869 [Listener at localhost/40188] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 105 msecs
2020-12-03 07:23:50,870 [Listener at localhost/40188] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:50,870 [Listener at localhost/40188] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:50,872 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:50,877 [Listener at localhost/43932] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43932 to access this namenode/service.
2020-12-03 07:23:50,878 [Listener at localhost/43932] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:50,878 [Listener at localhost/43932] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:50,908 [Listener at localhost/43932] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:50,919 [Listener at localhost/43932] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:50,926 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:50,930 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:50,944 [Listener at localhost/43932] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43932
2020-12-03 07:23:50,945 [Listener at localhost/43932] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:50,945 [Listener at localhost/43932] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:50,948 [Listener at localhost/43932] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:50,971 [CacheReplicationMonitor(864584614)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:51,000 [IPC Server handler 0 on default port 43932] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,003 [Listener at localhost/43932] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:51,212 [Listener at localhost/43932] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:51,213 [Listener at localhost/43932] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:51,214 [Listener at localhost/43932] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:51,214 [Listener at localhost/43932] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:51,215 [Listener at localhost/43932] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:51,215 [Listener at localhost/43932] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:51,215 [Listener at localhost/43932] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:51,216 [Listener at localhost/43932] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:51,217 [Listener at localhost/43932] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35381
2020-12-03 07:23:51,217 [Listener at localhost/43932] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:51,217 [Listener at localhost/43932] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:51,219 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,220 [Listener at localhost/43932] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:51,221 [Listener at localhost/43932] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:51,221 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,224 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:51,225 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:51,225 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:51,225 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:51,226 [Listener at localhost/43932] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34438
2020-12-03 07:23:51,226 [Listener at localhost/43932] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:51,228 [Listener at localhost/43932] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f72d88{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:51,229 [Listener at localhost/43932] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@87b5b49{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:51,237 [Listener at localhost/43932] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30c0d731{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:51,237 [Listener at localhost/43932] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d5037a9{HTTP/1.1,[http/1.1]}{localhost:34438}
2020-12-03 07:23:51,240 [Listener at localhost/43932] INFO  server.Server (Server.java:doStart(419)) - Started @19008ms
2020-12-03 07:23:51,260 [Listener at localhost/43932] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39218
2020-12-03 07:23:51,261 [Listener at localhost/43932] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:51,261 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30669dac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:51,261 [Listener at localhost/43932] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:51,261 [Listener at localhost/43932] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:51,262 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:51,270 [Listener at localhost/44815] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44815
2020-12-03 07:23:51,280 [Listener at localhost/44815] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:51,281 [Listener at localhost/44815] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:51,283 [Thread-705] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43932 starting to offer service
2020-12-03 07:23:51,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:51,284 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:51,309 [IPC Server handler 2 on default port 43932] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,311 [Thread-705] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43932
2020-12-03 07:23:51,316 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:51,316 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:51,317 [Thread-705] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:51,357 [Thread-705] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:51,391 [Thread-705] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:51,391 [Thread-705] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:51,392 [Thread-705] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:51,393 [Thread-705] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:51,394 [Thread-705] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43932. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:51,394 [Thread-705] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43932
2020-12-03 07:23:51,394 [Thread-705] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:51,418 [IPC Server handler 1 on default port 43932] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,419 [Listener at localhost/44815] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:35381', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:43932
2020-12-03 07:23:51,419 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:51,420 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:51,420 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:51,420 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@537c8c7e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:51,455 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30c0d731{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:51,461 [Listener at localhost/44815] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d5037a9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:51,468 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@87b5b49{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:51,469 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23f72d88{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:51,483 [Listener at localhost/44815] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44815
2020-12-03 07:23:51,484 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:51,493 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:51,501 [Listener at localhost/44815] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:51,502 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:51,502 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:51,502 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3971f0fe] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:51,502 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@552ed807] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:51,502 [Listener at localhost/44815] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:51,509 [Listener at localhost/44815] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:51,509 [Listener at localhost/44815] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:51,510 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:51,510 [CacheReplicationMonitor(864584614)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:51,511 [Listener at localhost/44815] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43932
2020-12-03 07:23:51,514 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:51,515 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:51,515 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:51,515 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:51,527 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:51,527 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:51,529 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72ee5d84{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:51,533 [Listener at localhost/44815] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@68c7ef83{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:51,535 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3533df16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:51,536 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ce9b9a9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:51,540 [Listener at localhost/44815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:51,549 [Listener at localhost/44815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:51,549 [Listener at localhost/44815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:51,561 [Listener at localhost/44815] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:51,561 [Listener at localhost/44815] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 9*** BLOCK_POOL recovery: numDirs=1 testCase=9 current=false previous=false previous.tmp=true removed.tmp=false should recover=true current exists after=true previous exists after=false
2020-12-03 07:23:51,625 [Listener at localhost/44815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:51,625 [Listener at localhost/44815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,626 [Listener at localhost/44815] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:51,628 [Listener at localhost/44815] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:51,630 [Listener at localhost/44815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:51,630 [Listener at localhost/44815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:51,631 [Listener at localhost/44815] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:51,638 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7063686f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:51,638 [Listener at localhost/44815] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:51,639 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,640 [Listener at localhost/44815] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:51,641 [Listener at localhost/44815] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:51,641 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,642 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:51,643 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:51,643 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:51,643 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:51,644 [Listener at localhost/44815] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:51,645 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:51,645 [Listener at localhost/44815] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45185
2020-12-03 07:23:51,645 [Listener at localhost/44815] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:51,648 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@243f003c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:51,648 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1639f93a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:51,654 [Listener at localhost/44815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@8b91134{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:51,656 [Listener at localhost/44815] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1fba386c{HTTP/1.1,[http/1.1]}{localhost:45185}
2020-12-03 07:23:51,657 [Listener at localhost/44815] INFO  server.Server (Server.java:doStart(419)) - Started @19425ms
2020-12-03 07:23:51,657 [Listener at localhost/44815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,657 [Listener at localhost/44815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,657 [Listener at localhost/44815] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:51,658 [Listener at localhost/44815] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:51,658 [Listener at localhost/44815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,658 [Listener at localhost/44815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,659 [Listener at localhost/44815] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:51,660 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:51,660 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:51,660 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:51,661 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:51,661 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:51,661 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:51,661 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:51,662 [Listener at localhost/44815] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:51,662 [Listener at localhost/44815] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:51,663 [Listener at localhost/44815] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:51,663 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:51,664 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:51
2020-12-03 07:23:51,664 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:51,664 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,665 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:51,665 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:51,679 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:51,679 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:51,680 [Listener at localhost/44815] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:51,680 [Listener at localhost/44815] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:51,681 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:51,682 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:51,682 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:51,682 [Listener at localhost/44815] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:51,682 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:51,682 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,683 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:51,683 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:51,685 [Listener at localhost/44815] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:51,686 [Listener at localhost/44815] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:51,686 [Listener at localhost/44815] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:51,686 [Listener at localhost/44815] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:51,686 [Listener at localhost/44815] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:51,686 [Listener at localhost/44815] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:51,687 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:51,687 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,687 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:51,687 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:51,688 [Listener at localhost/44815] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:51,688 [Listener at localhost/44815] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:51,688 [Listener at localhost/44815] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:51,689 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:51,689 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:51,689 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:51,689 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,690 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:51,690 [Listener at localhost/44815] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:51,741 [Listener at localhost/44815] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:51,742 [Listener at localhost/44815] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:51,743 [Listener at localhost/44815] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:51,748 [Listener at localhost/44815] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:51,750 [Listener at localhost/44815] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:51,750 [Listener at localhost/44815] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:51,750 [Listener at localhost/44815] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@736048ed expecting start txid #32
2020-12-03 07:23:51,750 [Listener at localhost/44815] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:51,751 [Listener at localhost/44815] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:51,755 [Listener at localhost/44815] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 5.0 ms
2020-12-03 07:23:51,756 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:51,756 [Listener at localhost/44815] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:51,831 [Listener at localhost/44815] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:51,831 [Listener at localhost/44815] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 141 msecs
2020-12-03 07:23:51,832 [Listener at localhost/44815] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:51,832 [Listener at localhost/44815] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:51,833 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:51,838 [Listener at localhost/37096] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37096 to access this namenode/service.
2020-12-03 07:23:51,839 [Listener at localhost/37096] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:51,839 [Listener at localhost/37096] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:51,851 [Listener at localhost/37096] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:51,854 [Listener at localhost/37096] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:51,871 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:51,872 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:51,873 [Listener at localhost/37096] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37096
2020-12-03 07:23:51,874 [Listener at localhost/37096] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:51,889 [Listener at localhost/37096] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:51,891 [Listener at localhost/37096] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:51,896 [CacheReplicationMonitor(2102694199)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:51,902 [IPC Server handler 0 on default port 37096] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,903 [Listener at localhost/37096] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:52,108 [Listener at localhost/37096] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:52,109 [Listener at localhost/37096] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:52,110 [Listener at localhost/37096] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:52,111 [Listener at localhost/37096] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:52,111 [Listener at localhost/37096] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:52,112 [Listener at localhost/37096] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:52,112 [Listener at localhost/37096] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:52,112 [Listener at localhost/37096] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:52,113 [Listener at localhost/37096] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41253
2020-12-03 07:23:52,113 [Listener at localhost/37096] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:52,113 [Listener at localhost/37096] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:52,114 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:52,120 [Listener at localhost/37096] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:52,121 [Listener at localhost/37096] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:52,121 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:52,123 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:52,123 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:52,124 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:52,124 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:52,136 [Listener at localhost/37096] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41765
2020-12-03 07:23:52,137 [Listener at localhost/37096] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:52,141 [Listener at localhost/37096] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d5b5fa7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:52,144 [Listener at localhost/37096] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6107165{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:52,152 [Listener at localhost/37096] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1aac188d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:52,153 [Listener at localhost/37096] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7026b7ee{HTTP/1.1,[http/1.1]}{localhost:41765}
2020-12-03 07:23:52,153 [Listener at localhost/37096] INFO  server.Server (Server.java:doStart(419)) - Started @19921ms
2020-12-03 07:23:52,335 [Listener at localhost/37096] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39727
2020-12-03 07:23:52,338 [Listener at localhost/37096] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:52,339 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cb8437d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:52,339 [Listener at localhost/37096] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:52,339 [Listener at localhost/37096] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:52,340 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:52,350 [Listener at localhost/45330] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45330
2020-12-03 07:23:52,360 [Listener at localhost/45330] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:52,360 [Listener at localhost/45330] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:52,361 [Thread-768] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37096 starting to offer service
2020-12-03 07:23:52,389 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:52,389 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:52,419 [Thread-768] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37096
2020-12-03 07:23:52,417 [IPC Server handler 2 on default port 37096] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,439 [Thread-768] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:52,443 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:52,444 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:52,500 [Thread-768] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:52,534 [Thread-768] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:52,535 [Thread-768] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:52,535 [Thread-768] INFO  common.Storage (Storage.java:doRecover(797)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 from previous upgrade
2020-12-03 07:23:52,545 [IPC Server handler 3 on default port 37096] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,546 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:52,546 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:52,568 [Thread-768] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:52,570 [Thread-768] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0ec8fe2a-e2db-4db8-bebf-98172c6d1be7
2020-12-03 07:23:52,570 [Thread-768] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:52,571 [Thread-768] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:52,572 [Thread-768] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:52,573 [Thread-768] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:52,573 [Thread-768] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:52,574 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:52,575 [Thread-780] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:23:52,586 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 11ms
2020-12-03 07:23:52,588 [Thread-768] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 15ms
2020-12-03 07:23:52,596 [Thread-781] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:52,599 [Thread-781] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:23:52,599 [Thread-781] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 3ms
2020-12-03 07:23:52,599 [Thread-768] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 11ms
2020-12-03 07:23:52,600 [Thread-768] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:28 AM with interval of 21600000ms
2020-12-03 07:23:52,622 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37096 beginning handshake with NN
2020-12-03 07:23:52,626 [IPC Server handler 4 on default port 37096] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41253, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=39727, infoSecurePort=0, ipcPort=45330, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:52,626 [IPC Server handler 4 on default port 37096] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41253
2020-12-03 07:23:52,626 [IPC Server handler 4 on default port 37096] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:41253).
2020-12-03 07:23:52,631 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37096 successfully registered with NN
2020-12-03 07:23:52,631 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37096 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:52,635 [IPC Server handler 7 on default port 37096] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0ec8fe2a-e2db-4db8-bebf-98172c6d1be7 for DN 127.0.0.1:41253
2020-12-03 07:23:52,646 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x486001061b2c6001: Processing first storage report for DS-0ec8fe2a-e2db-4db8-bebf-98172c6d1be7 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:52,647 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:52,649 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:52,649 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:52,649 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:52,649 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:52,655 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x486001061b2c6001: from storage DS-0ec8fe2a-e2db-4db8-bebf-98172c6d1be7 node DatanodeRegistration(127.0.0.1:41253, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=39727, infoSecurePort=0, ipcPort=45330, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2020-12-03 07:23:52,664 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:52,664 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:52,664 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:52,664 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:52,665 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:52,665 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-12-03 07:23:52,665 [IPC Server handler 9 on default port 37096] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:52,666 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:52,667 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:52,667 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:52,668 [Listener at localhost/45330] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:52,668 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4b7c4456] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:52,671 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x486001061b2c6001,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 30 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:52,694 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1aac188d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:52,694 [Listener at localhost/45330] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7026b7ee{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:52,695 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6107165{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:52,695 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d5b5fa7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:52,696 [Listener at localhost/45330] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45330
2020-12-03 07:23:52,697 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:52,701 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:52,701 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:52,702 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37096
2020-12-03 07:23:52,702 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:52,702 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37096] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:52,711 [Listener at localhost/45330] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:52,711 [Listener at localhost/45330] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:52,711 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:52,718 [Listener at localhost/45330] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:52,737 [Listener at localhost/45330] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:52,791 [Listener at localhost/45330] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:52,791 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:52,791 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:52,792 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4efc25fc] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:52,792 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@25da615a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:52,792 [Listener at localhost/45330] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:52,794 [Listener at localhost/45330] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 
2020-12-03 07:23:52,795 [Listener at localhost/45330] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:52,796 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:52,796 [CacheReplicationMonitor(2102694199)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:52,797 [Listener at localhost/45330] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37096
2020-12-03 07:23:52,800 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:52,822 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:52,821 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:52,807 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:52,842 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:52,843 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:52,851 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@8b91134{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:52,853 [Listener at localhost/45330] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1fba386c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:52,853 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1639f93a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:52,853 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@243f003c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:52,855 [Listener at localhost/45330] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:52,857 [Listener at localhost/45330] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:52,857 [Listener at localhost/45330] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:52,864 [Listener at localhost/45330] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:52,864 [Listener at localhost/45330] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 10*** BLOCK_POOL recovery: numDirs=1 testCase=10 current=true previous=false previous.tmp=false removed.tmp=true should recover=true current exists after=true previous exists after=false
2020-12-03 07:23:52,906 [Listener at localhost/45330] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:52,907 [Listener at localhost/45330] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:52,907 [Listener at localhost/45330] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:52,909 [Listener at localhost/45330] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:52,911 [Listener at localhost/45330] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:52,911 [Listener at localhost/45330] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:52,912 [Listener at localhost/45330] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:52,919 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ec2ecea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:52,920 [Listener at localhost/45330] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:52,920 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:52,922 [Listener at localhost/45330] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:52,922 [Listener at localhost/45330] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:52,923 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:52,924 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:52,925 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:52,925 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:52,925 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:52,926 [Listener at localhost/45330] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:52,927 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:52,927 [Listener at localhost/45330] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45719
2020-12-03 07:23:52,927 [Listener at localhost/45330] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:52,931 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b00ad9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:52,932 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f453e63{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:52,939 [Listener at localhost/45330] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@213bd3d5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:52,941 [Listener at localhost/45330] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@470a659f{HTTP/1.1,[http/1.1]}{localhost:45719}
2020-12-03 07:23:52,941 [Listener at localhost/45330] INFO  server.Server (Server.java:doStart(419)) - Started @20709ms
2020-12-03 07:23:52,942 [Listener at localhost/45330] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:52,942 [Listener at localhost/45330] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:52,942 [Listener at localhost/45330] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:52,942 [Listener at localhost/45330] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:52,943 [Listener at localhost/45330] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:52,943 [Listener at localhost/45330] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:52,955 [Listener at localhost/45330] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:52,955 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:52,956 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:52,956 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:52,956 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:52,957 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:52,957 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:52,957 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:52,958 [Listener at localhost/45330] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:52,958 [Listener at localhost/45330] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:52,958 [Listener at localhost/45330] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:52,959 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:52,959 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:52
2020-12-03 07:23:52,960 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:52,960 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:52,960 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:52,960 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:52,975 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:52,976 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:52,976 [Listener at localhost/45330] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:52,977 [Listener at localhost/45330] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:52,977 [Listener at localhost/45330] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:52,977 [Listener at localhost/45330] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:52,984 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:52,984 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:52,985 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:52,985 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:52,985 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:52,985 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:52,985 [Listener at localhost/45330] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:52,986 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:52,986 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:52,987 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:52,987 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:52,991 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:52,992 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:52,992 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:52,992 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:52,994 [Listener at localhost/45330] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:52,994 [Listener at localhost/45330] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:52,994 [Listener at localhost/45330] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:52,995 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:52,995 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:52,996 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:52,996 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:52,996 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:52,996 [Listener at localhost/45330] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:53,067 [Listener at localhost/45330] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:53,069 [Listener at localhost/45330] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:53,070 [Listener at localhost/45330] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:53,071 [Listener at localhost/45330] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:53,076 [Listener at localhost/45330] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:53,076 [Listener at localhost/45330] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:53,077 [Listener at localhost/45330] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7bebcd65 expecting start txid #32
2020-12-03 07:23:53,077 [Listener at localhost/45330] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:53,077 [Listener at localhost/45330] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:53,081 [Listener at localhost/45330] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:23:53,082 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:53,082 [Listener at localhost/45330] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:53,169 [Listener at localhost/45330] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:53,170 [Listener at localhost/45330] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 172 msecs
2020-12-03 07:23:53,170 [Listener at localhost/45330] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:53,171 [Listener at localhost/45330] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:53,172 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:53,178 [Listener at localhost/37918] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37918 to access this namenode/service.
2020-12-03 07:23:53,178 [Listener at localhost/37918] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:53,178 [Listener at localhost/37918] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:53,190 [Listener at localhost/37918] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:53,191 [Listener at localhost/37918] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:53,217 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:53,219 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:53,227 [Listener at localhost/37918] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37918
2020-12-03 07:23:53,228 [Listener at localhost/37918] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:53,228 [Listener at localhost/37918] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:53,230 [Listener at localhost/37918] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:53,233 [CacheReplicationMonitor(2075274027)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:53,247 [IPC Server handler 0 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:53,248 [Listener at localhost/37918] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:53,810 [Listener at localhost/37918] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:53,810 [Listener at localhost/37918] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:53,811 [Listener at localhost/37918] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:53,811 [Listener at localhost/37918] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,812 [Listener at localhost/37918] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:53,812 [Listener at localhost/37918] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:53,812 [Listener at localhost/37918] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:53,812 [Listener at localhost/37918] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:53,813 [Listener at localhost/37918] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35347
2020-12-03 07:23:53,813 [Listener at localhost/37918] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:53,813 [Listener at localhost/37918] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:53,814 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,815 [Listener at localhost/37918] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:53,816 [Listener at localhost/37918] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:53,816 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:53,818 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:53,819 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:53,819 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:53,819 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:53,820 [Listener at localhost/37918] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37291
2020-12-03 07:23:53,820 [Listener at localhost/37918] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:53,821 [Listener at localhost/37918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@367d2816{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:53,822 [Listener at localhost/37918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a82ebf8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:53,826 [Listener at localhost/37918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cb042da{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:53,827 [Listener at localhost/37918] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62461d58{HTTP/1.1,[http/1.1]}{localhost:37291}
2020-12-03 07:23:53,828 [Listener at localhost/37918] INFO  server.Server (Server.java:doStart(419)) - Started @21596ms
2020-12-03 07:23:53,843 [Listener at localhost/37918] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38812
2020-12-03 07:23:53,843 [Listener at localhost/37918] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:53,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@571a9686] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:53,843 [Listener at localhost/37918] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:53,844 [Listener at localhost/37918] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:53,845 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:53,848 [Listener at localhost/40153] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40153
2020-12-03 07:23:53,851 [Listener at localhost/40153] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:53,852 [Listener at localhost/40153] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:53,853 [Thread-835] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37918 starting to offer service
2020-12-03 07:23:53,855 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:53,856 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:53,870 [IPC Server handler 2 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:53,870 [Thread-835] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37918
2020-12-03 07:23:53,872 [Thread-835] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:53,872 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:53,872 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:53,974 [IPC Server handler 3 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:53,974 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:53,975 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,010 [Thread-835] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:54,076 [IPC Server handler 4 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,077 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,077 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,178 [IPC Server handler 5 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,179 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,179 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,260 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:54,260 [Thread-835] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:54,260 [Thread-835] INFO  common.Storage (Storage.java:doRecover(804)) - Completing previous rollback for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:54,280 [IPC Server handler 1 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,281 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,281 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,383 [IPC Server handler 2 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,383 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:54,384 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:54,439 [Thread-835] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:54,440 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-451351cf-439d-41a6-9620-41a6d9fd3737
2020-12-03 07:23:54,440 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:54,441 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:54,441 [Thread-835] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:54,442 [Thread-835] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:54,442 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:54,442 [Thread-847] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:54,443 [Thread-847] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:23:54,450 [Thread-847] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 8ms
2020-12-03 07:23:54,450 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 8ms
2020-12-03 07:23:54,451 [Thread-848] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:54,453 [Thread-848] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:23:54,453 [Thread-848] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 3ms
2020-12-03 07:23:54,453 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 3ms
2020-12-03 07:23:54,454 [Thread-835] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:36 AM with interval of 21600000ms
2020-12-03 07:23:54,455 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37918 beginning handshake with NN
2020-12-03 07:23:54,456 [IPC Server handler 3 on default port 37918] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35347, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=38812, infoSecurePort=0, ipcPort=40153, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:54,456 [IPC Server handler 3 on default port 37918] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35347
2020-12-03 07:23:54,456 [IPC Server handler 3 on default port 37918] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:35347).
2020-12-03 07:23:54,459 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37918 successfully registered with NN
2020-12-03 07:23:54,459 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37918 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:54,462 [IPC Server handler 4 on default port 37918] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-451351cf-439d-41a6-9620-41a6d9fd3737 for DN 127.0.0.1:35347
2020-12-03 07:23:54,473 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb3d77e26e31a57fb: Processing first storage report for DS-451351cf-439d-41a6-9620-41a6d9fd3737 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:23:54,473 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:54,475 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:54,475 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:23:54,475 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:54,475 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:54,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb3d77e26e31a57fb: from storage DS-451351cf-439d-41a6-9620-41a6d9fd3737 node DatanodeRegistration(127.0.0.1:35347, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=38812, infoSecurePort=0, ipcPort=40153, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:54,481 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:23:54,482 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb3d77e26e31a57fb,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:54,485 [IPC Server handler 6 on default port 37918] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:54,486 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:54,486 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:54,486 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:54,487 [Listener at localhost/40153] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:54,487 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7f7af971] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:54,506 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cb042da{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:54,507 [Listener at localhost/40153] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62461d58{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:54,507 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:54,507 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@367d2816{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:54,508 [Listener at localhost/40153] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40153
2020-12-03 07:23:54,514 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:54,514 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:54,515 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:54,515 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37918
2020-12-03 07:23:54,516 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:54,516 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37918] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:54,517 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:54,519 [Listener at localhost/40153] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:54,519 [Listener at localhost/40153] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:54,520 [Listener at localhost/40153] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:54,521 [Listener at localhost/40153] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:54,522 [Listener at localhost/40153] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:54,522 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:54,522 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:54,522 [Listener at localhost/40153] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:54,522 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2e3f79a2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:54,522 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1460c81d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:54,524 [Listener at localhost/40153] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:54,524 [Listener at localhost/40153] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:54,524 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:54,525 [CacheReplicationMonitor(2075274027)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:54,525 [Listener at localhost/40153] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37918
2020-12-03 07:23:54,526 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:54,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:54,527 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:54,527 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:54,535 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:54,535 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:54,536 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@213bd3d5{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:54,537 [Listener at localhost/40153] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@470a659f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:54,538 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f453e63{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:54,538 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b00ad9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:54,538 [Listener at localhost/40153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:54,540 [Listener at localhost/40153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:54,541 [Listener at localhost/40153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:54,665 [Listener at localhost/40153] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:54,666 [Listener at localhost/40153] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 11*** BLOCK_POOL recovery: numDirs=1 testCase=11 current=true previous=true previous.tmp=false removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:54,708 [Listener at localhost/40153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:54,708 [Listener at localhost/40153] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:54,709 [Listener at localhost/40153] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:54,710 [Listener at localhost/40153] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:54,711 [Listener at localhost/40153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:54,711 [Listener at localhost/40153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:54,712 [Listener at localhost/40153] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:54,717 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d0753c9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:54,717 [Listener at localhost/40153] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:54,717 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,719 [Listener at localhost/40153] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:54,720 [Listener at localhost/40153] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:54,720 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,722 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:54,723 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:54,723 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:54,723 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:54,725 [Listener at localhost/40153] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:54,725 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:54,725 [Listener at localhost/40153] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33779
2020-12-03 07:23:54,726 [Listener at localhost/40153] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:54,727 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28f878a0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:54,728 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5183ec{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:54,732 [Listener at localhost/40153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@57a2ed35{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:54,733 [Listener at localhost/40153] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12ffd1de{HTTP/1.1,[http/1.1]}{localhost:33779}
2020-12-03 07:23:54,735 [Listener at localhost/40153] INFO  server.Server (Server.java:doStart(419)) - Started @22504ms
2020-12-03 07:23:54,736 [Listener at localhost/40153] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:54,736 [Listener at localhost/40153] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:54,736 [Listener at localhost/40153] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:54,736 [Listener at localhost/40153] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:54,737 [Listener at localhost/40153] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:54,737 [Listener at localhost/40153] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:54,738 [Listener at localhost/40153] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:54,738 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:54,738 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:54,738 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:54,739 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:54,739 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:54,739 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:54,739 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:54,740 [Listener at localhost/40153] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:54,740 [Listener at localhost/40153] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:54,740 [Listener at localhost/40153] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:54,741 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:54,741 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:54
2020-12-03 07:23:54,741 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:54,741 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,742 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:54,742 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:54,755 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:54,755 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:54,756 [Listener at localhost/40153] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:54,756 [Listener at localhost/40153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:54,756 [Listener at localhost/40153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:54,757 [Listener at localhost/40153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:54,757 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:54,757 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:54,757 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:54,758 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:54,758 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:54,758 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:54,758 [Listener at localhost/40153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:54,759 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:54,759 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,759 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:54,760 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:54,770 [Listener at localhost/40153] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:54,771 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:54,771 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,771 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:54,771 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:54,772 [Listener at localhost/40153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:54,772 [Listener at localhost/40153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:54,772 [Listener at localhost/40153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:54,773 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:54,773 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:54,773 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:54,773 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:54,774 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:54,774 [Listener at localhost/40153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:54,915 [Listener at localhost/40153] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:54,917 [Listener at localhost/40153] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:54,918 [Listener at localhost/40153] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:54,920 [Listener at localhost/40153] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:54,921 [Listener at localhost/40153] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:54,921 [Listener at localhost/40153] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:54,921 [Listener at localhost/40153] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@184fb68d expecting start txid #32
2020-12-03 07:23:54,921 [Listener at localhost/40153] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:54,922 [Listener at localhost/40153] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:54,924 [Listener at localhost/40153] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:23:54,924 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:54,925 [Listener at localhost/40153] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:55,184 [Listener at localhost/40153] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:55,184 [Listener at localhost/40153] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 410 msecs
2020-12-03 07:23:55,185 [Listener at localhost/40153] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:55,185 [Listener at localhost/40153] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:55,186 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:55,189 [Listener at localhost/39331] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:39331 to access this namenode/service.
2020-12-03 07:23:55,190 [Listener at localhost/39331] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:55,190 [Listener at localhost/39331] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:55,288 [Listener at localhost/39331] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:55,290 [Listener at localhost/39331] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:55,293 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:55,293 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:55,295 [Listener at localhost/39331] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:39331
2020-12-03 07:23:55,295 [Listener at localhost/39331] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:55,295 [Listener at localhost/39331] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:55,297 [Listener at localhost/39331] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:55,299 [CacheReplicationMonitor(2129117918)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:55,307 [IPC Server handler 1 on default port 39331] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:55,307 [Listener at localhost/39331] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:55,720 [Listener at localhost/39331] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:55,720 [Listener at localhost/39331] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:55,722 [Listener at localhost/39331] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:55,724 [Listener at localhost/39331] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:55,724 [Listener at localhost/39331] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:55,724 [Listener at localhost/39331] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:55,724 [Listener at localhost/39331] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:55,724 [Listener at localhost/39331] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:55,725 [Listener at localhost/39331] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37578
2020-12-03 07:23:55,725 [Listener at localhost/39331] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:55,725 [Listener at localhost/39331] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:55,726 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:55,883 [Listener at localhost/39331] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:55,883 [Listener at localhost/39331] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:55,884 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:55,999 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:55,999 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:55,999 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:55,999 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:56,000 [Listener at localhost/39331] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42798
2020-12-03 07:23:56,000 [Listener at localhost/39331] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:56,002 [Listener at localhost/39331] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f3e7344{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:56,002 [Listener at localhost/39331] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62d73ead{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:56,007 [Listener at localhost/39331] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35e8316e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:56,007 [Listener at localhost/39331] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26d96e5{HTTP/1.1,[http/1.1]}{localhost:42798}
2020-12-03 07:23:56,008 [Listener at localhost/39331] INFO  server.Server (Server.java:doStart(419)) - Started @23777ms
2020-12-03 07:23:56,020 [Listener at localhost/39331] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34900
2020-12-03 07:23:56,021 [Listener at localhost/39331] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:56,021 [Listener at localhost/39331] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:56,021 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1846579f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:56,022 [Listener at localhost/39331] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:56,022 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:56,025 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36616
2020-12-03 07:23:56,028 [Listener at localhost/36616] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:56,028 [Listener at localhost/36616] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:56,029 [Thread-902] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39331 starting to offer service
2020-12-03 07:23:56,031 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:56,031 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:56,035 [Thread-902] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39331
2020-12-03 07:23:56,036 [Thread-902] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:56,036 [IPC Server handler 2 on default port 39331] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:56,039 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:56,039 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:56,140 [IPC Server handler 3 on default port 39331] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:56,141 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:56,141 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:56,170 [Thread-902] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:56,243 [IPC Server handler 4 on default port 39331] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:56,244 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:56,244 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:56,285 [Thread-902] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:56,285 [Thread-902] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:56,286 [Thread-902] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:56,286 [Thread-902] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:56,286 [Thread-902] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:39331. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:56,286 [Thread-902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:39331
2020-12-03 07:23:56,287 [Thread-902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:56,345 [IPC Server handler 0 on default port 39331] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:56,346 [Listener at localhost/36616] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:37578', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:39331
2020-12-03 07:23:56,346 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:56,346 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:56,346 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:56,347 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3681037] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:56,366 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35e8316e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:56,367 [Listener at localhost/36616] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26d96e5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,367 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62d73ead{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,368 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f3e7344{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,546 [Listener at localhost/36616] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36616
2020-12-03 07:23:56,548 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,548 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,552 [Listener at localhost/36616] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:56,552 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:56,553 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,553 [Listener at localhost/36616] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:56,553 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@702c436b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:56,553 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7a2b1eb4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:56,555 [Listener at localhost/36616] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 
2020-12-03 07:23:56,556 [Listener at localhost/36616] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:56,556 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:56,556 [CacheReplicationMonitor(2129117918)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:56,560 [Listener at localhost/36616] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39331
2020-12-03 07:23:56,562 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,562 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,562 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:56,562 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:56,572 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,573 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:56,574 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@57a2ed35{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:56,576 [Listener at localhost/36616] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12ffd1de{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,576 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5183ec{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,577 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28f878a0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,577 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:56,579 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:56,580 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:56,595 [Listener at localhost/36616] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:56,595 [Listener at localhost/36616] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 12*** BLOCK_POOL recovery: numDirs=1 testCase=12 current=true previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:56,639 [Listener at localhost/36616] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:56,639 [Listener at localhost/36616] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:56,640 [Listener at localhost/36616] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:56,641 [Listener at localhost/36616] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:56,642 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:56,643 [Listener at localhost/36616] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:56,643 [Listener at localhost/36616] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:56,656 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b4ae4e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:56,656 [Listener at localhost/36616] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:56,657 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:56,659 [Listener at localhost/36616] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:56,659 [Listener at localhost/36616] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:56,660 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:56,662 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:56,662 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:56,663 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:56,663 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:56,664 [Listener at localhost/36616] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:56,665 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:56,665 [Listener at localhost/36616] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39743
2020-12-03 07:23:56,665 [Listener at localhost/36616] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:56,668 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7be3a9ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:56,668 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3baf6936{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:56,673 [Listener at localhost/36616] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6bda1d19{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:56,673 [Listener at localhost/36616] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28c86134{HTTP/1.1,[http/1.1]}{localhost:39743}
2020-12-03 07:23:56,675 [Listener at localhost/36616] INFO  server.Server (Server.java:doStart(419)) - Started @24443ms
2020-12-03 07:23:56,675 [Listener at localhost/36616] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:56,676 [Listener at localhost/36616] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:56,676 [Listener at localhost/36616] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:56,676 [Listener at localhost/36616] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:56,676 [Listener at localhost/36616] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:56,676 [Listener at localhost/36616] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:56,677 [Listener at localhost/36616] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:56,678 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:56,679 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:56,679 [Listener at localhost/36616] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:56,679 [Listener at localhost/36616] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:56,679 [Listener at localhost/36616] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:56
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:56,680 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:56,686 [Listener at localhost/36616] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:56,687 [Listener at localhost/36616] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:56,688 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:56,688 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:56,689 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:56,689 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:56,697 [Listener at localhost/36616] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:56,697 [Listener at localhost/36616] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:56,697 [Listener at localhost/36616] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:56,697 [Listener at localhost/36616] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:56,697 [Listener at localhost/36616] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:56,698 [Listener at localhost/36616] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:56,698 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:56,698 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:56,698 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:56,698 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:56,699 [Listener at localhost/36616] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:56,699 [Listener at localhost/36616] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:56,699 [Listener at localhost/36616] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:56,700 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:56,700 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:56,700 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:56,700 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:56,701 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:56,701 [Listener at localhost/36616] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:56,840 [Listener at localhost/36616] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:56,842 [Listener at localhost/36616] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:56,843 [Listener at localhost/36616] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:56,844 [Listener at localhost/36616] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:56,846 [Listener at localhost/36616] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:56,846 [Listener at localhost/36616] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:56,846 [Listener at localhost/36616] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6794ac0b expecting start txid #32
2020-12-03 07:23:56,846 [Listener at localhost/36616] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:56,846 [Listener at localhost/36616] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:56,849 [Listener at localhost/36616] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:23:56,849 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:56,850 [Listener at localhost/36616] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:56,990 [Listener at localhost/36616] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:56,990 [Listener at localhost/36616] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 289 msecs
2020-12-03 07:23:56,991 [Listener at localhost/36616] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:56,991 [Listener at localhost/36616] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:56,992 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:56,996 [Listener at localhost/41815] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41815 to access this namenode/service.
2020-12-03 07:23:56,996 [Listener at localhost/41815] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:56,996 [Listener at localhost/41815] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:57,025 [Listener at localhost/41815] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:57,027 [Listener at localhost/41815] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:57,030 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:57,030 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:57,033 [Listener at localhost/41815] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41815
2020-12-03 07:23:57,033 [Listener at localhost/41815] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:57,033 [Listener at localhost/41815] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:57,035 [Listener at localhost/41815] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:57,036 [CacheReplicationMonitor(323168689)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:57,042 [IPC Server handler 1 on default port 41815] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:57,043 [Listener at localhost/41815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:57,506 [Listener at localhost/41815] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:57,507 [Listener at localhost/41815] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:57,508 [Listener at localhost/41815] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:57,508 [Listener at localhost/41815] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:57,508 [Listener at localhost/41815] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:57,508 [Listener at localhost/41815] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:57,509 [Listener at localhost/41815] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:57,509 [Listener at localhost/41815] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:57,509 [Listener at localhost/41815] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33619
2020-12-03 07:23:57,510 [Listener at localhost/41815] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:57,510 [Listener at localhost/41815] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:57,510 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:57,512 [Listener at localhost/41815] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:57,512 [Listener at localhost/41815] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:57,512 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:57,514 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:57,514 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:57,515 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:57,515 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:57,515 [Listener at localhost/41815] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40909
2020-12-03 07:23:57,516 [Listener at localhost/41815] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:57,517 [Listener at localhost/41815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a87b51{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:57,517 [Listener at localhost/41815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@144ab54{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:57,522 [Listener at localhost/41815] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17a703f5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:57,524 [Listener at localhost/41815] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5ff2b8ca{HTTP/1.1,[http/1.1]}{localhost:40909}
2020-12-03 07:23:57,525 [Listener at localhost/41815] INFO  server.Server (Server.java:doStart(419)) - Started @25293ms
2020-12-03 07:23:57,536 [Listener at localhost/41815] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46710
2020-12-03 07:23:57,537 [Listener at localhost/41815] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:57,537 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1aa6e3c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:57,537 [Listener at localhost/41815] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:57,537 [Listener at localhost/41815] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:57,538 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:57,541 [Listener at localhost/46642] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46642
2020-12-03 07:23:57,544 [Listener at localhost/46642] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:57,545 [Listener at localhost/46642] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:57,545 [Thread-963] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41815 starting to offer service
2020-12-03 07:23:57,548 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:57,548 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:57,557 [IPC Server handler 2 on default port 41815] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:57,558 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:57,558 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:57,558 [Thread-963] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41815
2020-12-03 07:23:57,559 [Thread-963] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:57,660 [IPC Server handler 4 on default port 41815] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:57,661 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:57,661 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:57,662 [Thread-963] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:57,763 [IPC Server handler 5 on default port 41815] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:57,765 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:57,765 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:57,801 [Thread-963] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:57,801 [Thread-963] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:57,801 [Thread-963] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:57,801 [Thread-963] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:57,802 [Thread-963] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41815. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:57,802 [Thread-963] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41815
2020-12-03 07:23:57,802 [Thread-963] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:57,866 [IPC Server handler 6 on default port 41815] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:57,867 [Listener at localhost/46642] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:33619', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:41815
2020-12-03 07:23:57,867 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:57,868 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:57,868 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:57,868 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@27e5b378] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:57,899 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17a703f5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:57,900 [Listener at localhost/46642] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5ff2b8ca{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:57,901 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@144ab54{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:57,901 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a87b51{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:57,902 [Listener at localhost/46642] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46642
2020-12-03 07:23:57,908 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:57,908 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:57,910 [Listener at localhost/46642] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:57,910 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:57,910 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:57,911 [Listener at localhost/46642] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:57,911 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@40712ee9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:57,912 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2e53b094] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:57,913 [Listener at localhost/46642] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:57,914 [Listener at localhost/46642] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:57,914 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:57,914 [CacheReplicationMonitor(323168689)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:57,915 [Listener at localhost/46642] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41815
2020-12-03 07:23:57,917 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:57,917 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:57,917 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:57,917 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:57,929 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:57,929 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:57,933 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6bda1d19{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:57,941 [Listener at localhost/46642] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28c86134{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:57,941 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3baf6936{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:57,941 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7be3a9ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:57,946 [Listener at localhost/46642] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:57,947 [Listener at localhost/46642] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:57,947 [Listener at localhost/46642] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:57,955 [Listener at localhost/46642] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:57,956 [Listener at localhost/46642] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 13*** BLOCK_POOL recovery: numDirs=1 testCase=13 current=true previous=false previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:57,996 [Listener at localhost/46642] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:57,997 [Listener at localhost/46642] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:57,998 [Listener at localhost/46642] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:58,001 [Listener at localhost/46642] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:58,013 [Listener at localhost/46642] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:58,013 [Listener at localhost/46642] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:58,014 [Listener at localhost/46642] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:58,032 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5633dafd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:58,032 [Listener at localhost/46642] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:58,033 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:58,035 [Listener at localhost/46642] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:58,036 [Listener at localhost/46642] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:58,036 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:58,039 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:58,040 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:58,040 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:58,040 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:58,042 [Listener at localhost/46642] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:58,042 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:58,043 [Listener at localhost/46642] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35210
2020-12-03 07:23:58,043 [Listener at localhost/46642] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:58,045 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@778d82e9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:58,045 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59901c4d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:58,052 [Listener at localhost/46642] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6778aea6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:58,053 [Listener at localhost/46642] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e1ce44{HTTP/1.1,[http/1.1]}{localhost:35210}
2020-12-03 07:23:58,053 [Listener at localhost/46642] INFO  server.Server (Server.java:doStart(419)) - Started @25821ms
2020-12-03 07:23:58,054 [Listener at localhost/46642] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:58,054 [Listener at localhost/46642] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:58,055 [Listener at localhost/46642] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:58,055 [Listener at localhost/46642] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:58,055 [Listener at localhost/46642] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:58,055 [Listener at localhost/46642] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:58,077 [Listener at localhost/46642] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:58,078 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:58,078 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:58,078 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:58,078 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:58,079 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:58,079 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:58,079 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:58,080 [Listener at localhost/46642] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:58,081 [Listener at localhost/46642] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:58,081 [Listener at localhost/46642] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:58,081 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:58,082 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:58
2020-12-03 07:23:58,082 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:58,082 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,082 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:58,082 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:58,088 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:58,089 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:58,090 [Listener at localhost/46642] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:58,090 [Listener at localhost/46642] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:58,090 [Listener at localhost/46642] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:58,090 [Listener at localhost/46642] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:58,090 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:58,091 [Listener at localhost/46642] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:58,092 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:58,092 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,092 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:58,092 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:58,094 [Listener at localhost/46642] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:58,094 [Listener at localhost/46642] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:58,095 [Listener at localhost/46642] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:58,095 [Listener at localhost/46642] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:58,095 [Listener at localhost/46642] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:58,095 [Listener at localhost/46642] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:58,095 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:58,096 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,096 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:58,096 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:58,098 [Listener at localhost/46642] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:58,098 [Listener at localhost/46642] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:58,098 [Listener at localhost/46642] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:58,099 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:58,099 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:58,100 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:58,100 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,100 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:58,100 [Listener at localhost/46642] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:58,224 [Listener at localhost/46642] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:58,226 [Listener at localhost/46642] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:58,226 [Listener at localhost/46642] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:58,228 [Listener at localhost/46642] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:58,230 [Listener at localhost/46642] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:58,231 [Listener at localhost/46642] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:58,231 [Listener at localhost/46642] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@21f459fc expecting start txid #32
2020-12-03 07:23:58,231 [Listener at localhost/46642] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:58,231 [Listener at localhost/46642] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:58,233 [Listener at localhost/46642] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:23:58,234 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:58,234 [Listener at localhost/46642] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:58,351 [Listener at localhost/46642] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:58,351 [Listener at localhost/46642] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 250 msecs
2020-12-03 07:23:58,352 [Listener at localhost/46642] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:58,352 [Listener at localhost/46642] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:58,353 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:58,356 [Listener at localhost/41193] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41193 to access this namenode/service.
2020-12-03 07:23:58,357 [Listener at localhost/41193] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:58,358 [Listener at localhost/41193] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:58,372 [Listener at localhost/41193] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:58,376 [Listener at localhost/41193] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:58,383 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:58,383 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:58,389 [Listener at localhost/41193] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41193
2020-12-03 07:23:58,389 [Listener at localhost/41193] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:58,389 [Listener at localhost/41193] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:58,401 [Listener at localhost/41193] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 11 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:58,422 [CacheReplicationMonitor(732651158)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:58,428 [IPC Server handler 0 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:58,429 [Listener at localhost/41193] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:58,864 [Listener at localhost/41193] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:58,865 [Listener at localhost/41193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:58,866 [Listener at localhost/41193] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:58,866 [Listener at localhost/41193] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:58,867 [Listener at localhost/41193] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:58,867 [Listener at localhost/41193] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:58,867 [Listener at localhost/41193] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:58,868 [Listener at localhost/41193] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:58,868 [Listener at localhost/41193] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36933
2020-12-03 07:23:58,869 [Listener at localhost/41193] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:58,869 [Listener at localhost/41193] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:58,870 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:58,872 [Listener at localhost/41193] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:58,874 [Listener at localhost/41193] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:58,884 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:58,887 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:58,888 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:58,888 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:58,888 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:58,889 [Listener at localhost/41193] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45910
2020-12-03 07:23:58,889 [Listener at localhost/41193] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:58,891 [Listener at localhost/41193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ee69ad8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:58,891 [Listener at localhost/41193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a6cf771{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:58,897 [Listener at localhost/41193] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3dd818e8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:58,898 [Listener at localhost/41193] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4cb40e3b{HTTP/1.1,[http/1.1]}{localhost:45910}
2020-12-03 07:23:58,898 [Listener at localhost/41193] INFO  server.Server (Server.java:doStart(419)) - Started @26666ms
2020-12-03 07:23:58,916 [Listener at localhost/41193] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35114
2020-12-03 07:23:58,916 [Listener at localhost/41193] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:58,917 [Listener at localhost/41193] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:58,916 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a543f31] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:58,917 [Listener at localhost/41193] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:58,918 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:58,921 [Listener at localhost/33877] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33877
2020-12-03 07:23:58,926 [Listener at localhost/33877] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:58,926 [Listener at localhost/33877] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:58,927 [Thread-1024] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41193 starting to offer service
2020-12-03 07:23:58,942 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:58,942 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:58,958 [IPC Server handler 1 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:58,960 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:58,960 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:58,985 [Thread-1024] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41193
2020-12-03 07:23:58,990 [Thread-1024] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:23:59,062 [IPC Server handler 5 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:59,063 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:59,063 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:59,165 [IPC Server handler 6 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:59,166 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:59,166 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:59,166 [Thread-1024] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:59,268 [IPC Server handler 8 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:59,272 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:59,273 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:59,339 [Thread-1024] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:59,339 [Thread-1024] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:23:59,340 [Thread-1024] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:59,340 [Thread-1024] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:59,341 [Thread-1024] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41193. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:59,341 [Thread-1024] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41193
2020-12-03 07:23:59,341 [Thread-1024] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:23:59,374 [IPC Server handler 3 on default port 41193] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:59,380 [Listener at localhost/33877] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:36933', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:41193
2020-12-03 07:23:59,380 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:59,381 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:59,381 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:59,382 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12d1f1d4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:59,460 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3dd818e8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:59,461 [Listener at localhost/33877] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4cb40e3b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:59,461 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a6cf771{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:59,461 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ee69ad8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:59,462 [Listener at localhost/33877] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33877
2020-12-03 07:23:59,466 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:59,466 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:59,472 [Listener at localhost/33877] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:59,472 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:59,472 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:59,472 [Listener at localhost/33877] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:59,473 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4fc142ec] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:59,472 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1d75e7af] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:59,474 [Listener at localhost/33877] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 
2020-12-03 07:23:59,475 [Listener at localhost/33877] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:59,475 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:59,476 [Listener at localhost/33877] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41193
2020-12-03 07:23:59,478 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:59,478 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:59,478 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:59,481 [CacheReplicationMonitor(732651158)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:59,478 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:59,495 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:59,495 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:59,497 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6778aea6{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:59,498 [Listener at localhost/33877] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e1ce44{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:59,499 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59901c4d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:59,499 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@778d82e9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:59,500 [Listener at localhost/33877] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:59,501 [Listener at localhost/33877] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:59,501 [Listener at localhost/33877] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:59,511 [Listener at localhost/33877] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:23:59,511 [Listener at localhost/33877] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 14*** BLOCK_POOL recovery: numDirs=1 testCase=14 current=false previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:23:59,567 [Listener at localhost/33877] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:23:59,568 [Listener at localhost/33877] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,568 [Listener at localhost/33877] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:59,580 [Listener at localhost/33877] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:59,585 [Listener at localhost/33877] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:59,586 [Listener at localhost/33877] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:59,588 [Listener at localhost/33877] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:59,599 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@474c9131] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:59,599 [Listener at localhost/33877] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:59,600 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:59,605 [Listener at localhost/33877] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:59,605 [Listener at localhost/33877] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:59,606 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:59,607 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:59,608 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:59,608 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:59,608 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:59,609 [Listener at localhost/33877] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:59,610 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:59,610 [Listener at localhost/33877] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44179
2020-12-03 07:23:59,611 [Listener at localhost/33877] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:59,617 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c8e67b9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:59,618 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49206065{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:59,625 [Listener at localhost/33877] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36c0d0bd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:59,626 [Listener at localhost/33877] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5e1fc2aa{HTTP/1.1,[http/1.1]}{localhost:44179}
2020-12-03 07:23:59,626 [Listener at localhost/33877] INFO  server.Server (Server.java:doStart(419)) - Started @27394ms
2020-12-03 07:23:59,627 [Listener at localhost/33877] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,627 [Listener at localhost/33877] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,627 [Listener at localhost/33877] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:59,627 [Listener at localhost/33877] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:23:59,628 [Listener at localhost/33877] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,628 [Listener at localhost/33877] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,631 [Listener at localhost/33877] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:59,632 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:59,632 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:59,633 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:59,633 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:59,633 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:59,633 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:59,634 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:59,634 [Listener at localhost/33877] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:59,635 [Listener at localhost/33877] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:59,636 [Listener at localhost/33877] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:59,636 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:59,637 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:59
2020-12-03 07:23:59,637 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:59,637 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:59,637 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:59,638 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:59,651 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:59,653 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:59,654 [Listener at localhost/33877] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:59,654 [Listener at localhost/33877] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:59,654 [Listener at localhost/33877] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:59,655 [Listener at localhost/33877] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:59,655 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:59,655 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:59,656 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:59,656 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:59,656 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:59,656 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:59,657 [Listener at localhost/33877] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:59,657 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:59,658 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:59,658 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:59,658 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:59,666 [Listener at localhost/33877] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:59,676 [Listener at localhost/33877] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:59,676 [Listener at localhost/33877] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:59,677 [Listener at localhost/33877] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:59,677 [Listener at localhost/33877] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:59,677 [Listener at localhost/33877] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:59,678 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:59,678 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:59,678 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:59,679 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:59,686 [Listener at localhost/33877] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:59,687 [Listener at localhost/33877] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:59,687 [Listener at localhost/33877] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:59,688 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:59,688 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:59,689 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:59,689 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:59,689 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:59,689 [Listener at localhost/33877] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:59,746 [Listener at localhost/33877] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:23:59,748 [Listener at localhost/33877] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:59,748 [Listener at localhost/33877] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:59,753 [Listener at localhost/33877] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:59,757 [Listener at localhost/33877] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:59,757 [Listener at localhost/33877] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:59,757 [Listener at localhost/33877] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@31ceba99 expecting start txid #32
2020-12-03 07:23:59,758 [Listener at localhost/33877] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:59,758 [Listener at localhost/33877] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:59,762 [Listener at localhost/33877] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:23:59,762 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:59,764 [Listener at localhost/33877] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:59,821 [Listener at localhost/33877] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:59,822 [Listener at localhost/33877] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 131 msecs
2020-12-03 07:23:59,822 [Listener at localhost/33877] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:59,823 [Listener at localhost/33877] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:59,828 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:59,850 [Listener at localhost/46387] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46387 to access this namenode/service.
2020-12-03 07:23:59,850 [Listener at localhost/46387] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:59,851 [Listener at localhost/46387] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:59,867 [Listener at localhost/46387] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:59,876 [Listener at localhost/46387] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:59,908 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:59,908 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:59,920 [Listener at localhost/46387] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46387
2020-12-03 07:23:59,920 [Listener at localhost/46387] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:59,921 [Listener at localhost/46387] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:59,922 [Listener at localhost/46387] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:59,940 [CacheReplicationMonitor(218141885)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:59,956 [IPC Server handler 0 on default port 46387] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:59,957 [Listener at localhost/46387] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:00,341 [Listener at localhost/46387] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:00,342 [Listener at localhost/46387] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:00,343 [Listener at localhost/46387] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:00,344 [Listener at localhost/46387] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:00,344 [Listener at localhost/46387] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:00,345 [Listener at localhost/46387] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:00,345 [Listener at localhost/46387] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:00,345 [Listener at localhost/46387] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:00,346 [Listener at localhost/46387] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40274
2020-12-03 07:24:00,347 [Listener at localhost/46387] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:00,347 [Listener at localhost/46387] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:00,348 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:00,350 [Listener at localhost/46387] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:00,351 [Listener at localhost/46387] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:00,352 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:00,354 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:00,354 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:00,354 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:00,355 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:00,356 [Listener at localhost/46387] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44697
2020-12-03 07:24:00,356 [Listener at localhost/46387] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:00,362 [Listener at localhost/46387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64b3b1ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:00,363 [Listener at localhost/46387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49ec6a9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:00,369 [Listener at localhost/46387] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2016f509{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:00,370 [Listener at localhost/46387] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f1a80fb{HTTP/1.1,[http/1.1]}{localhost:44697}
2020-12-03 07:24:00,370 [Listener at localhost/46387] INFO  server.Server (Server.java:doStart(419)) - Started @28139ms
2020-12-03 07:24:00,658 [Listener at localhost/46387] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36702
2020-12-03 07:24:00,660 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a0094c9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:00,660 [Listener at localhost/46387] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:00,660 [Listener at localhost/46387] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:00,661 [Listener at localhost/46387] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:00,663 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:00,688 [Listener at localhost/40272] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40272
2020-12-03 07:24:00,695 [Listener at localhost/40272] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:00,695 [Listener at localhost/40272] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:00,697 [Thread-1085] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46387 starting to offer service
2020-12-03 07:24:00,706 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:00,707 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:00,736 [Thread-1085] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46387
2020-12-03 07:24:00,738 [IPC Server handler 2 on default port 46387] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:00,739 [Thread-1085] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:24:00,739 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:00,740 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:00,828 [Thread-1085] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:00,841 [IPC Server handler 3 on default port 46387] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:00,842 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:00,842 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:00,898 [Thread-1085] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:00,898 [Thread-1085] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:00,898 [Thread-1085] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:00,899 [Thread-1085] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:00,899 [Thread-1085] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46387. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:00,900 [Thread-1085] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46387
2020-12-03 07:24:00,900 [Thread-1085] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:00,944 [IPC Server handler 0 on default port 46387] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:00,944 [Listener at localhost/40272] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:40274', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:46387
2020-12-03 07:24:00,945 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:00,945 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:00,945 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:00,946 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4f668f29] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:01,013 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2016f509{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:01,015 [Listener at localhost/40272] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6f1a80fb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:01,015 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49ec6a9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:01,016 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64b3b1ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:01,018 [Listener at localhost/40272] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40272
2020-12-03 07:24:01,019 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:01,020 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:01,024 [Listener at localhost/40272] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:01,024 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:01,025 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:01,025 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@a0db585] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:01,028 [Listener at localhost/40272] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:01,028 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2b34e38c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:01,030 [Listener at localhost/40272] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 9 
2020-12-03 07:24:01,031 [Listener at localhost/40272] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:01,031 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:01,032 [CacheReplicationMonitor(218141885)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:01,033 [Listener at localhost/40272] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46387
2020-12-03 07:24:01,034 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:01,035 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:01,036 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:01,040 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:01,059 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:01,059 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:01,060 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36c0d0bd{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:01,062 [Listener at localhost/40272] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5e1fc2aa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:01,063 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49206065{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:01,063 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c8e67b9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:01,071 [Listener at localhost/40272] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:01,071 [Listener at localhost/40272] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:01,071 [Listener at localhost/40272] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:01,103 [Listener at localhost/40272] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:01,103 [Listener at localhost/40272] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 15*** BLOCK_POOL recovery: numDirs=1 testCase=15 current=false previous=false previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:01,178 [Listener at localhost/40272] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:01,178 [Listener at localhost/40272] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,179 [Listener at localhost/40272] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:01,182 [Listener at localhost/40272] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:01,183 [Listener at localhost/40272] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:01,183 [Listener at localhost/40272] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:01,184 [Listener at localhost/40272] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:01,191 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6daf7d37] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:01,192 [Listener at localhost/40272] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:01,192 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,194 [Listener at localhost/40272] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:01,195 [Listener at localhost/40272] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:01,195 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,197 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:01,198 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:01,198 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:01,198 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:01,200 [Listener at localhost/40272] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:01,200 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:01,201 [Listener at localhost/40272] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41413
2020-12-03 07:24:01,201 [Listener at localhost/40272] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:01,216 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a8406c2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:01,217 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6850b758{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:01,224 [Listener at localhost/40272] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@317e9c3c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:01,224 [Listener at localhost/40272] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@18da4dd{HTTP/1.1,[http/1.1]}{localhost:41413}
2020-12-03 07:24:01,225 [Listener at localhost/40272] INFO  server.Server (Server.java:doStart(419)) - Started @28993ms
2020-12-03 07:24:01,225 [Listener at localhost/40272] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,225 [Listener at localhost/40272] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,226 [Listener at localhost/40272] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:01,226 [Listener at localhost/40272] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:01,226 [Listener at localhost/40272] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,226 [Listener at localhost/40272] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,228 [Listener at localhost/40272] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:01,228 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:01,228 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:01,228 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:01,229 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:01,229 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:01,229 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:01,229 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:01,230 [Listener at localhost/40272] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:01,230 [Listener at localhost/40272] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:01,231 [Listener at localhost/40272] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:01,231 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:01,231 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:01
2020-12-03 07:24:01,232 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:01,232 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:01,232 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:01,233 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:01,245 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:01,245 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:01,245 [Listener at localhost/40272] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:01,246 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:01,247 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:01,247 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:01,247 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:01,247 [Listener at localhost/40272] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:01,247 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:01,248 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:01,248 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:01,248 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:01,254 [Listener at localhost/40272] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:01,255 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:01,255 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:01,255 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:01,255 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:01,258 [Listener at localhost/40272] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:01,258 [Listener at localhost/40272] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:01,258 [Listener at localhost/40272] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:01,259 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:01,259 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:01,259 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:01,260 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:01,260 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:01,260 [Listener at localhost/40272] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:01,346 [Listener at localhost/40272] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:01,349 [Listener at localhost/40272] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:01,349 [Listener at localhost/40272] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:01,357 [Listener at localhost/40272] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:01,359 [Listener at localhost/40272] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:01,359 [Listener at localhost/40272] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:01,360 [Listener at localhost/40272] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@47ffe971 expecting start txid #32
2020-12-03 07:24:01,360 [Listener at localhost/40272] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:01,361 [Listener at localhost/40272] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:01,364 [Listener at localhost/40272] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:24:01,365 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:01,368 [Listener at localhost/40272] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:01,467 [Listener at localhost/40272] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:01,467 [Listener at localhost/40272] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 206 msecs
2020-12-03 07:24:01,468 [Listener at localhost/40272] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:01,468 [Listener at localhost/40272] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:01,469 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:01,480 [Listener at localhost/41268] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41268 to access this namenode/service.
2020-12-03 07:24:01,481 [Listener at localhost/41268] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:01,481 [Listener at localhost/41268] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:01,493 [Listener at localhost/41268] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:01,495 [Listener at localhost/41268] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:01,501 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:01,501 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:01,511 [Listener at localhost/41268] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41268
2020-12-03 07:24:01,512 [Listener at localhost/41268] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:01,512 [Listener at localhost/41268] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:01,513 [Listener at localhost/41268] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:01,533 [CacheReplicationMonitor(756657689)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:01,548 [IPC Server handler 0 on default port 41268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:01,549 [Listener at localhost/41268] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:01,883 [Listener at localhost/41268] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:01,883 [Listener at localhost/41268] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:01,884 [Listener at localhost/41268] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:01,885 [Listener at localhost/41268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:01,885 [Listener at localhost/41268] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:01,886 [Listener at localhost/41268] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:01,886 [Listener at localhost/41268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:01,886 [Listener at localhost/41268] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:01,887 [Listener at localhost/41268] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37057
2020-12-03 07:24:01,887 [Listener at localhost/41268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:01,887 [Listener at localhost/41268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:01,888 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,890 [Listener at localhost/41268] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:01,891 [Listener at localhost/41268] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:01,891 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,893 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:01,893 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:01,893 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:01,894 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:01,894 [Listener at localhost/41268] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41092
2020-12-03 07:24:01,895 [Listener at localhost/41268] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:01,896 [Listener at localhost/41268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c7f96b1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:01,897 [Listener at localhost/41268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a04fea7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:01,903 [Listener at localhost/41268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7903d448{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:01,904 [Listener at localhost/41268] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e08acf9{HTTP/1.1,[http/1.1]}{localhost:41092}
2020-12-03 07:24:01,904 [Listener at localhost/41268] INFO  server.Server (Server.java:doStart(419)) - Started @29673ms
2020-12-03 07:24:01,934 [Listener at localhost/41268] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45546
2020-12-03 07:24:01,935 [Listener at localhost/41268] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:01,935 [Listener at localhost/41268] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:01,935 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78cd163b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:01,936 [Listener at localhost/41268] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:01,956 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:01,971 [Listener at localhost/43794] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43794
2020-12-03 07:24:01,975 [Listener at localhost/43794] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:01,976 [Listener at localhost/43794] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:01,977 [Thread-1146] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41268 starting to offer service
2020-12-03 07:24:01,980 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:01,980 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:01,997 [IPC Server handler 1 on default port 41268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:01,998 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:01,998 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:02,001 [Thread-1146] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41268
2020-12-03 07:24:02,003 [Thread-1146] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:24:02,045 [Thread-1146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:02,104 [IPC Server handler 3 on default port 41268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:02,105 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:02,106 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:02,107 [Thread-1146] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:02,107 [Thread-1146] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:02,107 [Thread-1146] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:02,107 [Thread-1146] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:02,108 [Thread-1146] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41268. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:02,108 [Thread-1146] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41268
2020-12-03 07:24:02,108 [Thread-1146] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:02,207 [IPC Server handler 4 on default port 41268] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:02,207 [Listener at localhost/43794] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:37057', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:41268
2020-12-03 07:24:02,208 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:02,208 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:02,208 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:02,208 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@48840594] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:02,296 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7903d448{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:02,296 [Listener at localhost/43794] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e08acf9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:02,297 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a04fea7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:02,297 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c7f96b1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:02,298 [Listener at localhost/43794] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43794
2020-12-03 07:24:02,300 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:02,301 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:02,301 [Listener at localhost/43794] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:02,302 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:02,302 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:02,304 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@743e66f7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:02,304 [Listener at localhost/43794] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:02,308 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@15383681] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:02,368 [Listener at localhost/43794] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 4 
2020-12-03 07:24:02,370 [Listener at localhost/43794] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:02,370 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:02,377 [Listener at localhost/43794] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41268
2020-12-03 07:24:02,377 [CacheReplicationMonitor(756657689)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:02,379 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:02,379 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:02,380 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:02,380 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:02,392 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:02,393 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:02,394 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@317e9c3c{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:02,406 [Listener at localhost/43794] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@18da4dd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:02,407 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6850b758{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:02,407 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a8406c2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:02,408 [Listener at localhost/43794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:02,409 [Listener at localhost/43794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:02,409 [Listener at localhost/43794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:02,418 [Listener at localhost/43794] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:02,418 [Listener at localhost/43794] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 16*** BLOCK_POOL recovery: numDirs=1 testCase=16 current=false previous=false previous.tmp=false removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:02,461 [Listener at localhost/43794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:02,461 [Listener at localhost/43794] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,463 [Listener at localhost/43794] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:02,465 [Listener at localhost/43794] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:02,480 [Listener at localhost/43794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:02,481 [Listener at localhost/43794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:02,481 [Listener at localhost/43794] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:02,488 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6726cc69] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:02,488 [Listener at localhost/43794] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:02,489 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,490 [Listener at localhost/43794] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:02,491 [Listener at localhost/43794] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:02,492 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,493 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:02,494 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:02,496 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:02,496 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:02,498 [Listener at localhost/43794] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:02,498 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:02,499 [Listener at localhost/43794] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38418
2020-12-03 07:24:02,499 [Listener at localhost/43794] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:02,554 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@644ded04{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:02,555 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13d9261f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:02,560 [Listener at localhost/43794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61cd1c71{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:02,560 [Listener at localhost/43794] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6724cdec{HTTP/1.1,[http/1.1]}{localhost:38418}
2020-12-03 07:24:02,560 [Listener at localhost/43794] INFO  server.Server (Server.java:doStart(419)) - Started @30329ms
2020-12-03 07:24:02,561 [Listener at localhost/43794] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,561 [Listener at localhost/43794] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,561 [Listener at localhost/43794] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:02,562 [Listener at localhost/43794] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:02,562 [Listener at localhost/43794] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,562 [Listener at localhost/43794] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,563 [Listener at localhost/43794] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:02,564 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:02,564 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:02,564 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:02,564 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:02,565 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:02,565 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:02,565 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:02,566 [Listener at localhost/43794] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:02,566 [Listener at localhost/43794] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:02,566 [Listener at localhost/43794] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:02,567 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:02,568 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:02
2020-12-03 07:24:02,568 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:02,568 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:02,569 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:02,569 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:02,591 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:02,592 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:02,593 [Listener at localhost/43794] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:02,593 [Listener at localhost/43794] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:02,593 [Listener at localhost/43794] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:02,593 [Listener at localhost/43794] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:02,594 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:02,594 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:02,594 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:02,594 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:02,595 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:02,595 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:02,595 [Listener at localhost/43794] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:02,596 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:02,596 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:02,597 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:02,597 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:02,605 [Listener at localhost/43794] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:02,606 [Listener at localhost/43794] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:02,606 [Listener at localhost/43794] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:02,606 [Listener at localhost/43794] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:02,606 [Listener at localhost/43794] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:02,607 [Listener at localhost/43794] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:02,607 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:02,607 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:02,608 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:02,608 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:02,610 [Listener at localhost/43794] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:02,610 [Listener at localhost/43794] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:02,610 [Listener at localhost/43794] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:02,611 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:02,611 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:02,611 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:02,611 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:02,612 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:02,612 [Listener at localhost/43794] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:02,698 [Listener at localhost/43794] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:02,700 [Listener at localhost/43794] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:02,700 [Listener at localhost/43794] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:02,702 [Listener at localhost/43794] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:02,713 [Listener at localhost/43794] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:02,713 [Listener at localhost/43794] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:02,714 [Listener at localhost/43794] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4674d90 expecting start txid #32
2020-12-03 07:24:02,714 [Listener at localhost/43794] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:02,714 [Listener at localhost/43794] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:02,717 [Listener at localhost/43794] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:02,717 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:02,718 [Listener at localhost/43794] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:02,774 [Listener at localhost/43794] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:02,774 [Listener at localhost/43794] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 162 msecs
2020-12-03 07:24:02,775 [Listener at localhost/43794] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:02,775 [Listener at localhost/43794] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:02,776 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:02,780 [Listener at localhost/42117] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:42117 to access this namenode/service.
2020-12-03 07:24:02,780 [Listener at localhost/42117] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:02,781 [Listener at localhost/42117] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:02,798 [Listener at localhost/42117] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:02,803 [Listener at localhost/42117] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:02,807 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:02,807 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:02,824 [Listener at localhost/42117] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42117
2020-12-03 07:24:02,825 [Listener at localhost/42117] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:02,825 [Listener at localhost/42117] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:02,840 [Listener at localhost/42117] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 15 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:02,870 [CacheReplicationMonitor(452932642)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:02,879 [IPC Server handler 0 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:02,886 [Listener at localhost/42117] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:03,090 [Listener at localhost/42117] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:03,091 [Listener at localhost/42117] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:03,092 [Listener at localhost/42117] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,092 [Listener at localhost/42117] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,092 [Listener at localhost/42117] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:03,093 [Listener at localhost/42117] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,093 [Listener at localhost/42117] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,093 [Listener at localhost/42117] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,094 [Listener at localhost/42117] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45271
2020-12-03 07:24:03,094 [Listener at localhost/42117] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,094 [Listener at localhost/42117] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,095 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,096 [Listener at localhost/42117] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,097 [Listener at localhost/42117] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,097 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,098 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,099 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,099 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,099 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,100 [Listener at localhost/42117] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38935
2020-12-03 07:24:03,100 [Listener at localhost/42117] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,101 [Listener at localhost/42117] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2af69643{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,102 [Listener at localhost/42117] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48528634{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,107 [Listener at localhost/42117] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@210308d5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,107 [Listener at localhost/42117] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22a736d7{HTTP/1.1,[http/1.1]}{localhost:38935}
2020-12-03 07:24:03,107 [Listener at localhost/42117] INFO  server.Server (Server.java:doStart(419)) - Started @30876ms
2020-12-03 07:24:03,129 [Listener at localhost/42117] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38206
2020-12-03 07:24:03,129 [Listener at localhost/42117] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,129 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f353d99] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,129 [Listener at localhost/42117] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,130 [Listener at localhost/42117] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,131 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,137 [Listener at localhost/43302] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43302
2020-12-03 07:24:03,144 [Listener at localhost/43302] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,144 [Listener at localhost/43302] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,145 [Thread-1207] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42117 starting to offer service
2020-12-03 07:24:03,156 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,156 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,172 [IPC Server handler 2 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,173 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:03,173 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:03,191 [Thread-1207] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42117
2020-12-03 07:24:03,193 [Thread-1207] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:24:03,236 [Thread-1207] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:03,280 [IPC Server handler 3 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,281 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:03,282 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:03,383 [IPC Server handler 6 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,384 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:03,384 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:03,485 [IPC Server handler 7 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,486 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:03,486 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:03,588 [IPC Server handler 5 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,588 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:03,588 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:03,680 [Thread-1207] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:03,681 [Thread-1207] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:03,681 [Thread-1207] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:03,681 [Thread-1207] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:03,682 [Thread-1207] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:42117. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:03,682 [Thread-1207] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:42117
2020-12-03 07:24:03,682 [Thread-1207] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:03,690 [IPC Server handler 8 on default port 42117] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:03,690 [Listener at localhost/43302] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:45271', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:42117
2020-12-03 07:24:03,691 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:03,691 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:03,691 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:03,691 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@65bdd558] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:03,709 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@210308d5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:03,710 [Listener at localhost/43302] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22a736d7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:03,710 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48528634{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:03,710 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2af69643{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:03,713 [Listener at localhost/43302] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43302
2020-12-03 07:24:03,714 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:03,715 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:03,718 [Listener at localhost/43302] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:03,718 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:03,719 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:03,719 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@761e788f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:03,719 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6a472566] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:03,719 [Listener at localhost/43302] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:03,721 [Listener at localhost/43302] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:24:03,722 [Listener at localhost/43302] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:03,722 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:03,722 [CacheReplicationMonitor(452932642)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:03,754 [Listener at localhost/43302] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42117
2020-12-03 07:24:03,757 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:03,766 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:03,767 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:03,767 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:03,801 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:03,801 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:03,806 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61cd1c71{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:03,816 [Listener at localhost/43302] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6724cdec{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:03,817 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13d9261f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:03,818 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@644ded04{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:03,818 [Listener at localhost/43302] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:03,819 [Listener at localhost/43302] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:03,819 [Listener at localhost/43302] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:03,825 [Listener at localhost/43302] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:03,825 [Listener at localhost/43302] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 17*** BLOCK_POOL recovery: numDirs=1 testCase=17 current=false previous=true previous.tmp=false removed.tmp=true should recover=true current exists after=true previous exists after=true
2020-12-03 07:24:03,865 [Listener at localhost/43302] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:03,865 [Listener at localhost/43302] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:03,866 [Listener at localhost/43302] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:03,868 [Listener at localhost/43302] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:03,870 [Listener at localhost/43302] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:03,870 [Listener at localhost/43302] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:03,871 [Listener at localhost/43302] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:03,877 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21bd20ee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,877 [Listener at localhost/43302] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:03,878 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,879 [Listener at localhost/43302] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,880 [Listener at localhost/43302] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:03,880 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,882 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,882 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:03,883 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,883 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,884 [Listener at localhost/43302] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:03,884 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:03,884 [Listener at localhost/43302] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34296
2020-12-03 07:24:03,885 [Listener at localhost/43302] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,886 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@255eaa6b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,887 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a0e7ecd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,893 [Listener at localhost/43302] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55e42449{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:03,893 [Listener at localhost/43302] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e57e5d6{HTTP/1.1,[http/1.1]}{localhost:34296}
2020-12-03 07:24:03,894 [Listener at localhost/43302] INFO  server.Server (Server.java:doStart(419)) - Started @31662ms
2020-12-03 07:24:03,894 [Listener at localhost/43302] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:03,895 [Listener at localhost/43302] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:03,895 [Listener at localhost/43302] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:03,895 [Listener at localhost/43302] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:24:03,896 [Listener at localhost/43302] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:03,896 [Listener at localhost/43302] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:03,897 [Listener at localhost/43302] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:03,898 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:03,898 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:03,898 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:03,898 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:03,898 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:03,899 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:03,899 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:03,899 [Listener at localhost/43302] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,899 [Listener at localhost/43302] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:03,900 [Listener at localhost/43302] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:03,900 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:03,900 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:03
2020-12-03 07:24:03,900 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:03,901 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:03,901 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:03,901 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:03,906 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:03,906 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:03,907 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:03,908 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:03,908 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:03,908 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:03,908 [Listener at localhost/43302] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:03,908 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:03,909 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:03,909 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:03,909 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:03,914 [Listener at localhost/43302] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:03,915 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:03,915 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:03,915 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:03,915 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:03,917 [Listener at localhost/43302] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:03,917 [Listener at localhost/43302] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:03,917 [Listener at localhost/43302] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:03,918 [Listener at localhost/43302] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:03,964 [Listener at localhost/43302] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:03,966 [Listener at localhost/43302] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:03,967 [Listener at localhost/43302] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:03,969 [Listener at localhost/43302] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:03,970 [Listener at localhost/43302] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:03,970 [Listener at localhost/43302] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:03,971 [Listener at localhost/43302] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@561b61ed expecting start txid #32
2020-12-03 07:24:03,971 [Listener at localhost/43302] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:03,971 [Listener at localhost/43302] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:03,974 [Listener at localhost/43302] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:03,974 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:03,974 [Listener at localhost/43302] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:04,044 [Listener at localhost/43302] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:04,045 [Listener at localhost/43302] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 125 msecs
2020-12-03 07:24:04,045 [Listener at localhost/43302] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:04,046 [Listener at localhost/43302] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:04,056 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:04,061 [Listener at localhost/35948] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35948 to access this namenode/service.
2020-12-03 07:24:04,061 [Listener at localhost/35948] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:04,062 [Listener at localhost/35948] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:04,082 [Listener at localhost/35948] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:04,084 [Listener at localhost/35948] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:04,087 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:04,088 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:04,108 [Listener at localhost/35948] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35948
2020-12-03 07:24:04,109 [Listener at localhost/35948] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:04,109 [Listener at localhost/35948] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:04,110 [Listener at localhost/35948] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:04,146 [CacheReplicationMonitor(635361488)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:04,156 [IPC Server handler 0 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:04,157 [Listener at localhost/35948] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:04,595 [Listener at localhost/35948] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:04,596 [Listener at localhost/35948] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:04,597 [Listener at localhost/35948] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:04,598 [Listener at localhost/35948] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,598 [Listener at localhost/35948] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:04,598 [Listener at localhost/35948] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:04,598 [Listener at localhost/35948] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,599 [Listener at localhost/35948] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:04,599 [Listener at localhost/35948] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38423
2020-12-03 07:24:04,599 [Listener at localhost/35948] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:04,600 [Listener at localhost/35948] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:04,600 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,602 [Listener at localhost/35948] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:04,603 [Listener at localhost/35948] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:04,603 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,605 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:04,605 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:04,605 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:04,606 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:04,607 [Listener at localhost/35948] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39877
2020-12-03 07:24:04,607 [Listener at localhost/35948] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:04,608 [Listener at localhost/35948] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:04,609 [Listener at localhost/35948] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:04,614 [Listener at localhost/35948] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@799ed4e8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:04,615 [Listener at localhost/35948] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e66bc32{HTTP/1.1,[http/1.1]}{localhost:39877}
2020-12-03 07:24:04,615 [Listener at localhost/35948] INFO  server.Server (Server.java:doStart(419)) - Started @32383ms
2020-12-03 07:24:04,635 [Listener at localhost/35948] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41096
2020-12-03 07:24:04,637 [Listener at localhost/35948] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:04,637 [Listener at localhost/35948] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:04,638 [Listener at localhost/35948] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:04,638 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:04,640 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b65d9f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:04,646 [Listener at localhost/35887] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35887
2020-12-03 07:24:04,649 [Listener at localhost/35887] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:04,649 [Listener at localhost/35887] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:04,650 [Thread-1269] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35948 starting to offer service
2020-12-03 07:24:04,653 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:04,653 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:04,665 [IPC Server handler 2 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:04,665 [Thread-1269] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35948
2020-12-03 07:24:04,676 [Thread-1269] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:24:04,677 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:04,677 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:04,776 [Thread-1269] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:04,784 [IPC Server handler 3 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:04,787 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:04,787 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:04,889 [IPC Server handler 4 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:04,889 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:04,890 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:04,912 [Thread-1269] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:04,913 [Thread-1269] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:04,913 [Thread-1269] INFO  common.Storage (Storage.java:doRecover(809)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 from previous rollback
2020-12-03 07:24:04,991 [IPC Server handler 5 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:04,992 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:04,992 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:05,056 [Thread-1269] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:05,059 [Thread-1269] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fa9dfc1c-46af-4347-a625-848d1d705d2f
2020-12-03 07:24:05,059 [Thread-1269] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:05,060 [Thread-1269] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:05,061 [Thread-1269] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:05,062 [Thread-1269] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:05,062 [Thread-1269] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:05,063 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:05,064 [Thread-1281] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:05,075 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 13ms
2020-12-03 07:24:05,075 [Thread-1269] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 13ms
2020-12-03 07:24:05,076 [Thread-1282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:05,079 [Thread-1282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:05,079 [Thread-1282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 3ms
2020-12-03 07:24:05,079 [Thread-1269] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 4ms
2020-12-03 07:24:05,080 [Thread-1269] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:47 AM with interval of 21600000ms
2020-12-03 07:24:05,081 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35948 beginning handshake with NN
2020-12-03 07:24:05,085 [IPC Server handler 6 on default port 35948] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38423, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=41096, infoSecurePort=0, ipcPort=35887, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:05,085 [IPC Server handler 6 on default port 35948] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38423
2020-12-03 07:24:05,086 [IPC Server handler 6 on default port 35948] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:38423).
2020-12-03 07:24:05,088 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35948 successfully registered with NN
2020-12-03 07:24:05,088 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35948 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:05,090 [IPC Server handler 7 on default port 35948] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa9dfc1c-46af-4347-a625-848d1d705d2f for DN 127.0.0.1:38423
2020-12-03 07:24:05,093 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x97ffca2e5d5153b1: Processing first storage report for DS-fa9dfc1c-46af-4347-a625-848d1d705d2f from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:05,094 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:05,095 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:05,095 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:24:05,095 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:05,095 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:05,097 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x97ffca2e5d5153b1: from storage DS-fa9dfc1c-46af-4347-a625-848d1d705d2f node DatanodeRegistration(127.0.0.1:38423, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=41096, infoSecurePort=0, ipcPort=35887, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:24:05,098 [IPC Server handler 8 on default port 35948] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:05,099 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:05,100 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:05,100 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:05,100 [Listener at localhost/35887] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:05,100 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5e519ad3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:05,109 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:05,109 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:05,109 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:05,109 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:05,109 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:05,110 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-12-03 07:24:05,110 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x97ffca2e5d5153b1,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:05,128 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@799ed4e8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:05,129 [Listener at localhost/35887] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e66bc32{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:05,130 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:05,130 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:05,131 [Listener at localhost/35887] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35887
2020-12-03 07:24:05,134 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:05,134 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:05,134 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:05,135 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:35948
2020-12-03 07:24:05,135 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:05,135 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:35948] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:05,136 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:05,152 [Listener at localhost/35887] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:05,152 [Listener at localhost/35887] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:05,153 [Listener at localhost/35887] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:05,153 [Listener at localhost/35887] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:05,155 [Listener at localhost/35887] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:05,155 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:05,155 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:05,156 [Listener at localhost/35887] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:05,156 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@59dc36d4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:05,156 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@68d7a2df] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:05,158 [Listener at localhost/35887] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 
2020-12-03 07:24:05,159 [Listener at localhost/35887] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:05,159 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:05,160 [Listener at localhost/35887] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35948
2020-12-03 07:24:05,160 [CacheReplicationMonitor(635361488)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:05,162 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:05,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:05,164 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:05,164 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:05,216 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:05,217 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:05,218 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55e42449{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:05,228 [Listener at localhost/35887] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@e57e5d6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:05,229 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a0e7ecd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:05,230 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@255eaa6b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:05,240 [Listener at localhost/35887] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:05,248 [Listener at localhost/35887] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:05,249 [Listener at localhost/35887] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:05,280 [Listener at localhost/35887] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:05,284 [Listener at localhost/35887] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 18*** BLOCK_POOL recovery: numDirs=2 testCase=0 current=true previous=false previous.tmp=false removed.tmp=false should recover=true current exists after=true previous exists after=false
2020-12-03 07:24:05,394 [Listener at localhost/35887] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:05,395 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,395 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,396 [Listener at localhost/35887] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:05,398 [Listener at localhost/35887] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:05,404 [Listener at localhost/35887] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:05,404 [Listener at localhost/35887] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:05,405 [Listener at localhost/35887] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:05,411 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4613311f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:05,412 [Listener at localhost/35887] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:05,412 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:05,414 [Listener at localhost/35887] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:05,414 [Listener at localhost/35887] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:05,415 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:05,417 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:05,417 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:05,418 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:05,418 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:05,419 [Listener at localhost/35887] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:05,420 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:05,420 [Listener at localhost/35887] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39707
2020-12-03 07:24:05,420 [Listener at localhost/35887] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:05,435 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7efb53af{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:05,436 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3dfa819{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:05,441 [Listener at localhost/35887] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69fe0ed4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:05,442 [Listener at localhost/35887] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@20ab3e3a{HTTP/1.1,[http/1.1]}{localhost:39707}
2020-12-03 07:24:05,442 [Listener at localhost/35887] INFO  server.Server (Server.java:doStart(419)) - Started @33210ms
2020-12-03 07:24:05,442 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,442 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,443 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,443 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,443 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,443 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,444 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,444 [Listener at localhost/35887] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,445 [Listener at localhost/35887] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:05,446 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:05,447 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:05,448 [Listener at localhost/35887] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:05,449 [Listener at localhost/35887] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:05,449 [Listener at localhost/35887] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:05,449 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:05,450 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:05
2020-12-03 07:24:05,450 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:05,450 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:05,450 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:05,450 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:05,462 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:05,463 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:05,464 [Listener at localhost/35887] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:05,464 [Listener at localhost/35887] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:05,465 [Listener at localhost/35887] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:05,465 [Listener at localhost/35887] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:05,465 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:05,466 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:05,466 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:05,466 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:05,466 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:05,466 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:05,467 [Listener at localhost/35887] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:05,467 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:05,468 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:05,468 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:05,468 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:05,470 [Listener at localhost/35887] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:05,471 [Listener at localhost/35887] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:05,471 [Listener at localhost/35887] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:05,471 [Listener at localhost/35887] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:05,471 [Listener at localhost/35887] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:05,472 [Listener at localhost/35887] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:05,472 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:05,472 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:05,473 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:05,473 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:05,474 [Listener at localhost/35887] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:05,475 [Listener at localhost/35887] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:05,475 [Listener at localhost/35887] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:05,476 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:05,476 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:05,476 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:05,476 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:05,477 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:05,477 [Listener at localhost/35887] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:05,544 [Listener at localhost/35887] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:05,586 [Listener at localhost/35887] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:05,589 [Listener at localhost/35887] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:05,590 [Listener at localhost/35887] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:05,597 [Listener at localhost/35887] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:05,607 [Listener at localhost/35887] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:05,608 [Listener at localhost/35887] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:05,609 [Listener at localhost/35887] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:05,609 [Listener at localhost/35887] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@38eb0f4d expecting start txid #32
2020-12-03 07:24:05,609 [Listener at localhost/35887] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:05,609 [Listener at localhost/35887] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:05,611 [Listener at localhost/35887] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:05,612 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:05,612 [Listener at localhost/35887] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:05,696 [Listener at localhost/35887] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:05,696 [Listener at localhost/35887] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 219 msecs
2020-12-03 07:24:05,697 [Listener at localhost/35887] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:05,697 [Listener at localhost/35887] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:05,698 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:05,713 [Listener at localhost/36634] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36634 to access this namenode/service.
2020-12-03 07:24:05,714 [Listener at localhost/36634] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:05,714 [Listener at localhost/36634] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:05,715 [Listener at localhost/36634] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:05,750 [Listener at localhost/36634] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:05,761 [Listener at localhost/36634] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:05,780 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:05,781 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:05,782 [Listener at localhost/36634] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36634
2020-12-03 07:24:05,783 [Listener at localhost/36634] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:05,783 [Listener at localhost/36634] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:05,787 [Listener at localhost/36634] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 3 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:05,825 [CacheReplicationMonitor(1461795042)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:05,849 [IPC Server handler 0 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:05,850 [Listener at localhost/36634] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:06,381 [Listener at localhost/36634] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:06,382 [Listener at localhost/36634] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:06,382 [Listener at localhost/36634] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:06,383 [Listener at localhost/36634] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:06,384 [Listener at localhost/36634] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:06,384 [Listener at localhost/36634] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:06,393 [Listener at localhost/36634] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:06,393 [Listener at localhost/36634] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:06,394 [Listener at localhost/36634] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:06,394 [Listener at localhost/36634] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34784
2020-12-03 07:24:06,395 [Listener at localhost/36634] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:06,395 [Listener at localhost/36634] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:06,396 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:06,397 [Listener at localhost/36634] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:06,398 [Listener at localhost/36634] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:06,398 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:06,400 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:06,400 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:06,400 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:06,400 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:06,401 [Listener at localhost/36634] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37659
2020-12-03 07:24:06,401 [Listener at localhost/36634] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:06,405 [Listener at localhost/36634] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25aeb5ac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:06,406 [Listener at localhost/36634] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3bd2af5b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:06,413 [Listener at localhost/36634] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ea4300e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:06,413 [Listener at localhost/36634] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a1c3cb4{HTTP/1.1,[http/1.1]}{localhost:37659}
2020-12-03 07:24:06,414 [Listener at localhost/36634] INFO  server.Server (Server.java:doStart(419)) - Started @34182ms
2020-12-03 07:24:06,429 [Listener at localhost/36634] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32965
2020-12-03 07:24:06,430 [Listener at localhost/36634] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:06,430 [Listener at localhost/36634] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:06,430 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56637cff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:06,431 [Listener at localhost/36634] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:06,432 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:06,435 [Listener at localhost/42666] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42666
2020-12-03 07:24:06,437 [Listener at localhost/42666] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:06,438 [Listener at localhost/42666] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:06,441 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:06,441 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:06,444 [Thread-1337] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36634 starting to offer service
2020-12-03 07:24:06,460 [IPC Server handler 1 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:06,498 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:06,498 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:06,513 [Thread-1337] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36634
2020-12-03 07:24:06,517 [Thread-1337] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:06,559 [Thread-1337] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:06,601 [IPC Server handler 3 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:06,609 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:06,609 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:06,652 [Thread-1337] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:06,705 [Thread-1337] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:06,706 [Thread-1337] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:06,711 [IPC Server handler 4 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:06,712 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:06,712 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:06,763 [Thread-1337] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:06,764 [Thread-1337] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:06,814 [IPC Server handler 0 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:06,814 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:06,814 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:06,819 [Thread-1337] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:06,822 [Thread-1337] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-394a078f-0b51-4849-aac7-49827cdd7d4f
2020-12-03 07:24:06,822 [Thread-1337] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:06,823 [Thread-1337] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0400774e-d7ee-44df-b975-5e5379ee6669
2020-12-03 07:24:06,823 [Thread-1337] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:06,823 [Thread-1337] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:06,824 [Thread-1337] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:06,828 [Thread-1337] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:06,828 [Thread-1337] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:06,828 [Thread-1337] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:06,829 [Thread-1337] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:06,829 [Thread-1350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:06,831 [Thread-1350] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:06,832 [Thread-1349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:06,836 [Thread-1349] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:06,846 [Thread-1350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 16ms
2020-12-03 07:24:06,846 [Thread-1349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 14ms
2020-12-03 07:24:06,852 [Thread-1337] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 23ms
2020-12-03 07:24:06,908 [Thread-1351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:06,918 [Thread-1351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:06,919 [Thread-1351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 10ms
2020-12-03 07:24:06,918 [Thread-1352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:06,924 [IPC Server handler 1 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:06,925 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:06,925 [Thread-1352] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:06,926 [Thread-1352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 1ms
2020-12-03 07:24:06,928 [Thread-1337] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 77ms
2020-12-03 07:24:06,929 [Thread-1337] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:57 AM with interval of 21600000ms
2020-12-03 07:24:06,925 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:06,945 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36634 beginning handshake with NN
2020-12-03 07:24:06,957 [IPC Server handler 2 on default port 36634] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34784, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=32965, infoSecurePort=0, ipcPort=42666, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:06,957 [IPC Server handler 2 on default port 36634] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34784
2020-12-03 07:24:06,958 [IPC Server handler 2 on default port 36634] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:34784).
2020-12-03 07:24:06,974 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36634 successfully registered with NN
2020-12-03 07:24:06,974 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36634 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:06,989 [IPC Server handler 3 on default port 36634] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-394a078f-0b51-4849-aac7-49827cdd7d4f for DN 127.0.0.1:34784
2020-12-03 07:24:06,989 [IPC Server handler 3 on default port 36634] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0400774e-d7ee-44df-b975-5e5379ee6669 for DN 127.0.0.1:34784
2020-12-03 07:24:07,002 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe41f6876c00004ef: Processing first storage report for DS-394a078f-0b51-4849-aac7-49827cdd7d4f from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:07,002 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe41f6876c00004ef: from storage DS-394a078f-0b51-4849-aac7-49827cdd7d4f node DatanodeRegistration(127.0.0.1:34784, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=32965, infoSecurePort=0, ipcPort=42666, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:07,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe41f6876c00004ef: Processing first storage report for DS-0400774e-d7ee-44df-b975-5e5379ee6669 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:07,003 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:07,008 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:07,008 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:24:07,008 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:07,008 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:07,024 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe41f6876c00004ef: from storage DS-0400774e-d7ee-44df-b975-5e5379ee6669 node DatanodeRegistration(127.0.0.1:34784, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=32965, infoSecurePort=0, ipcPort=42666, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 22 msecs, invalidatedBlocks: 0
2020-12-03 07:24:07,038 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:07,038 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:07,038 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:07,038 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:07,038 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:07,039 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2020-12-03 07:24:07,040 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe41f6876c00004ef,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 40 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:07,061 [IPC Server handler 5 on default port 36634] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,064 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:07,079 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:07,079 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:07,079 [Listener at localhost/42666] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:07,079 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4228bf58] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:07,115 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ea4300e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:07,128 [Listener at localhost/42666] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a1c3cb4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:07,129 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3bd2af5b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:07,129 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25aeb5ac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:07,136 [Listener at localhost/42666] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42666
2020-12-03 07:24:07,146 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:07,146 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:07,146 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:07,146 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36634
2020-12-03 07:24:07,146 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:07,147 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36634] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:07,153 [Listener at localhost/42666] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:07,154 [Listener at localhost/42666] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:07,155 [Listener at localhost/42666] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:07,155 [Listener at localhost/42666] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:07,182 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:07,186 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:07,188 [Listener at localhost/42666] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:07,188 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:07,189 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:07,192 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@748d2277] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:07,192 [Listener at localhost/42666] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:07,196 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2f897dab] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:07,196 [Listener at localhost/42666] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 4 9 
2020-12-03 07:24:07,197 [Listener at localhost/42666] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:07,198 [Listener at localhost/42666] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:07,198 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:07,199 [CacheReplicationMonitor(1461795042)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:07,199 [Listener at localhost/42666] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36634
2020-12-03 07:24:07,200 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:07,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:07,208 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:07,209 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:07,234 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:07,235 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:07,237 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69fe0ed4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:07,246 [Listener at localhost/42666] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@20ab3e3a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:07,247 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3dfa819{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:07,248 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7efb53af{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:07,254 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:07,257 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:07,257 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:07,268 [Listener at localhost/42666] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:07,279 [Listener at localhost/42666] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 19*** BLOCK_POOL recovery: numDirs=2 testCase=1 current=true previous=true previous.tmp=false removed.tmp=false should recover=true current exists after=true previous exists after=true
2020-12-03 07:24:07,467 [Listener at localhost/42666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:07,467 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,468 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:07,468 [Listener at localhost/42666] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:07,470 [Listener at localhost/42666] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:07,472 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:07,472 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:07,472 [Listener at localhost/42666] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:07,476 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@267dc982] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:07,476 [Listener at localhost/42666] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:07,477 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:07,478 [Listener at localhost/42666] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:07,479 [Listener at localhost/42666] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:07,479 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:07,481 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:07,482 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:07,482 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:07,482 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:07,484 [Listener at localhost/42666] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:07,484 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:07,484 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35515
2020-12-03 07:24:07,485 [Listener at localhost/42666] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:07,496 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d7fb838{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:07,497 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a37a501{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:07,518 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@173a6728{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:07,519 [Listener at localhost/42666] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a22e0ef{HTTP/1.1,[http/1.1]}{localhost:35515}
2020-12-03 07:24:07,520 [Listener at localhost/42666] INFO  server.Server (Server.java:doStart(419)) - Started @35288ms
2020-12-03 07:24:07,520 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,521 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:07,521 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,521 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:07,522 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,522 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:07,522 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,522 [Listener at localhost/42666] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:07,524 [Listener at localhost/42666] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:07,525 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:07,525 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:07,526 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:07,526 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:07,526 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:07,526 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:07,526 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:07,527 [Listener at localhost/42666] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:07,527 [Listener at localhost/42666] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:07,527 [Listener at localhost/42666] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:07,528 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:07,528 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:07
2020-12-03 07:24:07,528 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:07,528 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:07,529 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:07,529 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:07,537 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:07,538 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:07,538 [Listener at localhost/42666] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:07,539 [Listener at localhost/42666] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:07,539 [Listener at localhost/42666] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:07,539 [Listener at localhost/42666] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:07,539 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:07,540 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:07,540 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:07,540 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:07,540 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:07,541 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:07,541 [Listener at localhost/42666] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:07,541 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:07,542 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:07,542 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:07,542 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:07,545 [Listener at localhost/42666] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:07,545 [Listener at localhost/42666] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:07,545 [Listener at localhost/42666] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:07,545 [Listener at localhost/42666] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:07,546 [Listener at localhost/42666] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:07,546 [Listener at localhost/42666] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:07,560 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:07,560 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:07,561 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:07,561 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:07,563 [Listener at localhost/42666] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:07,564 [Listener at localhost/42666] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:07,564 [Listener at localhost/42666] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:07,565 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:07,565 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:07,565 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:07,565 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:07,566 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:07,566 [Listener at localhost/42666] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:07,603 [Listener at localhost/42666] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:07,629 [Listener at localhost/42666] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:07,631 [Listener at localhost/42666] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:07,632 [Listener at localhost/42666] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:07,633 [Listener at localhost/42666] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:07,637 [Listener at localhost/42666] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:07,639 [Listener at localhost/42666] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:07,639 [Listener at localhost/42666] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:07,639 [Listener at localhost/42666] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@623ebac7 expecting start txid #32
2020-12-03 07:24:07,640 [Listener at localhost/42666] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:07,640 [Listener at localhost/42666] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:07,642 [Listener at localhost/42666] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:07,643 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:07,655 [Listener at localhost/42666] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:07,738 [Listener at localhost/42666] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:07,739 [Listener at localhost/42666] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 172 msecs
2020-12-03 07:24:07,739 [Listener at localhost/42666] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:07,740 [Listener at localhost/42666] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:07,744 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:07,750 [Listener at localhost/40204] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:40204 to access this namenode/service.
2020-12-03 07:24:07,751 [Listener at localhost/40204] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:07,751 [Listener at localhost/40204] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:07,751 [Listener at localhost/40204] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:08,029 [Listener at localhost/40204] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:08,048 [Listener at localhost/40204] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:08,060 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:08,064 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:08,065 [Listener at localhost/40204] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40204
2020-12-03 07:24:08,066 [Listener at localhost/40204] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:08,066 [Listener at localhost/40204] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:08,084 [Listener at localhost/40204] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 18 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:08,101 [CacheReplicationMonitor(1664201157)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:08,114 [IPC Server handler 0 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,116 [Listener at localhost/40204] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:09,000 [Listener at localhost/40204] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:09,001 [Listener at localhost/40204] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:09,001 [Listener at localhost/40204] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:09,002 [Listener at localhost/40204] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:09,002 [Listener at localhost/40204] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:09,003 [Listener at localhost/40204] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:09,003 [Listener at localhost/40204] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:09,003 [Listener at localhost/40204] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:09,003 [Listener at localhost/40204] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:09,007 [Listener at localhost/40204] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42941
2020-12-03 07:24:09,008 [Listener at localhost/40204] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:09,008 [Listener at localhost/40204] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:09,009 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:09,017 [Listener at localhost/40204] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:09,017 [Listener at localhost/40204] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:09,018 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:09,019 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:09,020 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:09,020 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:09,020 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:09,021 [Listener at localhost/40204] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46076
2020-12-03 07:24:09,021 [Listener at localhost/40204] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:09,023 [Listener at localhost/40204] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b9a77c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:09,023 [Listener at localhost/40204] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cd3ad8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:09,029 [Listener at localhost/40204] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7b4a0aef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:09,029 [Listener at localhost/40204] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@45cec376{HTTP/1.1,[http/1.1]}{localhost:46076}
2020-12-03 07:24:09,029 [Listener at localhost/40204] INFO  server.Server (Server.java:doStart(419)) - Started @36798ms
2020-12-03 07:24:09,056 [Listener at localhost/40204] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42444
2020-12-03 07:24:09,056 [Listener at localhost/40204] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:09,056 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@298f0a0b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:09,056 [Listener at localhost/40204] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:09,057 [Listener at localhost/40204] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:09,058 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:09,060 [Listener at localhost/45123] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45123
2020-12-03 07:24:09,063 [Listener at localhost/45123] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:09,064 [Listener at localhost/45123] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:09,072 [Thread-1412] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40204 starting to offer service
2020-12-03 07:24:09,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:09,092 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:09,112 [IPC Server handler 0 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,114 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,114 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,115 [Thread-1412] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40204
2020-12-03 07:24:09,116 [Thread-1412] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:09,171 [Thread-1412] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:09,224 [IPC Server handler 4 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,230 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,230 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,246 [Thread-1412] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:09,286 [Thread-1412] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,286 [Thread-1412] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,333 [IPC Server handler 9 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,335 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,335 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,342 [Thread-1412] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,343 [Thread-1412] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,376 [Thread-1412] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:09,378 [Thread-1412] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5155fc9b-b132-4b89-985e-ba571667f012
2020-12-03 07:24:09,378 [Thread-1412] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:09,379 [Thread-1412] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-857666ff-c5be-4b47-8175-0d837e278673
2020-12-03 07:24:09,379 [Thread-1412] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:09,380 [Thread-1412] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:09,380 [Thread-1412] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:09,388 [Thread-1412] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:09,388 [Thread-1412] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:09,389 [Thread-1412] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:09,396 [Thread-1412] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,400 [Thread-1424] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:09,402 [Thread-1424] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:09,408 [Thread-1425] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:09,410 [Thread-1425] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:09,417 [Thread-1424] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 17ms
2020-12-03 07:24:09,439 [Thread-1425] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 31ms
2020-12-03 07:24:09,441 [Thread-1412] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 44ms
2020-12-03 07:24:09,441 [IPC Server handler 5 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,448 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,448 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,452 [Thread-1426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:09,460 [Thread-1427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:09,461 [Thread-1427] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:09,461 [Thread-1427] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 1ms
2020-12-03 07:24:09,478 [Thread-1426] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:09,481 [Thread-1426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 28ms
2020-12-03 07:24:09,484 [Thread-1412] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 44ms
2020-12-03 07:24:09,485 [Thread-1412] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:04 AM with interval of 21600000ms
2020-12-03 07:24:09,493 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:40204 beginning handshake with NN
2020-12-03 07:24:09,497 [IPC Server handler 7 on default port 40204] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42941, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=42444, infoSecurePort=0, ipcPort=45123, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:09,497 [IPC Server handler 7 on default port 40204] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42941
2020-12-03 07:24:09,497 [IPC Server handler 7 on default port 40204] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:42941).
2020-12-03 07:24:09,504 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:40204 successfully registered with NN
2020-12-03 07:24:09,504 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40204 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,511 [IPC Server handler 8 on default port 40204] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5155fc9b-b132-4b89-985e-ba571667f012 for DN 127.0.0.1:42941
2020-12-03 07:24:09,511 [IPC Server handler 8 on default port 40204] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-857666ff-c5be-4b47-8175-0d837e278673 for DN 127.0.0.1:42941
2020-12-03 07:24:09,524 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8fa1b9ec13806269: Processing first storage report for DS-857666ff-c5be-4b47-8175-0d837e278673 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:09,524 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8fa1b9ec13806269: from storage DS-857666ff-c5be-4b47-8175-0d837e278673 node DatanodeRegistration(127.0.0.1:42941, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=42444, infoSecurePort=0, ipcPort=45123, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,528 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8fa1b9ec13806269: Processing first storage report for DS-5155fc9b-b132-4b89-985e-ba571667f012 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:09,529 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:09,536 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:09,536 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:24:09,536 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:09,536 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:09,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8fa1b9ec13806269: from storage DS-5155fc9b-b132-4b89-985e-ba571667f012 node DatanodeRegistration(127.0.0.1:42941, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=42444, infoSecurePort=0, ipcPort=45123, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:09,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:09,551 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:09,551 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:09,551 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:09,551 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-12-03 07:24:09,551 [IPC Server handler 1 on default port 40204] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,552 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8fa1b9ec13806269,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 36 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:09,552 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:09,553 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:09,553 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:09,554 [Listener at localhost/45123] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:09,556 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3743539f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:09,687 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7b4a0aef{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:09,689 [Listener at localhost/45123] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@45cec376{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:09,689 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cd3ad8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:09,689 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b9a77c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:09,714 [Listener at localhost/45123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45123
2020-12-03 07:24:09,717 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:09,718 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:40204
2020-12-03 07:24:09,718 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:09,718 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:09,718 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:40204] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:09,718 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:09,719 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:09,721 [Listener at localhost/45123] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:09,721 [Listener at localhost/45123] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:09,722 [Listener at localhost/45123] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:09,722 [Listener at localhost/45123] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:09,728 [Listener at localhost/45123] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:09,729 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:09,729 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:09,730 [Listener at localhost/45123] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:09,730 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4adc663e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:09,732 [Listener at localhost/45123] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:09,732 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:09,732 [Listener at localhost/45123] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:09,736 [Listener at localhost/45123] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:09,732 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7dbe2ebf] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:09,736 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:09,737 [CacheReplicationMonitor(1664201157)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:09,737 [Listener at localhost/45123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40204
2020-12-03 07:24:09,752 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:09,760 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:09,760 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:09,756 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:09,778 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:09,779 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:09,783 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@173a6728{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:09,793 [Listener at localhost/45123] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a22e0ef{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:09,793 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a37a501{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:09,794 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d7fb838{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:09,798 [Listener at localhost/45123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:09,798 [Listener at localhost/45123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:09,798 [Listener at localhost/45123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:09,820 [Listener at localhost/45123] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:09,820 [Listener at localhost/45123] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 20*** BLOCK_POOL recovery: numDirs=2 testCase=2 current=true previous=false previous.tmp=true removed.tmp=false should recover=true current exists after=true previous exists after=true
2020-12-03 07:24:09,929 [Listener at localhost/45123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:09,929 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:09,930 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:09,930 [Listener at localhost/45123] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:09,933 [Listener at localhost/45123] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:09,938 [Listener at localhost/45123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:09,938 [Listener at localhost/45123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:09,939 [Listener at localhost/45123] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:09,948 [Listener at localhost/45123] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:09,949 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:09,951 [Listener at localhost/45123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:09,952 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e4e1ef5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:09,952 [Listener at localhost/45123] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:09,953 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:09,955 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:09,955 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:09,955 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:09,956 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:09,957 [Listener at localhost/45123] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:09,958 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:09,958 [Listener at localhost/45123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33709
2020-12-03 07:24:09,958 [Listener at localhost/45123] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:10,024 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37468787{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:10,027 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@714f3da4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:10,034 [Listener at localhost/45123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cbc2e3b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:10,035 [Listener at localhost/45123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2975a9e{HTTP/1.1,[http/1.1]}{localhost:33709}
2020-12-03 07:24:10,035 [Listener at localhost/45123] INFO  server.Server (Server.java:doStart(419)) - Started @37804ms
2020-12-03 07:24:10,036 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:10,036 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:10,036 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:10,036 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:10,037 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:10,037 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:10,037 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:10,037 [Listener at localhost/45123] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:10,039 [Listener at localhost/45123] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:10,040 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:10,040 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:10,040 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:10,040 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:10,041 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:10,041 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:10,041 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:10,041 [Listener at localhost/45123] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:10,042 [Listener at localhost/45123] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:10,042 [Listener at localhost/45123] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:10,042 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:10,042 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:10
2020-12-03 07:24:10,043 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:10,043 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:10,043 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:10,043 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:10,048 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:10,048 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:10,049 [Listener at localhost/45123] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:10,049 [Listener at localhost/45123] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:10,049 [Listener at localhost/45123] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:10,049 [Listener at localhost/45123] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:10,049 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:10,050 [Listener at localhost/45123] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:10,051 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:10,051 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:10,051 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:10,051 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:10,054 [Listener at localhost/45123] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:10,055 [Listener at localhost/45123] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:10,055 [Listener at localhost/45123] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:10,055 [Listener at localhost/45123] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:10,055 [Listener at localhost/45123] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:10,055 [Listener at localhost/45123] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:10,056 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:10,056 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:10,063 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:10,063 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:10,064 [Listener at localhost/45123] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:10,064 [Listener at localhost/45123] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:10,064 [Listener at localhost/45123] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:10,065 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:10,065 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:10,065 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:10,065 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:10,065 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:10,066 [Listener at localhost/45123] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:10,108 [Listener at localhost/45123] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:10,186 [Listener at localhost/45123] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:10,188 [Listener at localhost/45123] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:10,188 [Listener at localhost/45123] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:10,189 [Listener at localhost/45123] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:10,203 [Listener at localhost/45123] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:10,204 [Listener at localhost/45123] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:10,204 [Listener at localhost/45123] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:10,204 [Listener at localhost/45123] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67064bdc expecting start txid #32
2020-12-03 07:24:10,204 [Listener at localhost/45123] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:10,204 [Listener at localhost/45123] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:10,207 [Listener at localhost/45123] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:10,207 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:10,212 [Listener at localhost/45123] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:10,335 [Listener at localhost/45123] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:10,335 [Listener at localhost/45123] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 269 msecs
2020-12-03 07:24:10,335 [Listener at localhost/45123] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:10,336 [Listener at localhost/45123] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:10,337 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:10,340 [Listener at localhost/37486] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37486 to access this namenode/service.
2020-12-03 07:24:10,341 [Listener at localhost/37486] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:10,341 [Listener at localhost/37486] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:10,341 [Listener at localhost/37486] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:10,366 [Listener at localhost/37486] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:10,374 [Listener at localhost/37486] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:10,444 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:10,448 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:10,449 [Listener at localhost/37486] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37486
2020-12-03 07:24:10,450 [Listener at localhost/37486] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:10,450 [Listener at localhost/37486] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:10,452 [Listener at localhost/37486] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:10,455 [CacheReplicationMonitor(194648261)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:10,477 [IPC Server handler 0 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:10,480 [Listener at localhost/37486] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:11,241 [Listener at localhost/37486] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:11,243 [Listener at localhost/37486] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:11,248 [Listener at localhost/37486] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:11,256 [Listener at localhost/37486] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:11,257 [Listener at localhost/37486] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:11,257 [Listener at localhost/37486] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:11,258 [Listener at localhost/37486] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:11,258 [Listener at localhost/37486] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:11,258 [Listener at localhost/37486] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:11,259 [Listener at localhost/37486] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35287
2020-12-03 07:24:11,259 [Listener at localhost/37486] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:11,259 [Listener at localhost/37486] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:11,264 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:11,267 [Listener at localhost/37486] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:11,267 [Listener at localhost/37486] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:11,268 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:11,269 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:11,270 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:11,270 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:11,270 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:11,271 [Listener at localhost/37486] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39783
2020-12-03 07:24:11,272 [Listener at localhost/37486] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:11,274 [Listener at localhost/37486] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60b34931{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:11,274 [Listener at localhost/37486] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71c17a57{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:11,281 [Listener at localhost/37486] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@feb98ef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:11,281 [Listener at localhost/37486] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7654f833{HTTP/1.1,[http/1.1]}{localhost:39783}
2020-12-03 07:24:11,282 [Listener at localhost/37486] INFO  server.Server (Server.java:doStart(419)) - Started @39050ms
2020-12-03 07:24:11,303 [Listener at localhost/37486] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45452
2020-12-03 07:24:11,303 [Listener at localhost/37486] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:11,304 [Listener at localhost/37486] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:11,303 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f4a3a8d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:11,304 [Listener at localhost/37486] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:11,305 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:11,307 [Listener at localhost/36223] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36223
2020-12-03 07:24:11,310 [Listener at localhost/36223] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:11,311 [Listener at localhost/36223] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:11,312 [Thread-1487] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37486 starting to offer service
2020-12-03 07:24:11,314 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:11,314 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:11,317 [Thread-1487] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37486
2020-12-03 07:24:11,319 [Thread-1487] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:11,319 [IPC Server handler 3 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,320 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,321 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,422 [IPC Server handler 4 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,424 [Thread-1487] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:11,428 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,428 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,532 [IPC Server handler 2 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,536 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,536 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,638 [IPC Server handler 3 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,638 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,639 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,720 [Thread-1487] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:11,740 [IPC Server handler 4 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,741 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,741 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,817 [Thread-1487] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:11,818 [Thread-1487] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:11,818 [Thread-1487] INFO  common.Storage (Storage.java:doRecover(792)) - Completing previous upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:11,844 [IPC Server handler 5 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,845 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,846 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,948 [IPC Server handler 6 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,949 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:11,950 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:11,977 [Thread-1487] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:11,977 [Thread-1487] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:11,978 [Thread-1487] INFO  common.Storage (Storage.java:doRecover(792)) - Completing previous upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:12,052 [IPC Server handler 7 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:12,052 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:12,053 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:12,133 [Thread-1487] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:12,135 [Thread-1487] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2f414ca9-4ef8-4c17-a722-94a726194797
2020-12-03 07:24:12,135 [Thread-1487] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:12,136 [Thread-1487] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0afbbf94-4731-4a96-ac81-a1164ab5e10e
2020-12-03 07:24:12,136 [Thread-1487] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:12,136 [Thread-1487] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:12,137 [Thread-1487] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:12,138 [Thread-1487] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:12,138 [Thread-1487] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:12,138 [Thread-1487] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:12,148 [Thread-1487] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:12,149 [Thread-1499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:12,150 [Thread-1499] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:12,152 [Thread-1500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:12,153 [Thread-1500] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:12,182 [Thread-1500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 30ms
2020-12-03 07:24:12,182 [Thread-1499] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 34ms
2020-12-03 07:24:12,183 [IPC Server handler 8 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:12,184 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:12,185 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:12,188 [Thread-1487] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 40ms
2020-12-03 07:24:12,192 [Thread-1501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:12,201 [Thread-1501] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:12,201 [Thread-1501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 9ms
2020-12-03 07:24:12,204 [Thread-1502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:12,205 [Thread-1502] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:12,219 [Thread-1502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 15ms
2020-12-03 07:24:12,220 [Thread-1487] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 31ms
2020-12-03 07:24:12,220 [Thread-1487] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:39 AM with interval of 21600000ms
2020-12-03 07:24:12,221 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37486 beginning handshake with NN
2020-12-03 07:24:12,223 [IPC Server handler 9 on default port 37486] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35287, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45452, infoSecurePort=0, ipcPort=36223, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:12,223 [IPC Server handler 9 on default port 37486] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35287
2020-12-03 07:24:12,223 [IPC Server handler 9 on default port 37486] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:35287).
2020-12-03 07:24:12,245 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37486 successfully registered with NN
2020-12-03 07:24:12,246 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37486 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:12,272 [IPC Server handler 1 on default port 37486] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2f414ca9-4ef8-4c17-a722-94a726194797 for DN 127.0.0.1:35287
2020-12-03 07:24:12,272 [IPC Server handler 1 on default port 37486] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0afbbf94-4731-4a96-ac81-a1164ab5e10e for DN 127.0.0.1:35287
2020-12-03 07:24:12,289 [IPC Server handler 2 on default port 37486] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:12,290 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:12,291 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:12,291 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:12,291 [Listener at localhost/36223] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:12,291 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2c8c16c0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:12,293 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ba2d0d5d6d2718a: Processing first storage report for DS-2f414ca9-4ef8-4c17-a722-94a726194797 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:12,293 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ba2d0d5d6d2718a: from storage DS-2f414ca9-4ef8-4c17-a722-94a726194797 node DatanodeRegistration(127.0.0.1:35287, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45452, infoSecurePort=0, ipcPort=36223, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:12,294 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ba2d0d5d6d2718a: Processing first storage report for DS-0afbbf94-4731-4a96-ac81-a1164ab5e10e from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:12,294 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:12,300 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:12,301 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:24:12,308 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:12,309 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:12,320 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ba2d0d5d6d2718a: from storage DS-0afbbf94-4731-4a96-ac81-a1164ab5e10e node DatanodeRegistration(127.0.0.1:35287, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45452, infoSecurePort=0, ipcPort=36223, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 27 msecs, invalidatedBlocks: 0
2020-12-03 07:24:12,341 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:12,341 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:12,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:12,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:12,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:12,342 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 22 msec
2020-12-03 07:24:12,342 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7ba2d0d5d6d2718a,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 61 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:12,393 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@feb98ef{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:12,396 [Listener at localhost/36223] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7654f833{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:12,397 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71c17a57{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:12,397 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60b34931{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:12,405 [Listener at localhost/36223] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36223
2020-12-03 07:24:12,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:12,408 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:12,408 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37486
2020-12-03 07:24:12,408 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:12,408 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:37486] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:12,410 [Listener at localhost/36223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:12,410 [Listener at localhost/36223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:12,411 [Listener at localhost/36223] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:12,411 [Listener at localhost/36223] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:12,412 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:12,413 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:12,415 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:12,432 [Listener at localhost/36223] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:12,433 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:12,433 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:12,434 [Listener at localhost/36223] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:12,434 [Listener at localhost/36223] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:12,435 [Listener at localhost/36223] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:12,442 [Listener at localhost/36223] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:12,436 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@435cc7f9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:12,436 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4364712f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:12,442 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:12,443 [CacheReplicationMonitor(194648261)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:12,443 [Listener at localhost/36223] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37486
2020-12-03 07:24:12,445 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:12,448 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:12,448 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:12,448 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:12,459 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:12,460 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:12,462 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4cbc2e3b{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:12,465 [Listener at localhost/36223] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2975a9e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:12,466 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@714f3da4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:12,466 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37468787{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:12,467 [Listener at localhost/36223] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:12,469 [Listener at localhost/36223] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:12,469 [Listener at localhost/36223] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:12,485 [Listener at localhost/36223] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:12,485 [Listener at localhost/36223] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 21*** BLOCK_POOL recovery: numDirs=2 testCase=3 current=true previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:12,581 [Listener at localhost/36223] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:12,581 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:12,582 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:12,582 [Listener at localhost/36223] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:12,584 [Listener at localhost/36223] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:12,585 [Listener at localhost/36223] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:12,585 [Listener at localhost/36223] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:12,586 [Listener at localhost/36223] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:12,590 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4277127c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:12,590 [Listener at localhost/36223] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:12,591 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:12,593 [Listener at localhost/36223] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:12,593 [Listener at localhost/36223] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:12,594 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:12,595 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:12,596 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:12,596 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:12,596 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:12,598 [Listener at localhost/36223] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:12,598 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:12,599 [Listener at localhost/36223] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37870
2020-12-03 07:24:12,599 [Listener at localhost/36223] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:12,606 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2687725a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:12,606 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c05ff9d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:12,612 [Listener at localhost/36223] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@257e0827{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:12,613 [Listener at localhost/36223] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22752544{HTTP/1.1,[http/1.1]}{localhost:37870}
2020-12-03 07:24:12,614 [Listener at localhost/36223] INFO  server.Server (Server.java:doStart(419)) - Started @40382ms
2020-12-03 07:24:12,614 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:12,614 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:12,615 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:12,615 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:12,616 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:12,616 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:12,616 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:12,617 [Listener at localhost/36223] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:12,618 [Listener at localhost/36223] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:12,619 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:12,619 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:12,619 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:12,619 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:12,620 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:12,620 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:12,620 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:12,621 [Listener at localhost/36223] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:12,621 [Listener at localhost/36223] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:12,621 [Listener at localhost/36223] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:12,622 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:12,622 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:12
2020-12-03 07:24:12,623 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:12,623 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:12,623 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:12,623 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:12,636 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:12,636 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:12,637 [Listener at localhost/36223] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:12,638 [Listener at localhost/36223] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:12,639 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:12,640 [Listener at localhost/36223] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:12,640 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:12,640 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:12,640 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:12,640 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:12,646 [Listener at localhost/36223] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:12,647 [Listener at localhost/36223] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:12,647 [Listener at localhost/36223] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:12,647 [Listener at localhost/36223] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:12,647 [Listener at localhost/36223] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:12,647 [Listener at localhost/36223] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:12,648 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:12,648 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:12,648 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:12,649 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:12,650 [Listener at localhost/36223] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:12,651 [Listener at localhost/36223] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:12,651 [Listener at localhost/36223] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:12,652 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:12,652 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:12,652 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:12,652 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:12,653 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:12,653 [Listener at localhost/36223] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:12,815 [Listener at localhost/36223] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:12,995 [Listener at localhost/36223] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:12,998 [Listener at localhost/36223] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:12,998 [Listener at localhost/36223] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:12,999 [Listener at localhost/36223] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:13,006 [Listener at localhost/36223] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:13,007 [Listener at localhost/36223] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:13,007 [Listener at localhost/36223] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:13,007 [Listener at localhost/36223] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@427ae189 expecting start txid #32
2020-12-03 07:24:13,007 [Listener at localhost/36223] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:13,008 [Listener at localhost/36223] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:13,010 [Listener at localhost/36223] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:13,011 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:13,012 [Listener at localhost/36223] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:13,417 [Listener at localhost/36223] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:13,417 [Listener at localhost/36223] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 764 msecs
2020-12-03 07:24:13,418 [Listener at localhost/36223] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:13,419 [Listener at localhost/36223] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:13,420 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:13,423 [Listener at localhost/46102] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46102 to access this namenode/service.
2020-12-03 07:24:13,423 [Listener at localhost/46102] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:13,424 [Listener at localhost/46102] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:13,424 [Listener at localhost/46102] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:13,443 [Listener at localhost/46102] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:13,448 [Listener at localhost/46102] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:13,458 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:13,459 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:13,461 [Listener at localhost/46102] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46102
2020-12-03 07:24:13,462 [Listener at localhost/46102] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:13,462 [Listener at localhost/46102] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:13,463 [Listener at localhost/46102] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:13,508 [CacheReplicationMonitor(2138557379)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:13,514 [IPC Server handler 1 on default port 46102] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:13,520 [Listener at localhost/46102] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:14,784 [Listener at localhost/46102] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:14,785 [Listener at localhost/46102] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:14,786 [Listener at localhost/46102] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:14,805 [Listener at localhost/46102] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:14,805 [Listener at localhost/46102] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:14,806 [Listener at localhost/46102] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:14,806 [Listener at localhost/46102] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:14,806 [Listener at localhost/46102] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:14,807 [Listener at localhost/46102] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:14,808 [Listener at localhost/46102] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38374
2020-12-03 07:24:14,808 [Listener at localhost/46102] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:14,808 [Listener at localhost/46102] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:14,813 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:14,815 [Listener at localhost/46102] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:14,820 [Listener at localhost/46102] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:14,821 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:14,823 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:14,824 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:14,824 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:14,824 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:14,825 [Listener at localhost/46102] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44080
2020-12-03 07:24:14,826 [Listener at localhost/46102] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:14,828 [Listener at localhost/46102] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@fe7b6b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:14,832 [Listener at localhost/46102] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77681ce4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:14,857 [Listener at localhost/46102] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3ae126d1{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:14,858 [Listener at localhost/46102] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@46a488c2{HTTP/1.1,[http/1.1]}{localhost:44080}
2020-12-03 07:24:14,858 [Listener at localhost/46102] INFO  server.Server (Server.java:doStart(419)) - Started @42626ms
2020-12-03 07:24:14,898 [Listener at localhost/46102] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42006
2020-12-03 07:24:14,900 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65ddee5a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:14,900 [Listener at localhost/46102] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:14,901 [Listener at localhost/46102] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:14,901 [Listener at localhost/46102] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:14,902 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:14,906 [Listener at localhost/42091] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42091
2020-12-03 07:24:14,908 [Listener at localhost/42091] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:14,909 [Listener at localhost/42091] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:14,910 [Thread-1559] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46102 starting to offer service
2020-12-03 07:24:14,916 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:14,916 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:14,930 [Thread-1559] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46102
2020-12-03 07:24:14,955 [Thread-1559] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:14,963 [IPC Server handler 3 on default port 46102] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:14,963 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:14,964 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:15,039 [Thread-1559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:15,065 [IPC Server handler 4 on default port 46102] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:15,066 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:15,066 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:15,149 [Thread-1559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:15,167 [IPC Server handler 5 on default port 46102] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:15,168 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:15,168 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:15,186 [Thread-1559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:15,186 [Thread-1559] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:15,186 [Thread-1559] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,187 [Thread-1559] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,197 [Thread-1559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:15,197 [Thread-1559] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:15,197 [Thread-1559] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,197 [Thread-1559] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,198 [Thread-1559] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46102. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,198 [Thread-1559] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46102
2020-12-03 07:24:15,198 [Thread-1559] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:15,270 [IPC Server handler 6 on default port 46102] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:15,270 [Listener at localhost/42091] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:38374', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:46102
2020-12-03 07:24:15,271 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:15,271 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:15,271 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:15,272 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@196ae579] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,326 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3ae126d1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,327 [Listener at localhost/42091] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@46a488c2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,327 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77681ce4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,328 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@fe7b6b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,328 [Listener at localhost/42091] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42091
2020-12-03 07:24:15,329 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,331 [Listener at localhost/42091] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,331 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:15,332 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:15,332 [Listener at localhost/42091] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:15,332 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3f1a4795] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:15,332 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@58d6b7b9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:15,333 [Listener at localhost/42091] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:15,333 [Listener at localhost/42091] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:15,334 [Listener at localhost/42091] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:15,334 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:15,334 [CacheReplicationMonitor(2138557379)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:15,335 [Listener at localhost/42091] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46102
2020-12-03 07:24:15,337 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,337 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,338 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:15,338 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:15,347 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:15,347 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:15,349 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@257e0827{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:15,350 [Listener at localhost/42091] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22752544{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,350 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c05ff9d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,350 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2687725a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,351 [Listener at localhost/42091] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:15,353 [Listener at localhost/42091] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:15,353 [Listener at localhost/42091] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:15,366 [Listener at localhost/42091] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:15,367 [Listener at localhost/42091] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 22*** BLOCK_POOL recovery: numDirs=2 testCase=4 current=true previous=true previous.tmp=true removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:15,507 [Listener at localhost/42091] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:15,507 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,508 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,508 [Listener at localhost/42091] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:15,511 [Listener at localhost/42091] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:15,512 [Listener at localhost/42091] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:15,512 [Listener at localhost/42091] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:15,513 [Listener at localhost/42091] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:15,517 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@95eb320] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:15,517 [Listener at localhost/42091] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:15,518 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:15,519 [Listener at localhost/42091] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:15,520 [Listener at localhost/42091] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:15,520 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:15,522 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:15,522 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:15,523 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:15,523 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:15,525 [Listener at localhost/42091] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:15,525 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:15,525 [Listener at localhost/42091] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35446
2020-12-03 07:24:15,526 [Listener at localhost/42091] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:15,528 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@506a1372{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:15,529 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77c233af{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:15,536 [Listener at localhost/42091] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@42fb8c87{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:15,537 [Listener at localhost/42091] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15eb0ae9{HTTP/1.1,[http/1.1]}{localhost:35446}
2020-12-03 07:24:15,537 [Listener at localhost/42091] INFO  server.Server (Server.java:doStart(419)) - Started @43305ms
2020-12-03 07:24:15,537 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,538 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,538 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,538 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,539 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,539 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,539 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,540 [Listener at localhost/42091] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,543 [Listener at localhost/42091] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:15,545 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:15,545 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:15,545 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:15,545 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:15,549 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:15,549 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:15,549 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:15,550 [Listener at localhost/42091] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:15,551 [Listener at localhost/42091] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:15,551 [Listener at localhost/42091] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:15,551 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:15,552 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:15
2020-12-03 07:24:15,564 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:15,565 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:15,565 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:15,565 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:15,594 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:15,594 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:15,595 [Listener at localhost/42091] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:15,595 [Listener at localhost/42091] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:15,595 [Listener at localhost/42091] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:15,595 [Listener at localhost/42091] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:15,596 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:15,596 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:15,596 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:15,596 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:15,597 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:15,597 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:15,597 [Listener at localhost/42091] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:15,598 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:15,598 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:15,598 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:15,598 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:15,605 [Listener at localhost/42091] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:15,605 [Listener at localhost/42091] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:15,605 [Listener at localhost/42091] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:15,605 [Listener at localhost/42091] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:15,606 [Listener at localhost/42091] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:15,606 [Listener at localhost/42091] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:15,606 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:15,606 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:15,607 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:15,607 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:15,609 [Listener at localhost/42091] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:15,609 [Listener at localhost/42091] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:15,610 [Listener at localhost/42091] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:15,610 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:15,611 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:15,611 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:15,611 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:15,611 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:15,612 [Listener at localhost/42091] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:15,656 [Listener at localhost/42091] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:15,686 [Listener at localhost/42091] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:15,688 [Listener at localhost/42091] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:15,688 [Listener at localhost/42091] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:15,689 [Listener at localhost/42091] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:15,705 [Listener at localhost/42091] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:15,712 [Listener at localhost/42091] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:15,713 [Listener at localhost/42091] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:15,713 [Listener at localhost/42091] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@43aeb5e0 expecting start txid #32
2020-12-03 07:24:15,713 [Listener at localhost/42091] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:15,714 [Listener at localhost/42091] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:15,717 [Listener at localhost/42091] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:24:15,718 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:15,724 [Listener at localhost/42091] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:15,829 [Listener at localhost/42091] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:15,829 [Listener at localhost/42091] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 216 msecs
2020-12-03 07:24:15,829 [Listener at localhost/42091] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:15,830 [Listener at localhost/42091] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:15,831 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:15,833 [Listener at localhost/37090] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37090 to access this namenode/service.
2020-12-03 07:24:15,834 [Listener at localhost/37090] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:15,834 [Listener at localhost/37090] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:15,835 [Listener at localhost/37090] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:15,918 [Listener at localhost/37090] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:15,923 [Listener at localhost/37090] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:15,930 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:15,940 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:15,945 [Listener at localhost/37090] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37090
2020-12-03 07:24:15,945 [Listener at localhost/37090] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:15,946 [Listener at localhost/37090] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:15,949 [Listener at localhost/37090] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 3 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:15,960 [CacheReplicationMonitor(1316534918)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:15,977 [IPC Server handler 0 on default port 37090] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:15,978 [Listener at localhost/37090] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:16,892 [Listener at localhost/37090] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:16,893 [Listener at localhost/37090] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:16,894 [Listener at localhost/37090] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:16,895 [Listener at localhost/37090] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:16,896 [Listener at localhost/37090] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:16,896 [Listener at localhost/37090] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:16,896 [Listener at localhost/37090] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:16,896 [Listener at localhost/37090] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:16,897 [Listener at localhost/37090] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:16,898 [Listener at localhost/37090] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43627
2020-12-03 07:24:16,898 [Listener at localhost/37090] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:16,898 [Listener at localhost/37090] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:16,900 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:16,902 [Listener at localhost/37090] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:16,902 [Listener at localhost/37090] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:16,903 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:16,905 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:16,905 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:16,906 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:16,906 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:16,907 [Listener at localhost/37090] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45054
2020-12-03 07:24:16,907 [Listener at localhost/37090] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:16,909 [Listener at localhost/37090] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5edc70ed{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:16,910 [Listener at localhost/37090] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e4c72d6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:16,917 [Listener at localhost/37090] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4b76aa5a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:16,918 [Listener at localhost/37090] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63a28987{HTTP/1.1,[http/1.1]}{localhost:45054}
2020-12-03 07:24:16,918 [Listener at localhost/37090] INFO  server.Server (Server.java:doStart(419)) - Started @44686ms
2020-12-03 07:24:16,934 [Listener at localhost/37090] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46868
2020-12-03 07:24:16,934 [Listener at localhost/37090] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:16,934 [Listener at localhost/37090] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:16,934 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38c9e0d6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:16,935 [Listener at localhost/37090] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:16,935 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:16,937 [Listener at localhost/36426] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36426
2020-12-03 07:24:16,940 [Listener at localhost/36426] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:16,940 [Listener at localhost/36426] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:16,940 [Thread-1621] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37090 starting to offer service
2020-12-03 07:24:16,945 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:16,946 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:16,950 [IPC Server handler 2 on default port 37090] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:16,951 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:16,951 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:16,952 [Thread-1621] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37090
2020-12-03 07:24:16,953 [Thread-1621] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:17,035 [Thread-1621] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:17,052 [IPC Server handler 1 on default port 37090] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:17,053 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:17,053 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:17,127 [Thread-1621] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:17,154 [IPC Server handler 3 on default port 37090] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:17,155 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:17,155 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:17,161 [Thread-1621] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:17,161 [Thread-1621] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:17,161 [Thread-1621] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,162 [Thread-1621] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,170 [Thread-1621] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:17,170 [Thread-1621] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:17,170 [Thread-1621] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,171 [Thread-1621] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,171 [Thread-1621] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37090. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,171 [Thread-1621] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:37090
2020-12-03 07:24:17,171 [Thread-1621] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:17,257 [IPC Server handler 4 on default port 37090] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:17,257 [Listener at localhost/36426] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:43627', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:37090
2020-12-03 07:24:17,257 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:17,258 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:17,258 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:17,258 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7e72a6cc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:17,393 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4b76aa5a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:17,400 [Listener at localhost/36426] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63a28987{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:17,401 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e4c72d6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:17,401 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5edc70ed{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:17,404 [Listener at localhost/36426] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36426
2020-12-03 07:24:17,409 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:17,409 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:17,419 [Listener at localhost/36426] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:17,419 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:17,419 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:17,420 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@b112b13] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:17,421 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@24eb65e3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:17,421 [Listener at localhost/36426] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:17,433 [Listener at localhost/36426] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-12-03 07:24:17,434 [Listener at localhost/36426] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:17,435 [Listener at localhost/36426] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:17,444 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:17,445 [CacheReplicationMonitor(1316534918)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:17,446 [Listener at localhost/36426] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37090
2020-12-03 07:24:17,464 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:17,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:17,466 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:17,466 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:17,481 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:17,481 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:17,483 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@42fb8c87{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:17,489 [Listener at localhost/36426] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15eb0ae9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:17,489 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77c233af{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:17,490 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@506a1372{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:17,493 [Listener at localhost/36426] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:17,493 [Listener at localhost/36426] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:17,494 [Listener at localhost/36426] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:17,508 [Listener at localhost/36426] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:17,508 [Listener at localhost/36426] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 23*** BLOCK_POOL recovery: numDirs=2 testCase=5 current=false previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:17,718 [Listener at localhost/36426] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:17,719 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:17,719 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:17,720 [Listener at localhost/36426] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:17,722 [Listener at localhost/36426] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:17,723 [Listener at localhost/36426] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:17,723 [Listener at localhost/36426] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:17,724 [Listener at localhost/36426] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:17,728 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@35ee466f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:17,728 [Listener at localhost/36426] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:17,729 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:17,730 [Listener at localhost/36426] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:17,740 [Listener at localhost/36426] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:17,741 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:17,742 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:17,743 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:17,743 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:17,743 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:17,745 [Listener at localhost/36426] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:17,745 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:17,745 [Listener at localhost/36426] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38911
2020-12-03 07:24:17,746 [Listener at localhost/36426] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:17,751 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@788ba63e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:17,751 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68ee3b6d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:17,757 [Listener at localhost/36426] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@404eca05{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:17,758 [Listener at localhost/36426] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58b91d57{HTTP/1.1,[http/1.1]}{localhost:38911}
2020-12-03 07:24:17,758 [Listener at localhost/36426] INFO  server.Server (Server.java:doStart(419)) - Started @45526ms
2020-12-03 07:24:17,758 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:17,759 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:17,759 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:17,759 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:17,760 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:17,760 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:17,760 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:17,760 [Listener at localhost/36426] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:17,762 [Listener at localhost/36426] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:17,763 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:17,763 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:17,763 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:17,763 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:17,763 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:17,764 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:17,764 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:17,769 [Listener at localhost/36426] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:17,769 [Listener at localhost/36426] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:17,769 [Listener at localhost/36426] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:17,770 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:17,770 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:17
2020-12-03 07:24:17,770 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:17,770 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:17,771 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:17,771 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:17,790 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:17,790 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:17,791 [Listener at localhost/36426] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:17,791 [Listener at localhost/36426] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:17,791 [Listener at localhost/36426] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:17,791 [Listener at localhost/36426] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:17,796 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:17,796 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:17,796 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:17,796 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:17,797 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:17,797 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:17,797 [Listener at localhost/36426] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:17,797 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:17,798 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:17,798 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:17,798 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:17,800 [Listener at localhost/36426] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:17,800 [Listener at localhost/36426] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:17,800 [Listener at localhost/36426] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:17,801 [Listener at localhost/36426] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:17,801 [Listener at localhost/36426] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:17,801 [Listener at localhost/36426] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:17,801 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:17,801 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:17,802 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:17,802 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:17,803 [Listener at localhost/36426] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:17,803 [Listener at localhost/36426] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:17,803 [Listener at localhost/36426] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:17,804 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:17,804 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:17,804 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:17,804 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:17,804 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:17,805 [Listener at localhost/36426] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:17,846 [Listener at localhost/36426] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:17,921 [Listener at localhost/36426] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:17,925 [Listener at localhost/36426] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:17,926 [Listener at localhost/36426] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:17,927 [Listener at localhost/36426] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:17,941 [Listener at localhost/36426] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:17,952 [Listener at localhost/36426] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:17,953 [Listener at localhost/36426] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:17,955 [Listener at localhost/36426] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@69afa141 expecting start txid #32
2020-12-03 07:24:17,956 [Listener at localhost/36426] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:17,956 [Listener at localhost/36426] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:17,958 [Listener at localhost/36426] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:17,959 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:17,964 [Listener at localhost/36426] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:18,081 [Listener at localhost/36426] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:18,082 [Listener at localhost/36426] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 276 msecs
2020-12-03 07:24:18,082 [Listener at localhost/36426] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:18,083 [Listener at localhost/36426] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:18,088 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:18,099 [Listener at localhost/45892] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:45892 to access this namenode/service.
2020-12-03 07:24:18,099 [Listener at localhost/45892] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:18,099 [Listener at localhost/45892] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:18,100 [Listener at localhost/45892] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:18,127 [Listener at localhost/45892] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:18,129 [Listener at localhost/45892] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:18,135 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:18,135 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:18,136 [Listener at localhost/45892] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45892
2020-12-03 07:24:18,137 [Listener at localhost/45892] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:18,137 [Listener at localhost/45892] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:18,138 [Listener at localhost/45892] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:18,149 [CacheReplicationMonitor(2045402824)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:18,163 [IPC Server handler 1 on default port 45892] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:18,164 [Listener at localhost/45892] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:19,466 [Listener at localhost/45892] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:19,466 [Listener at localhost/45892] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:19,467 [Listener at localhost/45892] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:19,468 [Listener at localhost/45892] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:19,475 [Listener at localhost/45892] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:19,475 [Listener at localhost/45892] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:19,475 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:19,476 [Listener at localhost/45892] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:19,476 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:19,478 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41709
2020-12-03 07:24:19,478 [Listener at localhost/45892] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:19,492 [Listener at localhost/45892] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:19,582 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:19,600 [Listener at localhost/45892] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:19,602 [Listener at localhost/45892] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:19,602 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:19,604 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:19,604 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:19,605 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:19,605 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:19,609 [Listener at localhost/45892] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38218
2020-12-03 07:24:19,610 [Listener at localhost/45892] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:19,619 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56b859a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:19,620 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42aae04d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:19,626 [Listener at localhost/45892] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2daf06fc{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:19,627 [Listener at localhost/45892] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28237492{HTTP/1.1,[http/1.1]}{localhost:38218}
2020-12-03 07:24:19,627 [Listener at localhost/45892] INFO  server.Server (Server.java:doStart(419)) - Started @47396ms
2020-12-03 07:24:19,647 [Listener at localhost/45892] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37122
2020-12-03 07:24:19,648 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:19,648 [Listener at localhost/45892] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:19,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7da31a40] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:19,649 [Listener at localhost/45892] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:19,650 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:19,653 [Listener at localhost/37230] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37230
2020-12-03 07:24:19,655 [Listener at localhost/37230] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:19,656 [Listener at localhost/37230] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:19,657 [Thread-1683] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45892 starting to offer service
2020-12-03 07:24:19,658 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:19,659 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:19,666 [Thread-1683] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45892
2020-12-03 07:24:19,673 [IPC Server handler 3 on default port 45892] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:19,673 [Thread-1683] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:19,676 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:19,676 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:19,736 [Thread-1683] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:19,784 [IPC Server handler 0 on default port 45892] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:19,785 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:19,785 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:19,856 [Thread-1683] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:19,886 [IPC Server handler 4 on default port 45892] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:19,887 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:19,887 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:19,932 [Thread-1683] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:19,933 [Thread-1683] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:19,933 [Thread-1683] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:19,933 [Thread-1683] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:19,945 [Thread-1683] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:19,945 [Thread-1683] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:19,945 [Thread-1683] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:19,946 [Thread-1683] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:19,946 [Thread-1683] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:45892. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:19,946 [Thread-1683] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:45892
2020-12-03 07:24:19,946 [Thread-1683] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:19,989 [IPC Server handler 5 on default port 45892] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:19,990 [Listener at localhost/37230] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:41709', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:45892
2020-12-03 07:24:19,990 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:19,990 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:19,990 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:19,991 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@135a8c6f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:20,067 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2daf06fc{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:20,073 [Listener at localhost/37230] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28237492{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:20,073 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42aae04d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:20,073 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56b859a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:20,075 [Listener at localhost/37230] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37230
2020-12-03 07:24:20,075 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:20,077 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:20,078 [Listener at localhost/37230] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:20,079 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:20,079 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:20,079 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4832f03b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:20,080 [Listener at localhost/37230] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:20,080 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7af3874e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:20,081 [Listener at localhost/37230] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:20,081 [Listener at localhost/37230] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:20,082 [Listener at localhost/37230] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:20,082 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:20,082 [CacheReplicationMonitor(2045402824)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:20,083 [Listener at localhost/37230] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45892
2020-12-03 07:24:20,084 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:20,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:20,085 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:20,085 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:20,099 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:20,099 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:20,101 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@404eca05{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:20,113 [Listener at localhost/37230] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58b91d57{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:20,114 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68ee3b6d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:20,115 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@788ba63e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:20,120 [Listener at localhost/37230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:20,121 [Listener at localhost/37230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:20,121 [Listener at localhost/37230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:20,146 [Listener at localhost/37230] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:20,146 [Listener at localhost/37230] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 24*** BLOCK_POOL recovery: numDirs=2 testCase=6 current=false previous=true previous.tmp=true removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:20,241 [Listener at localhost/37230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:20,241 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,241 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,242 [Listener at localhost/37230] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:20,246 [Listener at localhost/37230] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:20,247 [Listener at localhost/37230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:20,247 [Listener at localhost/37230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:20,248 [Listener at localhost/37230] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:20,251 [Listener at localhost/37230] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:20,251 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@149b0577] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:20,252 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:20,253 [Listener at localhost/37230] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:20,254 [Listener at localhost/37230] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:20,254 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:20,256 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:20,256 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:20,256 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:20,256 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:20,258 [Listener at localhost/37230] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:20,258 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:20,259 [Listener at localhost/37230] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34771
2020-12-03 07:24:20,259 [Listener at localhost/37230] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:20,261 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3119cf6f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:20,262 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d408060{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:20,266 [Listener at localhost/37230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35c9a231{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:20,267 [Listener at localhost/37230] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7a4d582c{HTTP/1.1,[http/1.1]}{localhost:34771}
2020-12-03 07:24:20,268 [Listener at localhost/37230] INFO  server.Server (Server.java:doStart(419)) - Started @48036ms
2020-12-03 07:24:20,268 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,268 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,268 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,269 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,269 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,269 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,269 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,270 [Listener at localhost/37230] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,271 [Listener at localhost/37230] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:20,272 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:20,272 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:20,272 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:20,272 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:20,273 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:20,273 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:20,273 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:20,273 [Listener at localhost/37230] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:20,274 [Listener at localhost/37230] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:20,274 [Listener at localhost/37230] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:20,274 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:20,274 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:20
2020-12-03 07:24:20,275 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:20,275 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:20,275 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:20,275 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:20,291 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:20,291 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:20,292 [Listener at localhost/37230] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:20,292 [Listener at localhost/37230] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:20,292 [Listener at localhost/37230] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:20,293 [Listener at localhost/37230] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:20,293 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:20,293 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:20,293 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:20,294 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:20,294 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:20,294 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:20,294 [Listener at localhost/37230] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:20,295 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:20,295 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:20,296 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:20,296 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:20,302 [Listener at localhost/37230] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:20,302 [Listener at localhost/37230] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:20,303 [Listener at localhost/37230] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:20,303 [Listener at localhost/37230] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:20,303 [Listener at localhost/37230] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:20,303 [Listener at localhost/37230] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:20,303 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:20,304 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:20,304 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:20,304 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:20,306 [Listener at localhost/37230] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:20,306 [Listener at localhost/37230] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:20,307 [Listener at localhost/37230] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:20,307 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:20,308 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:20,308 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:20,308 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:20,309 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:20,309 [Listener at localhost/37230] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:20,355 [Listener at localhost/37230] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:20,380 [Listener at localhost/37230] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:20,382 [Listener at localhost/37230] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:20,382 [Listener at localhost/37230] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:20,383 [Listener at localhost/37230] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:20,386 [Listener at localhost/37230] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:20,387 [Listener at localhost/37230] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:20,387 [Listener at localhost/37230] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:20,387 [Listener at localhost/37230] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@329548d0 expecting start txid #32
2020-12-03 07:24:20,388 [Listener at localhost/37230] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:20,388 [Listener at localhost/37230] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:20,391 [Listener at localhost/37230] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:20,391 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:20,392 [Listener at localhost/37230] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:20,456 [Listener at localhost/37230] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:20,456 [Listener at localhost/37230] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 147 msecs
2020-12-03 07:24:20,457 [Listener at localhost/37230] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:20,458 [Listener at localhost/37230] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:20,459 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:20,463 [Listener at localhost/42155] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:42155 to access this namenode/service.
2020-12-03 07:24:20,463 [Listener at localhost/42155] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:20,464 [Listener at localhost/42155] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:20,464 [Listener at localhost/42155] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:20,509 [Listener at localhost/42155] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:20,511 [Listener at localhost/42155] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:20,524 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:20,524 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:20,526 [Listener at localhost/42155] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42155
2020-12-03 07:24:20,527 [Listener at localhost/42155] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:20,527 [Listener at localhost/42155] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:20,529 [Listener at localhost/42155] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:20,543 [CacheReplicationMonitor(1387204321)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:20,550 [IPC Server handler 0 on default port 42155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:20,551 [Listener at localhost/42155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:21,085 [Listener at localhost/42155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:21,086 [Listener at localhost/42155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:21,086 [Listener at localhost/42155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:21,093 [Listener at localhost/42155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:21,093 [Listener at localhost/42155] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:21,094 [Listener at localhost/42155] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:21,094 [Listener at localhost/42155] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:21,094 [Listener at localhost/42155] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:21,095 [Listener at localhost/42155] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:21,096 [Listener at localhost/42155] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37074
2020-12-03 07:24:21,096 [Listener at localhost/42155] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:21,097 [Listener at localhost/42155] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:21,098 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:21,101 [Listener at localhost/42155] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:21,102 [Listener at localhost/42155] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:21,102 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:21,104 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:21,105 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:21,105 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:21,105 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:21,106 [Listener at localhost/42155] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42609
2020-12-03 07:24:21,106 [Listener at localhost/42155] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:21,110 [Listener at localhost/42155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4db60246{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:21,112 [Listener at localhost/42155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3902bd2c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:21,128 [Listener at localhost/42155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a53f215{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:21,129 [Listener at localhost/42155] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b63e6ad{HTTP/1.1,[http/1.1]}{localhost:42609}
2020-12-03 07:24:21,129 [Listener at localhost/42155] INFO  server.Server (Server.java:doStart(419)) - Started @48897ms
2020-12-03 07:24:21,172 [Listener at localhost/42155] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36121
2020-12-03 07:24:21,176 [Listener at localhost/42155] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:21,176 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6749fe50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:21,177 [Listener at localhost/42155] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:21,181 [Listener at localhost/42155] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:21,184 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:21,187 [Listener at localhost/36458] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36458
2020-12-03 07:24:21,191 [Listener at localhost/36458] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:21,191 [Listener at localhost/36458] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:21,192 [Thread-1747] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42155 starting to offer service
2020-12-03 07:24:21,193 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:21,193 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:21,199 [IPC Server handler 1 on default port 42155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:21,200 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:21,200 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:21,208 [Thread-1747] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42155
2020-12-03 07:24:21,212 [Thread-1747] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:21,277 [Thread-1747] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:21,309 [IPC Server handler 2 on default port 42155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:21,316 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:21,316 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:21,344 [Thread-1747] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:21,386 [Thread-1747] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:21,386 [Thread-1747] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:21,386 [Thread-1747] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:21,386 [Thread-1747] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:21,401 [Thread-1747] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:21,401 [Thread-1747] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:21,401 [Thread-1747] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:21,402 [Thread-1747] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: previous and previous.tmp cannot exist together.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:757)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:21,402 [Thread-1747] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:42155. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:21,402 [Thread-1747] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:42155
2020-12-03 07:24:21,403 [Thread-1747] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:21,418 [IPC Server handler 7 on default port 42155] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:21,420 [Listener at localhost/36458] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:37074', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:42155
2020-12-03 07:24:21,421 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:21,421 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:21,421 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:21,421 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60d6fdd4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:21,522 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a53f215{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:21,525 [Listener at localhost/36458] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b63e6ad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:21,525 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3902bd2c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:21,525 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4db60246{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:21,526 [Listener at localhost/36458] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36458
2020-12-03 07:24:21,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:21,526 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:21,538 [Listener at localhost/36458] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:21,538 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:21,538 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:21,538 [Listener at localhost/36458] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:21,538 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2b0dc227] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:21,546 [Listener at localhost/36458] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-12-03 07:24:21,548 [Listener at localhost/36458] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:21,549 [Listener at localhost/36458] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:21,556 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:21,576 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5634a861] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:21,580 [CacheReplicationMonitor(1387204321)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:21,580 [Listener at localhost/36458] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42155
2020-12-03 07:24:21,582 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:21,583 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:21,584 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:21,590 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:21,613 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:21,613 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:21,619 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35c9a231{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:21,628 [Listener at localhost/36458] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7a4d582c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:21,629 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d408060{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:21,630 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3119cf6f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:21,632 [Listener at localhost/36458] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:21,633 [Listener at localhost/36458] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:21,633 [Listener at localhost/36458] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:21,645 [Listener at localhost/36458] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:21,645 [Listener at localhost/36458] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 25*** BLOCK_POOL recovery: numDirs=2 testCase=7 current=false previous=false previous.tmp=false removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:21,777 [Listener at localhost/36458] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:21,778 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:21,778 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:21,779 [Listener at localhost/36458] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:21,783 [Listener at localhost/36458] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:21,784 [Listener at localhost/36458] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:21,784 [Listener at localhost/36458] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:21,785 [Listener at localhost/36458] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:21,806 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67531e3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:21,806 [Listener at localhost/36458] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:21,806 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:21,808 [Listener at localhost/36458] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:21,808 [Listener at localhost/36458] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:21,809 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:21,810 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:21,812 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:21,813 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:21,813 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:21,815 [Listener at localhost/36458] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:21,815 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:21,815 [Listener at localhost/36458] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39288
2020-12-03 07:24:21,815 [Listener at localhost/36458] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:21,817 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28757abd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:21,818 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c8a7e38{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:21,832 [Listener at localhost/36458] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77bc2e16{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:21,833 [Listener at localhost/36458] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48e8c32a{HTTP/1.1,[http/1.1]}{localhost:39288}
2020-12-03 07:24:21,833 [Listener at localhost/36458] INFO  server.Server (Server.java:doStart(419)) - Started @49602ms
2020-12-03 07:24:21,834 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:21,834 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:21,835 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:21,845 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:21,845 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:21,846 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:21,846 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:21,846 [Listener at localhost/36458] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:21,848 [Listener at localhost/36458] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:21,849 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:21,849 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:21,849 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:21,849 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:21,850 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:21,850 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:21,850 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:21,850 [Listener at localhost/36458] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:21,851 [Listener at localhost/36458] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:21,851 [Listener at localhost/36458] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:21,851 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:21,851 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:21
2020-12-03 07:24:21,852 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:21,852 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:21,852 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:21,852 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:21,862 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:21,863 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:21,863 [Listener at localhost/36458] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:21,863 [Listener at localhost/36458] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:21,863 [Listener at localhost/36458] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:21,864 [Listener at localhost/36458] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:21,864 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:21,864 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:21,864 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:21,864 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:21,865 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:21,865 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:21,865 [Listener at localhost/36458] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:21,865 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:21,865 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:21,866 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:21,866 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:21,871 [Listener at localhost/36458] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:21,872 [Listener at localhost/36458] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:21,872 [Listener at localhost/36458] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:21,872 [Listener at localhost/36458] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:21,872 [Listener at localhost/36458] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:21,872 [Listener at localhost/36458] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:21,873 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:21,873 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:21,873 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:21,874 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:21,875 [Listener at localhost/36458] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:21,876 [Listener at localhost/36458] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:21,876 [Listener at localhost/36458] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:21,877 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:21,877 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:21,877 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:21,877 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:21,877 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:21,878 [Listener at localhost/36458] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:21,922 [Listener at localhost/36458] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:21,956 [Listener at localhost/36458] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:21,958 [Listener at localhost/36458] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:21,959 [Listener at localhost/36458] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:21,960 [Listener at localhost/36458] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:21,961 [Listener at localhost/36458] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:21,963 [Listener at localhost/36458] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:21,963 [Listener at localhost/36458] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:21,963 [Listener at localhost/36458] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@17aa8a11 expecting start txid #32
2020-12-03 07:24:21,963 [Listener at localhost/36458] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:21,964 [Listener at localhost/36458] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:21,966 [Listener at localhost/36458] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:21,967 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:21,968 [Listener at localhost/36458] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:22,058 [Listener at localhost/36458] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:22,058 [Listener at localhost/36458] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 179 msecs
2020-12-03 07:24:22,058 [Listener at localhost/36458] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:22,059 [Listener at localhost/36458] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:22,060 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:22,062 [Listener at localhost/43907] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43907 to access this namenode/service.
2020-12-03 07:24:22,062 [Listener at localhost/43907] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:22,063 [Listener at localhost/43907] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:22,063 [Listener at localhost/43907] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:22,083 [Listener at localhost/43907] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:22,085 [Listener at localhost/43907] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:22,088 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:22,088 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:22,090 [Listener at localhost/43907] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43907
2020-12-03 07:24:22,090 [Listener at localhost/43907] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:22,090 [Listener at localhost/43907] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:22,091 [Listener at localhost/43907] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:22,095 [CacheReplicationMonitor(1465821150)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:22,101 [IPC Server handler 1 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,101 [Listener at localhost/43907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:22,359 [Listener at localhost/43907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:22,360 [Listener at localhost/43907] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:22,360 [Listener at localhost/43907] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:22,361 [Listener at localhost/43907] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:22,362 [Listener at localhost/43907] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:22,362 [Listener at localhost/43907] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:22,363 [Listener at localhost/43907] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:22,363 [Listener at localhost/43907] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:22,363 [Listener at localhost/43907] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:22,364 [Listener at localhost/43907] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38478
2020-12-03 07:24:22,364 [Listener at localhost/43907] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:22,364 [Listener at localhost/43907] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:22,365 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:22,367 [Listener at localhost/43907] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:22,368 [Listener at localhost/43907] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:22,368 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:22,369 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:22,370 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:22,370 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:22,370 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:22,371 [Listener at localhost/43907] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43689
2020-12-03 07:24:22,371 [Listener at localhost/43907] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:22,372 [Listener at localhost/43907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@dd2856e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:22,372 [Listener at localhost/43907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b1dc579{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:22,376 [Listener at localhost/43907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@463561c5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:22,377 [Listener at localhost/43907] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@659feb22{HTTP/1.1,[http/1.1]}{localhost:43689}
2020-12-03 07:24:22,377 [Listener at localhost/43907] INFO  server.Server (Server.java:doStart(419)) - Started @50145ms
2020-12-03 07:24:22,398 [Listener at localhost/43907] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40360
2020-12-03 07:24:22,399 [Listener at localhost/43907] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:22,399 [Listener at localhost/43907] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:22,399 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f4b98f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:22,400 [Listener at localhost/43907] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:22,400 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:22,402 [Listener at localhost/35510] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35510
2020-12-03 07:24:22,405 [Listener at localhost/35510] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:22,405 [Listener at localhost/35510] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:22,406 [Thread-1810] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43907 starting to offer service
2020-12-03 07:24:22,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:22,407 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:22,411 [IPC Server handler 0 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,411 [Thread-1810] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43907
2020-12-03 07:24:22,412 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:22,413 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:22,412 [Thread-1810] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:22,440 [Thread-1810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:22,514 [IPC Server handler 3 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,515 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:22,515 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:22,532 [Thread-1810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:22,591 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,591 [Thread-1810] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,591 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 and block pool id BP-552726158-172.17.0.2-1606980213726 is not formatted. Formatting ...
2020-12-03 07:24:22,591 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-552726158-172.17.0.2-1606980213726 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current
2020-12-03 07:24:22,617 [IPC Server handler 4 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,617 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:22,618 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:22,660 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,660 [Thread-1810] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,660 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 and block pool id BP-552726158-172.17.0.2-1606980213726 is not formatted. Formatting ...
2020-12-03 07:24:22,661 [Thread-1810] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-552726158-172.17.0.2-1606980213726 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current
2020-12-03 07:24:22,721 [IPC Server handler 5 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,722 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:22,723 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:22,726 [Thread-1810] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:22,728 [Thread-1810] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3ccbfaae-9688-4c5f-b45f-18e6a68c9934
2020-12-03 07:24:22,728 [Thread-1810] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:22,729 [Thread-1810] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c47f69cb-5908-4c02-b923-0c3075d35449
2020-12-03 07:24:22,729 [Thread-1810] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:22,730 [Thread-1810] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:22,730 [Thread-1810] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:22,731 [Thread-1810] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:22,731 [Thread-1810] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:22,731 [Thread-1810] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:22,732 [Thread-1810] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,733 [Thread-1822] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:22,733 [Thread-1823] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:22,852 [IPC Server handler 6 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,853 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:22,853 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:22,858 [Thread-1823] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 125ms
2020-12-03 07:24:22,859 [Thread-1822] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 126ms
2020-12-03 07:24:22,859 [Thread-1810] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 126ms
2020-12-03 07:24:22,859 [Thread-1826] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:22,859 [Thread-1827] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:22,859 [Thread-1826] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas doesn't exist 
2020-12-03 07:24:22,860 [Thread-1827] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas doesn't exist 
2020-12-03 07:24:22,860 [Thread-1827] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 1ms
2020-12-03 07:24:22,860 [Thread-1826] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 1ms
2020-12-03 07:24:22,861 [Thread-1810] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 1ms
2020-12-03 07:24:22,861 [Thread-1810] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:53 PM with interval of 21600000ms
2020-12-03 07:24:22,862 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43907 beginning handshake with NN
2020-12-03 07:24:22,863 [IPC Server handler 7 on default port 43907] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38478, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40360, infoSecurePort=0, ipcPort=35510, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:22,863 [IPC Server handler 7 on default port 43907] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38478
2020-12-03 07:24:22,864 [IPC Server handler 7 on default port 43907] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:38478).
2020-12-03 07:24:22,865 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43907 successfully registered with NN
2020-12-03 07:24:22,866 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43907 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:22,868 [IPC Server handler 8 on default port 43907] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ccbfaae-9688-4c5f-b45f-18e6a68c9934 for DN 127.0.0.1:38478
2020-12-03 07:24:22,868 [IPC Server handler 8 on default port 43907] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c47f69cb-5908-4c02-b923-0c3075d35449 for DN 127.0.0.1:38478
2020-12-03 07:24:22,872 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4ed3d55dd68a4af7: Processing first storage report for DS-c47f69cb-5908-4c02-b923-0c3075d35449 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:22,873 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4ed3d55dd68a4af7: from storage DS-c47f69cb-5908-4c02-b923-0c3075d35449 node DatanodeRegistration(127.0.0.1:38478, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40360, infoSecurePort=0, ipcPort=35510, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:22,873 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4ed3d55dd68a4af7: Processing first storage report for DS-3ccbfaae-9688-4c5f-b45f-18e6a68c9934 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:22,873 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4ed3d55dd68a4af7: from storage DS-3ccbfaae-9688-4c5f-b45f-18e6a68c9934 node DatanodeRegistration(127.0.0.1:38478, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40360, infoSecurePort=0, ipcPort=35510, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:22,873 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4ed3d55dd68a4af7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:22,955 [IPC Server handler 1 on default port 43907] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:22,956 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:22,956 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:22,956 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:22,956 [Listener at localhost/35510] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:22,956 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e0fbeb5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:22,973 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@463561c5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:22,973 [Listener at localhost/35510] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@659feb22{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:22,974 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b1dc579{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:22,974 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@dd2856e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:22,975 [Listener at localhost/35510] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35510
2020-12-03 07:24:22,975 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:22,976 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:22,976 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:22,976 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43907
2020-12-03 07:24:22,976 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:22,976 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:43907] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:22,977 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:22,977 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:22,982 [Listener at localhost/35510] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:22,982 [Listener at localhost/35510] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:22,983 [Listener at localhost/35510] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:22,983 [Listener at localhost/35510] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:22,984 [Listener at localhost/35510] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:22,984 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:22,985 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:22,985 [Listener at localhost/35510] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:22,985 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5b7aa898] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:22,986 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@40230eb9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:22,986 [Listener at localhost/35510] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:22,986 [Listener at localhost/35510] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:22,987 [Listener at localhost/35510] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:22,987 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:22,987 [CacheReplicationMonitor(1465821150)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:22,988 [Listener at localhost/35510] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43907
2020-12-03 07:24:22,989 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:22,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:22,990 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:22,990 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:23,000 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:23,000 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:23,001 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77bc2e16{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:23,002 [Listener at localhost/35510] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48e8c32a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:23,002 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c8a7e38{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:23,003 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28757abd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:23,003 [Listener at localhost/35510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:23,005 [Listener at localhost/35510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:23,005 [Listener at localhost/35510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:23,011 [Listener at localhost/35510] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:23,011 [Listener at localhost/35510] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 26*** BLOCK_POOL recovery: numDirs=2 testCase=8 current=false previous=true previous.tmp=false removed.tmp=false should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:23,077 [Listener at localhost/35510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:23,077 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,077 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,078 [Listener at localhost/35510] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:23,079 [Listener at localhost/35510] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:23,080 [Listener at localhost/35510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:23,080 [Listener at localhost/35510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:23,081 [Listener at localhost/35510] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:23,086 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@346f41a9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:23,086 [Listener at localhost/35510] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:23,086 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:23,088 [Listener at localhost/35510] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:23,088 [Listener at localhost/35510] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:23,088 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:23,090 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:23,090 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:23,090 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:23,090 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:23,092 [Listener at localhost/35510] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:23,092 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:23,093 [Listener at localhost/35510] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38731
2020-12-03 07:24:23,093 [Listener at localhost/35510] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:23,095 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f74900b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:23,095 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e26173{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:23,101 [Listener at localhost/35510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b5a4aed{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:23,102 [Listener at localhost/35510] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c991465{HTTP/1.1,[http/1.1]}{localhost:38731}
2020-12-03 07:24:23,102 [Listener at localhost/35510] INFO  server.Server (Server.java:doStart(419)) - Started @50870ms
2020-12-03 07:24:23,103 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,103 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,103 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,103 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,104 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,104 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,104 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,104 [Listener at localhost/35510] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:23,106 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:23,107 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:23,108 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:23
2020-12-03 07:24:23,108 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:23,108 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,108 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:23,108 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:23,118 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:23,119 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:23,120 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,120 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:23,120 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:23,124 [Listener at localhost/35510] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:23,125 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:23,125 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,125 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:23,125 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:23,126 [Listener at localhost/35510] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:23,126 [Listener at localhost/35510] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:23,126 [Listener at localhost/35510] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:23,127 [Listener at localhost/35510] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:23,163 [Listener at localhost/35510] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:23,196 [Listener at localhost/35510] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:23,198 [Listener at localhost/35510] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:23,198 [Listener at localhost/35510] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:23,199 [Listener at localhost/35510] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:23,201 [Listener at localhost/35510] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:23,202 [Listener at localhost/35510] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:23,202 [Listener at localhost/35510] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:23,202 [Listener at localhost/35510] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1cfc2538 expecting start txid #32
2020-12-03 07:24:23,202 [Listener at localhost/35510] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:23,202 [Listener at localhost/35510] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:23,204 [Listener at localhost/35510] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:23,205 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:23,205 [Listener at localhost/35510] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:23,264 [Listener at localhost/35510] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:23,264 [Listener at localhost/35510] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 137 msecs
2020-12-03 07:24:23,265 [Listener at localhost/35510] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:23,265 [Listener at localhost/35510] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:23,266 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:23,268 [Listener at localhost/34516] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34516 to access this namenode/service.
2020-12-03 07:24:23,268 [Listener at localhost/34516] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:23,269 [Listener at localhost/34516] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:23,269 [Listener at localhost/34516] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:23,305 [Listener at localhost/34516] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:23,309 [Listener at localhost/34516] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:23,312 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:23,313 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:23,313 [Listener at localhost/34516] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34516
2020-12-03 07:24:23,314 [Listener at localhost/34516] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:23,314 [Listener at localhost/34516] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:23,325 [Listener at localhost/34516] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:23,337 [CacheReplicationMonitor(1188455963)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:23,342 [IPC Server handler 0 on default port 34516] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:23,343 [Listener at localhost/34516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:23,686 [Listener at localhost/34516] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:23,686 [Listener at localhost/34516] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:23,687 [Listener at localhost/34516] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:23,688 [Listener at localhost/34516] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:23,689 [Listener at localhost/34516] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:23,689 [Listener at localhost/34516] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:23,689 [Listener at localhost/34516] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:23,690 [Listener at localhost/34516] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:23,690 [Listener at localhost/34516] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:23,690 [Listener at localhost/34516] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38991
2020-12-03 07:24:23,690 [Listener at localhost/34516] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:23,690 [Listener at localhost/34516] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:23,691 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:23,692 [Listener at localhost/34516] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:23,693 [Listener at localhost/34516] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:23,693 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:23,694 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:23,694 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:23,694 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:23,695 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:23,695 [Listener at localhost/34516] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38914
2020-12-03 07:24:23,695 [Listener at localhost/34516] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:23,696 [Listener at localhost/34516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@303c55fa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:23,697 [Listener at localhost/34516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7eb200ce{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:23,700 [Listener at localhost/34516] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a3bd45b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:23,701 [Listener at localhost/34516] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@34c70b5e{HTTP/1.1,[http/1.1]}{localhost:38914}
2020-12-03 07:24:23,701 [Listener at localhost/34516] INFO  server.Server (Server.java:doStart(419)) - Started @51469ms
2020-12-03 07:24:23,713 [Listener at localhost/34516] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45737
2020-12-03 07:24:23,713 [Listener at localhost/34516] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:23,713 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75156240] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:23,713 [Listener at localhost/34516] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:23,714 [Listener at localhost/34516] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:23,714 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:23,716 [Listener at localhost/39694] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39694
2020-12-03 07:24:23,719 [Listener at localhost/39694] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:23,720 [Listener at localhost/39694] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:23,721 [Thread-1881] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34516 starting to offer service
2020-12-03 07:24:23,728 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:23,728 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:23,729 [Thread-1881] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34516
2020-12-03 07:24:23,731 [Thread-1881] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:23,733 [IPC Server handler 2 on default port 34516] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:23,733 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:23,734 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:23,769 [Thread-1881] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:23,835 [IPC Server handler 3 on default port 34516] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:23,835 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:23,836 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:23,853 [Thread-1881] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:23,914 [Thread-1881] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:23,914 [Thread-1881] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:23,915 [Thread-1881] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:23,917 [Thread-1881] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:23,925 [Thread-1881] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:23,925 [Thread-1881] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:23,926 [Thread-1881] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:23,926 [Thread-1881] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: version file in current directory is missing.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:727)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:23,926 [Thread-1881] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:34516. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:23,926 [Thread-1881] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:34516
2020-12-03 07:24:23,926 [Thread-1881] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:23,937 [IPC Server handler 4 on default port 34516] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:23,937 [Listener at localhost/39694] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:38991', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:34516
2020-12-03 07:24:23,937 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:23,937 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:23,937 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:23,938 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@76e9f00b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:23,958 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a3bd45b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:23,959 [Listener at localhost/39694] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@34c70b5e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:23,959 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7eb200ce{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:23,959 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@303c55fa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:23,960 [Listener at localhost/39694] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39694
2020-12-03 07:24:23,960 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:23,960 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:23,961 [Listener at localhost/39694] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:23,961 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:23,961 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:23,961 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@28369db0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:23,961 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@30893e08] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:23,961 [Listener at localhost/39694] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:23,962 [Listener at localhost/39694] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:23,962 [Listener at localhost/39694] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:23,963 [Listener at localhost/39694] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:23,963 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:23,963 [CacheReplicationMonitor(1188455963)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:23,964 [Listener at localhost/39694] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34516
2020-12-03 07:24:23,965 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:23,965 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:23,965 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:23,965 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:23,973 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:23,973 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:23,974 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b5a4aed{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:23,980 [Listener at localhost/39694] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c991465{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:23,980 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e26173{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:23,981 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f74900b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:23,981 [Listener at localhost/39694] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:23,981 [Listener at localhost/39694] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:23,982 [Listener at localhost/39694] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:23,989 [Listener at localhost/39694] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:23,990 [Listener at localhost/39694] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 27*** BLOCK_POOL recovery: numDirs=2 testCase=9 current=false previous=false previous.tmp=true removed.tmp=false should recover=true current exists after=true previous exists after=false
2020-12-03 07:24:24,066 [Listener at localhost/39694] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:24,067 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,067 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,067 [Listener at localhost/39694] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:24,069 [Listener at localhost/39694] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:24,069 [Listener at localhost/39694] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:24,070 [Listener at localhost/39694] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:24,070 [Listener at localhost/39694] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:24,075 [Listener at localhost/39694] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:24,075 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@497b560e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:24,075 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:24,076 [Listener at localhost/39694] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:24,077 [Listener at localhost/39694] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:24,077 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:24,078 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:24,078 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:24,078 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:24,079 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:24,080 [Listener at localhost/39694] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:24,080 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:24,080 [Listener at localhost/39694] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36912
2020-12-03 07:24:24,080 [Listener at localhost/39694] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:24,082 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@239f017e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:24,082 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@772caabe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:24,086 [Listener at localhost/39694] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b5ac798{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:24,087 [Listener at localhost/39694] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42383cb0{HTTP/1.1,[http/1.1]}{localhost:36912}
2020-12-03 07:24:24,087 [Listener at localhost/39694] INFO  server.Server (Server.java:doStart(419)) - Started @51855ms
2020-12-03 07:24:24,087 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,087 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,087 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,088 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,088 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,088 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,088 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,088 [Listener at localhost/39694] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,090 [Listener at localhost/39694] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:24,090 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:24,090 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:24,090 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:24,090 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:24,091 [Listener at localhost/39694] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:24,092 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:24,092 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:24
2020-12-03 07:24:24,092 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:24,092 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:24,092 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:24,093 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:24,096 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:24,096 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:24,096 [Listener at localhost/39694] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:24,097 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:24,098 [Listener at localhost/39694] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:24,098 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:24,098 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:24,098 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:24,098 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:24,100 [Listener at localhost/39694] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:24,100 [Listener at localhost/39694] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:24,100 [Listener at localhost/39694] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:24,100 [Listener at localhost/39694] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:24,100 [Listener at localhost/39694] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:24,101 [Listener at localhost/39694] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:24,101 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:24,101 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:24,101 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:24,101 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:24,102 [Listener at localhost/39694] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:24,102 [Listener at localhost/39694] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:24,102 [Listener at localhost/39694] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:24,102 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:24,102 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:24,103 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:24,103 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:24,103 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:24,103 [Listener at localhost/39694] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:24,195 [Listener at localhost/39694] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:24,272 [Listener at localhost/39694] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:24,273 [Listener at localhost/39694] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:24,273 [Listener at localhost/39694] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:24,274 [Listener at localhost/39694] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:24,276 [Listener at localhost/39694] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:24,277 [Listener at localhost/39694] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:24,277 [Listener at localhost/39694] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:24,277 [Listener at localhost/39694] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@609e57da expecting start txid #32
2020-12-03 07:24:24,278 [Listener at localhost/39694] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:24,278 [Listener at localhost/39694] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:24,280 [Listener at localhost/39694] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:24,280 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:24,280 [Listener at localhost/39694] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:24,416 [Listener at localhost/39694] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:24,417 [Listener at localhost/39694] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 313 msecs
2020-12-03 07:24:24,417 [Listener at localhost/39694] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:24,417 [Listener at localhost/39694] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:24,418 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:24,420 [Listener at localhost/46672] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46672 to access this namenode/service.
2020-12-03 07:24:24,421 [Listener at localhost/46672] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:24,421 [Listener at localhost/46672] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:24,421 [Listener at localhost/46672] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:24,438 [Listener at localhost/46672] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:24,439 [Listener at localhost/46672] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:24,441 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:24,441 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:24,442 [Listener at localhost/46672] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46672
2020-12-03 07:24:24,442 [Listener at localhost/46672] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:24,442 [Listener at localhost/46672] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:24,443 [Listener at localhost/46672] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:24,446 [CacheReplicationMonitor(496559258)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:24,458 [IPC Server handler 0 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:24,459 [Listener at localhost/46672] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:24,847 [Listener at localhost/46672] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:24,848 [Listener at localhost/46672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:24,848 [Listener at localhost/46672] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:24,849 [Listener at localhost/46672] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:24,850 [Listener at localhost/46672] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:24,850 [Listener at localhost/46672] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:24,850 [Listener at localhost/46672] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:24,851 [Listener at localhost/46672] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:24,851 [Listener at localhost/46672] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:24,851 [Listener at localhost/46672] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40315
2020-12-03 07:24:24,851 [Listener at localhost/46672] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:24,851 [Listener at localhost/46672] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:24,852 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:24,853 [Listener at localhost/46672] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:24,854 [Listener at localhost/46672] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:24,854 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:24,855 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:24,855 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:24,855 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:24,855 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:24,856 [Listener at localhost/46672] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39152
2020-12-03 07:24:24,856 [Listener at localhost/46672] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:24,857 [Listener at localhost/46672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e977098{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:24,857 [Listener at localhost/46672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6690b9fa{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:24,861 [Listener at localhost/46672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12a2585b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:24,861 [Listener at localhost/46672] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21b6c9c2{HTTP/1.1,[http/1.1]}{localhost:39152}
2020-12-03 07:24:24,861 [Listener at localhost/46672] INFO  server.Server (Server.java:doStart(419)) - Started @52630ms
2020-12-03 07:24:24,880 [Listener at localhost/46672] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39687
2020-12-03 07:24:24,884 [Listener at localhost/46672] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:24,884 [Listener at localhost/46672] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:24,884 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b95a6db] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:24,885 [Listener at localhost/46672] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:24,892 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:24,894 [Listener at localhost/40392] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40392
2020-12-03 07:24:24,900 [Listener at localhost/40392] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:24,901 [Listener at localhost/40392] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:24,902 [Thread-1947] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46672 starting to offer service
2020-12-03 07:24:24,904 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:24,916 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:24,938 [IPC Server handler 1 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:24,940 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:24,940 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:24,942 [Thread-1947] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46672
2020-12-03 07:24:24,944 [Thread-1947] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:24,978 [Thread-1947] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:25,042 [IPC Server handler 3 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:25,043 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:25,043 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:25,114 [Thread-1947] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:25,145 [IPC Server handler 4 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:25,146 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:25,146 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:25,187 [Thread-1947] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,188 [Thread-1947] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,188 [Thread-1947] INFO  common.Storage (Storage.java:doRecover(797)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 from previous upgrade
2020-12-03 07:24:25,257 [Thread-1947] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,257 [IPC Server handler 5 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:25,257 [Thread-1947] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,257 [Thread-1947] INFO  common.Storage (Storage.java:doRecover(797)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 from previous upgrade
2020-12-03 07:24:25,257 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:25,258 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:25,298 [Thread-1947] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:25,300 [Thread-1947] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e96e67ea-c4c9-4098-9134-c8e8713d857a
2020-12-03 07:24:25,300 [Thread-1947] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:25,301 [Thread-1947] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-701c9114-ced1-4e7d-92d9-72340ddbb787
2020-12-03 07:24:25,301 [Thread-1947] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:25,301 [Thread-1947] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:25,302 [Thread-1947] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:25,303 [Thread-1947] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:25,303 [Thread-1947] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:25,303 [Thread-1947] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:25,304 [Thread-1947] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,304 [Thread-1959] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:25,304 [Thread-1960] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:25,305 [Thread-1959] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:25,305 [Thread-1960] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:25,312 [Thread-1960] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 8ms
2020-12-03 07:24:25,319 [Thread-1959] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 15ms
2020-12-03 07:24:25,320 [Thread-1947] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 16ms
2020-12-03 07:24:25,320 [Thread-1961] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:25,320 [Thread-1962] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:25,321 [Thread-1961] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:25,321 [Thread-1962] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:25,321 [Thread-1961] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 1ms
2020-12-03 07:24:25,321 [Thread-1962] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 1ms
2020-12-03 07:24:25,322 [Thread-1947] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 2ms
2020-12-03 07:24:25,322 [Thread-1947] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:46 AM with interval of 21600000ms
2020-12-03 07:24:25,322 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46672 beginning handshake with NN
2020-12-03 07:24:25,324 [IPC Server handler 6 on default port 46672] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40315, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=39687, infoSecurePort=0, ipcPort=40392, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:25,324 [IPC Server handler 6 on default port 46672] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40315
2020-12-03 07:24:25,324 [IPC Server handler 6 on default port 46672] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:40315).
2020-12-03 07:24:25,326 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46672 successfully registered with NN
2020-12-03 07:24:25,326 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46672 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:25,328 [IPC Server handler 7 on default port 46672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e96e67ea-c4c9-4098-9134-c8e8713d857a for DN 127.0.0.1:40315
2020-12-03 07:24:25,329 [IPC Server handler 7 on default port 46672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-701c9114-ced1-4e7d-92d9-72340ddbb787 for DN 127.0.0.1:40315
2020-12-03 07:24:25,331 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x552246addd648d37: Processing first storage report for DS-701c9114-ced1-4e7d-92d9-72340ddbb787 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:25,332 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:25,333 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:25,333 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:25,333 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:25,333 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:25,335 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x552246addd648d37: from storage DS-701c9114-ced1-4e7d-92d9-72340ddbb787 node DatanodeRegistration(127.0.0.1:40315, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=39687, infoSecurePort=0, ipcPort=40392, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:25,339 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:24:25,339 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x552246addd648d37: Processing first storage report for DS-e96e67ea-c4c9-4098-9134-c8e8713d857a from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:25,339 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x552246addd648d37: from storage DS-e96e67ea-c4c9-4098-9134-c8e8713d857a node DatanodeRegistration(127.0.0.1:40315, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=39687, infoSecurePort=0, ipcPort=40392, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:25,340 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x552246addd648d37,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 1 msec to generate and 10 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:25,359 [IPC Server handler 9 on default port 46672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:25,360 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:25,360 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:25,361 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:25,361 [Listener at localhost/40392] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:25,361 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@ffd4cba] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:25,375 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12a2585b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:25,375 [Listener at localhost/40392] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21b6c9c2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:25,376 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6690b9fa{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:25,376 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e977098{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:25,377 [Listener at localhost/40392] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40392
2020-12-03 07:24:25,377 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:25,377 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:25,377 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:25,377 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46672
2020-12-03 07:24:25,378 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:25,378 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:25,378 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:25,378 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:25,379 [Listener at localhost/40392] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:25,380 [Listener at localhost/40392] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:25,380 [Listener at localhost/40392] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:25,381 [Listener at localhost/40392] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:25,383 [Listener at localhost/40392] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:25,383 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:25,383 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:25,383 [Listener at localhost/40392] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:25,383 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1682c08c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:25,383 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7affc159] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:25,384 [Listener at localhost/40392] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 0 
2020-12-03 07:24:25,384 [Listener at localhost/40392] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:25,385 [Listener at localhost/40392] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:25,385 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:25,385 [CacheReplicationMonitor(496559258)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:25,385 [Listener at localhost/40392] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46672
2020-12-03 07:24:25,386 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:25,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:25,386 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:25,386 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:25,394 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:25,394 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:25,395 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b5ac798{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:25,396 [Listener at localhost/40392] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42383cb0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:25,397 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@772caabe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:25,397 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@239f017e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:25,398 [Listener at localhost/40392] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:25,399 [Listener at localhost/40392] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:25,399 [Listener at localhost/40392] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:25,406 [Listener at localhost/40392] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:25,406 [Listener at localhost/40392] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 28*** BLOCK_POOL recovery: numDirs=2 testCase=10 current=true previous=false previous.tmp=false removed.tmp=true should recover=true current exists after=true previous exists after=false
2020-12-03 07:24:25,475 [Listener at localhost/40392] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:25,476 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,476 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,476 [Listener at localhost/40392] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:25,478 [Listener at localhost/40392] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:25,478 [Listener at localhost/40392] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:25,479 [Listener at localhost/40392] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:25,479 [Listener at localhost/40392] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:25,484 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6680f714] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:25,484 [Listener at localhost/40392] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:25,484 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:25,485 [Listener at localhost/40392] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:25,486 [Listener at localhost/40392] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:25,486 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:25,487 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:25,487 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:25,487 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:25,487 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:25,488 [Listener at localhost/40392] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:25,489 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:25,489 [Listener at localhost/40392] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32949
2020-12-03 07:24:25,489 [Listener at localhost/40392] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:25,490 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@276cc8dc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:25,491 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d3f4505{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:25,494 [Listener at localhost/40392] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d8b0500{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:25,495 [Listener at localhost/40392] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76544c0a{HTTP/1.1,[http/1.1]}{localhost:32949}
2020-12-03 07:24:25,495 [Listener at localhost/40392] INFO  server.Server (Server.java:doStart(419)) - Started @53263ms
2020-12-03 07:24:25,495 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,495 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,496 [Listener at localhost/40392] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,498 [Listener at localhost/40392] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:25,498 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:25,498 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:25,498 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:25,499 [Listener at localhost/40392] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:25
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,500 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:25,501 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:25,504 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:25,504 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:25,504 [Listener at localhost/40392] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:25,504 [Listener at localhost/40392] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:25,505 [Listener at localhost/40392] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:25,506 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:25,506 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,506 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:25,506 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:25,508 [Listener at localhost/40392] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:25,508 [Listener at localhost/40392] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:25,508 [Listener at localhost/40392] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:25,508 [Listener at localhost/40392] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:25,509 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:25,510 [Listener at localhost/40392] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:25,510 [Listener at localhost/40392] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:25,510 [Listener at localhost/40392] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:25,511 [Listener at localhost/40392] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:25,574 [Listener at localhost/40392] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:25,661 [Listener at localhost/40392] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:25,663 [Listener at localhost/40392] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:25,663 [Listener at localhost/40392] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:25,664 [Listener at localhost/40392] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:25,666 [Listener at localhost/40392] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:25,667 [Listener at localhost/40392] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:25,667 [Listener at localhost/40392] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:25,667 [Listener at localhost/40392] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1835dc92 expecting start txid #32
2020-12-03 07:24:25,667 [Listener at localhost/40392] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:25,667 [Listener at localhost/40392] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:25,670 [Listener at localhost/40392] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:25,670 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:25,671 [Listener at localhost/40392] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:25,801 [Listener at localhost/40392] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:25,801 [Listener at localhost/40392] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 289 msecs
2020-12-03 07:24:25,801 [Listener at localhost/40392] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:25,802 [Listener at localhost/40392] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:25,802 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:25,804 [Listener at localhost/36145] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36145 to access this namenode/service.
2020-12-03 07:24:25,805 [Listener at localhost/36145] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:25,805 [Listener at localhost/36145] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:25,805 [Listener at localhost/36145] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:25,820 [Listener at localhost/36145] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:25,821 [Listener at localhost/36145] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:25,824 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:25,824 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:25,825 [Listener at localhost/36145] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36145
2020-12-03 07:24:25,825 [Listener at localhost/36145] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:25,825 [Listener at localhost/36145] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:25,826 [Listener at localhost/36145] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:25,828 [CacheReplicationMonitor(2007736530)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:25,832 [IPC Server handler 0 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:25,833 [Listener at localhost/36145] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:26,231 [Listener at localhost/36145] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:26,232 [Listener at localhost/36145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:26,232 [Listener at localhost/36145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:26,233 [Listener at localhost/36145] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:26,234 [Listener at localhost/36145] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,235 [Listener at localhost/36145] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:26,235 [Listener at localhost/36145] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:26,235 [Listener at localhost/36145] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,235 [Listener at localhost/36145] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:26,236 [Listener at localhost/36145] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44740
2020-12-03 07:24:26,236 [Listener at localhost/36145] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:26,236 [Listener at localhost/36145] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:26,237 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,238 [Listener at localhost/36145] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:26,238 [Listener at localhost/36145] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:26,239 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,240 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:26,240 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:26,240 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:26,240 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:26,241 [Listener at localhost/36145] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33597
2020-12-03 07:24:26,241 [Listener at localhost/36145] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:26,242 [Listener at localhost/36145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70025b99{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:26,243 [Listener at localhost/36145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7134b8a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:26,247 [Listener at localhost/36145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a1ef65c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:26,247 [Listener at localhost/36145] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72976b4{HTTP/1.1,[http/1.1]}{localhost:33597}
2020-12-03 07:24:26,247 [Listener at localhost/36145] INFO  server.Server (Server.java:doStart(419)) - Started @54015ms
2020-12-03 07:24:26,261 [Listener at localhost/36145] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40881
2020-12-03 07:24:26,261 [Listener at localhost/36145] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:26,261 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1319bc2a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:26,261 [Listener at localhost/36145] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:26,262 [Listener at localhost/36145] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:26,263 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:26,264 [Listener at localhost/37400] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37400
2020-12-03 07:24:26,267 [Listener at localhost/37400] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:26,267 [Listener at localhost/37400] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:26,268 [Thread-2017] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36145 starting to offer service
2020-12-03 07:24:26,269 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:26,269 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:26,273 [IPC Server handler 2 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:26,273 [Thread-2017] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36145
2020-12-03 07:24:26,274 [Thread-2017] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:26,275 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:26,276 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:26,316 [Thread-2017] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:26,377 [IPC Server handler 3 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:26,378 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:26,378 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:26,409 [Thread-2017] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:26,450 [Thread-2017] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,450 [Thread-2017] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,450 [Thread-2017] INFO  common.Storage (Storage.java:doRecover(804)) - Completing previous rollback for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,479 [IPC Server handler 4 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:26,480 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:26,480 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:26,509 [Thread-2017] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,509 [Thread-2017] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,509 [Thread-2017] INFO  common.Storage (Storage.java:doRecover(804)) - Completing previous rollback for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,569 [Thread-2017] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:26,570 [Thread-2017] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3f556ccb-86ad-4482-a624-c14cd8afe86b
2020-12-03 07:24:26,571 [Thread-2017] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:26,571 [Thread-2017] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a895c8-db49-4b9f-9a9d-9223392988e8
2020-12-03 07:24:26,571 [Thread-2017] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:26,571 [Thread-2017] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:26,572 [Thread-2017] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:26,572 [Thread-2017] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:26,573 [Thread-2017] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:26,573 [Thread-2017] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:26,573 [Thread-2017] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,574 [Thread-2029] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:26,574 [Thread-2030] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:26,575 [Thread-2030] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:26,575 [Thread-2029] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:26,581 [Thread-2029] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 8ms
2020-12-03 07:24:26,582 [IPC Server handler 5 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:26,582 [Thread-2030] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 8ms
2020-12-03 07:24:26,582 [Thread-2017] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 9ms
2020-12-03 07:24:26,582 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:26,582 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:26,582 [Thread-2032] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:26,582 [Thread-2031] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:26,584 [Thread-2031] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:26,585 [Thread-2031] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 2ms
2020-12-03 07:24:26,585 [Thread-2032] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:26,587 [Thread-2032] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 5ms
2020-12-03 07:24:26,587 [Thread-2017] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 5ms
2020-12-03 07:24:26,588 [Thread-2017] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:05 AM with interval of 21600000ms
2020-12-03 07:24:26,588 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36145 beginning handshake with NN
2020-12-03 07:24:26,589 [IPC Server handler 6 on default port 36145] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44740, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40881, infoSecurePort=0, ipcPort=37400, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:26,590 [IPC Server handler 6 on default port 36145] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44740
2020-12-03 07:24:26,590 [IPC Server handler 6 on default port 36145] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:44740).
2020-12-03 07:24:26,591 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36145 successfully registered with NN
2020-12-03 07:24:26,592 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36145 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:26,594 [IPC Server handler 7 on default port 36145] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3f556ccb-86ad-4482-a624-c14cd8afe86b for DN 127.0.0.1:44740
2020-12-03 07:24:26,594 [IPC Server handler 7 on default port 36145] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a895c8-db49-4b9f-9a9d-9223392988e8 for DN 127.0.0.1:44740
2020-12-03 07:24:26,596 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa51e12e4355f1d36: Processing first storage report for DS-3f556ccb-86ad-4482-a624-c14cd8afe86b from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:26,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa51e12e4355f1d36: from storage DS-3f556ccb-86ad-4482-a624-c14cd8afe86b node DatanodeRegistration(127.0.0.1:44740, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40881, infoSecurePort=0, ipcPort=37400, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:26,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa51e12e4355f1d36: Processing first storage report for DS-e2a895c8-db49-4b9f-9a9d-9223392988e8 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:26,597 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:26,598 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:26,598 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:26,598 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:26,598 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:26,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa51e12e4355f1d36: from storage DS-e2a895c8-db49-4b9f-9a9d-9223392988e8 node DatanodeRegistration(127.0.0.1:44740, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=40881, infoSecurePort=0, ipcPort=37400, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:26,604 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:24:26,605 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa51e12e4355f1d36,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:26,684 [IPC Server handler 9 on default port 36145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:26,685 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:26,686 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:26,686 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:26,686 [Listener at localhost/37400] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:26,686 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1665fa54] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:26,702 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a1ef65c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:26,703 [Listener at localhost/37400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72976b4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:26,703 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7134b8a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:26,704 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70025b99{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:26,704 [Listener at localhost/37400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37400
2020-12-03 07:24:26,705 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:26,705 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:26,705 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:26,705 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36145
2020-12-03 07:24:26,705 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:26,705 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:36145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:26,706 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:26,706 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:26,708 [Listener at localhost/37400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:26,708 [Listener at localhost/37400] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:26,709 [Listener at localhost/37400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:26,709 [Listener at localhost/37400] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:26,711 [Listener at localhost/37400] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:26,711 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:26,711 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:26,711 [Listener at localhost/37400] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:26,711 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6ca30b8a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:26,711 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@21263314] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:26,712 [Listener at localhost/37400] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:26,713 [Listener at localhost/37400] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:26,713 [Listener at localhost/37400] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:26,713 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:26,714 [CacheReplicationMonitor(2007736530)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:26,714 [Listener at localhost/37400] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36145
2020-12-03 07:24:26,714 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:26,714 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:26,714 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:26,714 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:26,722 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:26,723 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:26,724 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d8b0500{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:26,726 [Listener at localhost/37400] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76544c0a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:26,727 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d3f4505{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:26,728 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@276cc8dc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:26,729 [Listener at localhost/37400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:26,731 [Listener at localhost/37400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:26,731 [Listener at localhost/37400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:26,739 [Listener at localhost/37400] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:26,739 [Listener at localhost/37400] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 29*** BLOCK_POOL recovery: numDirs=2 testCase=11 current=true previous=true previous.tmp=false removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:26,804 [Listener at localhost/37400] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:26,804 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,805 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,805 [Listener at localhost/37400] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:26,806 [Listener at localhost/37400] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:26,807 [Listener at localhost/37400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:26,807 [Listener at localhost/37400] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:26,808 [Listener at localhost/37400] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:26,813 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ec1963c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:26,813 [Listener at localhost/37400] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:26,813 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,814 [Listener at localhost/37400] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:26,814 [Listener at localhost/37400] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:26,815 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,816 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:26,816 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:26,816 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:26,816 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:26,817 [Listener at localhost/37400] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:26,817 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:26,818 [Listener at localhost/37400] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33132
2020-12-03 07:24:26,818 [Listener at localhost/37400] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:26,819 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a44cfc0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:26,820 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@80b122b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:26,823 [Listener at localhost/37400] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@796f632b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:26,824 [Listener at localhost/37400] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5d94a2dc{HTTP/1.1,[http/1.1]}{localhost:33132}
2020-12-03 07:24:26,824 [Listener at localhost/37400] INFO  server.Server (Server.java:doStart(419)) - Started @54592ms
2020-12-03 07:24:26,824 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,824 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,825 [Listener at localhost/37400] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,827 [Listener at localhost/37400] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:26,827 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:26,827 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:26,827 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:26,827 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:26,828 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:26,828 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:26,828 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:26,828 [Listener at localhost/37400] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,829 [Listener at localhost/37400] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:26,829 [Listener at localhost/37400] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:26,829 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:26,829 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:26
2020-12-03 07:24:26,830 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:26,830 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:26,830 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:26,830 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:26,834 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:26,835 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:26,836 [Listener at localhost/37400] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:26,837 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:26,837 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:26,837 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:26,837 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:26,839 [Listener at localhost/37400] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:26,839 [Listener at localhost/37400] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:26,839 [Listener at localhost/37400] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:26,839 [Listener at localhost/37400] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:26,839 [Listener at localhost/37400] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:26,840 [Listener at localhost/37400] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:26,840 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:26,840 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:26,840 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:26,840 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:26,841 [Listener at localhost/37400] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:26,841 [Listener at localhost/37400] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:26,841 [Listener at localhost/37400] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:26,842 [Listener at localhost/37400] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:26,882 [Listener at localhost/37400] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:26,907 [Listener at localhost/37400] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:26,909 [Listener at localhost/37400] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:26,909 [Listener at localhost/37400] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:26,910 [Listener at localhost/37400] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:26,913 [Listener at localhost/37400] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:26,914 [Listener at localhost/37400] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:26,914 [Listener at localhost/37400] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:26,914 [Listener at localhost/37400] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@60a7e509 expecting start txid #32
2020-12-03 07:24:26,914 [Listener at localhost/37400] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:26,915 [Listener at localhost/37400] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:26,917 [Listener at localhost/37400] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:26,917 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:26,918 [Listener at localhost/37400] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:26,975 [Listener at localhost/37400] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:26,975 [Listener at localhost/37400] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 133 msecs
2020-12-03 07:24:26,976 [Listener at localhost/37400] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:26,976 [Listener at localhost/37400] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:26,977 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:26,979 [Listener at localhost/41168] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41168 to access this namenode/service.
2020-12-03 07:24:26,980 [Listener at localhost/41168] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:26,980 [Listener at localhost/41168] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:26,980 [Listener at localhost/41168] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:26,995 [Listener at localhost/41168] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:26,996 [Listener at localhost/41168] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:27,000 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,000 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,000 [Listener at localhost/41168] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41168
2020-12-03 07:24:27,001 [Listener at localhost/41168] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:27,001 [Listener at localhost/41168] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:27,002 [Listener at localhost/41168] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:27,006 [CacheReplicationMonitor(272004140)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:27,012 [IPC Server handler 0 on default port 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:27,013 [Listener at localhost/41168] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:27,703 [Listener at localhost/41168] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:27,704 [Listener at localhost/41168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:27,705 [Listener at localhost/41168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:27,706 [Listener at localhost/41168] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,707 [Listener at localhost/41168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,707 [Listener at localhost/41168] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:27,707 [Listener at localhost/41168] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,708 [Listener at localhost/41168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,708 [Listener at localhost/41168] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,709 [Listener at localhost/41168] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38162
2020-12-03 07:24:27,709 [Listener at localhost/41168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,710 [Listener at localhost/41168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,711 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,713 [Listener at localhost/41168] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,714 [Listener at localhost/41168] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,714 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,716 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,716 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,717 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,717 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,718 [Listener at localhost/41168] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45579
2020-12-03 07:24:27,718 [Listener at localhost/41168] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,720 [Listener at localhost/41168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32bb0072{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,720 [Listener at localhost/41168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@427a12b6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,724 [Listener at localhost/41168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fe87ddd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,725 [Listener at localhost/41168] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4eea94a4{HTTP/1.1,[http/1.1]}{localhost:45579}
2020-12-03 07:24:27,725 [Listener at localhost/41168] INFO  server.Server (Server.java:doStart(419)) - Started @55493ms
2020-12-03 07:24:27,737 [Listener at localhost/41168] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45375
2020-12-03 07:24:27,738 [Listener at localhost/41168] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,738 [Listener at localhost/41168] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,738 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65f40689] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,738 [Listener at localhost/41168] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,739 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,741 [Listener at localhost/43860] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43860
2020-12-03 07:24:27,743 [Listener at localhost/43860] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,744 [Listener at localhost/43860] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,744 [Thread-2087] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168 starting to offer service
2020-12-03 07:24:27,746 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,746 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,749 [IPC Server handler 2 on default port 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:27,750 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:27,750 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:27,750 [Thread-2087] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168
2020-12-03 07:24:27,751 [Thread-2087] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,791 [Thread-2087] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:27,851 [IPC Server handler 3 on default port 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:27,852 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:27,852 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:27,860 [Thread-2087] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:27,902 [Thread-2087] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:27,903 [Thread-2087] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:27,903 [Thread-2087] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:27,903 [Thread-2087] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:27,910 [Thread-2087] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:27,911 [Thread-2087] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:27,911 [Thread-2087] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:27,911 [Thread-2087] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:27,911 [Thread-2087] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41168. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:27,911 [Thread-2087] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41168
2020-12-03 07:24:27,912 [Thread-2087] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:27,953 [IPC Server handler 4 on default port 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:27,954 [Listener at localhost/43860] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:38162', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:41168
2020-12-03 07:24:27,954 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:27,955 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:27,955 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:27,955 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@659f226a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:27,973 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fe87ddd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:27,974 [Listener at localhost/43860] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4eea94a4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:27,974 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@427a12b6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:27,974 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32bb0072{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:27,975 [Listener at localhost/43860] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43860
2020-12-03 07:24:27,975 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:27,975 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:27,976 [Listener at localhost/43860] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:27,976 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:27,976 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:27,976 [Listener at localhost/43860] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:27,976 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4dde8976] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:27,976 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4887de2b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:27,977 [Listener at localhost/43860] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:27,977 [Listener at localhost/43860] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:27,978 [Listener at localhost/43860] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:27,978 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:27,978 [CacheReplicationMonitor(272004140)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:27,979 [Listener at localhost/43860] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41168
2020-12-03 07:24:27,980 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:27,980 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:27,980 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:27,980 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:27,988 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:27,988 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:27,989 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@796f632b{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:27,990 [Listener at localhost/43860] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5d94a2dc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:27,990 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@80b122b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:27,990 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a44cfc0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:27,992 [Listener at localhost/43860] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:27,992 [Listener at localhost/43860] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:27,992 [Listener at localhost/43860] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:28,005 [Listener at localhost/43860] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:28,005 [Listener at localhost/43860] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 30*** BLOCK_POOL recovery: numDirs=2 testCase=12 current=true previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:28,076 [Listener at localhost/43860] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:28,077 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,077 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,077 [Listener at localhost/43860] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:28,080 [Listener at localhost/43860] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:28,081 [Listener at localhost/43860] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:28,081 [Listener at localhost/43860] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:28,081 [Listener at localhost/43860] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:28,086 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@388d14e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,086 [Listener at localhost/43860] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:28,086 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,087 [Listener at localhost/43860] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,088 [Listener at localhost/43860] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:28,088 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,089 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,089 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:28,089 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,089 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,090 [Listener at localhost/43860] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:28,090 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:28,091 [Listener at localhost/43860] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46019
2020-12-03 07:24:28,091 [Listener at localhost/43860] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,092 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55f4887d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,093 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2dbc408c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,096 [Listener at localhost/43860] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3fa7df1{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:28,096 [Listener at localhost/43860] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4dd90166{HTTP/1.1,[http/1.1]}{localhost:46019}
2020-12-03 07:24:28,097 [Listener at localhost/43860] INFO  server.Server (Server.java:doStart(419)) - Started @55865ms
2020-12-03 07:24:28,097 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,097 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,097 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,097 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,098 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,098 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,098 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,098 [Listener at localhost/43860] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,099 [Listener at localhost/43860] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:28,100 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:28,101 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:28,101 [Listener at localhost/43860] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,101 [Listener at localhost/43860] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:28,101 [Listener at localhost/43860] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:28,101 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:28,102 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:28
2020-12-03 07:24:28,102 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:28,102 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:28,102 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:28,103 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:28,106 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:28,106 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:28,106 [Listener at localhost/43860] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:28,106 [Listener at localhost/43860] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:28,107 [Listener at localhost/43860] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:28,108 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:28,108 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:28,108 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:28,108 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:28,110 [Listener at localhost/43860] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:28,110 [Listener at localhost/43860] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:28,110 [Listener at localhost/43860] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:28,111 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:28,112 [Listener at localhost/43860] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:28,112 [Listener at localhost/43860] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:28,112 [Listener at localhost/43860] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:28,113 [Listener at localhost/43860] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:28,206 [Listener at localhost/43860] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:28,381 [Listener at localhost/43860] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:28,383 [Listener at localhost/43860] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:28,383 [Listener at localhost/43860] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:28,384 [Listener at localhost/43860] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:28,387 [Listener at localhost/43860] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:28,388 [Listener at localhost/43860] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:28,388 [Listener at localhost/43860] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:28,389 [Listener at localhost/43860] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3135bf25 expecting start txid #32
2020-12-03 07:24:28,389 [Listener at localhost/43860] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:28,389 [Listener at localhost/43860] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:28,392 [Listener at localhost/43860] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:28,392 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:28,393 [Listener at localhost/43860] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:28,772 [Listener at localhost/43860] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:28,773 [Listener at localhost/43860] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 659 msecs
2020-12-03 07:24:28,773 [Listener at localhost/43860] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:28,773 [Listener at localhost/43860] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,774 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,776 [Listener at localhost/43517] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43517 to access this namenode/service.
2020-12-03 07:24:28,777 [Listener at localhost/43517] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:28,777 [Listener at localhost/43517] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:28,777 [Listener at localhost/43517] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:28,792 [Listener at localhost/43517] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:28,794 [Listener at localhost/43517] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:28,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,796 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,797 [Listener at localhost/43517] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43517
2020-12-03 07:24:28,797 [Listener at localhost/43517] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:28,798 [Listener at localhost/43517] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:28,798 [Listener at localhost/43517] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:28,801 [CacheReplicationMonitor(1144823441)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:28,805 [IPC Server handler 0 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,805 [Listener at localhost/43517] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:29,693 [Listener at localhost/43517] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:29,694 [Listener at localhost/43517] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:29,694 [Listener at localhost/43517] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:29,695 [Listener at localhost/43517] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:29,696 [Listener at localhost/43517] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:29,697 [Listener at localhost/43517] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:29,697 [Listener at localhost/43517] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:29,697 [Listener at localhost/43517] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:29,697 [Listener at localhost/43517] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:29,698 [Listener at localhost/43517] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44521
2020-12-03 07:24:29,698 [Listener at localhost/43517] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:29,698 [Listener at localhost/43517] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:29,699 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:29,700 [Listener at localhost/43517] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:29,700 [Listener at localhost/43517] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:29,700 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:29,701 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:29,702 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:29,702 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:29,702 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:29,702 [Listener at localhost/43517] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33885
2020-12-03 07:24:29,703 [Listener at localhost/43517] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:29,704 [Listener at localhost/43517] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4373f66f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:29,704 [Listener at localhost/43517] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44114b9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:29,708 [Listener at localhost/43517] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f59ea8c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:29,709 [Listener at localhost/43517] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b2ccba5{HTTP/1.1,[http/1.1]}{localhost:33885}
2020-12-03 07:24:29,709 [Listener at localhost/43517] INFO  server.Server (Server.java:doStart(419)) - Started @57477ms
2020-12-03 07:24:29,721 [Listener at localhost/43517] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40357
2020-12-03 07:24:29,721 [Listener at localhost/43517] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:29,721 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d5a51b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:29,721 [Listener at localhost/43517] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:29,722 [Listener at localhost/43517] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:29,723 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:29,724 [Listener at localhost/33495] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33495
2020-12-03 07:24:29,727 [Listener at localhost/33495] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:29,727 [Listener at localhost/33495] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:29,728 [Thread-2149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43517 starting to offer service
2020-12-03 07:24:29,729 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:29,729 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:29,733 [Thread-2149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43517
2020-12-03 07:24:29,733 [IPC Server handler 2 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,733 [Thread-2149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:29,734 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,734 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,835 [IPC Server handler 1 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,836 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,836 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,882 [Thread-2149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:29,937 [IPC Server handler 2 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,938 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,938 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,039 [IPC Server handler 3 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,040 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,040 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,141 [IPC Server handler 4 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,142 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,142 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,243 [IPC Server handler 5 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,244 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,244 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,248 [Thread-2149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:30,346 [IPC Server handler 6 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,346 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,347 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,384 [Thread-2149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:30,384 [Thread-2149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:30,384 [Thread-2149] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:30,385 [Thread-2149] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:30,394 [Thread-2149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:30,394 [Thread-2149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:30,394 [Thread-2149] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:30,395 [Thread-2149] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:30,395 [Thread-2149] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43517. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:30,395 [Thread-2149] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43517
2020-12-03 07:24:30,395 [Thread-2149] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:30,449 [IPC Server handler 7 on default port 43517] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,450 [Listener at localhost/33495] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:44521', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:43517
2020-12-03 07:24:30,450 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:30,451 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:30,451 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:30,451 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4cfa83f9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:30,494 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f59ea8c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:30,494 [Listener at localhost/33495] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b2ccba5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:30,495 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44114b9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:30,495 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4373f66f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:30,495 [Listener at localhost/33495] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33495
2020-12-03 07:24:30,496 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:30,496 [Listener at localhost/33495] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:30,496 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:30,497 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:30,497 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:30,497 [Listener at localhost/33495] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:30,497 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3fa21d49] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:30,497 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@416d56f2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:30,498 [Listener at localhost/33495] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:30,498 [Listener at localhost/33495] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:30,499 [Listener at localhost/33495] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:30,499 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:30,499 [CacheReplicationMonitor(1144823441)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:30,501 [Listener at localhost/33495] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43517
2020-12-03 07:24:30,502 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:30,503 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:30,503 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:30,503 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:30,513 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:30,514 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:30,515 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3fa7df1{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:30,516 [Listener at localhost/33495] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4dd90166{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:30,516 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2dbc408c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:30,519 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55f4887d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:30,521 [Listener at localhost/33495] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:30,522 [Listener at localhost/33495] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:30,522 [Listener at localhost/33495] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:30,535 [Listener at localhost/33495] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:30,535 [Listener at localhost/33495] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 31*** BLOCK_POOL recovery: numDirs=2 testCase=13 current=true previous=false previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:30,620 [Listener at localhost/33495] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:30,620 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,621 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,621 [Listener at localhost/33495] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:30,623 [Listener at localhost/33495] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:30,624 [Listener at localhost/33495] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:30,624 [Listener at localhost/33495] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:30,625 [Listener at localhost/33495] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:30,628 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@220c9a63] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:30,629 [Listener at localhost/33495] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:30,629 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:30,630 [Listener at localhost/33495] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:30,630 [Listener at localhost/33495] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:30,631 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:30,632 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:30,632 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:30,632 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:30,632 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:30,634 [Listener at localhost/33495] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:30,634 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:30,634 [Listener at localhost/33495] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33228
2020-12-03 07:24:30,634 [Listener at localhost/33495] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:30,636 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7645f03e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:30,637 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a6ea47d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:30,641 [Listener at localhost/33495] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4faf104{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:30,642 [Listener at localhost/33495] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5995851e{HTTP/1.1,[http/1.1]}{localhost:33228}
2020-12-03 07:24:30,642 [Listener at localhost/33495] INFO  server.Server (Server.java:doStart(419)) - Started @58410ms
2020-12-03 07:24:30,642 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,642 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,643 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,643 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,643 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,643 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,643 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,644 [Listener at localhost/33495] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,645 [Listener at localhost/33495] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:30,645 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:30,646 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:30,647 [Listener at localhost/33495] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:30,647 [Listener at localhost/33495] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:30,647 [Listener at localhost/33495] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:30,647 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:30,648 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:30
2020-12-03 07:24:30,648 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:30,648 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:30,648 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:30,648 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:30,658 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:30,659 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:30,659 [Listener at localhost/33495] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:30,659 [Listener at localhost/33495] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:30,659 [Listener at localhost/33495] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:30,659 [Listener at localhost/33495] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:30,660 [Listener at localhost/33495] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:30,661 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:30,661 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:30,661 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:30,661 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:30,665 [Listener at localhost/33495] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:30,665 [Listener at localhost/33495] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:30,665 [Listener at localhost/33495] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:30,665 [Listener at localhost/33495] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:30,666 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:30,668 [Listener at localhost/33495] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:30,668 [Listener at localhost/33495] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:30,668 [Listener at localhost/33495] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:30,668 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:30,669 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:30,669 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:30,669 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:30,669 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:30,669 [Listener at localhost/33495] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:30,794 [Listener at localhost/33495] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:30,877 [Listener at localhost/33495] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:30,879 [Listener at localhost/33495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:30,879 [Listener at localhost/33495] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:30,880 [Listener at localhost/33495] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:30,882 [Listener at localhost/33495] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:30,882 [Listener at localhost/33495] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:30,883 [Listener at localhost/33495] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:30,883 [Listener at localhost/33495] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@77c3c037 expecting start txid #32
2020-12-03 07:24:30,883 [Listener at localhost/33495] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:30,883 [Listener at localhost/33495] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:30,885 [Listener at localhost/33495] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 3.0 ms
2020-12-03 07:24:30,886 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:30,886 [Listener at localhost/33495] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:30,970 [Listener at localhost/33495] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:30,970 [Listener at localhost/33495] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 301 msecs
2020-12-03 07:24:30,971 [Listener at localhost/33495] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:30,971 [Listener at localhost/33495] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:30,972 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:30,974 [Listener at localhost/41981] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:41981 to access this namenode/service.
2020-12-03 07:24:30,974 [Listener at localhost/41981] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:30,974 [Listener at localhost/41981] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:30,974 [Listener at localhost/41981] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:30,987 [Listener at localhost/41981] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:30,988 [Listener at localhost/41981] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:30,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:30,990 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:30,991 [Listener at localhost/41981] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41981
2020-12-03 07:24:30,991 [Listener at localhost/41981] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:30,991 [Listener at localhost/41981] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:30,992 [Listener at localhost/41981] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:31,020 [CacheReplicationMonitor(248229291)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:31,022 [IPC Server handler 0 on default port 41981] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,023 [Listener at localhost/41981] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:31,599 [Listener at localhost/41981] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:31,600 [Listener at localhost/41981] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:31,600 [Listener at localhost/41981] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:31,601 [Listener at localhost/41981] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:31,603 [Listener at localhost/41981] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:31,603 [Listener at localhost/41981] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:31,603 [Listener at localhost/41981] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:31,603 [Listener at localhost/41981] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:31,604 [Listener at localhost/41981] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:31,604 [Listener at localhost/41981] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40284
2020-12-03 07:24:31,604 [Listener at localhost/41981] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:31,605 [Listener at localhost/41981] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:31,607 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,609 [Listener at localhost/41981] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:31,610 [Listener at localhost/41981] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:31,610 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,611 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:31,611 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:31,611 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:31,611 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:31,612 [Listener at localhost/41981] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45094
2020-12-03 07:24:31,612 [Listener at localhost/41981] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:31,613 [Listener at localhost/41981] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1989e8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:31,614 [Listener at localhost/41981] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@104dc1a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:31,620 [Listener at localhost/41981] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7f323b3a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:31,620 [Listener at localhost/41981] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f169009{HTTP/1.1,[http/1.1]}{localhost:45094}
2020-12-03 07:24:31,621 [Listener at localhost/41981] INFO  server.Server (Server.java:doStart(419)) - Started @59389ms
2020-12-03 07:24:31,638 [Listener at localhost/41981] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35067
2020-12-03 07:24:31,639 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4207852d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:31,639 [Listener at localhost/41981] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:31,639 [Listener at localhost/41981] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:31,639 [Listener at localhost/41981] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:31,640 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:31,643 [Listener at localhost/40586] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40586
2020-12-03 07:24:31,646 [Listener at localhost/40586] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:31,647 [Listener at localhost/40586] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:31,647 [Thread-2211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41981 starting to offer service
2020-12-03 07:24:31,649 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:31,649 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:31,654 [IPC Server handler 2 on default port 41981] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,654 [Thread-2211] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41981
2020-12-03 07:24:31,654 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:31,655 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:31,655 [Thread-2211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:31,694 [Thread-2211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:31,756 [IPC Server handler 3 on default port 41981] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,757 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:31,757 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:31,779 [Thread-2211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:31,813 [Thread-2211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:31,813 [Thread-2211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:31,813 [Thread-2211] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,814 [Thread-2211] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,820 [Thread-2211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:31,820 [Thread-2211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:31,820 [Thread-2211] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,821 [Thread-2211] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,821 [Thread-2211] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41981. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,821 [Thread-2211] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:41981
2020-12-03 07:24:31,821 [Thread-2211] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:31,858 [IPC Server handler 4 on default port 41981] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,858 [Listener at localhost/40586] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:40284', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:41981
2020-12-03 07:24:31,859 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:31,859 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:31,859 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:31,859 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@460b50df] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,875 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7f323b3a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,875 [Listener at localhost/40586] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f169009{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,876 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@104dc1a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,876 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1989e8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,876 [Listener at localhost/40586] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40586
2020-12-03 07:24:31,877 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,877 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,878 [Listener at localhost/40586] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,878 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:31,878 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:31,879 [Listener at localhost/40586] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:31,879 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@9f86dc3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:31,879 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7c369270] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:31,880 [Listener at localhost/40586] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:31,880 [Listener at localhost/40586] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:31,881 [Listener at localhost/40586] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:31,881 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:31,881 [CacheReplicationMonitor(248229291)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:31,882 [Listener at localhost/40586] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41981
2020-12-03 07:24:31,883 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,883 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,883 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:31,883 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:31,894 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:31,894 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:31,895 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4faf104{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:31,896 [Listener at localhost/40586] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5995851e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,896 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a6ea47d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,897 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7645f03e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,898 [Listener at localhost/40586] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:31,898 [Listener at localhost/40586] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:31,898 [Listener at localhost/40586] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:31,912 [Listener at localhost/40586] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:31,912 [Listener at localhost/40586] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 32*** BLOCK_POOL recovery: numDirs=2 testCase=14 current=false previous=true previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:31,984 [Listener at localhost/40586] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:31,985 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:31,985 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:31,985 [Listener at localhost/40586] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:31,987 [Listener at localhost/40586] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:31,988 [Listener at localhost/40586] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:31,988 [Listener at localhost/40586] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:31,988 [Listener at localhost/40586] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:31,993 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7499eac7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:31,993 [Listener at localhost/40586] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:31,994 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,995 [Listener at localhost/40586] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:31,995 [Listener at localhost/40586] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:31,996 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:31,997 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:31,997 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:31,997 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:31,997 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:31,998 [Listener at localhost/40586] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:31,999 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:31,999 [Listener at localhost/40586] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35109
2020-12-03 07:24:31,999 [Listener at localhost/40586] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:32,000 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8bd076a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:32,001 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1378eea2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:32,005 [Listener at localhost/40586] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2abc8034{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:32,005 [Listener at localhost/40586] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@467b0f6e{HTTP/1.1,[http/1.1]}{localhost:35109}
2020-12-03 07:24:32,005 [Listener at localhost/40586] INFO  server.Server (Server.java:doStart(419)) - Started @59774ms
2020-12-03 07:24:32,006 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:32,006 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:32,006 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:32,006 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:32,006 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:32,007 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:32,007 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:32,007 [Listener at localhost/40586] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:32,008 [Listener at localhost/40586] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:32,009 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:32,010 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:32,010 [Listener at localhost/40586] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:32,010 [Listener at localhost/40586] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:32,010 [Listener at localhost/40586] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:32
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:32,011 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:32,021 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:32,022 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:32,023 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:32,024 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:32,024 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:32,024 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:32,029 [Listener at localhost/40586] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:32,029 [Listener at localhost/40586] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:32,029 [Listener at localhost/40586] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:32,029 [Listener at localhost/40586] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:32,029 [Listener at localhost/40586] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:32,030 [Listener at localhost/40586] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:32,030 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:32,030 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:32,030 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:32,030 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:32,032 [Listener at localhost/40586] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:32,032 [Listener at localhost/40586] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:32,032 [Listener at localhost/40586] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:32,032 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:32,032 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:32,033 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:32,033 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:32,033 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:32,033 [Listener at localhost/40586] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:32,074 [Listener at localhost/40586] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:32,108 [Listener at localhost/40586] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:32,110 [Listener at localhost/40586] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:32,110 [Listener at localhost/40586] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:32,110 [Listener at localhost/40586] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:32,113 [Listener at localhost/40586] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:32,114 [Listener at localhost/40586] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:32,114 [Listener at localhost/40586] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:32,114 [Listener at localhost/40586] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@ca8ef3a expecting start txid #32
2020-12-03 07:24:32,114 [Listener at localhost/40586] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:32,114 [Listener at localhost/40586] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:32,117 [Listener at localhost/40586] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:32,117 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:32,117 [Listener at localhost/40586] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:32,186 [Listener at localhost/40586] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:32,186 [Listener at localhost/40586] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 153 msecs
2020-12-03 07:24:32,186 [Listener at localhost/40586] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:32,187 [Listener at localhost/40586] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:32,188 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:32,189 [Listener at localhost/36568] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36568 to access this namenode/service.
2020-12-03 07:24:32,190 [Listener at localhost/36568] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:32,190 [Listener at localhost/36568] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:32,190 [Listener at localhost/36568] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:32,206 [Listener at localhost/36568] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:32,208 [Listener at localhost/36568] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:32,211 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:32,211 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:32,212 [Listener at localhost/36568] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36568
2020-12-03 07:24:32,212 [Listener at localhost/36568] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:32,212 [Listener at localhost/36568] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:32,214 [Listener at localhost/36568] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:32,218 [CacheReplicationMonitor(2113710410)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:32,223 [IPC Server handler 0 on default port 36568] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,223 [Listener at localhost/36568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:32,876 [Listener at localhost/36568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:32,876 [Listener at localhost/36568] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:32,877 [Listener at localhost/36568] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:32,877 [Listener at localhost/36568] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:32,879 [Listener at localhost/36568] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:32,879 [Listener at localhost/36568] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:32,879 [Listener at localhost/36568] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:32,879 [Listener at localhost/36568] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:32,879 [Listener at localhost/36568] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:32,880 [Listener at localhost/36568] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35236
2020-12-03 07:24:32,880 [Listener at localhost/36568] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:32,880 [Listener at localhost/36568] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:32,882 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:32,883 [Listener at localhost/36568] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:32,883 [Listener at localhost/36568] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:32,883 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:32,884 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:32,885 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:32,885 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:32,885 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:32,885 [Listener at localhost/36568] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37135
2020-12-03 07:24:32,885 [Listener at localhost/36568] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:32,887 [Listener at localhost/36568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d2b6960{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:32,887 [Listener at localhost/36568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@234c5e41{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:32,890 [Listener at localhost/36568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@180b3819{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:32,891 [Listener at localhost/36568] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@733c464f{HTTP/1.1,[http/1.1]}{localhost:37135}
2020-12-03 07:24:32,891 [Listener at localhost/36568] INFO  server.Server (Server.java:doStart(419)) - Started @60659ms
2020-12-03 07:24:32,904 [Listener at localhost/36568] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37249
2020-12-03 07:24:32,905 [Listener at localhost/36568] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:32,905 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73fbdf68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:32,905 [Listener at localhost/36568] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:32,905 [Listener at localhost/36568] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:32,906 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:32,908 [Listener at localhost/42675] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42675
2020-12-03 07:24:32,910 [Listener at localhost/42675] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:32,911 [Listener at localhost/42675] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:32,911 [Thread-2273] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36568 starting to offer service
2020-12-03 07:24:32,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:32,913 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:32,915 [IPC Server handler 2 on default port 36568] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,915 [Thread-2273] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36568
2020-12-03 07:24:32,916 [Thread-2273] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:32,916 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:32,916 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:32,957 [Thread-2273] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:33,017 [IPC Server handler 3 on default port 36568] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,018 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:33,018 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:33,025 [Thread-2273] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:33,067 [Thread-2273] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:33,067 [Thread-2273] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:33,067 [Thread-2273] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:33,068 [Thread-2273] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:33,075 [Thread-2273] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:33,075 [Thread-2273] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:33,075 [Thread-2273] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:33,076 [Thread-2273] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:33,076 [Thread-2273] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36568. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:33,080 [Thread-2273] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:36568
2020-12-03 07:24:33,080 [Thread-2273] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:33,119 [IPC Server handler 4 on default port 36568] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,120 [Listener at localhost/42675] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:35236', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:36568
2020-12-03 07:24:33,120 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:33,120 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:33,120 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:33,121 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a7d9b41] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,137 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@180b3819{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,138 [Listener at localhost/42675] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@733c464f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,138 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@234c5e41{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,138 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d2b6960{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,139 [Listener at localhost/42675] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42675
2020-12-03 07:24:33,139 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,140 [Listener at localhost/42675] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,140 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:33,140 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:33,140 [Listener at localhost/42675] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:33,140 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@19bedeb8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:33,140 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1ba467c2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:33,141 [Listener at localhost/42675] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-12-03 07:24:33,141 [Listener at localhost/42675] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:33,142 [Listener at localhost/42675] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:33,142 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:33,142 [CacheReplicationMonitor(2113710410)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:33,143 [Listener at localhost/42675] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36568
2020-12-03 07:24:33,144 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,145 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,145 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:33,145 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:33,156 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:33,156 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:33,157 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2abc8034{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:33,158 [Listener at localhost/42675] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@467b0f6e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,158 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1378eea2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,159 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8bd076a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,159 [Listener at localhost/42675] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:33,159 [Listener at localhost/42675] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:33,160 [Listener at localhost/42675] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:33,170 [Listener at localhost/42675] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:33,170 [Listener at localhost/42675] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 33*** BLOCK_POOL recovery: numDirs=2 testCase=15 current=false previous=false previous.tmp=true removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:33,237 [Listener at localhost/42675] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:33,237 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,237 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,238 [Listener at localhost/42675] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:33,239 [Listener at localhost/42675] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:33,240 [Listener at localhost/42675] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:33,240 [Listener at localhost/42675] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:33,241 [Listener at localhost/42675] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:33,245 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a02e34b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:33,245 [Listener at localhost/42675] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:33,246 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:33,247 [Listener at localhost/42675] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:33,247 [Listener at localhost/42675] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:33,247 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:33,248 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:33,249 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:33,249 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:33,249 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:33,250 [Listener at localhost/42675] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:33,250 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:33,250 [Listener at localhost/42675] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45212
2020-12-03 07:24:33,251 [Listener at localhost/42675] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:33,252 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2001e48c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:33,252 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@306c7bf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:33,256 [Listener at localhost/42675] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4bc59b27{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:33,257 [Listener at localhost/42675] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d7a64ca{HTTP/1.1,[http/1.1]}{localhost:45212}
2020-12-03 07:24:33,257 [Listener at localhost/42675] INFO  server.Server (Server.java:doStart(419)) - Started @61026ms
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,258 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,259 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,259 [Listener at localhost/42675] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,260 [Listener at localhost/42675] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:33,261 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:33,262 [Listener at localhost/42675] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:33,262 [Listener at localhost/42675] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:33,262 [Listener at localhost/42675] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:33,262 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:33,263 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:33
2020-12-03 07:24:33,263 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:33,263 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:33,263 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:33,263 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:33,273 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:33,274 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:33,275 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:33,276 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:33,276 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:33,281 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:33,282 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:33,282 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:33,282 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:33,283 [Listener at localhost/42675] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:33,283 [Listener at localhost/42675] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:33,283 [Listener at localhost/42675] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:33,284 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:33,284 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:33,284 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:33,284 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:33,285 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:33,285 [Listener at localhost/42675] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:33,347 [Listener at localhost/42675] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:33,390 [Listener at localhost/42675] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:33,391 [Listener at localhost/42675] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:33,392 [Listener at localhost/42675] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:33,392 [Listener at localhost/42675] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:33,394 [Listener at localhost/42675] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:33,395 [Listener at localhost/42675] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:33,395 [Listener at localhost/42675] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:33,395 [Listener at localhost/42675] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2accaec2 expecting start txid #32
2020-12-03 07:24:33,396 [Listener at localhost/42675] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:33,396 [Listener at localhost/42675] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:33,397 [Listener at localhost/42675] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:33,398 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:33,398 [Listener at localhost/42675] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:33,475 [Listener at localhost/42675] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:33,475 [Listener at localhost/42675] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 190 msecs
2020-12-03 07:24:33,476 [Listener at localhost/42675] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:33,476 [Listener at localhost/42675] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:33,477 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:33,479 [Listener at localhost/33493] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33493 to access this namenode/service.
2020-12-03 07:24:33,479 [Listener at localhost/33493] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:33,479 [Listener at localhost/33493] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:33,479 [Listener at localhost/33493] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:33,494 [Listener at localhost/33493] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:33,496 [Listener at localhost/33493] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:33,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:33,499 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:33,500 [Listener at localhost/33493] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33493
2020-12-03 07:24:33,500 [Listener at localhost/33493] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:33,501 [Listener at localhost/33493] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:33,501 [Listener at localhost/33493] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:33,505 [CacheReplicationMonitor(1090709679)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:33,508 [IPC Server handler 0 on default port 33493] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:33,509 [Listener at localhost/33493] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:34,515 [Listener at localhost/33493] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:34,515 [Listener at localhost/33493] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:34,516 [Listener at localhost/33493] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:34,517 [Listener at localhost/33493] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:34,519 [Listener at localhost/33493] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,519 [Listener at localhost/33493] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:34,519 [Listener at localhost/33493] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:34,520 [Listener at localhost/33493] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,520 [Listener at localhost/33493] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:34,520 [Listener at localhost/33493] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39430
2020-12-03 07:24:34,520 [Listener at localhost/33493] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:34,520 [Listener at localhost/33493] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:34,521 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,522 [Listener at localhost/33493] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:34,523 [Listener at localhost/33493] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:34,523 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,524 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:34,524 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:34,524 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:34,524 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:34,525 [Listener at localhost/33493] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35731
2020-12-03 07:24:34,525 [Listener at localhost/33493] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:34,526 [Listener at localhost/33493] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ae1c281{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:34,526 [Listener at localhost/33493] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e957e2f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:34,530 [Listener at localhost/33493] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e700eba{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:34,530 [Listener at localhost/33493] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6436e181{HTTP/1.1,[http/1.1]}{localhost:35731}
2020-12-03 07:24:34,530 [Listener at localhost/33493] INFO  server.Server (Server.java:doStart(419)) - Started @62299ms
2020-12-03 07:24:34,547 [Listener at localhost/33493] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45422
2020-12-03 07:24:34,548 [Listener at localhost/33493] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:34,548 [Listener at localhost/33493] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:34,548 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b649efa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:34,548 [Listener at localhost/33493] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:34,549 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:34,551 [Listener at localhost/45189] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45189
2020-12-03 07:24:34,555 [Listener at localhost/45189] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:34,555 [Listener at localhost/45189] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:34,555 [Thread-2335] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33493 starting to offer service
2020-12-03 07:24:34,557 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:34,557 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:34,559 [IPC Server handler 2 on default port 33493] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,559 [Thread-2335] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33493
2020-12-03 07:24:34,560 [Thread-2335] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:34,560 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,560 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,613 [Thread-2335] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:34,661 [IPC Server handler 3 on default port 33493] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,662 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,662 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,744 [Thread-2335] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:34,763 [IPC Server handler 4 on default port 33493] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,763 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:34,763 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:34,815 [Thread-2335] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:34,815 [Thread-2335] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:34,815 [Thread-2335] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:34,815 [Thread-2335] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:34,821 [Thread-2335] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:34,821 [Thread-2335] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:34,821 [Thread-2335] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:34,822 [Thread-2335] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: too many temporary directories.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:738)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:34,822 [Thread-2335] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33493. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:34,822 [Thread-2335] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:33493
2020-12-03 07:24:34,822 [Thread-2335] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:34,864 [IPC Server handler 5 on default port 33493] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:34,865 [Listener at localhost/45189] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:39430', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:33493
2020-12-03 07:24:34,865 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:34,865 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:34,865 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:34,865 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@c02670f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:34,882 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e700eba{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:34,882 [Listener at localhost/45189] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6436e181{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:34,882 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e957e2f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:34,883 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ae1c281{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:34,883 [Listener at localhost/45189] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45189
2020-12-03 07:24:34,883 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:34,883 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:34,884 [Listener at localhost/45189] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:34,884 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:34,884 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:34,884 [Listener at localhost/45189] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:34,884 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4aa2877c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:34,884 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@307e4c44] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:34,885 [Listener at localhost/45189] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:34,885 [Listener at localhost/45189] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:34,886 [Listener at localhost/45189] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:34,886 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:34,886 [CacheReplicationMonitor(1090709679)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:34,887 [Listener at localhost/45189] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33493
2020-12-03 07:24:34,887 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:34,888 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:34,888 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:34,888 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:34,895 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:34,895 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:34,896 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4bc59b27{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:34,897 [Listener at localhost/45189] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d7a64ca{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:34,897 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@306c7bf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:34,898 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2001e48c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:34,898 [Listener at localhost/45189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:34,898 [Listener at localhost/45189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:34,899 [Listener at localhost/45189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:34,907 [Listener at localhost/45189] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:34,907 [Listener at localhost/45189] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 34*** BLOCK_POOL recovery: numDirs=2 testCase=16 current=false previous=false previous.tmp=false removed.tmp=true should recover=false current exists after=false previous exists after=false
2020-12-03 07:24:34,967 [Listener at localhost/45189] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:34,967 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:34,967 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:34,968 [Listener at localhost/45189] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:34,969 [Listener at localhost/45189] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:34,970 [Listener at localhost/45189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:34,970 [Listener at localhost/45189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:34,971 [Listener at localhost/45189] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:34,975 [Listener at localhost/45189] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:34,975 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b009e7b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:34,976 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,977 [Listener at localhost/45189] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:34,977 [Listener at localhost/45189] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:34,977 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,978 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:34,979 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:34,979 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:34,979 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:34,980 [Listener at localhost/45189] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:34,980 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:34,980 [Listener at localhost/45189] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42306
2020-12-03 07:24:34,980 [Listener at localhost/45189] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:34,982 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f347d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:34,982 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c134052{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:34,986 [Listener at localhost/45189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@602f8f94{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:34,986 [Listener at localhost/45189] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42507640{HTTP/1.1,[http/1.1]}{localhost:42306}
2020-12-03 07:24:34,987 [Listener at localhost/45189] INFO  server.Server (Server.java:doStart(419)) - Started @62755ms
2020-12-03 07:24:34,987 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:34,987 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:34,987 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:34,987 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:34,988 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:34,988 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:34,988 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:34,988 [Listener at localhost/45189] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:34,989 [Listener at localhost/45189] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:34,990 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:34,991 [Listener at localhost/45189] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,991 [Listener at localhost/45189] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:34,991 [Listener at localhost/45189] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:34,991 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:34,991 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:34
2020-12-03 07:24:34,992 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:34,992 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,992 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:34,992 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:34,998 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:34,998 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:34,998 [Listener at localhost/45189] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:34,999 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:35,000 [Listener at localhost/45189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:35,000 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:35,000 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:35,000 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:35,000 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:35,002 [Listener at localhost/45189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:35,002 [Listener at localhost/45189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:35,002 [Listener at localhost/45189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:35,002 [Listener at localhost/45189] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:35,003 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:35,005 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:35,006 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:35,006 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:35,006 [Listener at localhost/45189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:35,090 [Listener at localhost/45189] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:35,159 [Listener at localhost/45189] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:35,160 [Listener at localhost/45189] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:35,160 [Listener at localhost/45189] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:35,161 [Listener at localhost/45189] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:35,163 [Listener at localhost/45189] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:35,164 [Listener at localhost/45189] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:35,164 [Listener at localhost/45189] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:35,165 [Listener at localhost/45189] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@12f279b5 expecting start txid #32
2020-12-03 07:24:35,165 [Listener at localhost/45189] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:35,165 [Listener at localhost/45189] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:35,167 [Listener at localhost/45189] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 2.0 ms
2020-12-03 07:24:35,167 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:35,168 [Listener at localhost/45189] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:35,328 [Listener at localhost/45189] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:35,329 [Listener at localhost/45189] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 322 msecs
2020-12-03 07:24:35,329 [Listener at localhost/45189] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:35,330 [Listener at localhost/45189] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,332 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,339 [Listener at localhost/43463] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43463 to access this namenode/service.
2020-12-03 07:24:35,340 [Listener at localhost/43463] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:35,340 [Listener at localhost/43463] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:35,340 [Listener at localhost/43463] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:35,353 [Listener at localhost/43463] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:35,355 [Listener at localhost/43463] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:35,358 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,358 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,359 [Listener at localhost/43463] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43463
2020-12-03 07:24:35,359 [Listener at localhost/43463] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:35,359 [Listener at localhost/43463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:35,360 [Listener at localhost/43463] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:35,362 [CacheReplicationMonitor(1532243654)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:35,366 [IPC Server handler 0 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,366 [Listener at localhost/43463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:35,806 [Listener at localhost/43463] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:35,807 [Listener at localhost/43463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:35,807 [Listener at localhost/43463] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:35,808 [Listener at localhost/43463] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,809 [Listener at localhost/43463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,809 [Listener at localhost/43463] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:35,809 [Listener at localhost/43463] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,809 [Listener at localhost/43463] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,809 [Listener at localhost/43463] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,810 [Listener at localhost/43463] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45437
2020-12-03 07:24:35,810 [Listener at localhost/43463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,810 [Listener at localhost/43463] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,811 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,812 [Listener at localhost/43463] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,812 [Listener at localhost/43463] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,812 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,813 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,813 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,814 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,814 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,814 [Listener at localhost/43463] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39613
2020-12-03 07:24:35,814 [Listener at localhost/43463] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,816 [Listener at localhost/43463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67332b1e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,816 [Listener at localhost/43463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@679dd234{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,820 [Listener at localhost/43463] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@59fc6d05{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,820 [Listener at localhost/43463] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@78307a56{HTTP/1.1,[http/1.1]}{localhost:39613}
2020-12-03 07:24:35,820 [Listener at localhost/43463] INFO  server.Server (Server.java:doStart(419)) - Started @63589ms
2020-12-03 07:24:35,830 [Listener at localhost/43463] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34055
2020-12-03 07:24:35,831 [Listener at localhost/43463] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,831 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23ad71bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,831 [Listener at localhost/43463] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,831 [Listener at localhost/43463] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,832 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,833 [Listener at localhost/43403] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43403
2020-12-03 07:24:35,836 [Listener at localhost/43403] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,836 [Listener at localhost/43403] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,837 [Thread-2397] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43463 starting to offer service
2020-12-03 07:24:35,838 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,838 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,840 [Thread-2397] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43463
2020-12-03 07:24:35,840 [Thread-2397] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,842 [IPC Server handler 2 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,842 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,842 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,943 [IPC Server handler 3 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,944 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,944 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,970 [Thread-2397] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:36,045 [IPC Server handler 4 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,046 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,046 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,147 [IPC Server handler 5 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,147 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,147 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,248 [IPC Server handler 6 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,249 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,249 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,286 [Thread-2397] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:36,349 [IPC Server handler 7 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,350 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,350 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,451 [Thread-2397] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:36,451 [IPC Server handler 1 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,451 [Thread-2397] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:36,452 [Thread-2397] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:36,452 [Thread-2397] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:36,452 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,452 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,458 [Thread-2397] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:36,458 [Thread-2397] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:36,458 [Thread-2397] WARN  common.Storage (BlockPoolSliceStorage.java:loadBpStorageDirectories(228)) - Failed to analyze storage directories for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:36,458 [Thread-2397] WARN  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(467)) - Failed to add storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 for block pool BP-552726158-172.17.0.2-1606980213726
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 is in an inconsistent state: one and only one directory current or previous must be present when removed.tmp exists.
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:767)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadStorageDirectory(BlockPoolSliceStorage.java:156)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:253)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadBlockPoolSliceStorage(DataStorage.java:457)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:559)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:36,458 [Thread-2397] ERROR datanode.DataNode (BPServiceActor.java:run(836)) - Initialization failed for Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43463. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:560)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1743)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1679)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:36,459 [Thread-2397] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:43463
2020-12-03 07:24:36,459 [Thread-2397] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool <registering> (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:36,553 [IPC Server handler 2 on default port 43463] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,554 [Listener at localhost/43403] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2774)) - BPOfferService in datanode DataNode{data=null, localName='127.0.0.1:45437', datanodeUuid='8c680083-5d1f-4061-9fe5-a63a727e294b', xmitsInProgress=0} failed to connect to namenode at localhost/127.0.0.1:43463
2020-12-03 07:24:36,554 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:36,554 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:36,554 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:36,555 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@da4cf09] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:36,573 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@59fc6d05{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:36,574 [Listener at localhost/43403] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@78307a56{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:36,574 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@679dd234{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:36,574 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67332b1e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:36,575 [Listener at localhost/43403] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43403
2020-12-03 07:24:36,575 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:36,575 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:36,576 [Listener at localhost/43403] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:36,576 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:36,576 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:36,576 [Listener at localhost/43403] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:36,576 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@15d0d6c9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:36,576 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3ab35b9c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:36,576 [Listener at localhost/43403] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:36,577 [Listener at localhost/43403] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:36,577 [Listener at localhost/43403] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:36,578 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:36,578 [CacheReplicationMonitor(1532243654)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:36,578 [Listener at localhost/43403] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43463
2020-12-03 07:24:36,579 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:36,579 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:36,579 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:36,579 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:36,586 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:36,587 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:36,587 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@602f8f94{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:36,588 [Listener at localhost/43403] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42507640{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:36,588 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c134052{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:36,588 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f347d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:36,589 [Listener at localhost/43403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:36,589 [Listener at localhost/43403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:36,589 [Listener at localhost/43403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:36,596 [Listener at localhost/43403] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(111)) - ============================================================
2020-12-03 07:24:36,596 [Listener at localhost/43403] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:log(112)) - ***TEST 35*** BLOCK_POOL recovery: numDirs=2 testCase=17 current=false previous=true previous.tmp=false removed.tmp=true should recover=true current exists after=true previous exists after=true
2020-12-03 07:24:36,656 [Listener at localhost/43403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-12-03 07:24:36,657 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:36,657 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:36,657 [Listener at localhost/43403] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:36,659 [Listener at localhost/43403] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:36,659 [Listener at localhost/43403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:36,660 [Listener at localhost/43403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:36,660 [Listener at localhost/43403] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:36,665 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f0bab7e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:36,665 [Listener at localhost/43403] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:36,666 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:36,667 [Listener at localhost/43403] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:36,667 [Listener at localhost/43403] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:36,667 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:36,668 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:36,669 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:36,669 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:36,669 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:36,670 [Listener at localhost/43403] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:36,670 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:36,671 [Listener at localhost/43403] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43701
2020-12-03 07:24:36,671 [Listener at localhost/43403] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:36,672 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@750ed637{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:36,673 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@673e76b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:36,677 [Listener at localhost/43403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d66e944{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:36,677 [Listener at localhost/43403] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@469a7575{HTTP/1.1,[http/1.1]}{localhost:43701}
2020-12-03 07:24:36,677 [Listener at localhost/43403] INFO  server.Server (Server.java:doStart(419)) - Started @64445ms
2020-12-03 07:24:36,677 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:36,678 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:36,679 [Listener at localhost/43403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:36,680 [Listener at localhost/43403] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:36,680 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:36,680 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:36,681 [Listener at localhost/43403] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:36
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:36,682 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:36,683 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:36,683 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:36,686 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:36,686 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:36,687 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:36,688 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:36,690 [Listener at localhost/43403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:36,690 [Listener at localhost/43403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:36,690 [Listener at localhost/43403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:36,691 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:36,692 [Listener at localhost/43403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:36,692 [Listener at localhost/43403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:36,692 [Listener at localhost/43403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:36,693 [Listener at localhost/43403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:36,811 [Listener at localhost/43403] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:36,964 [Listener at localhost/43403] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:36,966 [Listener at localhost/43403] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:24:36,966 [Listener at localhost/43403] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:24:36,966 [Listener at localhost/43403] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:24:36,969 [Listener at localhost/43403] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:24:36,970 [Listener at localhost/43403] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:36,970 [Listener at localhost/43403] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:24:36,970 [Listener at localhost/43403] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@412c5e8b expecting start txid #32
2020-12-03 07:24:36,970 [Listener at localhost/43403] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:36,970 [Listener at localhost/43403] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:24:36,972 [Listener at localhost/43403] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1694.0, total edits 30.0, total load time 1.0 ms
2020-12-03 07:24:36,972 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:36,973 [Listener at localhost/43403] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:24:37,219 [Listener at localhost/43403] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:37,219 [Listener at localhost/43403] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 526 msecs
2020-12-03 07:24:37,220 [Listener at localhost/43403] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:37,220 [Listener at localhost/43403] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:37,221 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:37,223 [Listener at localhost/46144] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46144 to access this namenode/service.
2020-12-03 07:24:37,223 [Listener at localhost/46144] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:37,223 [Listener at localhost/46144] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:24:37,223 [Listener at localhost/46144] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:24:37,240 [Listener at localhost/46144] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:37,242 [Listener at localhost/46144] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:37,244 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:37,244 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:37,245 [Listener at localhost/46144] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46144
2020-12-03 07:24:37,246 [Listener at localhost/46144] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:37,246 [Listener at localhost/46144] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:37,247 [Listener at localhost/46144] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:37,249 [CacheReplicationMonitor(183338859)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:37,252 [IPC Server handler 0 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,253 [Listener at localhost/46144] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:37,769 [Listener at localhost/46144] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:37,770 [Listener at localhost/46144] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:37,770 [Listener at localhost/46144] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:37,771 [Listener at localhost/46144] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:37,772 [Listener at localhost/46144] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:37,773 [Listener at localhost/46144] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:24:37,773 [Listener at localhost/46144] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:37,773 [Listener at localhost/46144] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:37,773 [Listener at localhost/46144] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:37,774 [Listener at localhost/46144] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45606
2020-12-03 07:24:37,774 [Listener at localhost/46144] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:37,774 [Listener at localhost/46144] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:37,775 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:37,776 [Listener at localhost/46144] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:37,777 [Listener at localhost/46144] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:37,777 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:37,778 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:37,778 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:37,778 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:37,778 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:37,779 [Listener at localhost/46144] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42900
2020-12-03 07:24:37,779 [Listener at localhost/46144] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:37,780 [Listener at localhost/46144] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d705112{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:37,781 [Listener at localhost/46144] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19489b27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:37,784 [Listener at localhost/46144] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12d2ddde{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:37,784 [Listener at localhost/46144] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62b475e2{HTTP/1.1,[http/1.1]}{localhost:42900}
2020-12-03 07:24:37,785 [Listener at localhost/46144] INFO  server.Server (Server.java:doStart(419)) - Started @65553ms
2020-12-03 07:24:37,795 [Listener at localhost/46144] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45666
2020-12-03 07:24:37,795 [Listener at localhost/46144] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:37,795 [Listener at localhost/46144] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:37,795 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c61eda5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:37,795 [Listener at localhost/46144] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:37,796 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:37,798 [Listener at localhost/40401] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40401
2020-12-03 07:24:37,800 [Listener at localhost/40401] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:37,801 [Listener at localhost/40401] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:37,801 [Thread-2459] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46144 starting to offer service
2020-12-03 07:24:37,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:37,802 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:37,805 [Thread-2459] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46144
2020-12-03 07:24:37,806 [Thread-2459] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:37,806 [IPC Server handler 2 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,807 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,807 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,867 [Thread-2459] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:37,908 [IPC Server handler 3 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,908 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,909 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,939 [Thread-2459] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 7346@8562ead12aec
2020-12-03 07:24:37,980 [Thread-2459] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:37,980 [Thread-2459] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:37,980 [Thread-2459] INFO  common.Storage (Storage.java:doRecover(809)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726 from previous rollback
2020-12-03 07:24:38,010 [IPC Server handler 4 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,010 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:38,010 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:38,110 [Thread-2459] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:38,110 [Thread-2459] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:38,110 [Thread-2459] INFO  common.Storage (Storage.java:doRecover(809)) - Recovering storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726 from previous rollback
2020-12-03 07:24:38,112 [IPC Server handler 5 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,112 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:38,112 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:38,144 [Thread-2459] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=170866041;bpid=BP-552726158-172.17.0.2-1606980213726;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=170866041;c=1606980213726;bpid=BP-552726158-172.17.0.2-1606980213726;dnuuid=8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:38,145 [Thread-2459] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8a4f6dca-cdf4-4ace-a69f-f9ff3d4a0c33
2020-12-03 07:24:38,145 [Thread-2459] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:24:38,146 [Thread-2459] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-37d9d38b-52bd-41bc-b1c4-4d2555eb0962
2020-12-03 07:24:38,146 [Thread-2459] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:24:38,146 [Thread-2459] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:38,147 [Thread-2459] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:38,147 [Thread-2459] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:24:38,147 [Thread-2459] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:38,148 [Thread-2459] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:24:38,148 [Thread-2459] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:38,149 [Thread-2471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:38,149 [Thread-2472] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:38,150 [Thread-2472] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:38,150 [Thread-2471] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current: 41200
2020-12-03 07:24:38,156 [Thread-2472] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 7ms
2020-12-03 07:24:38,157 [Thread-2471] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-552726158-172.17.0.2-1606980213726 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 9ms
2020-12-03 07:24:38,157 [Thread-2459] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-552726158-172.17.0.2-1606980213726: 9ms
2020-12-03 07:24:38,158 [Thread-2473] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:24:38,158 [Thread-2474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:24:38,159 [Thread-2474] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:38,159 [Thread-2473] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726/current/replicas
2020-12-03 07:24:38,159 [Thread-2474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 2ms
2020-12-03 07:24:38,159 [Thread-2473] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-552726158-172.17.0.2-1606980213726 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 2ms
2020-12-03 07:24:38,160 [Thread-2459] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-552726158-172.17.0.2-1606980213726: 2ms
2020-12-03 07:24:38,160 [Thread-2459] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:28 AM with interval of 21600000ms
2020-12-03 07:24:38,160 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46144 beginning handshake with NN
2020-12-03 07:24:38,162 [IPC Server handler 6 on default port 46144] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45606, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45666, infoSecurePort=0, ipcPort=40401, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726) storage 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:38,162 [IPC Server handler 6 on default port 46144] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45606
2020-12-03 07:24:38,162 [IPC Server handler 6 on default port 46144] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c680083-5d1f-4061-9fe5-a63a727e294b (127.0.0.1:45606).
2020-12-03 07:24:38,164 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46144 successfully registered with NN
2020-12-03 07:24:38,164 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46144 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:38,166 [IPC Server handler 7 on default port 46144] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a4f6dca-cdf4-4ace-a69f-f9ff3d4a0c33 for DN 127.0.0.1:45606
2020-12-03 07:24:38,167 [IPC Server handler 7 on default port 46144] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-37d9d38b-52bd-41bc-b1c4-4d2555eb0962 for DN 127.0.0.1:45606
2020-12-03 07:24:38,169 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x893cb4ad1da791b8: Processing first storage report for DS-37d9d38b-52bd-41bc-b1c4-4d2555eb0962 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:38,169 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x893cb4ad1da791b8: from storage DS-37d9d38b-52bd-41bc-b1c4-4d2555eb0962 node DatanodeRegistration(127.0.0.1:45606, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45666, infoSecurePort=0, ipcPort=40401, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,169 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x893cb4ad1da791b8: Processing first storage report for DS-8a4f6dca-cdf4-4ace-a69f-f9ff3d4a0c33 from datanode 8c680083-5d1f-4061-9fe5-a63a727e294b
2020-12-03 07:24:38,169 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:38,170 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:38,170 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:38,170 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:24:38,170 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:38,172 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x893cb4ad1da791b8: from storage DS-8a4f6dca-cdf4-4ace-a69f-f9ff3d4a0c33 node DatanodeRegistration(127.0.0.1:45606, datanodeUuid=8c680083-5d1f-4061-9fe5-a63a727e294b, infoPort=45666, infoSecurePort=0, ipcPort=40401, storageInfo=lv=-57;cid=testClusterID;nsid=170866041;c=1606980213726), blocks: 16, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:38,176 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:24:38,177 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x893cb4ad1da791b8,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:24:38,213 [IPC Server handler 9 on default port 46144] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,214 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:38,215 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:38,215 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:38,215 [Listener at localhost/40401] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,215 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@322e49ee] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,230 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12d2ddde{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,230 [Listener at localhost/40401] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62b475e2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,231 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19489b27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,231 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d705112{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,232 [Listener at localhost/40401] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40401
2020-12-03 07:24:38,232 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,232 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,233 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b) service to localhost/127.0.0.1:46144
2020-12-03 07:24:38,233 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-552726158-172.17.0.2-1606980213726 (Datanode Uuid 8c680083-5d1f-4061-9fe5-a63a727e294b)
2020-12-03 07:24:38,233 [BP-552726158-172.17.0.2-1606980213726 heartbeating to localhost/127.0.0.1:46144] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-552726158-172.17.0.2-1606980213726
2020-12-03 07:24:38,233 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,234 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-552726158-172.17.0.2-1606980213726] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,234 [Listener at localhost/40401] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,234 [Listener at localhost/40401] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,235 [Listener at localhost/40401] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,235 [Listener at localhost/40401] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,237 [Listener at localhost/40401] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,237 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:38,237 [Listener at localhost/40401] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:38,237 [Listener at localhost/40401] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:24:38,237 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4293e066] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:38,237 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3ad8717d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:38,238 [Listener at localhost/40401] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:24:38,238 [Listener at localhost/40401] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:38,239 [Listener at localhost/40401] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:24:38,239 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:38,239 [CacheReplicationMonitor(183338859)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:38,239 [Listener at localhost/40401] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46144
2020-12-03 07:24:38,240 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,240 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,240 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:38,240 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:38,247 [Listener at localhost/40401] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:38,248 [Listener at localhost/40401] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:38,248 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d66e944{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:38,249 [Listener at localhost/40401] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@469a7575{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,250 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@673e76b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,250 [Listener at localhost/40401] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@750ed637{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,250 [Listener at localhost/40401] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:38,251 [Listener at localhost/40401] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:38,251 [Listener at localhost/40401] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:38,260 [Listener at localhost/40401] INFO  hdfs.TestDFSStorageStateRecovery (TestDFSStorageStateRecovery.java:tearDown(454)) - Shutting down MiniDFSCluster
2020-12-03 07:24:38,260 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:38,260 [Listener at localhost/40401] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
msx-rc 0
