2020-12-03 07:23:02,751 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:23:02,960 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:03,095 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:03,096 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:23:03,237 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:03,253 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,268 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1245ms
2020-12-03 07:23:03,407 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:03,448 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:03,449 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,460 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:03,462 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:03,463 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:03,463 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:03,495 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46138
2020-12-03 07:23:03,497 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:03,548 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:03,550 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:03,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@740cae06{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:03,598 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:46138}
2020-12-03 07:23:03,598 [main] INFO  server.Server (Server.java:doStart(419)) - Started @1575ms
2020-12-03 07:23:03,600 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:03,629 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,640 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,927 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:03,930 [Listener at localhost/41696] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:03,933 [Listener at localhost/41696] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:03,934 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,936 [Listener at localhost/41696] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:03,937 [Listener at localhost/41696] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:03,937 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:03,941 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:03,942 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:03,942 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:03,943 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:03,944 [Listener at localhost/41696] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34150
2020-12-03 07:23:03,945 [Listener at localhost/41696] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:03,948 [Listener at localhost/41696] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:03,949 [Listener at localhost/41696] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:03,960 [Listener at localhost/41696] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4397ad89{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:03,961 [Listener at localhost/41696] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51495ec{HTTP/1.1,[http/1.1]}{localhost:34150}
2020-12-03 07:23:03,962 [Listener at localhost/41696] INFO  server.Server (Server.java:doStart(419)) - Started @1938ms
2020-12-03 07:23:03,963 [Listener at localhost/41696] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:03,963 [Listener at localhost/41696] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:03,964 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:03,968 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:03,970 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,014 [Listener at localhost/42666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:04,018 [Listener at localhost/42666] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:04,018 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,020 [Listener at localhost/42666] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:04,021 [Listener at localhost/42666] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:04,021 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,024 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:04,025 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:04,030 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:04,030 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:04,032 [Listener at localhost/42666] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43755
2020-12-03 07:23:04,032 [Listener at localhost/42666] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:04,034 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43b9fd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:04,035 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8e50104{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:04,044 [Listener at localhost/42666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3688eb5b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:04,045 [Listener at localhost/42666] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@69f1a286{HTTP/1.1,[http/1.1]}{localhost:43755}
2020-12-03 07:23:04,046 [Listener at localhost/42666] INFO  server.Server (Server.java:doStart(419)) - Started @2023ms
2020-12-03 07:23:04,047 [Listener at localhost/42666] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:04,047 [Listener at localhost/42666] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:04,048 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:04,052 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:04,052 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:04,721 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 98: Call -> /127.0.0.1:46026: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,721 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 96: Call -> /127.0.0.1:41696: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,721 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 97: Call -> /127.0.0.1:42666: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,773 [IPC Server handler 0 on default port 46026] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/waitactive
2020-12-03 07:23:04,773 [IPC Server handler 0 on default port 41696] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/waitactive
2020-12-03 07:23:04,773 [IPC Server handler 0 on default port 42666] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/waitactive
2020-12-03 07:23:04,794 [IPC Server handler 0 on default port 42666] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/waitactive does not exist
2020-12-03 07:23:04,794 [IPC Server handler 0 on default port 41696] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/waitactive does not exist
2020-12-03 07:23:04,794 [IPC Server handler 0 on default port 46026] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/waitactive does not exist
2020-12-03 07:23:04,799 [IPC Server handler 0 on default port 42666] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:04,799 [IPC Server handler 0 on default port 41696] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:04,799 [IPC Server handler 0 on default port 46026] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:04,832 [IPC Server handler 0 on default port 42666] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:04,832 [IPC Server handler 0 on default port 42666] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:04,833 [IPC Server handler 0 on default port 41696] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:04,833 [IPC Server handler 0 on default port 41696] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:04,836 [IPC Server handler 0 on default port 46026] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:04,837 [IPC Server handler 0 on default port 46026] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:04,843 [Logger channel (from single-thread executor) to /127.0.0.1:46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 260ms
2020-12-03 07:23:04,843 [Logger channel (from single-thread executor) to /127.0.0.1:42666] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 260ms
2020-12-03 07:23:04,843 [Logger channel (from single-thread executor) to /127.0.0.1:41696] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 260ms
2020-12-03 07:23:04,844 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 98: Response <- /127.0.0.1:46026: isFormatted {isFormatted: false}
2020-12-03 07:23:04,844 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 97: Response <- /127.0.0.1:42666: isFormatted {isFormatted: false}
2020-12-03 07:23:04,844 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 96: Response <- /127.0.0.1:41696: isFormatted {isFormatted: false}
2020-12-03 07:23:04,855 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 107: Call -> /127.0.0.1:42666: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,855 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 108: Call -> /127.0.0.1:46026: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,856 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 106: Call -> /127.0.0.1:41696: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,859 [Logger channel (from single-thread executor) to /127.0.0.1:46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 4ms
2020-12-03 07:23:04,859 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 108: Response <- /127.0.0.1:46026: isFormatted {isFormatted: false}
2020-12-03 07:23:04,862 [Logger channel (from single-thread executor) to /127.0.0.1:41696] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 6ms
2020-12-03 07:23:04,862 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 106: Response <- /127.0.0.1:41696: isFormatted {isFormatted: false}
2020-12-03 07:23:04,862 [Logger channel (from single-thread executor) to /127.0.0.1:42666] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 7ms
2020-12-03 07:23:04,863 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 107: Response <- /127.0.0.1:42666: isFormatted {isFormatted: false}
2020-12-03 07:23:04,871 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 114: Call -> /127.0.0.1:41696: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,872 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 116: Call -> /127.0.0.1:46026: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,872 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 115: Call -> /127.0.0.1:42666: isFormatted {jid { identifier: "waitactive" }}
2020-12-03 07:23:04,876 [Logger channel (from single-thread executor) to /127.0.0.1:41696] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 6ms
2020-12-03 07:23:04,878 [Logger channel (from single-thread executor) to /127.0.0.1:42666] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 7ms
2020-12-03 07:23:04,878 [Logger channel (from single-thread executor) to /127.0.0.1:46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: isFormatted took 7ms
2020-12-03 07:23:04,878 [Logger channel (from single-thread executor) to /127.0.0.1:42666] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 115: Response <- /127.0.0.1:42666: isFormatted {isFormatted: false}
2020-12-03 07:23:04,878 [Logger channel (from single-thread executor) to /127.0.0.1:46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 116: Response <- /127.0.0.1:46026: isFormatted {isFormatted: false}
2020-12-03 07:23:04,880 [Logger channel (from single-thread executor) to /127.0.0.1:41696] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 114: Response <- /127.0.0.1:41696: isFormatted {isFormatted: false}
2020-12-03 07:23:05,118 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41696: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:05,136 [IPC Server handler 0 on default port 41696] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal
2020-12-03 07:23:05,136 [IPC Server handler 0 on default port 41696] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal does not exist
2020-12-03 07:23:05,137 [IPC Server handler 0 on default port 41696] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,143 [IPC Server handler 0 on default port 41696] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:05,143 [IPC Server handler 0 on default port 41696] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:05,143 [IPC Server handler 0 on default port 41696] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:05,144 [IPC Server handler 0 on default port 41696] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal does not exist. Creating ...
2020-12-03 07:23:05,211 [IPC Server handler 0 on default port 41696] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,212 [IPC Server handler 0 on default port 41696] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal; location= null with nsid: 12345
2020-12-03 07:23:05,254 [IPC Server handler 0 on default port 41696] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal/current/paxos
2020-12-03 07:23:05,295 [IPC Server handler 0 on default port 41696] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,296 [IPC Server handler 0 on default port 41696] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,299 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 185ms
2020-12-03 07:23:05,300 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:41696: format {}
2020-12-03 07:23:05,303 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42666: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:05,306 [IPC Server handler 0 on default port 42666] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal
2020-12-03 07:23:05,306 [IPC Server handler 0 on default port 42666] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal does not exist
2020-12-03 07:23:05,307 [IPC Server handler 0 on default port 42666] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,320 [IPC Server handler 0 on default port 42666] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:05,320 [IPC Server handler 0 on default port 42666] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:05,320 [IPC Server handler 0 on default port 42666] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:05,320 [IPC Server handler 0 on default port 42666] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal does not exist. Creating ...
2020-12-03 07:23:05,355 [IPC Server handler 0 on default port 42666] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,355 [IPC Server handler 0 on default port 42666] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal; location= null with nsid: 12345
2020-12-03 07:23:05,389 [IPC Server handler 0 on default port 42666] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/paxos
2020-12-03 07:23:05,422 [IPC Server handler 0 on default port 42666] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,423 [IPC Server handler 0 on default port 42666] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,424 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 121ms
2020-12-03 07:23:05,424 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:42666: format {}
2020-12-03 07:23:05,428 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46026: format {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } force: false}
2020-12-03 07:23:05,430 [IPC Server handler 0 on default port 46026] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal
2020-12-03 07:23:05,431 [IPC Server handler 0 on default port 46026] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal does not exist
2020-12-03 07:23:05,431 [IPC Server handler 0 on default port 46026] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,437 [IPC Server handler 0 on default port 46026] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:05,437 [IPC Server handler 0 on default port 46026] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:05,437 [IPC Server handler 0 on default port 46026] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : test-journal with namespace info: lv=-65;cid=mycluster;nsid=12345;c=0;bpid=my-bp and force: false
2020-12-03 07:23:05,438 [IPC Server handler 0 on default port 46026] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal does not exist. Creating ...
2020-12-03 07:23:05,481 [IPC Server handler 0 on default port 46026] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,481 [IPC Server handler 0 on default port 46026] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal; location= null with nsid: 12345
2020-12-03 07:23:05,532 [IPC Server handler 0 on default port 46026] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/paxos
2020-12-03 07:23:05,616 [IPC Server handler 0 on default port 46026] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/in_use.lock acquired by nodename 6106@5cae4f03508f
2020-12-03 07:23:05,617 [IPC Server handler 0 on default port 46026] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:23:05,618 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: format took 191ms
2020-12-03 07:23:05,618 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46026: format {}
2020-12-03 07:23:05,620 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:05,625 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41696: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:05,631 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 7ms
2020-12-03 07:23:05,633 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:41696: getJournalState {lastPromisedEpoch: 0 httpPort: 46138 fromURL: "http://localhost:46138"}
2020-12-03 07:23:05,634 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42666: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:05,636 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 2ms
2020-12-03 07:23:05,637 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:42666: getJournalState {lastPromisedEpoch: 0 httpPort: 34150 fromURL: "http://localhost:34150"}
2020-12-03 07:23:05,640 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46026: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:05,643 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 3ms
2020-12-03 07:23:05,644 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46026: getJournalState {lastPromisedEpoch: 0 httpPort: 43755 fromURL: "http://localhost:43755"}
2020-12-03 07:23:05,651 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:05,654 [IPC Server handler 2 on default port 41696] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:05,703 [IPC Server handler 2 on default port 41696] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal)
2020-12-03 07:23:05,705 [IPC Server handler 2 on default port 41696] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal)
2020-12-03 07:23:05,706 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 56ms
2020-12-03 07:23:05,707 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41696: newEpoch {}
2020-12-03 07:23:05,709 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:05,716 [IPC Server handler 2 on default port 42666] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:05,777 [IPC Server handler 2 on default port 42666] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal)
2020-12-03 07:23:05,777 [IPC Server handler 2 on default port 42666] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal)
2020-12-03 07:23:05,778 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 71ms
2020-12-03 07:23:05,779 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: newEpoch {}
2020-12-03 07:23:05,780 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 1}
2020-12-03 07:23:05,783 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:05,836 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal)
2020-12-03 07:23:05,839 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal)
2020-12-03 07:23:05,841 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 61ms
2020-12-03 07:23:05,841 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: newEpoch {}
2020-12-03 07:23:05,843 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:23:05,848 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:05,851 [IPC Server handler 3 on default port 41696] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:06,114 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 267ms
2020-12-03 07:23:06,115 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41696: startLogSegment {}
2020-12-03 07:23:06,116 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:06,129 [IPC Server handler 0 on default port 42666] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:06,232 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 116ms
2020-12-03 07:23:06,233 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: startLogSegment {}
2020-12-03 07:23:06,234 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: startLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 0 } txid: 1 layoutVersion: -65}
2020-12-03 07:23:06,239 [IPC Server handler 0 on default port 46026] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 1 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:06,325 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: startLogSegment took 91ms
2020-12-03 07:23:06,325 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: startLogSegment {}
2020-12-03 07:23:06,430 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:06,438 [IPC Server handler 1 on default port 41696] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:06,451 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 22ms
2020-12-03 07:23:06,453 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:41696: journal {}
2020-12-03 07:23:06,455 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:06,460 [IPC Server handler 1 on default port 42666] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:06,491 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 36ms
2020-12-03 07:23:06,494 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: journal {}
2020-12-03 07:23:06,496 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 1 } firstTxnId: 1 numTxns: 3 records: "\003\000\000\000D\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\000\000\004tx 1\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000^\257\246\240\003\000\000\000D\000\000\000\000\000\000\000\002\000\000\000\000\000\000\000\000\000\004tx 2\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\276d\313\001\003\000\000\000D\000\000\000\000\000\000\000\003\000\000\000\000\000\000\000\000\000\004tx 3\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\341\335\357\236" segmentTxnId: 1}
2020-12-03 07:23:06,503 [IPC Server handler 1 on default port 46026] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:23:06,507 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 11ms
2020-12-03 07:23:06,508 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: journal {}
2020-12-03 07:23:06,513 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:06,585 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 72ms
2020-12-03 07:23:06,586 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: journal {}
2020-12-03 07:23:06,588 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 3 } firstTxnId: 4 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\004\000\000\000\000\000\000\000\000\000\004tx 4\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\244\203\026\002" segmentTxnId: 1}
2020-12-03 07:23:06,615 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 28ms
2020-12-03 07:23:06,616 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: journal {}
2020-12-03 07:23:06,619 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 2 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:06,629 [IPC Server handler 2 on default port 41696] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 41696, call Call#26 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.journal from 127.0.0.1:41786
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:06,634 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: journal {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
}
2020-12-03 07:23:06,636 [Listener at localhost/46026] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(400)) - Remote journal 127.0.0.1:41696 failed to write txns 5-5. Will try to write to this JN again after the next log roll.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 5 expecting nextTxId=4 ; journal id: test-journal
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:191)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:397)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:390)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:57)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at org.apache.hadoop.hdfs.qjournal.client.DirectExecutorService.execute(DirectExecutorService.java:152)
	at com.google.common.util.concurrent.MoreExecutors$ListeningDecorator.execute(MoreExecutors.java:525)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134)
	at com.google.common.util.concurrent.AbstractListeningExecutorService.submit(AbstractListeningExecutorService.java:66)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.sendEdits(IPCLoggerChannel.java:390)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$e6f78e59.CGLIB$sendEdits$8(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$e6f78e59$$FastClassByMockitoWithCGLIB$$c324ba3d.invoke(<generated>)
	at org.mockito.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:216)
	at org.mockito.internal.creation.AbstractMockitoMethodProxy.invokeSuper(AbstractMockitoMethodProxy.java:10)
	at org.mockito.internal.invocation.realmethod.CGLIBProxyRealMethod.invoke(CGLIBProxyRealMethod.java:22)
	at org.mockito.internal.invocation.realmethod.FilteredCGLIBProxyRealMethod.invoke(FilteredCGLIBProxyRealMethod.java:27)
	at org.mockito.internal.invocation.Invocation.callRealMethod(Invocation.java:211)
	at org.mockito.internal.stubbing.answers.CallsRealMethods.answer(CallsRealMethods.java:36)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:99)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager$1$1$$EnhancerByMockitoWithCGLIB$$e6f78e59.sendEdits(<generated>)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:110)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:115)
	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:109)
	at org.apache.hadoop.hdfs.qjournal.QJMTestUtil.writeTxns(QJMTestUtil.java:112)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setupLoggers345(TestQuorumJournalManager.java:579)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.doOutOfSyncTest(TestQuorumJournalManager.java:437)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testChangeWritersLogsOutOfSync1(TestQuorumJournalManager.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:06,639 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: journal {reqInfo { journalId { identifier: "test-journal" } epoch: 1 ipcSerialNumber: 3 committedTxId: 4 } firstTxnId: 5 numTxns: 1 records: "\003\000\000\000D\000\000\000\000\000\000\000\005\000\000\000\000\000\000\000\000\000\004tx 5\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\btestuser\ttestgroup\001\377\000\000\000\000\000\373:2\235" segmentTxnId: 1}
2020-12-03 07:23:06,691 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: journal took 52ms
2020-12-03 07:23:06,692 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: journal {}
2020-12-03 07:23:06,697 [Listener at localhost/46026] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41696
2020-12-03 07:23:06,699 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:06,702 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:06,708 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@740cae06{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:06,715 [Listener at localhost/46026] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@449a4f23{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:06,717 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4de4b452{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:06,717 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15aab8c6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:06,719 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/waitactive; location= null
2020-12-03 07:23:06,720 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal; location= null
2020-12-03 07:23:06,733 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:06,736 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:41696: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:06,739 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: getJournalState {java.net.ConnectException: Call From 5cae4f03508f/172.17.0.4 to localhost:41696 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:06,742 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:42666: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:06,746 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 4ms
2020-12-03 07:23:06,746 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:42666: getJournalState {lastPromisedEpoch: 1 httpPort: 34150 fromURL: "http://localhost:34150"}
2020-12-03 07:23:06,749 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> /127.0.0.1:46026: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:06,754 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: getJournalState took 5ms
2020-12-03 07:23:06,754 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- /127.0.0.1:46026: getJournalState {lastPromisedEpoch: 1 httpPort: 43755 fromURL: "http://localhost:43755"}
2020-12-03 07:23:06,757 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:06,759 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: newEpoch {java.net.ConnectException: Call From 5cae4f03508f/172.17.0.4 to localhost:41696 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:06,760 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:06,772 [IPC Server handler 3 on default port 42666] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:06,812 [IPC Server handler 3 on default port 42666] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal)
2020-12-03 07:23:06,851 [IPC Server handler 3 on default port 42666] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:06,852 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 92ms
2020-12-03 07:23:06,853 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:06,854 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: newEpoch {jid { identifier: "test-journal" } nsInfo { buildVersion: "Unknown" unused: 0 blockPoolID: "my-bp" storageInfo { layoutVersion: 4294967231 namespceID: 12345 clusterID: "mycluster" cTime: 0 } softwareVersion: "3.2.1" capabilities: 1 } epoch: 2}
2020-12-03 07:23:06,858 [IPC Server handler 0 on default port 46026] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: test-journal
2020-12-03 07:23:06,896 [IPC Server handler 0 on default port 46026] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal)
2020-12-03 07:23:06,902 [IPC Server handler 0 on default port 46026] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) ; journal id: test-journal
2020-12-03 07:23:06,905 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: newEpoch took 51ms
2020-12-03 07:23:06,906 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: newEpoch {lastSegmentTxId: 1}
2020-12-03 07:23:06,908 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:23:06,911 [Listener at localhost/46026] DEBUG client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(482)) - newEpoch(2) responses:
127.0.0.1:42666: lastSegmentTxId: 1
127.0.0.1:46026: lastSegmentTxId: 1
2020-12-03 07:23:06,911 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 1
2020-12-03 07:23:06,913 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: getJournalState {jid { identifier: "test-journal" }}
2020-12-03 07:23:06,915 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: getJournalState {java.net.ConnectException: Call From 5cae4f03508f/172.17.0.4 to localhost:41696 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:06,919 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:06,947 [IPC Server handler 0 on default port 42666] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:06,948 [IPC Server handler 0 on default port 42666] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3 ; journal id: test-journal
2020-12-03 07:23:06,951 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 33ms
2020-12-03 07:23:06,952 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: prepareRecovery {segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3}
2020-12-03 07:23:06,953 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: prepareRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } segmentTxId: 1}
2020-12-03 07:23:06,964 [IPC Server handler 1 on default port 46026] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:06,964 [IPC Server handler 1 on default port 46026] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4 ; journal id: test-journal
2020-12-03 07:23:06,965 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: prepareRecovery took 12ms
2020-12-03 07:23:06,965 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: prepareRecovery {segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4}
2020-12-03 07:23:06,967 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:42666: segmentState { startTxId: 1 endTxId: 4 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 3
127.0.0.1:46026: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 4
2020-12-03 07:23:06,976 [Listener at localhost/46026] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:46026=segmentState {
  startTxId: 1
  endTxId: 5
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 4

2020-12-03 07:23:06,984 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 0 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:43755/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:06,986 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: acceptRecovery {java.net.ConnectException: Call From 5cae4f03508f/172.17.0.4 to localhost:41696 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:06,987 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:43755/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:07,007 [IPC Server handler 1 on default port 42666] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000004,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 4 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:07,007 [IPC Server handler 1 on default port 42666] INFO  server.Journal (Journal.java:acceptRecovery(905)) - Synchronizing log startTxId: 1 endTxId: 5 isInProgress: true: old segment startTxId: 1 endTxId: 4 isInProgress: true is not the right length ; journal id: test-journal
2020-12-03 07:23:07,014 [IPC Server handler 1 on default port 42666] INFO  server.Journal (Journal.java:syncLog(995)) - Synchronizing log startTxId: 1 endTxId: 5 isInProgress: true from http://localhost:43755/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true
2020-12-03 07:23:07,198 [qtp286649365-86] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:07,317 [IPC Server handler 1 on default port 42666] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.03s. The file download took 0.03s at 36571.43 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001.epoch=2 took 0.00s.
2020-12-03 07:23:07,351 [IPC Server handler 1 on default port 42666] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:07,354 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 366ms
2020-12-03 07:23:07,355 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: acceptRecovery {}
2020-12-03 07:23:07,357 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: acceptRecovery {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } stateToAccept { startTxId: 1 endTxId: 5 isInProgress: true } fromURL: "http://localhost:43755/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-65%3A12345%3A0%3Amycluster&inProgressOk=true"}
2020-12-03 07:23:07,368 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001,first=0000000000000000001,last=0000000000000000005,inProgress=true,hasCorruptHeader=false) -> startTxId: 1 endTxId: 5 isInProgress: true ; journal id: test-journal
2020-12-03 07:23:07,368 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 5 isInProgress: true: already have up-to-date logs ; journal id: test-journal
2020-12-03 07:23:07,418 [IPC Server handler 2 on default port 46026] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 5 isInProgress: true } acceptedInEpoch: 2 ; journal id: test-journal
2020-12-03 07:23:07,420 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: acceptRecovery took 63ms
2020-12-03 07:23:07,420 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: acceptRecovery {}
2020-12-03 07:23:07,437 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:41696: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 1 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:07,439 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(239)) - 1: Exception <- localhost/127.0.0.1:41696: finalizeLogSegment {java.net.ConnectException: Call From 5cae4f03508f/172.17.0.4 to localhost:41696 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused}
2020-12-03 07:23:07,441 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:42666: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 2 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:07,458 [IPC Server handler 2 on default port 42666] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:07,465 [IPC Server handler 2 on default port 42666] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:23:07,493 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 51ms
2020-12-03 07:23:07,493 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:42666: finalizeLogSegment {}
2020-12-03 07:23:07,496 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(224)) - 1: Call -> localhost/127.0.0.1:46026: finalizeLogSegment {reqInfo { journalId { identifier: "test-journal" } epoch: 2 ipcSerialNumber: 2 } startTxId: 1 endTxId: 5}
2020-12-03 07:23:07,504 [IPC Server handler 3 on default port 46026] INFO  server.Journal (Journal.java:finalizeLogSegment(663)) - Validating log segment /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 about to be finalized ; journal id: test-journal
2020-12-03 07:23:07,509 [IPC Server handler 3 on default port 46026] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal/current/edits_0000000000000000001-0000000000000000005
2020-12-03 07:23:07,510 [Listener at localhost/46026] DEBUG ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:invoke(254)) - Call: finalizeLogSegment took 14ms
2020-12-03 07:23:07,511 [Listener at localhost/46026] TRACE ipc.ProtobufRpcEngine (ProtobufRpcEngine.java:getReturnMessage(292)) - 1: Response <- localhost/127.0.0.1:46026: finalizeLogSegment {}
2020-12-03 07:23:07,520 [Listener at localhost/46026] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41696
2020-12-03 07:23:07,520 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/waitactive; location= null
2020-12-03 07:23:07,520 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-0/test-journal; location= null
2020-12-03 07:23:07,521 [Listener at localhost/46026] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42666
2020-12-03 07:23:07,521 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:07,521 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:07,522 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4397ad89{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:07,527 [Listener at localhost/46026] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51495ec{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:07,528 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20435c40{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:07,528 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41294f8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:07,532 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/waitactive; location= null
2020-12-03 07:23:07,532 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-1/test-journal; location= null
2020-12-03 07:23:07,533 [Listener at localhost/46026] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JournalNode metrics system...
2020-12-03 07:23:07,535 [Listener at localhost/46026] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JournalNode metrics system stopped.
2020-12-03 07:23:07,535 [Listener at localhost/46026] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - JournalNode metrics system shutdown complete.
2020-12-03 07:23:07,535 [Listener at localhost/46026] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46026
2020-12-03 07:23:07,537 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:07,537 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:07,538 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3688eb5b{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:07,542 [Listener at localhost/46026] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@69f1a286{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:07,543 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8e50104{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:07,544 [Listener at localhost/46026] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43b9fd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:07,547 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/waitactive; location= null
2020-12-03 07:23:07,548 [Listener at localhost/46026] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RX7HkNkaPH/journalnode-2/test-journal; location= null
msx-rc 0
