2020-12-03 07:22:39,525 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,540 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,561 [main] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 19b93cb8e93f
2020-12-03 07:22:39,563 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,569 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,682 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /0.0.0.0:35030
2020-12-03 07:22:39,687 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,688 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,754 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,770 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2106ms
2020-12-03 07:22:39,911 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,918 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,919 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,935 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,938 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,941 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,973 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36083
2020-12-03 07:22:39,975 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:40,023 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b695b06{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:40,024 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f53b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:40,063 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@776a6d9b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:40,072 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1169afe1{HTTP/1.1,[http/1.1]}{localhost:36083}
2020-12-03 07:22:40,073 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2409ms
2020-12-03 07:22:40,547 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /0.0.0.0:43251
2020-12-03 07:22:40,554 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1046d517] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,567 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,567 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,605 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,627 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,662 [Listener at 0.0.0.0/36034] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /0.0.0.0:36034
2020-12-03 07:22:40,683 [Listener at 0.0.0.0/36034] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,696 [Listener at 0.0.0.0/36034] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,708 [Thread-13] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:5020 starting to offer service
2020-12-03 07:22:40,719 [Thread-13] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:22:40,767 [Thread-13] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/in_use.lock acquired by nodename 3903@19b93cb8e93f
2020-12-03 07:22:40,769 [Thread-13] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data is not formatted for namespace 1. Formatting...
2020-12-03 07:22:40,770 [Thread-13] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dca2f6b4-e009-4cd1-9c99-dd85ac0973e8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data 
2020-12-03 07:22:40,914 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-TEST
2020-12-03 07:22:40,915 [Thread-13] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST
2020-12-03 07:22:40,915 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data and block pool id BP-TEST is not formatted. Formatting ...
2020-12-03 07:22:40,915 [Thread-13] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-TEST directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current
2020-12-03 07:22:40,977 [Thread-13] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1;bpid=BP-TEST;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1;c=1;bpid=BP-TEST;dnuuid=null
2020-12-03 07:22:41,011 [Thread-13] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3818fc0a-7eff-4e6c-a128-851df3ae2fcb
2020-12-03 07:22:41,388 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dca2f6b4-e009-4cd1-9c99-dd85ac0973e8
2020-12-03 07:22:41,388 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, StorageType: DISK
2020-12-03 07:22:41,392 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:41,397 [Thread-13] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:41,418 [Thread-13] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:41,420 [Thread-13] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-TEST
2020-12-03 07:22:41,421 [Thread-18] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data...
2020-12-03 07:22:41,445 [Thread-18] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-TEST on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data: 24ms
2020-12-03 07:22:41,445 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-TEST: 26ms
2020-12-03 07:22:41,448 [Thread-20] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data...
2020-12-03 07:22:41,448 [Thread-20] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/replicas doesn't exist 
2020-12-03 07:22:41,451 [Thread-20] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data: 3ms
2020-12-03 07:22:41,451 [Thread-13] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-TEST: 4ms
2020-12-03 07:22:41,455 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-TEST on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
2020-12-03 07:22:41,457 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-dca2f6b4-e009-4cd1-9c99-dd85ac0973e8): finished scanning block pool BP-TEST
2020-12-03 07:22:41,480 [Thread-13] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:24 PM with interval of 21600000ms
2020-12-03 07:22:41,485 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-dca2f6b4-e009-4cd1-9c99-dd85ac0973e8): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:41,486 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb) service to localhost/127.0.0.1:5020 beginning handshake with NN
2020-12-03 07:22:41,487 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb) service to localhost/127.0.0.1:5020 successfully registered with NN
2020-12-03 07:22:41,487 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:5020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,490 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb) service to localhost/127.0.0.1:5020 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:41,490 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb) service to localhost/127.0.0.1:5020
2020-12-03 07:22:41,496 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x18a3cce5098deb40,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 0 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:41,656 [Thread-24] DEBUG datanode.TestBlockRecovery (TestBlockRecovery.java:testNotMatchedReplicaID(685)) - Running testNotMatchedReplicaID
2020-12-03 07:22:41,670 [Thread-24] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1000_2000, recoveryId=3001, replica=ReplicaBeingWritten, blk_1000_2000, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  bytesAcked=0
  bytesOnDisk=0
2020-12-03 07:22:41,671 [Thread-24] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1000_2000, recoveryId=3001, replica=ReplicaBeingWritten, blk_1000_2000, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  bytesAcked=0
  bytesOnDisk=0
2020-12-03 07:22:41,671 [Thread-24] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1000_2000 from RBW to RUR
2020-12-03 07:22:41,675 [Thread-24] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-TEST:blk_1000_2000 (length=3000), isTruncateRecovery=false, syncList=[block:blk_1000_2000[numBytes=3000,originalReplicaState=FINALIZED] node:0.0.0.0:35030]
2020-12-03 07:22:41,675 [Thread-24] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(293)) - BlockRecoveryWorker: block=BP-TEST:blk_1000_2000 (length=3000), bestState=FINALIZED, newBlock=BP-TEST:blk_1000_3000 (length=3000), participatingList=[block:blk_1000_2000[numBytes=3000,originalReplicaState=FINALIZED] node:0.0.0.0:35030]
2020-12-03 07:22:41,676 [Thread-24] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-TEST:blk_1000_2000[numBytes=3000,originalReplicaState=FINALIZED], recoveryId=3000, length=3000, replica=ReplicaUnderRecovery, blk_1000_2000, RUR
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  recoveryId=3001
  original=ReplicaBeingWritten, blk_1000_2000, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  bytesAcked=0
  bytesOnDisk=0
2020-12-03 07:22:41,677 [Thread-24] WARN  protocol.InterDatanodeProtocol (BlockRecoveryWorker.java:syncBlock(306)) - Failed to updateBlock (newblock=BP-TEST:blk_1000_3000, datanode=0.0.0.0:35030)
java.io.IOException: THIS IS NOT SUPPOSED TO HAPPEN: replica.getBytesOnDisk() != block.getNumBytes(), block=BP-TEST:blk_1000_2000[numBytes=3000,originalReplicaState=FINALIZED], replica=ReplicaUnderRecovery, blk_1000_2000, RUR
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  recoveryId=3001
  original=ReplicaBeingWritten, blk_1000_2000, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST/current/rbw/blk_1000
  bytesAcked=0
  bytesOnDisk=0
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.updateReplicaUnderRecovery(FsDatasetImpl.java:2685)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.updateReplicaUnderRecovery(DataNode.java:2941)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$BlockRecord.updateReplicaUnderRecovery(BlockRecoveryWorker.java:88)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$BlockRecord.access$700(BlockRecoveryWorker.java:71)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.syncBlock(BlockRecoveryWorker.java:302)
	at org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNotMatchedReplicaID(TestBlockRecovery.java:698)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:41,691 [Listener at 0.0.0.0/36034] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:41,692 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data, DS-dca2f6b4-e009-4cd1-9c99-dd85ac0973e8) exiting.
2020-12-03 07:22:41,723 [Listener at 0.0.0.0/36034] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@776a6d9b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:41,729 [Listener at 0.0.0.0/36034] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1169afe1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:41,729 [Listener at 0.0.0.0/36034] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f53b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:41,730 [Listener at 0.0.0.0/36034] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b695b06{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:41,733 [Listener at 0.0.0.0/36034] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36034
2020-12-03 07:22:41,733 [BP-TEST heartbeating to localhost/127.0.0.1:5020] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:41,734 [BP-TEST heartbeating to localhost/127.0.0.1:5020] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb) service to localhost/127.0.0.1:5020
2020-12-03 07:22:41,734 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-TEST (Datanode Uuid 3818fc0a-7eff-4e6c-a128-851df3ae2fcb)
2020-12-03 07:22:41,734 [BP-TEST heartbeating to localhost/127.0.0.1:5020] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-TEST
2020-12-03 07:22:41,742 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/current/BP-TEST] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:41,743 [Listener at 0.0.0.0/36034] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:41,743 [Listener at 0.0.0.0/36034] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:41,743 [Listener at 0.0.0.0/36034] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:41,743 [Listener at 0.0.0.0/36034] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:41,748 [Listener at 0.0.0.0/36034] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
msx-rc 0
